{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErickJLA/Co-Met/blob/main/Co_Met_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TKxhknlidcLn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title üìä IMPORT LIBRARIES & AUTHENTICATE\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 1: ENVIRONMENT SETUP\n",
        "# Purpose: Import required libraries and authenticate Google Sheets access\n",
        "# Dependencies: None\n",
        "# Outputs: Authentication status, library versions, system info\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from scipy.stats import norm, chi2\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import sys\n",
        "import warnings\n",
        "from scipy.special import gamma\n",
        "\n",
        "# Suppress unnecessary warnings for cleaner output\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# --- Configuration Constants ---\n",
        "REQUIRED_COLUMNS = {\n",
        "    'effect_data': ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc'],\n",
        "    'metadata': ['id']\n",
        "}\n",
        "\n",
        "SUPPORTED_EFFECT_SIZES = {\n",
        "    'lnRR': 'Log Response Ratio',\n",
        "    'hedges_g': \"Hedges' g (corrected SMD)\",\n",
        "    'cohen_d': \"Cohen's d (uncorrected SMD)\",\n",
        "    'log_OR': 'Log Odds Ratio'\n",
        "}\n",
        "\n",
        "# --- Authentication ---\n",
        "print(\"=\" * 70)\n",
        "print(\"META-ANALYSIS PIPELINE - INITIALIZATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Execution Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    auth_status = \"‚úì SUCCESS\"\n",
        "    auth_details = \"Google Sheets API access granted\"\n",
        "except Exception as e:\n",
        "    auth_status = \"‚úó FAILED\"\n",
        "    auth_details = str(e)\n",
        "    print(f\"\\n‚ùå AUTHENTICATION ERROR: {e}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"  1. Ensure you're running in Google Colab\")\n",
        "    print(\"  2. Check your Google account permissions\")\n",
        "    print(\"  3. Try re-running the cell\")\n",
        "    raise Exception(\"Stopping execution due to authentication failure.\")\n",
        "\n",
        "# --- Library Version Check ---\n",
        "print(\"\\nüì¶ LIBRARY VERSIONS:\")\n",
        "print(f\"  ‚Ä¢ NumPy:      {np.__version__}\")\n",
        "print(f\"  ‚Ä¢ Pandas:     {pd.__version__}\")\n",
        "print(f\"  ‚Ä¢ gspread:    {gspread.__version__}\")\n",
        "print(f\"  ‚Ä¢ Matplotlib: {plt.matplotlib.__version__}\")\n",
        "\n",
        "# --- Configuration Summary ---\n",
        "print(\"\\n‚öôÔ∏è  CONFIGURATION:\")\n",
        "print(f\"  ‚Ä¢ Required effect data columns: {', '.join(REQUIRED_COLUMNS['effect_data'])}\")\n",
        "print(f\"  ‚Ä¢ Required metadata columns:    {', '.join(REQUIRED_COLUMNS['metadata'])}\")\n",
        "print(f\"  ‚Ä¢ Supported effect sizes:       {len(SUPPORTED_EFFECT_SIZES)}\")\n",
        "for key, name in SUPPORTED_EFFECT_SIZES.items():\n",
        "    print(f\"      - {key}: {name}\")\n",
        "\n",
        "# --- Status Summary ---\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"INITIALIZATION STATUS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Authentication:  {auth_status}\")\n",
        "print(f\"Details:         {auth_details}\")\n",
        "print(f\"Ready:           {'YES ‚úì' if auth_status == '‚úì SUCCESS' else 'NO ‚úó'}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Store initialization metadata for later reference\n",
        "INIT_METADATA = {\n",
        "    'timestamp': datetime.datetime.now(),\n",
        "    'auth_status': auth_status,\n",
        "    'numpy_version': np.__version__,\n",
        "    'pandas_version': pd.__version__,\n",
        "    'supported_effects': list(SUPPORTED_EFFECT_SIZES.keys())\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Setup complete. Proceed to next cell to load data.\\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# UTILITY FUNCTIONS - Extracted from original cells for reusability\n",
        "# =============================================================================\n",
        "\n",
        "# --- STATISTICAL FUNCTIONS ---\n",
        "\n",
        "def calculate_tau_squared_DL(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    DerSimonian-Laird estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Simple, fast\n",
        "    - Non-iterative\n",
        "    - Always converges\n",
        "\n",
        "    Disadvantages:\n",
        "    - Can underestimate tau¬≤ in small samples\n",
        "    - Negative values truncated to 0\n",
        "    - Less efficient than ML methods\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Fixed-effects weights\n",
        "        w = 1 / df[var_col]\n",
        "        sum_w = w.sum()\n",
        "\n",
        "        if sum_w <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        # Fixed-effects pooled estimate\n",
        "        pooled_effect = (w * df[effect_col]).sum() / sum_w\n",
        "\n",
        "        # Q statistic\n",
        "        Q = (w * (df[effect_col] - pooled_effect)**2).sum()\n",
        "        df_Q = k - 1\n",
        "\n",
        "        # C constant\n",
        "        sum_w_sq = (w**2).sum()\n",
        "        C = sum_w - (sum_w_sq / sum_w)\n",
        "\n",
        "        # Tau-squared\n",
        "        if C > 0 and Q > df_Q:\n",
        "            tau_sq = (Q - df_Q) / C\n",
        "        else:\n",
        "            tau_sq = 0.0\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in DL estimator: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "\n",
        "def calculate_tau_squared(df, effect_col, var_col, method='REML', **kwargs):\n",
        "    \"\"\"\n",
        "    Unified function to calculate tau-squared using specified method\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    method : str\n",
        "        Estimation method: 'DL', 'REML', 'ML', 'PM', 'SJ'\n",
        "        Default: 'REML' (recommended)\n",
        "    **kwargs : dict\n",
        "        Additional arguments passed to estimator\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    dict : additional information (method used, convergence, etc.)\n",
        "    \"\"\"\n",
        "    method = method.upper()\n",
        "\n",
        "    estimators = {\n",
        "        'DL': calculate_tau_squared_DL,\n",
        "        'REML': calculate_tau_squared_REML,\n",
        "        'ML': calculate_tau_squared_ML,\n",
        "        'PM': calculate_tau_squared_PM,\n",
        "        'SJ': calculate_tau_squared_SJ\n",
        "    }\n",
        "\n",
        "    if method not in estimators:\n",
        "        warnings.warn(f\"Unknown method '{method}', using REML\")\n",
        "        method = 'REML'\n",
        "\n",
        "    try:\n",
        "        tau_sq = estimators[method](df, effect_col, var_col, **kwargs)\n",
        "\n",
        "        info = {\n",
        "            'method': method,\n",
        "            'tau_squared': tau_sq,\n",
        "            'tau': np.sqrt(tau_sq),\n",
        "            'success': True\n",
        "        }\n",
        "\n",
        "        return tau_sq, info\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error with {method}, falling back to DL: {e}\")\n",
        "        tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        info = {\n",
        "            'method': 'DL',\n",
        "            'tau_squared': tau_sq,\n",
        "            'tau': np.sqrt(tau_sq),\n",
        "            'success': False,\n",
        "            'fallback': True,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "        return tau_sq, info\n",
        "\n",
        "\n",
        "\n",
        "def calculate_tau_squared_dl(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Calculate Tau-squared. Uses Global Advanced Estimator (Cell 4.5) if available,\n",
        "    otherwise falls back to DerSimonian-Laird (DL).\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2: return 0.0\n",
        "\n",
        "    # Try using the advanced REML estimator from Cell 4.5 first\n",
        "    if 'calculate_tau_squared' in globals():\n",
        "        tau_method = 'REML' # Prefer REML for consistency\n",
        "        try:\n",
        "            tau_sq, info = calculate_tau_squared(df, effect_col, var_col, method=tau_method)\n",
        "            if info.get('success', True):\n",
        "                return tau_sq\n",
        "        except Exception:\n",
        "            pass # Fall back to DL if REML fails (common in small cumulative steps)\n",
        "\n",
        "    # Classic DL Method (Fallback)\n",
        "    try:\n",
        "        w_fixed = 1 / df[var_col]\n",
        "        sum_w = w_fixed.sum()\n",
        "        if sum_w <= 0: return 0.0\n",
        "        pooled_effect = (w_fixed * df[effect_col]).sum() / sum_w\n",
        "        Qt = (w_fixed * (df[effect_col] - pooled_effect)**2).sum()\n",
        "        df_Q = k - 1\n",
        "        sum_w_sq = (w_fixed**2).sum()\n",
        "        C = sum_w - (sum_w_sq / sum_w)\n",
        "        if C > 0 and Qt > df_Q:\n",
        "            tau_squared = (Qt - df_Q) / C\n",
        "        else:\n",
        "            tau_squared = 0.0\n",
        "        return max(0.0, tau_squared)\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "def calculate_re_pooled(df, tau_squared, effect_col, var_col, alpha=0.05):\n",
        "    \"\"\"Calculate Random-Effects pooled estimate with CI\"\"\"\n",
        "    k = len(df)\n",
        "    if k < 1: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "    try:\n",
        "        w_re = 1 / (df[var_col] + tau_squared)\n",
        "        sum_w_re = w_re.sum()\n",
        "        if sum_w_re <= 0: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "        pooled_effect = (w_re * df[effect_col]).sum() / sum_w_re\n",
        "        pooled_var = 1 / sum_w_re\n",
        "        pooled_se = np.sqrt(pooled_var)\n",
        "\n",
        "        z_crit = norm.ppf(1 - alpha / 2)\n",
        "        ci_lower = pooled_effect - z_crit * pooled_se\n",
        "        ci_upper = pooled_effect + z_crit * pooled_se\n",
        "\n",
        "        # Calculate I-squared\n",
        "        w_fixed = 1 / df[var_col]\n",
        "        sum_w_fixed = w_fixed.sum()\n",
        "        pooled_effect_fe = (w_fixed * df[effect_col]).sum() / sum_w_fixed\n",
        "        Q = (w_fixed * (df[effect_col] - pooled_effect_fe)**2).sum()\n",
        "        df_Q = k - 1\n",
        "        I_sq = max(0, ((Q - df_Q) / Q) * 100) if Q > 0 else 0\n",
        "\n",
        "        return pooled_effect, pooled_se, ci_lower, ci_upper, I_sq\n",
        "    except Exception:\n",
        "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "\n",
        "def calculate_knapp_hartung_ci(yi, vi, tau_sq, pooled_effect, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Calculate Knapp-Hartung adjusted confidence interval\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    yi = np.array(yi)\n",
        "    vi = np.array(vi)\n",
        "\n",
        "    # Random-effects weights\n",
        "    wi_star = 1 / (vi + tau_sq)\n",
        "    sum_wi_star = np.sum(wi_star)\n",
        "\n",
        "    # Degrees of freedom\n",
        "    k = len(yi)\n",
        "    df = k - 1\n",
        "\n",
        "    if df <= 0:\n",
        "        # Can't use K-H with k=1\n",
        "        return None\n",
        "\n",
        "    # Calculate Q statistic (residual heterogeneity)\n",
        "    Q = np.sum(wi_star * (yi - pooled_effect)**2)\n",
        "\n",
        "    # Standard random-effects variance\n",
        "    var_standard = 1 / sum_wi_star\n",
        "\n",
        "    # Knapp-Hartung adjusted variance\n",
        "    # SE_KH¬≤ = (Q / (k-1)) √ó (1 / Œ£w*)\n",
        "    var_KH = (Q / df) * var_standard\n",
        "    se_KH = np.sqrt(var_KH)\n",
        "\n",
        "    # t-distribution critical value\n",
        "    t_crit = t.ppf(1 - alpha/2, df)\n",
        "\n",
        "    # Confidence interval\n",
        "    ci_lower = pooled_effect - t_crit * se_KH\n",
        "    ci_upper = pooled_effect + t_crit * se_KH\n",
        "\n",
        "    # Test statistic and p-value\n",
        "    t_stat = pooled_effect / se_KH\n",
        "    p_value = 2 * (1 - t.cdf(abs(t_stat), df))\n",
        "\n",
        "    return {\n",
        "        'se_KH': se_KH,\n",
        "        'var_KH': var_KH,\n",
        "        'ci_lower': ci_lower,\n",
        "        'ci_upper': ci_upper,\n",
        "        't_stat': t_stat,\n",
        "        't_crit': t_crit,\n",
        "        'df': df,\n",
        "        'p_value': p_value,\n",
        "        'Q': Q\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def compare_tau_estimators(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Compare all tau-squared estimators on the same dataset\n",
        "\n",
        "    Useful for sensitivity analysis and understanding which method\n",
        "    is most appropriate for your data.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame : Comparison of all methods\n",
        "    \"\"\"\n",
        "    methods = ['DL', 'REML', 'ML', 'PM', 'SJ']\n",
        "    results = []\n",
        "\n",
        "    for method in methods:\n",
        "        try:\n",
        "            tau_sq, info = calculate_tau_squared(df, effect_col, var_col, method=method)\n",
        "\n",
        "            results.append({\n",
        "                'Method': method,\n",
        "                'œÑ¬≤': tau_sq,\n",
        "                'œÑ': np.sqrt(tau_sq),\n",
        "                'Success': info['success']\n",
        "            })\n",
        "        except Exception as e:\n",
        "            results.append({\n",
        "                'Method': method,\n",
        "                'œÑ¬≤': np.nan,\n",
        "                'œÑ': np.nan,\n",
        "                'Success': False\n",
        "            })\n",
        "\n",
        "    comparison_df = pd.DataFrame(results)\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "\n",
        "\n",
        "def calculate_hedges_g_python(df):\n",
        "    \"\"\"Calculate Hedges' g using EXACT Gamma correction.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Pooled SD\n",
        "    n_e, n_c = df['ne'], df['nc']\n",
        "    sd_e, sd_c = df['sde'], df['sdc']\n",
        "    mean_e, mean_c = df['xe'], df['xc']\n",
        "\n",
        "    df_d = n_e + n_c - 2\n",
        "    sd_pooled = np.sqrt(((n_e - 1)*sd_e**2 + (n_c - 1)*sd_c**2) / df_d)\n",
        "\n",
        "    # Cohen's d\n",
        "    d = (mean_e - mean_c) / sd_pooled\n",
        "\n",
        "    # Hedges' correction (J) - EXACT FORMULA to match metafor\n",
        "    # J = exp(lgamma(m/2) - log(sqrt(m/2)) - lgamma((m-1)/2))\n",
        "    m = df_d\n",
        "    J = gamma(m / 2) / (np.sqrt(m / 2) * gamma((m - 1) / 2))\n",
        "\n",
        "    g = d * J\n",
        "\n",
        "    # Variance of g (Exact)\n",
        "    vg = ((n_e + n_c) / (n_e * n_c) + (g**2 / (2 * (n_e + n_c)))) * J**2\n",
        "\n",
        "    return g, vg\n",
        "\n",
        "\n",
        "# --- THREE-LEVEL MODEL FUNCTIONS ---\n",
        "\n",
        "def _get_three_level_estimates(params, y_all, v_all, N_total, M_studies):\n",
        "    \"\"\"\n",
        "    Core function to calculate estimates using Sherman-Morrison inversion.\n",
        "    Matches R's metafor implementation logic.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tau_sq, sigma_sq = params\n",
        "        # Safety check for negatives\n",
        "        if tau_sq < 0: tau_sq = 1e-10\n",
        "        if sigma_sq < 0: sigma_sq = 1e-10\n",
        "\n",
        "        sum_log_det_Vi = 0.0\n",
        "        sum_S = 0.0       # 1' * V_i‚Åª¬π * 1\n",
        "        sum_Sy = 0.0      # 1' * V_i‚Åª¬π * y_i\n",
        "        sum_ySy = 0.0     # y_i' * V_i‚Åª¬π * y_i\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = y_all[i]\n",
        "            v_i = v_all[i]\n",
        "\n",
        "            # V_i = A + œÑ¬≤J, where A = diag(v_ij + œÉ¬≤)\n",
        "            A_diag = v_i + sigma_sq\n",
        "            inv_A_diag = 1.0 / A_diag\n",
        "\n",
        "            # Components for Sherman-Morrison\n",
        "            sum_inv_A = np.sum(inv_A_diag)\n",
        "            denom = 1 + tau_sq * sum_inv_A\n",
        "\n",
        "            # Log Determinant\n",
        "            log_det_A = np.sum(np.log(A_diag))\n",
        "            log_det_Vi = log_det_A + np.log(denom)\n",
        "            sum_log_det_Vi += log_det_Vi\n",
        "\n",
        "            # Inversion: V‚Åª¬πy\n",
        "            inv_A_y = inv_A_diag * y_i\n",
        "            sum_inv_A_y = np.sum(inv_A_y)\n",
        "            w_y = inv_A_y - (tau_sq * inv_A_diag * sum_inv_A_y) / denom\n",
        "\n",
        "            # Inversion: V‚Åª¬π1\n",
        "            w_1 = inv_A_diag - (tau_sq * inv_A_diag * sum_inv_A) / denom\n",
        "\n",
        "            # Summing up\n",
        "            sum_S += np.sum(w_1)\n",
        "            sum_Sy += np.sum(w_y) # Note: sum(w_y) is effectively 1' * V^-1 * y\n",
        "            sum_ySy += np.dot(y_i, w_y)\n",
        "\n",
        "        if sum_S <= 1e-10:\n",
        "            return {'log_lik_reml': np.inf}\n",
        "\n",
        "        # Pooled Effect (Œº)\n",
        "        mu_hat = sum_Sy / sum_S\n",
        "        var_mu = 1.0 / sum_S\n",
        "        se_mu = np.sqrt(var_mu)\n",
        "\n",
        "        # Residual Sum of Squares\n",
        "        # (y - Xb)' V^-1 (y - Xb) = y'V^-1y - 2b X'V^-1y + b' X'V^-1X b\n",
        "        residual_ss = sum_ySy - 2.0 * mu_hat * sum_Sy + mu_hat**2 * sum_S\n",
        "\n",
        "        # REML Log-Likelihood\n",
        "        log_lik_reml = -0.5 * (sum_log_det_Vi + np.log(sum_S) + residual_ss)\n",
        "\n",
        "        # ML Log-Likelihood (for AIC/BIC)\n",
        "        log_lik_ml = -0.5 * (N_total * np.log(2.0 * np.pi) + sum_log_det_Vi + residual_ss)\n",
        "\n",
        "        return {\n",
        "            'mu': mu_hat, 'se_mu': se_mu, 'var_mu': var_mu,\n",
        "            'log_lik_reml': log_lik_reml, 'log_lik_ml': log_lik_ml,\n",
        "            'tau_sq': tau_sq, 'sigma_sq': sigma_sq\n",
        "        }\n",
        "\n",
        "    except (FloatingPointError, ValueError, np.linalg.LinAlgError):\n",
        "        return {'log_lik_reml': np.inf}\n",
        "\n",
        "\n",
        "def _negative_log_likelihood_reml(params, y_all, v_all, N_total, M_studies):\n",
        "    \"\"\"Wrapper for optimizer.\"\"\"\n",
        "    estimates = _get_three_level_estimates(params, y_all, v_all, N_total, M_studies)\n",
        "    return -estimates['log_lik_reml']\n",
        "\n",
        "\n",
        "def _get_three_level_estimates_loo(params, y_all, v_all, N_total, M_studies):\n",
        "    \"\"\"Core calculation for 3-level estimates (Silent Version).\"\"\"\n",
        "    try:\n",
        "        tau_sq, sigma_sq = params\n",
        "        if tau_sq < 0: tau_sq = 1e-10\n",
        "        if sigma_sq < 0: sigma_sq = 1e-10\n",
        "\n",
        "        sum_log_det_Vi = 0.0\n",
        "        sum_S = 0.0\n",
        "        sum_Sy = 0.0\n",
        "        sum_ySy = 0.0\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = y_all[i]\n",
        "            v_i = v_all[i]\n",
        "\n",
        "            A_diag = v_i + sigma_sq\n",
        "            inv_A_diag = 1.0 / A_diag\n",
        "            sum_inv_A = np.sum(inv_A_diag)\n",
        "            denom = 1 + tau_sq * sum_inv_A\n",
        "\n",
        "            log_det_A = np.sum(np.log(A_diag))\n",
        "            sum_log_det_Vi += log_det_A + np.log(denom)\n",
        "\n",
        "            inv_A_y = inv_A_diag * y_i\n",
        "            sum_inv_A_y = np.sum(inv_A_y)\n",
        "\n",
        "            w_y = inv_A_y - (tau_sq * inv_A_diag * sum_inv_A_y) / denom\n",
        "            w_1 = inv_A_diag - (tau_sq * inv_A_diag * sum_inv_A) / denom\n",
        "\n",
        "            sum_S += np.sum(w_1)\n",
        "            sum_Sy += np.sum(w_y)\n",
        "            sum_ySy += np.dot(y_i, w_y)\n",
        "\n",
        "        if sum_S <= 1e-10: return {'log_lik_reml': np.inf}\n",
        "\n",
        "        mu_hat = sum_Sy / sum_S\n",
        "        var_mu = 1.0 / sum_S\n",
        "        se_mu = np.sqrt(var_mu)\n",
        "        residual_ss = sum_ySy - 2.0 * mu_hat * sum_Sy + mu_hat**2 * sum_S\n",
        "\n",
        "        log_lik_reml = -0.5 * (sum_log_det_Vi + np.log(sum_S) + residual_ss)\n",
        "        if np.isnan(log_lik_reml): return {'log_lik_reml': np.inf}\n",
        "\n",
        "        return {'mu': mu_hat, 'se_mu': se_mu, 'log_lik_reml': log_lik_reml,\n",
        "                'tau_sq': tau_sq, 'sigma_sq': sigma_sq}\n",
        "\n",
        "    except (FloatingPointError, ValueError, np.linalg.LinAlgError):\n",
        "        return {'log_lik_reml': np.inf}\n",
        "\n",
        "\n",
        "def _neg_log_lik_reml_loo(params, y_all, v_all, N_total, M_studies):\n",
        "    est = _get_three_level_estimates_loo(params, y_all, v_all, N_total, M_studies)\n",
        "    return -est['log_lik_reml']\n",
        "\n",
        "\n",
        "def _negative_log_likelihood_reml_loo(params, y_all, v_all, N_total, M_studies):\n",
        "    \"\"\"Wrapper for optimizer.\"\"\"\n",
        "    estimates = _get_three_level_estimates_loo(params, y_all, v_all, N_total, M_studies)\n",
        "    return -estimates['log_lik_reml']\n",
        "\n",
        "\n",
        "def _neg_log_lik_reml(params, y, v, groups):\n",
        "    tau2, sigma2 = params\n",
        "    # Bounds are handled by optimizer, but safe-guard here for math domain errors\n",
        "    if tau2 < 0: tau2 = 1e-10\n",
        "    if sigma2 < 0: sigma2 = 1e-10\n",
        "\n",
        "    unique_groups = np.unique(groups)\n",
        "\n",
        "    log_lik = 0\n",
        "    sum_S = 0\n",
        "    sum_Sy = 0\n",
        "    sum_ySy = 0\n",
        "\n",
        "    for grp in unique_groups:\n",
        "        mask = (groups == grp)\n",
        "        y_i = y[mask]\n",
        "        v_i = v[mask]\n",
        "\n",
        "        # V_i = D + sigma2*I + tau2*J\n",
        "        # A = D + sigma2*I (Diagonal matrix)\n",
        "        A_diag = v_i + sigma2\n",
        "        inv_A_diag = 1.0 / A_diag\n",
        "\n",
        "        # Woodbury/Sherman-Morrison components\n",
        "        # (A + uv^T)^-1 = A^-1 - (A^-1 u v^T A^-1) / (1 + v^T A^-1 u)\n",
        "        # Here u = v = tau * 1\n",
        "\n",
        "        sum_inv_A = np.sum(inv_A_diag)\n",
        "        denom = 1 + tau2 * sum_inv_A\n",
        "\n",
        "        # Log Determinant of V_i\n",
        "        # det(A + uv^T) = det(A) * (1 + v^T A^-1 u)\n",
        "        log_det_A = np.sum(np.log(A_diag))\n",
        "        log_det_Vi = log_det_A + np.log(denom)\n",
        "        log_lik += log_det_Vi\n",
        "\n",
        "        # Inversion Operations\n",
        "        inv_A_y = inv_A_diag * y_i\n",
        "        # w_y = V_i^-1 * y_i\n",
        "        w_y = inv_A_y - (tau2 * inv_A_diag * np.sum(inv_A_y)) / denom\n",
        "\n",
        "        # w_1 = V_i^-1 * 1\n",
        "        w_1 = inv_A_diag - (tau2 * inv_A_diag * sum_inv_A) / denom\n",
        "\n",
        "        sum_S += np.sum(w_1)      # 1^T V^-1 1\n",
        "        sum_Sy += np.sum(w_y)     # 1^T V^-1 y\n",
        "        sum_ySy += np.dot(y_i, w_y) # y^T V^-1 y\n",
        "\n",
        "    # REML Profile Likelihood Calculation\n",
        "    mu = sum_Sy / sum_S\n",
        "    resid = sum_ySy - 2*mu*sum_Sy + mu**2 * sum_S\n",
        "\n",
        "    # Full REML Log Likelihood\n",
        "    total_log_lik = -0.5 * (log_lik + np.log(sum_S) + resid)\n",
        "\n",
        "    return -total_log_lik\n",
        "\n",
        "\n",
        "def run_python_3level(yi, vi, study_ids):\n",
        "    # 1. First Pass: L-BFGS-B (Global search)\n",
        "    best_res = None\n",
        "    best_fun = np.inf\n",
        "\n",
        "    # Multiple start points to avoid local minima\n",
        "    start_points = [[0.01, 0.01], [0.5, 0.1], [0.1, 0.5], [0.001, 0.001]]\n",
        "\n",
        "    for start in start_points:\n",
        "        res = minimize(_neg_log_lik_reml, x0=start, args=(yi, vi, study_ids),\n",
        "                       bounds=[(1e-8, None), (1e-8, None)],\n",
        "                       method='L-BFGS-B',\n",
        "                       options={'ftol': 1e-12, 'gtol': 1e-12}) # High precision\n",
        "        if res.success and res.fun < best_fun:\n",
        "            best_fun = res.fun\n",
        "            best_res = res\n",
        "\n",
        "    if not best_res: return None\n",
        "\n",
        "    # 2. Second Pass: Nelder-Mead (Polishing)\n",
        "    # Sometimes gradient methods get stuck slightly off in flat valleys\n",
        "    final_res = minimize(_neg_log_lik_reml, x0=best_res.x, args=(yi, vi, study_ids),\n",
        "                         method='Nelder-Mead',\n",
        "                         bounds=[(1e-8, None), (1e-8, None)],\n",
        "                         options={'xatol': 1e-12, 'fatol': 1e-12})\n",
        "\n",
        "    tau2, sigma2 = final_res.x\n",
        "    return tau2, sigma2\n",
        "\n",
        "\n",
        "# --- REGRESSION FUNCTIONS ---\n",
        "\n",
        "def _get_three_level_regression_estimates_v2(params, y_all, v_all, X_all, N_total, M_studies, p_params):\n",
        "    \"\"\"Calculates betas (slopes) and likelihood for a given tau2/sigma2.\"\"\"\n",
        "    try:\n",
        "        tau_sq, sigma_sq = params\n",
        "        if tau_sq < 0: tau_sq = 1e-10\n",
        "        if sigma_sq < 0: sigma_sq = 1e-10\n",
        "\n",
        "        sum_log_det_Vi = 0.0\n",
        "        sum_XWX = np.zeros((p_params, p_params))\n",
        "        sum_XWy = np.zeros(p_params)\n",
        "        sum_yWy = 0.0\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = y_all[i]\n",
        "            v_i = v_all[i]\n",
        "            X_i = X_all[i] # Predictors for study i\n",
        "\n",
        "            # V_i = D + sigma2*I + tau2*J\n",
        "            # Inversion using Sherman-Morrison\n",
        "            A_diag = v_i + sigma_sq\n",
        "            inv_A_diag = 1.0 / A_diag\n",
        "\n",
        "            sum_inv_A = np.sum(inv_A_diag)\n",
        "            denom = 1 + tau_sq * sum_inv_A\n",
        "\n",
        "            # Log Determinant\n",
        "            log_det_A = np.sum(np.log(A_diag))\n",
        "            sum_log_det_Vi += log_det_A + np.log(denom)\n",
        "\n",
        "            # Fast Matrix Multiplication for X' V^-1 X and X' V^-1 y\n",
        "            # V^-1 = A^-1 - (tau2 * A^-1 J A^-1) / denom\n",
        "\n",
        "            # 1. Precompute A^-1 * X and A^-1 * y\n",
        "            # (Since A is diagonal, this is just element-wise mult)\n",
        "            inv_A_X = inv_A_diag[:, None] * X_i\n",
        "            inv_A_y = inv_A_diag * y_i\n",
        "\n",
        "            # 2. Compute column sums (equivalent to 1' A^-1 X)\n",
        "            sum_inv_A_X = np.sum(inv_A_X, axis=0)\n",
        "            sum_inv_A_y = np.sum(inv_A_y)\n",
        "\n",
        "            # 3. Compute W * X and W * y\n",
        "            # W X = inv_A_X - (tau2 * inv_A_1 * sum_inv_A_X) / denom\n",
        "            # Note: inv_A_1 is just inv_A_diag\n",
        "\n",
        "            # We don't need full W_X, just X' W X\n",
        "            # X' W X = X' (A^-1 X) - X' (correction)\n",
        "            #        = (X' A^-1 X) - (tau2 / denom) * (X' A^-1 1) * (1' A^-1 X)\n",
        "\n",
        "            xt_invA_x = X_i.T @ inv_A_X\n",
        "            correction_term = (tau_sq / denom) * np.outer(sum_inv_A_X, sum_inv_A_X)\n",
        "            sum_XWX += xt_invA_x - correction_term\n",
        "\n",
        "            # Same for y\n",
        "            xt_invA_y = X_i.T @ inv_A_y\n",
        "            correction_y = (tau_sq / denom) * sum_inv_A_X * sum_inv_A_y\n",
        "            sum_XWy += xt_invA_y - correction_y\n",
        "\n",
        "            # Same for y'Wy\n",
        "            yt_invA_y = np.dot(y_i, inv_A_y)\n",
        "            correction_yy = (tau_sq / denom) * (sum_inv_A_y**2)\n",
        "            sum_yWy += yt_invA_y - correction_yy\n",
        "\n",
        "        # Solve for Betas: (X' W X) beta = X' W y\n",
        "        # Add small jitter for stability if singular\n",
        "        try:\n",
        "            betas = np.linalg.solve(sum_XWX, sum_XWy)\n",
        "            var_betas = np.linalg.inv(sum_XWX)\n",
        "        except np.linalg.LinAlgError:\n",
        "            return {'log_lik_reml': np.inf}\n",
        "\n",
        "        # Calculate Residual Sum of Squares for REML\n",
        "        # RSS = y'Wy - b' X'Wy\n",
        "        residual_ss = sum_yWy - np.dot(betas, sum_XWy)\n",
        "\n",
        "        # REML Log Likelihood\n",
        "        # L = -0.5 * [ log|V| + log|X'V^-1X| + (y-Xb)'V^-1(y-Xb) ]\n",
        "        # We use sign, logdet = np.linalg.slogdet(sum_XWX) for stability\n",
        "        sign, log_det_XWX = np.linalg.slogdet(sum_XWX)\n",
        "\n",
        "        log_lik_reml = -0.5 * (sum_log_det_Vi + log_det_XWX + residual_ss)\n",
        "\n",
        "        return {\n",
        "            'betas': betas,\n",
        "            'se_betas': np.sqrt(np.diag(var_betas)),\n",
        "            'var_betas_robust': var_betas, # Saving standard var-cov for now\n",
        "            'log_lik_reml': log_lik_reml,\n",
        "            'tau_sq': tau_sq,\n",
        "            'sigma_sq': sigma_sq\n",
        "        }\n",
        "\n",
        "    except (FloatingPointError, ValueError, np.linalg.LinAlgError):\n",
        "        return {'log_lik_reml': np.inf}\n",
        "\n",
        "\n",
        "def _neg_log_lik_reml_reg(params, y_all, v_all, X_all, N_total, M_studies, p_params):\n",
        "    est = _get_three_level_regression_estimates_v2(params, y_all, v_all, X_all, N_total, M_studies, p_params)\n",
        "    return -est['log_lik_reml']\n",
        "\n",
        "\n",
        "def _negative_log_likelihood_reml_reg_v2(params, y_all, v_all, X_all, N_total, M_studies, p_params):\n",
        "    \"\"\"Wrapper for optimizer.\"\"\"\n",
        "    estimates = _get_three_level_regression_estimates_v2(params, y_all, v_all, X_all, N_total, M_studies, p_params)\n",
        "    return -estimates['log_lik_reml']\n",
        "\n",
        "\n",
        "# --- PLOTTING FUNCTIONS ---\n",
        "\n",
        "def plot_trim_fill(data, effect_col, se_col, results, es_label):\n",
        "    \"\"\"Simple Forest Plot for Trim/Fill (Preview)\"\"\"\n",
        "    k0 = results['k0']\n",
        "    orig_est = results['pooled_original']\n",
        "    fill_est = results['pooled_filled']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Plot Original Studies\n",
        "    ax.scatter(data[effect_col], data[se_col], c='black', alpha=0.6, label='Observed Studies')\n",
        "\n",
        "    # Plot Filled Studies\n",
        "    if k0 > 0:\n",
        "        se_filled = np.sqrt(results['vi_filled'])\n",
        "        ax.scatter(results['yi_filled'], se_filled, c='white', edgecolors='red', marker='o', label='Imputed Studies')\n",
        "\n",
        "    # Plot Center Lines\n",
        "    ax.axvline(orig_est, color='black', linestyle='--', label=f'Original: {orig_est:.3f}')\n",
        "    ax.axvline(fill_est, color='red', linestyle='-', label=f'Adjusted: {fill_est:.3f}')\n",
        "\n",
        "    y_max = data[se_col].max() * 1.1\n",
        "    ax.set_ylim(y_max, 0)\n",
        "    ax.set_xlabel(es_label)\n",
        "    ax.set_ylabel(\"Standard Error\")\n",
        "    ax.set_title(f\"Trim-and-Fill Funnel Plot (Missing: {results['side']})\")\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "# functions\n",
        "\n",
        "#@title üîß ADVANCED HETEROGENEITY ESTIMATORS\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 4.5: ADVANCED TAU-SQUARED ESTIMATORS\n",
        "# Purpose: Provides multiple methods for estimating between-study variance\n",
        "# Dependencies: None (standalone functions)\n",
        "# Used by: Cell 6 (Overall Analysis), Cell 8 (Subgroup Analysis)\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize_scalar, minimize\n",
        "from scipy.stats import chi2\n",
        "import warnings\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"HETEROGENEITY ESTIMATORS MODULE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# --- 1. DERSIMONIAN-LAIRD (Your current method) ---\n",
        "\n",
        "# --- 2. RESTRICTED MAXIMUM LIKELIHOOD (REML) ---\n",
        "\n",
        "def calculate_tau_squared_REML(df, effect_col, var_col, max_iter=100, tol=1e-8):\n",
        "    \"\"\"\n",
        "    REML estimator for tau-squared (RECOMMENDED - Gold Standard)\n",
        "\n",
        "    Advantages:\n",
        "    - Unbiased for tau¬≤\n",
        "    - Accounts for uncertainty in estimating mu\n",
        "    - Better performance in small samples\n",
        "    - Generally preferred in literature\n",
        "\n",
        "    Disadvantages:\n",
        "    - Iterative (slightly slower)\n",
        "    - Can fail to converge in extreme cases\n",
        "\n",
        "    Reference:\n",
        "    Viechtbauer, W. (2005). Bias and efficiency of meta-analytic variance\n",
        "    estimators in the random-effects model. Journal of Educational and\n",
        "    Behavioral Statistics, 30(3), 261-293.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    max_iter : int\n",
        "        Maximum iterations for optimization\n",
        "    tol : float\n",
        "        Convergence tolerance\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Extract data\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        # Remove any infinite or negative variances\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            warnings.warn(f\"Removed {(~valid_mask).sum()} observations with invalid variances\")\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 2:\n",
        "            return 0.0\n",
        "\n",
        "        # REML objective function (negative log-likelihood)\n",
        "        def reml_objective(tau2):\n",
        "            # Ensure tau2 is non-negative\n",
        "            tau2 = max(0, tau2)\n",
        "\n",
        "            # Weights\n",
        "            wi = 1 / (vi + tau2)\n",
        "            sum_wi = wi.sum()\n",
        "\n",
        "            if sum_wi <= 0:\n",
        "                return 1e10\n",
        "\n",
        "            # Pooled estimate\n",
        "            mu = (wi * yi).sum() / sum_wi\n",
        "\n",
        "            # Q statistic\n",
        "            Q = (wi * (yi - mu)**2).sum()\n",
        "\n",
        "            # REML log-likelihood (negative for minimization)\n",
        "            # L = -0.5 * [sum(log(vi + tau2)) + log(sum(wi)) + Q]\n",
        "            log_lik = -0.5 * (\n",
        "                np.sum(np.log(vi + tau2)) +\n",
        "                np.log(sum_wi) +\n",
        "                Q\n",
        "            )\n",
        "\n",
        "            return -log_lik  # Return negative for minimization\n",
        "\n",
        "        # Get reasonable bounds for tau2\n",
        "        # Lower bound: 0\n",
        "        # Upper bound: Use variance of effect sizes as upper limit\n",
        "        var_yi = np.var(yi, ddof=1) if k > 2 else 1.0\n",
        "        upper_bound = max(10 * var_yi, 100)\n",
        "\n",
        "        # Optimize\n",
        "        result = minimize_scalar(\n",
        "            reml_objective,\n",
        "            bounds=(0, upper_bound),\n",
        "            method='bounded',\n",
        "            options={'maxiter': max_iter, 'xatol': tol}\n",
        "        )\n",
        "\n",
        "        if result.success:\n",
        "            tau_sq = result.x\n",
        "        else:\n",
        "            warnings.warn(\"REML optimization did not converge, using DL fallback\")\n",
        "            tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in REML estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 3. MAXIMUM LIKELIHOOD (ML) ---\n",
        "\n",
        "def calculate_tau_squared_ML(df, effect_col, var_col, max_iter=100, tol=1e-8):\n",
        "    \"\"\"\n",
        "    Maximum Likelihood estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Efficient asymptotically\n",
        "    - Produces valid estimates\n",
        "\n",
        "    Disadvantages:\n",
        "    - Biased downward (underestimates tau¬≤)\n",
        "    - Less preferred than REML\n",
        "    - REML is generally recommended instead\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    max_iter : int\n",
        "        Maximum iterations\n",
        "    tol : float\n",
        "        Convergence tolerance\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 2:\n",
        "            return 0.0\n",
        "\n",
        "        # ML objective function\n",
        "        def ml_objective(tau2):\n",
        "            tau2 = max(0, tau2)\n",
        "            wi = 1 / (vi + tau2)\n",
        "            sum_wi = wi.sum()\n",
        "\n",
        "            if sum_wi <= 0:\n",
        "                return 1e10\n",
        "\n",
        "            mu = (wi * yi).sum() / sum_wi\n",
        "            Q = (wi * (yi - mu)**2).sum()\n",
        "\n",
        "            # ML log-likelihood (without the constant term)\n",
        "            log_lik = -0.5 * (np.sum(np.log(vi + tau2)) + Q)\n",
        "\n",
        "            return -log_lik\n",
        "\n",
        "        var_yi = np.var(yi, ddof=1) if k > 2 else 1.0\n",
        "        upper_bound = max(10 * var_yi, 100)\n",
        "\n",
        "        result = minimize_scalar(\n",
        "            ml_objective,\n",
        "            bounds=(0, upper_bound),\n",
        "            method='bounded',\n",
        "            options={'maxiter': max_iter, 'xatol': tol}\n",
        "        )\n",
        "\n",
        "        if result.success:\n",
        "            tau_sq = result.x\n",
        "        else:\n",
        "            warnings.warn(\"ML optimization did not converge, using DL fallback\")\n",
        "            tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in ML estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 4. PAULE-MANDEL (PM) ---\n",
        "\n",
        "def calculate_tau_squared_PM(df, effect_col, var_col, max_iter=100, tol=1e-8):\n",
        "    \"\"\"\n",
        "    Paule-Mandel estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Exact solution to Q = k-1 equation\n",
        "    - Non-iterative in principle\n",
        "    - Good performance\n",
        "\n",
        "    Disadvantages:\n",
        "    - Can be unstable with few studies\n",
        "    - Requires iterative solution in practice\n",
        "\n",
        "    Reference:\n",
        "    Paule, R. C., & Mandel, J. (1982). Consensus values and weighting factors.\n",
        "    Journal of Research of the National Bureau of Standards, 87(5), 377-385.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    max_iter : int\n",
        "        Maximum iterations\n",
        "    tol : float\n",
        "        Convergence tolerance\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 2:\n",
        "            return 0.0\n",
        "\n",
        "        df_Q = k - 1\n",
        "\n",
        "        # PM objective: Find tau2 such that Q(tau2) = k - 1\n",
        "        def pm_objective(tau2):\n",
        "            tau2 = max(0, tau2)\n",
        "            wi = 1 / (vi + tau2)\n",
        "            sum_wi = wi.sum()\n",
        "\n",
        "            if sum_wi <= 0:\n",
        "                return 1e10\n",
        "\n",
        "            mu = (wi * yi).sum() / sum_wi\n",
        "            Q = (wi * (yi - mu)**2).sum()\n",
        "\n",
        "            # We want Q = k - 1\n",
        "            return (Q - df_Q)**2\n",
        "\n",
        "        var_yi = np.var(yi, ddof=1) if k > 2 else 1.0\n",
        "        upper_bound = max(10 * var_yi, 100)\n",
        "\n",
        "        result = minimize_scalar(\n",
        "            pm_objective,\n",
        "            bounds=(0, upper_bound),\n",
        "            method='bounded',\n",
        "            options={'maxiter': max_iter, 'xatol': tol}\n",
        "        )\n",
        "\n",
        "        if result.success and result.fun < 1:  # Good convergence\n",
        "            tau_sq = result.x\n",
        "        else:\n",
        "            # If PM fails, use DL\n",
        "            tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in PM estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 5. SIDIK-JONKMAN (SJ) ---\n",
        "\n",
        "def calculate_tau_squared_SJ(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Sidik-Jonkman estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Simple, non-iterative\n",
        "    - Good performance with few studies\n",
        "    - Conservative (tends to produce larger estimates)\n",
        "\n",
        "    Disadvantages:\n",
        "    - Can be overly conservative\n",
        "    - Less commonly used\n",
        "\n",
        "    Reference:\n",
        "    Sidik, K., & Jonkman, J. N. (2005). Simple heterogeneity variance\n",
        "    estimation for meta-analysis. Journal of the Royal Statistical Society,\n",
        "    Series C, 54(2), 367-384.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 3:  # Need at least 3 studies for SJ\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "    try:\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 3:\n",
        "            return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        # Weights for typical average\n",
        "        wi = 1 / vi\n",
        "        sum_wi = wi.sum()\n",
        "\n",
        "        # Typical average (weighted mean)\n",
        "        y_bar = (wi * yi).sum() / sum_wi\n",
        "\n",
        "        # SJ estimator\n",
        "        numerator = ((yi - y_bar)**2 / vi).sum()\n",
        "        denominator = k - 1\n",
        "\n",
        "        tau_sq = (numerator / denominator) - (k / sum_wi)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in SJ estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 6. UNIFIED ESTIMATOR FUNCTION ---\n",
        "\n",
        "# --- 7. COMPARISON FUNCTION ---\n",
        "\n",
        "# --- 8. DISPLAY MODULE INFO ---\n",
        "print(\"\\n‚úÖ Heterogeneity estimators loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìö R Validation: Imports & Setup\n",
        "# =============================================================================\n",
        "# VALIDATION NOTEBOOK - SETUP\n",
        "# Purpose: Install R, rpy2, and Python stats libraries.\n",
        "# =============================================================================\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm, t\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# --- 1. Install/Check R Interface ---\n",
        "try:\n",
        "    import rpy2.robjects as ro\n",
        "    from rpy2.robjects import pandas2ri\n",
        "    from rpy2.robjects.packages import importr\n",
        "    pandas2ri.activate()\n",
        "    print(\"‚úÖ rpy2 detected.\")\n",
        "except ImportError:\n",
        "    print(\"‚öôÔ∏è Installing rpy2...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rpy2\"])\n",
        "    import rpy2.robjects as ro\n",
        "    from rpy2.robjects import pandas2ri\n",
        "    from rpy2.robjects.packages import importr\n",
        "    pandas2ri.activate()\n",
        "\n",
        "# --- 2. Install R 'metafor' Package ---\n",
        "print(\"‚öôÔ∏è Checking R 'metafor' package...\")\n",
        "ro.r(\"\"\"\n",
        "if (!require(\"metafor\")) {\n",
        "    install.packages(\"metafor\", repos=\"https://cloud.r-project.org\", quiet=TRUE)\n",
        "}\n",
        "library(metafor)\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n‚úÖ Environment Ready: Python & R (metafor) are linked.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PGtVnkSzxL2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìÅ Step 1: LOAD DATA\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 2: LOAD DATA FROM GOOGLE SHEETS\n",
        "# Purpose: Authenticate and load the raw DataFrame from a selected worksheet.\n",
        "# Dependencies: Cell 1 (authentication and libraries)\n",
        "# Outputs: Global 'raw_data_from_sheet' DataFrame\n",
        "# =============================================================================\n",
        "\n",
        "# --- 1. Authenticate (Silently) ---\n",
        "try:\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "except Exception as e:\n",
        "    print(f\"‚úó Authentication failed: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- 2. Widget Definitions ---\n",
        "\n",
        "# Step 1: Select Google Sheet\n",
        "sheetName_widget = widgets.Text(\n",
        "    value='tesis',\n",
        "    description='1. GSheet Name:',\n",
        "    layout=widgets.Layout(width='500px'),\n",
        "    style={'description_width': '120px'}\n",
        ")\n",
        "load_sheets_button = widgets.Button(description=\"Fetch Worksheets\", button_style='primary')\n",
        "sheet_loader_output = widgets.Output()\n",
        "\n",
        "# Step 2: Select Worksheet\n",
        "worksheet_select_widget = widgets.Dropdown(\n",
        "    options=[],\n",
        "    description='2. Select Sheet:',\n",
        "    layout=widgets.Layout(width='500px'),\n",
        "    style={'description_width': '120px'},\n",
        "    disabled=True\n",
        ")\n",
        "load_data_button = widgets.Button(description=\"Load Data from Sheet\", button_style='success', disabled=True)\n",
        "data_loader_output = widgets.Output()\n",
        "\n",
        "# --- 3. Widget Handlers ---\n",
        "\n",
        "def on_load_sheets_clicked(b):\n",
        "    \"\"\"Event handler for 'Fetch Worksheets' button.\"\"\"\n",
        "    with sheet_loader_output:\n",
        "        clear_output(wait=True)\n",
        "        sheet_name = sheetName_widget.value\n",
        "        if not sheet_name:\n",
        "            print(\"‚úó Please enter a Google Sheet name.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Opening '{sheet_name}'...\")\n",
        "        try:\n",
        "            global spreadsheet\n",
        "            spreadsheet = gc.open(sheet_name)\n",
        "            worksheets = spreadsheet.worksheets()\n",
        "            worksheet_names = [ws.title for ws in worksheets]\n",
        "\n",
        "            worksheet_select_widget.options = worksheet_names\n",
        "            worksheet_select_widget.disabled = False\n",
        "            load_data_button.disabled = False\n",
        "            print(f\"‚úì Success! Found {len(worksheet_names)} worksheets. Please select one below.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó ERROR opening Google Sheet: {e}\")\n",
        "            print(\"  Troubleshooting:\")\n",
        "            print(\"  1. Is the name spelled correctly?\")\n",
        "            print(\"  2. Have you shared the sheet with your Google Colab email?\")\n",
        "            worksheet_select_widget.options = []\n",
        "            worksheet_select_widget.disabled = True\n",
        "            load_data_button.disabled = True\n",
        "\n",
        "def on_load_data_clicked(b):\n",
        "    \"\"\"Event handler for 'Load Data from Sheet' button.\"\"\"\n",
        "    with data_loader_output:\n",
        "        clear_output(wait=True)\n",
        "        worksheet_name = worksheet_select_widget.value\n",
        "        if not worksheet_name:\n",
        "            print(\"‚úó Please select a worksheet.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Loading data from '{worksheet_name}'...\")\n",
        "        try:\n",
        "            worksheet = spreadsheet.worksheet(worksheet_name)\n",
        "            rows = worksheet.get_all_values()\n",
        "\n",
        "            if not rows or len(rows) < 2:\n",
        "                raise ValueError(\"Worksheet has no data or no header row.\")\n",
        "\n",
        "            # Create DataFrame\n",
        "            column_names = rows[0]\n",
        "            data_records = rows[1:]\n",
        "\n",
        "            # Store in a global variable for the next cell\n",
        "            global raw_data_from_sheet\n",
        "            raw_data_from_sheet = pd.DataFrame.from_records(data_records, columns=column_names)\n",
        "\n",
        "            print(f\"‚úì Data loaded successfully!\")\n",
        "            print(f\"  ‚Ä¢ {raw_data_from_sheet.shape[0]} rows √ó {raw_data_from_sheet.shape[1]} columns found.\")\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"‚úÖ PLEASE PROCEED TO THE NEXT CELL TO CONFIGURE YOUR DATA\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó ERROR reading worksheet: {e}\")\n",
        "\n",
        "# --- 4. Attach Handlers ---\n",
        "load_sheets_button.on_click(on_load_sheets_clicked)\n",
        "load_data_button.on_click(on_load_data_clicked)\n",
        "\n",
        "# --- 5. Display UI ---\n",
        "box1 = widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>Step 1: Load Google Sheet</h3>\"),\n",
        "    sheetName_widget,\n",
        "    load_sheets_button,\n",
        "    sheet_loader_output\n",
        "])\n",
        "\n",
        "box2 = widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>Step 2: Select Worksheet & Load Data</h3>\"),\n",
        "    worksheet_select_widget,\n",
        "    load_data_button,\n",
        "    data_loader_output\n",
        "])\n",
        "\n",
        "display(box1, box2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HUYpMXVg_yej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öôÔ∏è Step 2: CONFIGURE ANALYSIS\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 3: CONFIGURE ANALYSIS FILTERS\n",
        "# Purpose: Set up all filters and mappings for the analysis.\n",
        "# Dependencies: Cell 2 (global 'raw_data_from_sheet')\n",
        "# Outputs: 'ANALYSIS_CONFIG' dictionary with user's choices.\n",
        "# =============================================================================\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "\n",
        "# --- 1. PRE-RUN: Check for Data and Find Moderators ---\n",
        "try:\n",
        "    if 'raw_data_from_sheet' not in globals():\n",
        "        raise NameError(\"raw_data_from_sheet\")\n",
        "\n",
        "    # --- 1a. Helper function for auto-guessing columns ---\n",
        "    def guess_column(options, matches, default=None):\n",
        "        \"\"\"Finds the best match from a list of options.\"\"\"\n",
        "        options_lower = [str(o).lower() for o in options]\n",
        "        for match in matches:\n",
        "            if match in options_lower:\n",
        "                return options[options_lower.index(match)]\n",
        "        return default if default else options[0] if options else None\n",
        "\n",
        "    # --- 1b. Load data and find all columns ---\n",
        "    all_column_names = list(raw_data_from_sheet.columns)\n",
        "    if not all_column_names:\n",
        "        raise ValueError(\"Data loaded from sheet has no columns.\")\n",
        "\n",
        "    # --- 1c. Auto-guess core columns to build a temporary_raw_data ---\n",
        "    temp_col_map = {\n",
        "        guess_column(all_column_names, ['id', 'study', 'study_id', 'paper']): 'id',\n",
        "        guess_column(all_column_names, ['xe', 'mean_e', 'mean_exp', 'x_e']): 'xe',\n",
        "        guess_column(all_column_names, ['sde', 'sd_e', 'sd_exp']): 'sde',\n",
        "        guess_column(all_column_names, ['ne', 'n_e', 'n_exp']): 'ne',\n",
        "        guess_column(all_column_names, ['xc', 'mean_c', 'mean_ctrl', 'x_c']): 'xc',\n",
        "        guess_column(all_column_names, ['sdc', 'sd_c', 'sd_ctrl']): 'sdc',\n",
        "        guess_column(all_column_names, ['nc', 'n_c', 'n_ctrl']): 'nc'\n",
        "    }\n",
        "\n",
        "    # Invert map for renaming, but handle None if a column wasn't found\n",
        "    temp_col_map_inv = {v: k for k, v in temp_col_map.items() if k is not None}\n",
        "\n",
        "    # Find other non-core columns\n",
        "    other_cols = [col for col in all_column_names if col not in temp_col_map_inv.values()]\n",
        "\n",
        "    # Create temporary cleaned data\n",
        "    temp_raw_data = raw_data_from_sheet[list(temp_col_map_inv.values()) + other_cols].copy()\n",
        "    temp_raw_data.rename(columns=temp_col_map_inv, inplace=True)\n",
        "\n",
        "    # --- 1d. Run minimal cleaning just to find moderators ---\n",
        "    for col in ['id']: # Only need ID for this step\n",
        "        if col not in temp_raw_data.columns:\n",
        "            temp_raw_data[col] = pd.Series(dtype='object')\n",
        "    temp_raw_data['id'] = temp_raw_data['id'].astype(str).str.strip()\n",
        "\n",
        "    # Find moderators\n",
        "    excluded_cols = ['id', 'xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "    available_moderators = [col for col in temp_raw_data.columns\n",
        "                            if col not in excluded_cols\n",
        "                            and temp_raw_data[col].dtype == 'object']\n",
        "\n",
        "except NameError:\n",
        "    display(HTML(\"<div style='background-color: #fff3cd; border: 1px solid #ffeeba; padding: 15px; border-radius: 5px; color: #856404;'>\"\n",
        "                 \"<b>‚ùå ERROR: No data found.</b> Please run Cell 2 (LOAD DATA) successfully before running this cell.\"\n",
        "                 \"</div>\"))\n",
        "    raise\n",
        "except Exception as e:\n",
        "    display(HTML(f\"<div style='background-color: #f8d7da; border: 1px solid #f5c6cb; padding: 15px; border-radius: 5px; color: #721c24;'>\"\n",
        "                 f\"<b>‚ùå An error occurred during pre-load:</b> {e}<br>\"\n",
        "                 f\"Please check your sheet and column names.\"\n",
        "                 f\"</div>\"))\n",
        "    raise\n",
        "\n",
        "# --- 2. Widget Definitions ---\n",
        "\n",
        "# --- Box 1: Column Mapping (Hidden in Accordion) ---\n",
        "id_col_widget = widgets.Dropdown(description='Study ID (id):', options=all_column_names,\n",
        "                                 value=temp_col_map_inv.get('id'),\n",
        "                                 layout=widgets.Layout(width='500px'), style={'description_width': '150px'})\n",
        "xe_col_widget = widgets.Dropdown(description='Exp. Mean (xe):', options=all_column_names,\n",
        "                                 value=temp_col_map_inv.get('xe'),\n",
        "                                 layout=widgets.Layout(width='500px'), style={'description_width': '150px'})\n",
        "sde_col_widget = widgets.Dropdown(description='Exp. SD (sde):', options=all_column_names,\n",
        "                                  value=temp_col_map_inv.get('sde'),\n",
        "                                  layout=widgets.Layout(width='500px'), style={'description_width': '150px'})\n",
        "ne_col_widget = widgets.Dropdown(description='Exp. N (ne):', options=all_column_names,\n",
        "                                 value=temp_col_map_inv.get('ne'),\n",
        "                                 layout=widgets.Layout(width='500px'), style={'description_width': '150px'})\n",
        "xc_col_widget = widgets.Dropdown(description='Ctrl. Mean (xc):', options=all_column_names,\n",
        "                                 value=temp_col_map_inv.get('xc'),\n",
        "                                 layout=widgets.Layout(width='500px'), style={'description_width': '150px'})\n",
        "sdc_col_widget = widgets.Dropdown(description='Ctrl. SD (sdc):', options=all_column_names,\n",
        "                                  value=temp_col_map_inv.get('sdc'),\n",
        "                                  layout=widgets.Layout(width='500px'), style={'description_width': '150px'})\n",
        "nc_col_widget = widgets.Dropdown(description='Ctrl. N (nc):', options=all_column_names,\n",
        "                                 value=temp_col_map_inv.get('nc'),\n",
        "                                 layout=widgets.Layout(width='500px'), style={'description_width': '150px'})\n",
        "\n",
        "column_mapping_box = widgets.VBox([\n",
        "    widgets.HTML(\"Map your sheet's columns to the names the pipeline requires. The system has auto-guessed, but please verify.\"),\n",
        "    id_col_widget,\n",
        "    xe_col_widget, sde_col_widget, ne_col_widget,\n",
        "    xc_col_widget, sdc_col_widget, nc_col_widget\n",
        "])\n",
        "column_accordion = widgets.Accordion(children=[column_mapping_box])\n",
        "column_accordion.set_title(0, 'Step 2a (Optional): Verify Column Names')\n",
        "column_accordion.selected_index = None # Start closed\n",
        "\n",
        "# --- Box 2: Analysis Configuration ---\n",
        "prefilter_col_widget = widgets.Dropdown(description='Filter by:', options=['None'] + available_moderators, value='None',\n",
        "                                        style={'description_width': '120px'}, layout=widgets.Layout(width='500px'))\n",
        "prefilter_values_widget = widgets.VBox()\n",
        "filterCol1_widget = widgets.Dropdown(description='Factor 1:', options=available_moderators if available_moderators else ['None'],\n",
        "                                     value=available_moderators[0] if available_moderators else 'None',\n",
        "                                     style={'description_width': '120px'}, layout=widgets.Layout(width='500px'))\n",
        "filterCol2_widget = widgets.Dropdown(description='Factor 2:', options=['None'] + available_moderators, value='None',\n",
        "                                     style={'description_width': '120px'}, layout=widgets.Layout(width='500px'))\n",
        "minPapers_widget = widgets.IntSlider(value=2, min=1, max=10, step=1, description='Min Papers:',\n",
        "                                     style={'description_width': '120px'}, layout=widgets.Layout(width='500px'))\n",
        "minObservations_widget = widgets.IntSlider(value=2, min=1, max=20, step=1, description='Min Observations:',\n",
        "                                           style={'description_width': '120px'}, layout=widgets.Layout(width='500px'))\n",
        "\n",
        "# --- Box 3: Final Button ---\n",
        "save_config_button = widgets.Button(\n",
        "    description='‚ñ∂ Save Configuration',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='500px', height='50px'),\n",
        "    style={'font_weight': 'bold', 'font_size': '14px'}\n",
        ")\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# --- 4. Widget Handlers ---\n",
        "\n",
        "def update_prefilter_checkboxes(change):\n",
        "    \"\"\"Update checkboxes when column selection changes\"\"\"\n",
        "    selected_col = change['new']\n",
        "    if selected_col == 'None':\n",
        "        prefilter_values_widget.children = []\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Use the *uncleaned* temp_raw_data for a quick preview\n",
        "        unique_values = sorted(temp_raw_data[selected_col].dropna().unique())\n",
        "        checkboxes = [\n",
        "            widgets.Checkbox(\n",
        "                value=True,\n",
        "                description=f\"{val} (n={len(temp_raw_data[temp_raw_data[selected_col] == val])})\",\n",
        "                style={'description_width': 'initial'},\n",
        "                layout=widgets.Layout(width='500px')\n",
        "            ) for val in unique_values\n",
        "        ]\n",
        "        prefilter_values_widget.children = [\n",
        "            widgets.HTML(\"<p style='margin: 10px 0; font-weight: bold;'>Select values to KEEP:</p>\")\n",
        "        ] + checkboxes\n",
        "    except Exception as e:\n",
        "        prefilter_values_widget.children = [widgets.HTML(f\"<p style='color: red;'>Error updating list: {e}</p>\")]\n",
        "\n",
        "prefilter_col_widget.observe(update_prefilter_checkboxes, names='value')\n",
        "\n",
        "@save_config_button.on_click\n",
        "def on_save_config_clicked(b):\n",
        "    \"\"\"Main function: JUST save the config.\"\"\"\n",
        "    with output_area:\n",
        "        clear_output(wait=True)\n",
        "        \"\"\"\n",
        "        print(\"=\"*70)\n",
        "        print(\"CONFIGURING ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # --- 1. Get Column Mappings ---\n",
        "            global col_map\n",
        "            col_map = {\n",
        "                id_col_widget.value: 'id',\n",
        "                xe_col_widget.value: 'xe',\n",
        "                sde_col_widget.value: 'sde',\n",
        "                ne_col_widget.value: 'ne',\n",
        "                xc_col_widget.value: 'xc',\n",
        "                sdc_col_widget.value: 'sdc',\n",
        "                nc_col_widget.value: 'nc'\n",
        "            }\n",
        "\n",
        "            # Check for duplicate mappings\n",
        "            mapped_keys = [k for k in col_map.keys() if k is not None]\n",
        "            if len(set(mapped_keys)) != len(mapped_keys):\n",
        "                raise ValueError(\"Duplicate columns mapped. Please assign one sheet column to one role.\")\n",
        "\n",
        "            # --- 2. Get Pre-filter selections ---\n",
        "            prefilter_col = prefilter_col_widget.value\n",
        "            selected_values = []\n",
        "            if prefilter_col != 'None':\n",
        "                selected_values = [\n",
        "                    cb.description.split(' (n=')[0]\n",
        "                    for cb in prefilter_values_widget.children[1:] # Skip HTML title\n",
        "                    if hasattr(cb, 'value') and cb.value\n",
        "                ]\n",
        "\n",
        "            # --- 3. Save Configuration to Global ANALYSIS_CONFIG ---\n",
        "            global ANALYSIS_CONFIG\n",
        "            ANALYSIS_CONFIG = {\n",
        "                'col_map': col_map,\n",
        "                'prefilter_col': prefilter_col,\n",
        "                'prefilter_values_kept': selected_values if prefilter_col != 'None' else 'All',\n",
        "                'filterCol1': filterCol1_widget.value,\n",
        "                'filterCol2': filterCol2_widget.value,\n",
        "                'minPapers': minPapers_widget.value,\n",
        "                'minObservations': minObservations_widget.value,\n",
        "            }\n",
        "\n",
        "            # --- 4. Print Final Summary ---\n",
        "\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"‚úÖ CONFIGURATION SAVED RUN THE NEXT CELL TO APPLY\")\n",
        "            print(\"=\"*70)\n",
        "            \"\"\"\n",
        "            print(\"\\nüìã Analysis Configuration Summary:\")\n",
        "            print(\"-\" * 70)\n",
        "            print(f\"  1Ô∏è‚É£  COLUMN MAPPING:\")\n",
        "            print(f\"      ‚Ä¢ Study ID: '{id_col_widget.value}'\")\n",
        "            print(f\"      ‚Ä¢ Exp. Mean: '{xe_col_widget.value}'\")\n",
        "            print(f\"      ‚Ä¢ Ctrl. Mean: '{xc_col_widget.value}'\")\n",
        "            print(f\"  2Ô∏è‚É£  SUBGROUP ANALYSIS:\")\n",
        "            print(f\"      ‚Ä¢ Primary factor:   {ANALYSIS_CONFIG['filterCol1']}\")\n",
        "            print(f\"      ‚Ä¢ Secondary factor: {ANALYSIS_CONFIG['filterCol2']}\")\n",
        "            print(f\"  3Ô∏è‚É£  QUALITY THRESHOLDS:\")\n",
        "            print(f\"      ‚Ä¢ Min Papers:       {ANALYSIS_CONFIG['minPapers']}\")\n",
        "            print(f\"      ‚Ä¢ Min Observations: {ANALYSIS_CONFIG['minObservations']}\")\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"‚ñ∂Ô∏è  Run the next cell to clean data and apply this configuration.\")\n",
        "            print(\"=\"*70)\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå AN ERROR OCCURRED:\\n\")\n",
        "            print(f\"  Type: {type(e).__name__}\")\n",
        "            print(f\"  Message: {e}\")\n",
        "            print(\"\\n  Traceback:\")\n",
        "            traceback.print_exc(file=sys.stdout)\n",
        "\n",
        "# --- 5. Assemble & Display Final UI ---\n",
        "box1 = column_accordion\n",
        "box2 = widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>Step 2b: Configure Analysis Filters</h3>\"),\n",
        "    widgets.HTML(\"<h4 style='color: #444; margin-bottom: 5px;'>üìå Pre-Filter (Optional)</h4>\"),\n",
        "    prefilter_col_widget,\n",
        "    prefilter_values_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0; border: none; border-top: 1px solid #eee;'>\"),\n",
        "    widgets.HTML(\"<h4 style='color: #444; margin-bottom: 5px;'>üìä Subgroup Analysis</h4>\"),\n",
        "    filterCol1_widget,\n",
        "    filterCol2_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0; border: none; border-top: 1px solid #eee;'>\"),\n",
        "    widgets.HTML(\"<h4 style='color: #444; margin-bottom: 5px;'>‚öôÔ∏è Quality Filters</h4>\"),\n",
        "    minPapers_widget,\n",
        "    minObservations_widget\n",
        "])\n",
        "box3 = widgets.VBox([\n",
        "    widgets.HTML(\"<hr style='margin: 20px 0; border: none; border-top: 2px solid #ddd;'>\"),\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>Step 2c: Save Configuration</h3>\"),\n",
        "    save_config_button,\n",
        "    output_area\n",
        "])\n",
        "\n",
        "display(box1, box2, box3)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7sjfhYeu_7Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öôÔ∏è Step 3: APPLY CONFIGURATION & PREPARE DATA\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 4: CLEAN DATA & APPLY CONFIGURATION\n",
        "# Purpose: Run cleaning and filtering based on choices from Cell 3.\n",
        "# Dependencies: Cell 2 (global 'raw_data_from_sheet'), Cell 3 (global 'ANALYSIS_CONFIG')\n",
        "# Outputs: Global 'raw_data' (cleaned), 'data_filtered', 'LOAD_METADATA'\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "\"\"\"\n",
        "print(\"=\"*70)\n",
        "print(\"APPLYING CONFIGURATION & PREPARING DATA\")\n",
        "print(\"=\"*70)\n",
        "\"\"\"\n",
        "try:\n",
        "    # --- 1. Check for inputs ---\n",
        "    if 'raw_data_from_sheet' not in globals():\n",
        "        raise NameError(\"Data not loaded. Please re-run Cell 2.\")\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"Configuration not set. Please run Cell 3 and click 'Save Configuration'.\")\n",
        "\n",
        "    #print(\"STEP 1: Loading configuration from Cell 3...\")\n",
        "    col_map = ANALYSIS_CONFIG['col_map']\n",
        "\n",
        "    # --- 2. Rename & Clean Data ---\n",
        "    #print(\"STEP 2: Cleaning and converting data...\")\n",
        "    global raw_data\n",
        "\n",
        "    mapped_cols = col_map.keys()\n",
        "    other_cols = [col for col in raw_data_from_sheet.columns if col not in mapped_cols]\n",
        "\n",
        "    raw_data = raw_data_from_sheet[list(mapped_cols) + other_cols].copy()\n",
        "    raw_data.rename(columns=col_map, inplace=True)\n",
        "\n",
        "    original_rows = len(raw_data)\n",
        "    cleaning_log = []\n",
        "\n",
        "    # Convert numeric columns\n",
        "    numeric_columns = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "    for col in numeric_columns:\n",
        "        if col not in raw_data.columns:\n",
        "             raise ValueError(f\"Mapped column '{col}' not found after loading.\")\n",
        "        raw_data[col] = raw_data[col].astype(str).str.strip().replace('', np.nan)\n",
        "        raw_data[col] = pd.to_numeric(raw_data[col], errors='coerce')\n",
        "\n",
        "    # Ensure ID is string\n",
        "    raw_data['id'] = raw_data['id'].astype(str).str.strip()\n",
        "\n",
        "    # Drop rows with missing essential values\n",
        "    essential_cols = ['xe', 'ne', 'xc', 'nc']\n",
        "    missing_essential = raw_data[essential_cols].isna().any(axis=1).sum()\n",
        "    raw_data.dropna(subset=essential_cols, inplace=True)\n",
        "    if missing_essential > 0:\n",
        "        cleaning_log.append(f\"Dropped {missing_essential} rows (missing xe/ne/xc/nc)\")\n",
        "\n",
        "    # Ensure N >= 1\n",
        "    invalid_n_count = 0\n",
        "    for col in ['ne', 'nc']:\n",
        "        raw_data[col] = raw_data[col].fillna(0).astype(int)\n",
        "        invalid_n = (raw_data[col] < 1).sum()\n",
        "        if invalid_n > 0:\n",
        "            raw_data = raw_data[raw_data[col] >= 1]\n",
        "            invalid_n_count += invalid_n\n",
        "    if invalid_n_count > 0:\n",
        "        cleaning_log.append(f\"Dropped {invalid_n_count} rows (n < 1)\")\n",
        "\n",
        "    final_rows = len(raw_data)\n",
        "    print(f\"  ‚úì Clean dataset ready: {final_rows} rows remaining ({original_rows - final_rows} total removed)\")\n",
        "\n",
        "    # --- 3. Identify Moderators ---\n",
        "    #print(\"STEP 3: Identifying moderators...\")\n",
        "    excluded_cols = ['id', 'xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "    global available_moderators\n",
        "    available_moderators = [col for col in raw_data.columns\n",
        "                            if col not in excluded_cols\n",
        "                            and raw_data[col].dtype == 'object']\n",
        "\n",
        "    print(f\"  ‚úì Found {len(available_moderators)} potential moderators.\")\n",
        "\n",
        "    # --- 4. Apply Pre-filter (if selected) ---\n",
        "    #print(\"STEP 4: Applying pre-filter...\")\n",
        "    global data_filtered\n",
        "    data_filtered = raw_data.copy()\n",
        "\n",
        "    prefilter_col = ANALYSIS_CONFIG['prefilter_col']\n",
        "    selected_values = ANALYSIS_CONFIG['prefilter_values_kept']\n",
        "\n",
        "    if prefilter_col != 'None':\n",
        "        data_filtered = data_filtered[data_filtered[prefilter_col].isin(selected_values)]\n",
        "        print(f\"  ‚úì Pre-filter applied. {len(data_filtered)} rows remain.\")\n",
        "    else:\n",
        "        print(\"  ‚úì No pre-filter applied.\")\n",
        "\n",
        "    # --- 5. Save Metadata ---\n",
        "    global LOAD_METADATA\n",
        "    LOAD_METADATA = {\n",
        "        'timestamp': datetime.datetime.now(),\n",
        "        'original_rows': original_rows,\n",
        "        'final_rows_cleaned': final_rows,\n",
        "        'final_rows_filtered': len(data_filtered),\n",
        "        'cleaning_log': cleaning_log,\n",
        "        'available_moderators': available_moderators,\n",
        "        'column_map': col_map\n",
        "    }\n",
        "\n",
        "    # Update ANALYSIS_CONFIG with final counts\n",
        "    ANALYSIS_CONFIG['n_observations_pre_filter'] = final_rows\n",
        "    ANALYSIS_CONFIG['n_observations_post_filter'] = len(data_filtered)\n",
        "    ANALYSIS_CONFIG['n_papers_post_filter'] = data_filtered['id'].nunique()\n",
        "\n",
        "    # --- 6. Print Final Summary ---\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ DATA READY FOR ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    \"\"\"\n",
        "    print(\"\\nüìã Final Data Summary:\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"  ‚Ä¢ Rows available for analysis: {len(data_filtered)}\")\n",
        "    print(f\"  ‚Ä¢ Unique studies: {data_filtered['id'].nunique()}\")\n",
        "    print(f\"  ‚Ä¢ Subgroup Factor 1: {ANALYSIS_CONFIG['filterCol1']}\")\n",
        "    print(f\"  ‚Ä¢ Subgroup Factor 2: {ANALYSIS_CONFIG['filterCol2']}\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚ñ∂Ô∏è  Run the next cell to proceed.\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå AN ERROR OCCURRED:\\n\")\n",
        "    print(f\"  Type: {type(e).__name__}\")\n",
        "    print(f\"  Message: {e}\")\n",
        "    print(\"\\n  Traceback:\")\n",
        "    traceback.print_exc(file=sys.stdout)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lATv4QaoJNE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üî¨ DETECT & SELECT EFFECT SIZE TYPE\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 4: EFFECT SIZE TYPE DETECTION AND SELECTION\n",
        "# Purpose: Analyze data characteristics and recommend appropriate effect size\n",
        "# Fixes: Added educational context to Tabs 2 & 3 for new users.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# --- 1. STABILITY FIX: USE RAW DATA IF AVAILABLE ---\n",
        "target_df = raw_data if 'raw_data' in globals() else data_filtered\n",
        "\n",
        "# --- 2. ANALYZE DATA ---\n",
        "xe_stats = target_df['xe'].describe()\n",
        "xc_stats = target_df['xc'].describe()\n",
        "\n",
        "# Standard Deviations\n",
        "has_sde = 'sde' in target_df.columns and target_df['sde'].notna().any()\n",
        "has_sdc = 'sdc' in target_df.columns and target_df['sdc'].notna().any()\n",
        "sd_availability = target_df[['sde', 'sdc']].notna().all(axis=1).sum() if has_sde and has_sdc else 0\n",
        "sd_pct = (sd_availability / len(target_df)) * 100 if len(target_df) > 0 else 0\n",
        "\n",
        "# 1. Normalization Check\n",
        "control_near_one = ((target_df['xc'] >= 0.95) & (target_df['xc'] <= 1.05)).sum()\n",
        "control_exactly_one = (target_df['xc'] == 1.0).sum()\n",
        "pct_control_near_one = (control_near_one / len(target_df)) * 100\n",
        "pct_control_exactly_one = (control_exactly_one / len(target_df)) * 100\n",
        "\n",
        "# 2. Negative Values\n",
        "n_negative_xe = (target_df['xe'] < 0).sum()\n",
        "n_negative_xc = (target_df['xc'] < 0).sum()\n",
        "has_negative = n_negative_xe > 0 or n_negative_xc > 0\n",
        "\n",
        "# 3. Zero Values\n",
        "n_zero_xe = (target_df['xe'] == 0).sum()\n",
        "n_zero_xc = (target_df['xc'] == 0).sum()\n",
        "has_zero = n_zero_xe > 0 or n_zero_xc > 0\n",
        "\n",
        "# 4. Scale Heterogeneity\n",
        "xe_range = xe_stats['max'] - xe_stats['min']\n",
        "xc_range = xc_stats['max'] - xc_stats['min']\n",
        "scale_ratio = max(xe_range, xc_range) / (min(xe_range, xc_range) + 0.0001)\n",
        "\n",
        "# --- 3. RECOMMENDATION LOGIC ---\n",
        "score_lnRR = 0\n",
        "score_hedges_g = 0\n",
        "reasons = []\n",
        "\n",
        "# Rule 1: Negatives (The \"Hard\" Constraint)\n",
        "if has_negative:\n",
        "    score_hedges_g += 10\n",
        "    reasons.append(('Negative Values', '+++', 'Hedges g', 'Ratio metrics (lnRR) mathematically fail with negative numbers.'))\n",
        "else:\n",
        "    score_lnRR += 2\n",
        "    reasons.append(('All Positive', '+', 'lnRR', 'Data is compatible with ratio-based metrics.'))\n",
        "\n",
        "# Rule 2: Normalization\n",
        "if pct_control_exactly_one > 50:\n",
        "    score_lnRR += 5\n",
        "    reasons.append(('Fold-Change Data', '+++', 'lnRR', 'Controls set to 1.0 implies data is already a ratio.'))\n",
        "elif pct_control_near_one > 30:\n",
        "    score_lnRR += 3\n",
        "    reasons.append(('Normalized Data', '++', 'lnRR', 'Controls clustered around 1.0 suggests ratio data.'))\n",
        "elif 0.8 < xc_stats['mean'] < 1.2:\n",
        "    score_lnRR += 1\n",
        "    reasons.append(('Unity Baseline', '+', 'lnRR', 'Control group mean is close to 1.0.'))\n",
        "\n",
        "# Rule 3: Heterogeneity\n",
        "if scale_ratio > 100:\n",
        "    score_lnRR += 3\n",
        "    reasons.append(('High Scale Variance', '+++', 'lnRR', 'Studies measure vastly different scales. Ratios handle this best.'))\n",
        "elif scale_ratio > 10:\n",
        "    score_lnRR += 2\n",
        "    reasons.append(('Moderate Scale Variance', '++', 'lnRR', 'Ratios normalize scale differences effectively.'))\n",
        "else:\n",
        "    score_hedges_g += 1\n",
        "    reasons.append(('Consistent Scales', '+', 'Hedges g', 'Scales are similar across studies; standardized differences work well.'))\n",
        "\n",
        "# Rule 4: Zeros\n",
        "if has_zero:\n",
        "    score_hedges_g += 2\n",
        "    reasons.append(('Zero Values', '++', 'Hedges g', 'log(0) is undefined. lnRR requires adding arbitrary constants.'))\n",
        "\n",
        "# Rule 5: SD Availability\n",
        "if sd_pct > 80:\n",
        "    score_hedges_g += 1\n",
        "    reasons.append(('Good SD Data', '+', 'Hedges g', 'Hedges g requires SDs. Your data has good coverage.'))\n",
        "elif sd_pct < 20:\n",
        "    reasons.append(('Missing SDs', '‚ö†', 'Neither', 'Hedges g requires imputation. Response Ratios might be safer if SDs are rare.'))\n",
        "\n",
        "# Winner\n",
        "score_diff = abs(score_lnRR - score_hedges_g)\n",
        "if score_lnRR > score_hedges_g:\n",
        "    recommended_type = 'lnRR'\n",
        "    confidence = \"High\" if score_diff >= 5 else \"Moderate\" if score_diff >= 3 else \"Low\"\n",
        "elif score_hedges_g > score_lnRR:\n",
        "    recommended_type = 'hedges_g'\n",
        "    confidence = \"High\" if score_diff >= 5 else \"Moderate\" if score_diff >= 3 else \"Low\"\n",
        "else:\n",
        "    recommended_type = 'hedges_g'\n",
        "    confidence = \"Low\"\n",
        "\n",
        "# --- 4. SETUP UI ---\n",
        "tab_main = widgets.Output()\n",
        "tab_patterns = widgets.Output()\n",
        "tab_logic = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_main, tab_patterns, tab_logic])\n",
        "tabs.set_title(0, 'üí° Recommendation')\n",
        "tabs.set_title(1, 'üìä Data Patterns')\n",
        "tabs.set_title(2, 'üß† Decision Logic')\n",
        "\n",
        "# --- TAB 2: DATA PATTERNS (Educational) ---\n",
        "with tab_patterns:\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style='padding:10px; font-size:14px; line-height:1.6;'>\n",
        "        <h4 style='margin-top:0; color:#2E86AB;'>üîç Diagnostic Checks</h4>\n",
        "        <p>We analyzed <b>{len(target_df)} observations</b> to determine the statistical properties of your dataset.\n",
        "        Here is what we found:</p>\n",
        "\n",
        "        <hr>\n",
        "\n",
        "        <b>1Ô∏è‚É£ Control Group Normalization</b><br>\n",
        "        Values near 1.0 often indicate \"Fold-Change\" data (e.g., gene expression normalized to a control).<br>\n",
        "        ‚Ä¢ <b>Result:</b> {pct_control_exactly_one:.1f}% of controls are exactly 1.0.<br>\n",
        "        ‚Ä¢ <b>Implication:</b> {'Strong evidence for Ratio data.' if pct_control_exactly_one > 50 else 'No strong evidence of pre-normalization.'}\n",
        "        <br><br>\n",
        "\n",
        "        <b>2Ô∏è‚É£ Negative Values</b><br>\n",
        "        Log-based metrics (like lnRR) <i>cannot</i> mathematically handle negative numbers.<br>\n",
        "        ‚Ä¢ <b>Result:</b> Found {n_negative_xe + n_negative_xc} negative values.<br>\n",
        "        ‚Ä¢ <b>Implication:</b> {'‚ùå MUST use Standardized Difference (Hedges g).' if has_negative else '‚úì Compatible with Ratio metrics.'}\n",
        "        <br><br>\n",
        "\n",
        "        <b>3Ô∏è‚É£ Zero Values</b><br>\n",
        "        Log of zero is undefined. Zeros require adding a \"small constant\" to work with lnRR.<br>\n",
        "        ‚Ä¢ <b>Result:</b> Found {n_zero_xe + n_zero_xc} zero values.<br>\n",
        "        ‚Ä¢ <b>Implication:</b> {'‚ö†Ô∏è lnRR will require adjustment.' if has_zero else '‚úì Clean data.'}\n",
        "        <br><br>\n",
        "\n",
        "        <b>4Ô∏è‚É£ Scale Heterogeneity</b><br>\n",
        "        Do studies measure things on the same scale (e.g., all in grams) or different scales (grams vs. tons)?<br>\n",
        "        ‚Ä¢ <b>Result:</b> Largest value is {scale_ratio:.1f}√ó larger than the smallest range.<br>\n",
        "        ‚Ä¢ <b>Implication:</b> {'High variation favors Ratios (lnRR).' if scale_ratio > 10 else 'Low variation allows Standardized Differences.'}\n",
        "        <br><br>\n",
        "\n",
        "        <b>5Ô∏è‚É£ Data Completeness</b><br>\n",
        "        Standardized differences (Hedges' g) require Standard Deviations (SD) to calculate.<br>\n",
        "        ‚Ä¢ <b>Result:</b> {sd_pct:.1f}% of rows have valid SDs.<br>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "# --- TAB 3: LOGIC (Educational) ---\n",
        "with tab_logic:\n",
        "    # Create HTML table rows\n",
        "    rows_html = \"\"\n",
        "    for r in reasons:\n",
        "        rows_html += f\"<tr><td><b>{r[0]}</b></td><td>{r[1]}</td><td>{r[2]}</td><td>{r[3]}</td></tr>\"\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style='padding:10px; font-size:14px;'>\n",
        "        <h4 style='margin-top:0; color:#2E86AB;'>üß† How the Algorithm Decides</h4>\n",
        "        <p>We use a weighted scoring system to recommend the most statistically appropriate effect size.\n",
        "        Some factors (like negative values) are \"hard constraints,\" while others are preferences.</p>\n",
        "\n",
        "        <table style='width:100%; border-collapse:collapse; margin-top:10px;'>\n",
        "            <tr style='background-color:#f0f0f0; text-align:left; border-bottom:2px solid #ddd;'>\n",
        "                <th style='padding:8px;'>Diagnostic Factor</th>\n",
        "                <th style='padding:8px;'>Weight</th>\n",
        "                <th style='padding:8px;'>Favors</th>\n",
        "                <th style='padding:8px;'>Educational Note</th>\n",
        "            </tr>\n",
        "            {rows_html}\n",
        "        </table>\n",
        "\n",
        "        <div style='margin-top:20px; padding:10px; background-color:#eef; border-radius:5px;'>\n",
        "            <b>Final Score:</b><br>\n",
        "            üìä <b>log Response Ratio (lnRR):</b> {score_lnRR} points<br>\n",
        "            üìä <b>Hedges' g (SMD):</b> {score_hedges_g} points\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "# --- TAB 1: MAIN (Selection) ---\n",
        "with tab_main:\n",
        "    # 1. Recommendation Box\n",
        "    if recommended_type == 'lnRR':\n",
        "        html_rec = f\"\"\"\n",
        "        <div style='background-color: #d4edda; border-left: 5px solid #28a745; padding: 15px; margin-bottom: 20px;'>\n",
        "            <h3 style='color: #155724; margin-top: 0;'>üí° Recommendation: log Response Ratio (lnRR)</h3>\n",
        "            <p style='color: #155724; margin-bottom: 0;'><b>Why?</b> Your data appears to be <b>ratio-based</b> (e.g., fold-changes, growth rates).\n",
        "            lnRR is the natural metric for this data type because it handles scale differences and has a direct biological interpretation (% change).</p>\n",
        "        </div>\"\"\"\n",
        "    else:\n",
        "        html_rec = f\"\"\"\n",
        "        <div style='background-color: #d1ecf1; border-left: 5px solid #17a2b8; padding: 15px; margin-bottom: 20px;'>\n",
        "            <h3 style='color: #0c5460; margin-top: 0;'>üí° Recommendation: Hedges' g (SMD)</h3>\n",
        "            <p style='color: #0c5460; margin-bottom: 0;'><b>Why?</b> Your data appears to be <b>absolute measurements</b> on potentially different scales.\n",
        "            Hedges' g is ideal here because it standardizes effects into \"SD units,\" making them comparable even if units differ.</p>\n",
        "        </div>\"\"\"\n",
        "\n",
        "    display(HTML(html_rec))\n",
        "\n",
        "    # 2. Selection Widget\n",
        "    effect_size_widget = widgets.RadioButtons(\n",
        "        options=[\n",
        "            ('log Response Ratio (lnRR) - for ratio/fold-change data', 'lnRR'),\n",
        "            (\"Hedges' g - for standardized mean differences (corrected)\", 'hedges_g'),\n",
        "            (\"Cohen's d - for standardized mean differences (uncorrected)\", 'cohen_d'),\n",
        "            ('log Odds Ratio (logOR) - for binary outcomes', 'log_or')\n",
        "        ],\n",
        "        value=recommended_type,\n",
        "        description='Select Type:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='600px')\n",
        "    )\n",
        "\n",
        "    # 3. Info Panel\n",
        "    info_output = widgets.Output()\n",
        "    info_panels = {\n",
        "        'lnRR': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>üéì About lnRR:</b> Calculates the log-ratio of means (ln(Xe/Xc)). Essential for data where 'doubling' is the same magnitude of effect as 'halving'. Commonly used in ecology for biomass, abundance, and size.</div>\",\n",
        "        'hedges_g': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>üéì About Hedges' g:</b> A variation of Cohen's d that includes a correction factor (J) for small sample sizes. It prevents overestimation of effects in small studies, making it the gold standard for SMD in meta-analysis.</div>\",\n",
        "        'cohen_d': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>üéì About Cohen's d:</b> The classic standardized mean difference. It is slightly biased (too high) when sample sizes are small (N < 20). Hedges' g is usually preferred.</div>\",\n",
        "        'log_or': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>üéì About logOR:</b> The log-odds ratio. Strictly for binary 'Yes/No' or 'Event/Non-event' data. Do not use for continuous measurements like weight or length.</div>\"\n",
        "    }\n",
        "\n",
        "    def update_info(change):\n",
        "        with info_output:\n",
        "            clear_output()\n",
        "            display(HTML(info_panels[change['new']]))\n",
        "\n",
        "    effect_size_widget.observe(update_info, names='value')\n",
        "    with info_output: display(HTML(info_panels[recommended_type]))\n",
        "\n",
        "    # 4. Confirm Button\n",
        "    proceed_button = widgets.Button(\n",
        "        description='‚úì Confirm Selection',\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='300px', height='40px'),\n",
        "        style={'font_weight': 'bold'}\n",
        "    )\n",
        "    proceed_output = widgets.Output()\n",
        "\n",
        "    def on_proceed(b):\n",
        "        with proceed_output:\n",
        "            clear_output()\n",
        "            sel = effect_size_widget.value\n",
        "            print(f\"‚úì Confirmed Selection: {sel}\")\n",
        "\n",
        "            # --- CONFIGURATION ---\n",
        "            es_configs = {\n",
        "                'lnRR': {\n",
        "                    'effect_col': 'lnRR', 'var_col': 'var_lnRR', 'se_col': 'SE_lnRR',\n",
        "                    'ci_lower_col': 'CI_lower_lnRR', 'ci_upper_col': 'CI_upper_lnRR',\n",
        "                    'effect_label': 'log Response Ratio', 'effect_label_short': 'lnRR',\n",
        "                    'has_fold_change': True, 'null_value': 0, 'scale': 'log', 'allows_negative': False\n",
        "                },\n",
        "                'hedges_g': {\n",
        "                    'effect_col': 'hedges_g', 'var_col': 'Vg', 'se_col': 'SE_g',\n",
        "                    'ci_lower_col': 'CI_lower_g', 'ci_upper_col': 'CI_upper_g',\n",
        "                    'effect_label': \"Hedges' g\", 'effect_label_short': 'g',\n",
        "                    'has_fold_change': False, 'null_value': 0, 'scale': 'standardized', 'allows_negative': True\n",
        "                },\n",
        "                'cohen_d': {\n",
        "                    'effect_col': 'cohen_d', 'var_col': 'Vd', 'se_col': 'SE_d',\n",
        "                    'ci_lower_col': 'CI_lower_d', 'ci_upper_col': 'CI_upper_d',\n",
        "                    'effect_label': \"Cohen's d\", 'effect_label_short': 'd',\n",
        "                    'has_fold_change': False, 'null_value': 0, 'scale': 'standardized', 'allows_negative': True\n",
        "                },\n",
        "                'log_or': {\n",
        "                    'effect_col': 'log_OR', 'var_col': 'var_log_OR', 'se_col': 'SE_log_OR',\n",
        "                    'ci_lower_col': 'CI_lower_log_OR', 'ci_upper_col': 'CI_upper_log_OR',\n",
        "                    'effect_label': 'log Odds Ratio', 'effect_label_short': 'logOR',\n",
        "                    'has_fold_change': True, 'null_value': 0, 'scale': 'log', 'allows_negative': False\n",
        "                }\n",
        "            }\n",
        "\n",
        "            ANALYSIS_CONFIG['effect_size_type'] = sel\n",
        "            ANALYSIS_CONFIG['es_config'] = es_configs[sel]\n",
        "\n",
        "            # Pre-set global vars\n",
        "            ANALYSIS_CONFIG['effect_col'] = es_configs[sel]['effect_col']\n",
        "            ANALYSIS_CONFIG['var_col'] = es_configs[sel]['var_col']\n",
        "            ANALYSIS_CONFIG['se_col'] = es_configs[sel]['se_col']\n",
        "\n",
        "            print(f\"‚úì Configuration saved. Please run the next cell to calculate values.\")\n",
        "\n",
        "    proceed_button.on_click(on_proceed)\n",
        "\n",
        "    display(widgets.VBox([\n",
        "        effect_size_widget,\n",
        "        info_output,\n",
        "        widgets.HTML(\"<br>\"),\n",
        "        proceed_button,\n",
        "        proceed_output\n",
        "    ]))\n",
        "\n",
        "# --- DISPLAY ---\n",
        "display(tabs)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y_DSJBpuxpBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üßÆ CALCULATE EFFECT SIZES (V2)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 5: EFFECT SIZE CALCULATION\n",
        "# Purpose: Calculate effect sizes, variances, and weights for meta-analysis\n",
        "# Fix: Corrected KeyError by using dynamic column names for filtering.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from scipy.special import gamma\n",
        "\n",
        "# --- 1. SETUP TABS ---\n",
        "tab_summary = widgets.Output()\n",
        "tab_diag = widgets.Output()\n",
        "tab_stats = widgets.Output()\n",
        "tab_interp = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_summary, tab_diag, tab_stats, tab_interp])\n",
        "tabs.set_title(0, 'üìä Summary')\n",
        "tabs.set_title(1, 'üìâ Diagnostics')\n",
        "tabs.set_title(2, 'üìè Detailed Stats')\n",
        "tabs.set_title(3, 'üß† Interpretation')\n",
        "\n",
        "# --- 2. CALCULATION ENGINE ---\n",
        "def run_calculation():\n",
        "    # Logs for different tabs\n",
        "    log_diag = []\n",
        "    log_summary = []\n",
        "\n",
        "    # --- CONFIG ---\n",
        "    try:\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "             print(\"‚ùå ERROR: ANALYSIS_CONFIG not found. Run Cell 4 first.\")\n",
        "             return\n",
        "        effect_size_type = ANALYSIS_CONFIG['effect_size_type']\n",
        "        es_config = ANALYSIS_CONFIG['es_config']\n",
        "        log_summary.append(f\"Configuration: {es_config['effect_label']} ({es_config['effect_label_short']})\")\n",
        "    except KeyError:\n",
        "        print(\"‚ùå ERROR: Configuration keys missing. Run Cell 4 first.\")\n",
        "        return\n",
        "\n",
        "    # --- DATA LOADING ---\n",
        "    if 'data_filtered' not in globals():\n",
        "        print(\"‚ùå ERROR: Data not found. Run Cell 3 first.\")\n",
        "        return\n",
        "\n",
        "    df = data_filtered.copy()\n",
        "    initial_obs = len(df)\n",
        "    initial_papers = df['id'].nunique()\n",
        "\n",
        "    # --- VALIDATION ---\n",
        "    req_cols = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "    missing = [c for c in req_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        print(f\"‚ùå ERROR: Missing columns: {missing}\")\n",
        "        return\n",
        "\n",
        "    # --- IMPUTATION (SD) ---\n",
        "    log_diag.append(\"<b>1. Standard Deviation Imputation</b>\")\n",
        "\n",
        "    # Handle zeros\n",
        "    if 'sde' in df.columns: df['sde'] = df['sde'].replace(0, np.nan)\n",
        "    if 'sdc' in df.columns: df['sdc'] = df['sdc'].replace(0, np.nan)\n",
        "\n",
        "    # Calculate CV\n",
        "    valid_e = (df['sde'] > 0) & (df['xe'] > 0)\n",
        "    valid_c = (df['sdc'] > 0) & (df['xc'] > 0)\n",
        "\n",
        "    # Calculate median CV for imputation (use default 0.1 if no valid data)\n",
        "    cv_e = (df.loc[valid_e, 'sde'] / df.loc[valid_e, 'xe']).median() if valid_e.any() else 0.1\n",
        "    cv_c = (df.loc[valid_c, 'sdc'] / df.loc[valid_c, 'xc']).median() if valid_c.any() else 0.1\n",
        "\n",
        "    df['sde_imputed'] = df['sde'].fillna(df['xe'] * cv_e)\n",
        "    df['sdc_imputed'] = df['sdc'].fillna(df['xc'] * cv_c)\n",
        "\n",
        "    n_imp_e = df['sde'].isna().sum()\n",
        "    n_imp_c = df['sdc'].isna().sum()\n",
        "\n",
        "    log_diag.append(f\"‚Ä¢ Imputed {n_imp_e} Exp SDs (using CV={cv_e:.4f})\")\n",
        "    log_diag.append(f\"‚Ä¢ Imputed {n_imp_c} Ctl SDs (using CV={cv_c:.4f})\")\n",
        "\n",
        "    # --- CLEANING (Negative/Zero) ---\n",
        "    log_diag.append(\"<br><b>2. Data Cleaning</b>\")\n",
        "\n",
        "    if effect_size_type in ['lnRR', 'log_or']:\n",
        "        # Remove negatives\n",
        "        neg_mask = (df['xe'] < 0) | (df['xc'] < 0)\n",
        "        n_neg = neg_mask.sum()\n",
        "        if n_neg > 0:\n",
        "            df = df[~neg_mask]\n",
        "            log_diag.append(f\"‚Ä¢ Removed {n_neg} rows with negative values (invalid for {effect_size_type})\")\n",
        "\n",
        "        # Handle zeros\n",
        "        zero_mask = (df['xe'] == 0) | (df['xc'] == 0)\n",
        "        n_zero = zero_mask.sum()\n",
        "        if n_zero > 0:\n",
        "            df.loc[zero_mask, ['xe', 'xc']] += 0.001\n",
        "            log_diag.append(f\"‚Ä¢ Adjusted {n_zero} rows with zero values (added 0.001)\")\n",
        "\n",
        "    # --- CALCULATION ---\n",
        "    # Initialize dynamic column names to avoid KeyErrors later\n",
        "    effect_col = es_config['effect_col']\n",
        "    var_col = es_config['var_col']\n",
        "    se_col = es_config['se_col']\n",
        "\n",
        "    if effect_size_type == 'lnRR':\n",
        "        df[effect_col] = np.log(df['xe'] / df['xc'])\n",
        "        df[var_col] = (df['sde_imputed']**2 / (df['ne']*df['xe']**2)) + (df['sdc_imputed']**2 / (df['nc']*df['xc']**2))\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "        # Fold Change\n",
        "        df['Response_Ratio'] = np.exp(df[effect_col])\n",
        "        df['fold_change'] = df.apply(lambda r: r['Response_Ratio'] if r[effect_col]>=0 else -1/r['Response_Ratio'], axis=1)\n",
        "        df['Percent_Change'] = (df['Response_Ratio'] - 1) * 100\n",
        "\n",
        "    elif effect_size_type == 'hedges_g':\n",
        "        df['df'] = df['ne'] + df['nc'] - 2\n",
        "        df['sp'] = np.sqrt(((df['ne']-1)*df['sde_imputed']**2 + (df['nc']-1)*df['sdc_imputed']**2) / df['df'])\n",
        "        df['d'] = (df['xe'] - df['xc']) / df['sp']\n",
        "\n",
        "        # Exact Gamma correction\n",
        "        m = df['df']\n",
        "        df['J'] = gamma(m/2) / (np.sqrt(m/2) * gamma((m-1)/2))\n",
        "\n",
        "        df[effect_col] = df['d'] * df['J']\n",
        "        df[var_col] = ((df['ne']+df['nc']) / (df['ne']*df['nc']) + (df[effect_col]**2)/(2*(df['ne']+df['nc']))) * df['J']**2\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    elif effect_size_type == 'cohen_d':\n",
        "        df['df'] = df['ne'] + df['nc'] - 2\n",
        "        df['sp'] = np.sqrt(((df['ne']-1)*df['sde_imputed']**2 + (df['nc']-1)*df['sdc_imputed']**2) / df['df'])\n",
        "        df[effect_col] = (df['xe'] - df['xc']) / df['sp']\n",
        "        df[var_col] = (df['ne']+df['nc']) / (df['ne']*df['nc']) + (df[effect_col]**2)/(2*(df['ne']+df['nc']))\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    elif effect_size_type == 'log_or':\n",
        "        # Simplified logOR\n",
        "        df[effect_col] = np.log(df['xe'] / df['xc'])\n",
        "        df[var_col] = (1/df['xe'] + 1/df['ne'] + 1/df['xc'] + 1/df['nc'])\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    # --- CI & WEIGHTS ---\n",
        "    # Use dynamic column names from es_config\n",
        "    ci_lower_col = es_config.get('ci_lower_col', f\"CI_lower_{es_config['effect_label_short']}\")\n",
        "    ci_upper_col = es_config.get('ci_upper_col', f\"CI_upper_{es_config['effect_label_short']}\")\n",
        "\n",
        "    df[ci_lower_col] = df[effect_col] - 1.96 * df[se_col]\n",
        "    df[ci_upper_col] = df[effect_col] + 1.96 * df[se_col]\n",
        "    df['w_fixed'] = 1 / df[var_col]\n",
        "\n",
        "    # --- FINAL CLEANING ---\n",
        "    # Use the DYNAMIC variable names, not hardcoded strings\n",
        "    df = df.dropna(subset=[effect_col, var_col]).copy()\n",
        "    df = df[df[var_col] > 0].copy()\n",
        "\n",
        "    # --- UPDATE CONFIG ---\n",
        "    ANALYSIS_CONFIG['analysis_data'] = df\n",
        "    # Ensure these match what was used\n",
        "    ANALYSIS_CONFIG['effect_col'] = effect_col\n",
        "    ANALYSIS_CONFIG['var_col'] = var_col\n",
        "    ANALYSIS_CONFIG['se_col'] = se_col\n",
        "    ANALYSIS_CONFIG['ci_lower_col'] = ci_lower_col\n",
        "    ANALYSIS_CONFIG['ci_upper_col'] = ci_upper_col\n",
        "\n",
        "    # --- POPULATE TABS ---\n",
        "\n",
        "    # 1. SUMMARY TAB\n",
        "    with tab_summary:\n",
        "        clear_output()\n",
        "        final_n = len(df)\n",
        "        final_papers = df['id'].nunique()\n",
        "\n",
        "        html_sum = f\"\"\"\n",
        "        <div style='display:flex; gap:20px; margin-bottom:20px;'>\n",
        "            <div style='background:#e8f5e9; padding:15px; border-radius:8px; flex:1; text-align:center;'>\n",
        "                <h2 style='margin:0; color:#2e7d32;'>{final_n}</h2>\n",
        "                <p style='margin:0; color:#1b5e20;'>Observations</p>\n",
        "            </div>\n",
        "            <div style='background:#e3f2fd; padding:15px; border-radius:8px; flex:1; text-align:center;'>\n",
        "                <h2 style='margin:0; color:#1565c0;'>{final_papers}</h2>\n",
        "                <p style='margin:0; color:#0d47a1;'>Studies</p>\n",
        "            </div>\n",
        "            <div style='background:#fff3e0; padding:15px; border-radius:8px; flex:1; text-align:center;'>\n",
        "                <h2 style='margin:0; color:#e65100;'>{initial_obs - final_n}</h2>\n",
        "                <p style='margin:0; color:#bf360c;'>Removed</p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='padding:10px; border-left:4px solid #2E86AB; background:#f8f9fa;'>\n",
        "            <b>‚úÖ Status:</b> Calculation complete using <b>{es_config['effect_label']}</b>.<br>\n",
        "            Data is ready for Meta-Analysis.\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(html_sum))\n",
        "\n",
        "        # Stats Summary\n",
        "        if not df.empty:\n",
        "            desc = df[effect_col].describe()\n",
        "            print(f\"\\nüìä {es_config['effect_label']} Statistics:\")\n",
        "            print(f\"   Mean:   {desc['mean']:.4f}\")\n",
        "            print(f\"   Median: {desc['50%']:.4f}\")\n",
        "            print(f\"   Min:    {desc['min']:.4f}\")\n",
        "            print(f\"   Max:    {desc['max']:.4f}\")\n",
        "            print(f\"   StdDev: {desc['std']:.4f}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No valid data remaining.\")\n",
        "\n",
        "    # 2. DIAGNOSTICS TAB\n",
        "    with tab_diag:\n",
        "        clear_output()\n",
        "        display(HTML(\"<b>üîç Processing Log:</b>\"))\n",
        "        for line in log_diag:\n",
        "            display(HTML(line))\n",
        "\n",
        "        if not df.empty:\n",
        "            # Outliers\n",
        "            q1, q3 = df[effect_col].quantile([0.25, 0.75])\n",
        "            iqr = q3 - q1\n",
        "            outliers = df[(df[effect_col] < q1 - 1.5*iqr) | (df[effect_col] > q3 + 1.5*iqr)]\n",
        "\n",
        "            display(HTML(\"<br><b>‚ö†Ô∏è Outlier Check (IQR Method):</b>\"))\n",
        "            if len(outliers) > 0:\n",
        "                print(f\"   Found {len(outliers)} potential outliers.\")\n",
        "                print(f\"   Range: {outliers[effect_col].min():.2f} to {outliers[effect_col].max():.2f}\")\n",
        "            else:\n",
        "                print(\"   No statistical outliers detected.\")\n",
        "\n",
        "    # 3. DETAILED STATS TAB\n",
        "    with tab_stats:\n",
        "        clear_output()\n",
        "        if not df.empty:\n",
        "            # Create a nice summary table\n",
        "            stats_df = pd.DataFrame({\n",
        "                'Effect Size': df[effect_col].describe(),\n",
        "                'Variance': df[var_col].describe(),\n",
        "                'Standard Error': df[se_col].describe(),\n",
        "                'Weight (Fixed)': df['w_fixed'].describe()\n",
        "            })\n",
        "            display(stats_df.round(4))\n",
        "\n",
        "            print(\"\\nüìã Preview (First 5 rows):\")\n",
        "            cols_show = ['id', 'xe', 'xc', 'ne', 'nc', effect_col, se_col]\n",
        "            display(df[cols_show].head())\n",
        "\n",
        "    # 4. INTERPRETATION TAB\n",
        "    with tab_interp:\n",
        "        clear_output()\n",
        "        if not df.empty:\n",
        "            # Direction\n",
        "            n_pos = (df[effect_col] > 0).sum()\n",
        "            n_neg = (df[effect_col] < 0).sum()\n",
        "\n",
        "            # Magnitude (Cohen's benchmarks for g/d)\n",
        "            if effect_size_type in ['hedges_g', 'cohen_d']:\n",
        "                mag_small = ((df[effect_col].abs() >= 0.2) & (df[effect_col].abs() < 0.5)).sum()\n",
        "                mag_med = ((df[effect_col].abs() >= 0.5) & (df[effect_col].abs() < 0.8)).sum()\n",
        "                mag_large = (df[effect_col].abs() >= 0.8).sum()\n",
        "\n",
        "                mag_html = f\"\"\"\n",
        "                <br><b>üìè Magnitude (Cohen's Benchmarks):</b>\n",
        "                <ul>\n",
        "                    <li><b>Small (0.2-0.5):</b> {mag_small} ({mag_small/len(df):.1%})</li>\n",
        "                    <li><b>Medium (0.5-0.8):</b> {mag_med} ({mag_med/len(df):.1%})</li>\n",
        "                    <li><b>Large (>0.8):</b> {mag_large} ({mag_large/len(df):.1%})</li>\n",
        "                </ul>\n",
        "                \"\"\"\n",
        "            else:\n",
        "                mag_html = \"\"\n",
        "\n",
        "            html_interp = f\"\"\"\n",
        "            <div style='font-size:14px;'>\n",
        "                <h4>üìà Effect Direction</h4>\n",
        "                <ul>\n",
        "                    <li><b>Positive Effect:</b> {n_pos} studies ({n_pos/len(df):.1%})<br>\n",
        "                    <i>(Treatment > Control)</i></li>\n",
        "                    <li><b>Negative Effect:</b> {n_neg} studies ({n_neg/len(df):.1%})<br>\n",
        "                    <i>(Treatment < Control)</i></li>\n",
        "                </ul>\n",
        "\n",
        "                {mag_html}\n",
        "\n",
        "                <br><b>üéØ Precision Check</b>\n",
        "                <ul>\n",
        "                    <li><b>Mean CI Width:</b> {(df[ANALYSIS_CONFIG['ci_upper_col']] - df[ANALYSIS_CONFIG['ci_lower_col']]).mean():.4f}</li>\n",
        "                    <li><b>Zero Variance Studies:</b> {(df[var_col] == 0).sum()} (Removed)</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(html_interp))\n",
        "\n",
        "# --- 3. RUN ---\n",
        "run_calculation()\n",
        "display(tabs)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a2QZg1GYpjH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üßÆ CALCULATE EFFECT SIZES (V2.1)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 5: EFFECT SIZE CALCULATION (Validation Fix)\n",
        "# Purpose: Calculate effect sizes, variances, and weights for meta-analysis\n",
        "# Fix: Aligned Hedges' g variance formula with R (metafor) standards.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from scipy.special import gamma\n",
        "\n",
        "# --- 1. SETUP TABS ---\n",
        "tab_summary = widgets.Output()\n",
        "tab_diag = widgets.Output()\n",
        "tab_stats = widgets.Output()\n",
        "tab_interp = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_summary, tab_diag, tab_stats, tab_interp])\n",
        "tabs.set_title(0, 'üìä Summary')\n",
        "tabs.set_title(1, 'üìâ Diagnostics')\n",
        "tabs.set_title(2, 'üìè Detailed Stats')\n",
        "tabs.set_title(3, 'üß† Interpretation')\n",
        "\n",
        "# --- 2. CALCULATION ENGINE ---\n",
        "def run_calculation():\n",
        "    # Logs for different tabs\n",
        "    log_diag = []\n",
        "    log_summary = []\n",
        "\n",
        "    # --- CONFIG ---\n",
        "    try:\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "             print(\"‚ùå ERROR: ANALYSIS_CONFIG not found. Run Cell 4 first.\")\n",
        "             return\n",
        "        effect_size_type = ANALYSIS_CONFIG['effect_size_type']\n",
        "        es_config = ANALYSIS_CONFIG['es_config']\n",
        "        log_summary.append(f\"Configuration: {es_config['effect_label']} ({es_config['effect_label_short']})\")\n",
        "    except KeyError:\n",
        "        print(\"‚ùå ERROR: Configuration keys missing. Run Cell 4 first.\")\n",
        "        return\n",
        "\n",
        "    # --- DATA LOADING ---\n",
        "    if 'data_filtered' not in globals():\n",
        "        print(\"‚ùå ERROR: Data not found. Run Cell 3 first.\")\n",
        "        return\n",
        "\n",
        "    df = data_filtered.copy()\n",
        "    initial_obs = len(df)\n",
        "    initial_papers = df['id'].nunique()\n",
        "\n",
        "    # --- VALIDATION ---\n",
        "    req_cols = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "    missing = [c for c in req_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        print(f\"‚ùå ERROR: Missing columns: {missing}\")\n",
        "        return\n",
        "\n",
        "    # --- IMPUTATION (SD) ---\n",
        "    log_diag.append(\"<b>1. Standard Deviation Imputation</b>\")\n",
        "\n",
        "    # Handle zeros\n",
        "    if 'sde' in df.columns: df['sde'] = df['sde'].replace(0, np.nan)\n",
        "    if 'sdc' in df.columns: df['sdc'] = df['sdc'].replace(0, np.nan)\n",
        "\n",
        "    # Calculate CV\n",
        "    valid_e = (df['sde'] > 0) & (df['xe'] > 0)\n",
        "    valid_c = (df['sdc'] > 0) & (df['xc'] > 0)\n",
        "\n",
        "    # Calculate median CV for imputation (use default 0.1 if no valid data)\n",
        "    cv_e = (df.loc[valid_e, 'sde'] / df.loc[valid_e, 'xe']).median() if valid_e.any() else 0.1\n",
        "    cv_c = (df.loc[valid_c, 'sdc'] / df.loc[valid_c, 'xc']).median() if valid_c.any() else 0.1\n",
        "\n",
        "    df['sde_imputed'] = df['sde'].fillna(df['xe'] * cv_e)\n",
        "    df['sdc_imputed'] = df['sdc'].fillna(df['xc'] * cv_c)\n",
        "\n",
        "    n_imp_e = df['sde'].isna().sum()\n",
        "    n_imp_c = df['sdc'].isna().sum()\n",
        "\n",
        "    log_diag.append(f\"‚Ä¢ Imputed {n_imp_e} Exp SDs (using CV={cv_e:.4f})\")\n",
        "    log_diag.append(f\"‚Ä¢ Imputed {n_imp_c} Ctl SDs (using CV={cv_c:.4f})\")\n",
        "\n",
        "    # --- CLEANING (Negative/Zero) ---\n",
        "    log_diag.append(\"<br><b>2. Data Cleaning</b>\")\n",
        "\n",
        "    if effect_size_type in ['lnRR', 'log_or']:\n",
        "        # Remove negatives\n",
        "        neg_mask = (df['xe'] < 0) | (df['xc'] < 0)\n",
        "        n_neg = neg_mask.sum()\n",
        "        if n_neg > 0:\n",
        "            df = df[~neg_mask]\n",
        "            log_diag.append(f\"‚Ä¢ Removed {n_neg} rows with negative values (invalid for {effect_size_type})\")\n",
        "\n",
        "        # Handle zeros\n",
        "        zero_mask = (df['xe'] == 0) | (df['xc'] == 0)\n",
        "        n_zero = zero_mask.sum()\n",
        "        if n_zero > 0:\n",
        "            df.loc[zero_mask, ['xe', 'xc']] += 0.001\n",
        "            log_diag.append(f\"‚Ä¢ Adjusted {n_zero} rows with zero values (added 0.001)\")\n",
        "\n",
        "    # --- CALCULATION ---\n",
        "    # Initialize dynamic column names to avoid KeyErrors later\n",
        "    effect_col = es_config['effect_col']\n",
        "    var_col = es_config['var_col']\n",
        "    se_col = es_config['se_col']\n",
        "\n",
        "    if effect_size_type == 'lnRR':\n",
        "        df[effect_col] = np.log(df['xe'] / df['xc'])\n",
        "        df[var_col] = (df['sde_imputed']**2 / (df['ne']*df['xe']**2)) + (df['sdc_imputed']**2 / (df['nc']*df['xc']**2))\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "        # Fold Change\n",
        "        df['Response_Ratio'] = np.exp(df[effect_col])\n",
        "        df['fold_change'] = df.apply(lambda r: r['Response_Ratio'] if r[effect_col]>=0 else -1/r['Response_Ratio'], axis=1)\n",
        "        df['Percent_Change'] = (df['Response_Ratio'] - 1) * 100\n",
        "\n",
        "    elif effect_size_type == 'hedges_g':\n",
        "        df['df'] = df['ne'] + df['nc'] - 2\n",
        "        df['sp'] = np.sqrt(((df['ne']-1)*df['sde_imputed']**2 + (df['nc']-1)*df['sdc_imputed']**2) / df['df'])\n",
        "        df['d'] = (df['xe'] - df['xc']) / df['sp']\n",
        "\n",
        "        # Exact Gamma correction\n",
        "        m = df['df']\n",
        "        df['J'] = gamma(m/2) / (np.sqrt(m/2) * gamma((m-1)/2))\n",
        "\n",
        "        df[effect_col] = df['d'] * df['J']\n",
        "\n",
        "        # --- VARIANCE FIX ---\n",
        "        # Use standard Large Sample approximation to match R (metafor)\n",
        "        # Vg = 1/ne + 1/nc + g^2 / (2*(ne+nc))\n",
        "        df[var_col] = (1/df['ne']) + (1/df['nc']) + (df[effect_col]**2 / (2*(df['ne'] + df['nc'])))\n",
        "\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    elif effect_size_type == 'cohen_d':\n",
        "        df['df'] = df['ne'] + df['nc'] - 2\n",
        "        df['sp'] = np.sqrt(((df['ne']-1)*df['sde_imputed']**2 + (df['nc']-1)*df['sdc_imputed']**2) / df['df'])\n",
        "        df[effect_col] = (df['xe'] - df['xc']) / df['sp']\n",
        "        df[var_col] = (df['ne']+df['nc']) / (df['ne']*df['nc']) + (df[effect_col]**2)/(2*(df['ne']+df['nc']))\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    elif effect_size_type == 'log_or':\n",
        "        # Simplified logOR\n",
        "        df[effect_col] = np.log(df['xe'] / df['xc'])\n",
        "        df[var_col] = (1/df['xe'] + 1/df['ne'] + 1/df['xc'] + 1/df['nc'])\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    # --- CI & WEIGHTS ---\n",
        "    # Use dynamic column names from es_config\n",
        "    ci_lower_col = es_config.get('ci_lower_col', f\"CI_lower_{es_config['effect_label_short']}\")\n",
        "    ci_upper_col = es_config.get('ci_upper_col', f\"CI_upper_{es_config['effect_label_short']}\")\n",
        "\n",
        "    df[ci_lower_col] = df[effect_col] - 1.96 * df[se_col]\n",
        "    df[ci_upper_col] = df[effect_col] + 1.96 * df[se_col]\n",
        "    df['w_fixed'] = 1 / df[var_col]\n",
        "\n",
        "    # --- FINAL CLEANING ---\n",
        "    # Use the DYNAMIC variable names, not hardcoded strings\n",
        "    df = df.dropna(subset=[effect_col, var_col]).copy()\n",
        "    df = df[df[var_col] > 0].copy()\n",
        "\n",
        "    # --- UPDATE CONFIG ---\n",
        "    ANALYSIS_CONFIG['analysis_data'] = df\n",
        "    # Ensure these match what was used\n",
        "    ANALYSIS_CONFIG['effect_col'] = effect_col\n",
        "    ANALYSIS_CONFIG['var_col'] = var_col\n",
        "    ANALYSIS_CONFIG['se_col'] = se_col\n",
        "    ANALYSIS_CONFIG['ci_lower_col'] = ci_lower_col\n",
        "    ANALYSIS_CONFIG['ci_upper_col'] = ci_upper_col\n",
        "\n",
        "    # --- POPULATE TABS ---\n",
        "\n",
        "    # 1. SUMMARY TAB\n",
        "    with tab_summary:\n",
        "        clear_output()\n",
        "        final_n = len(df)\n",
        "        final_papers = df['id'].nunique()\n",
        "\n",
        "        html_sum = f\"\"\"\n",
        "        <div style='display:flex; gap:20px; margin-bottom:20px;'>\n",
        "            <div style='background:#e8f5e9; padding:15px; border-radius:8px; flex:1; text-align:center;'>\n",
        "                <h2 style='margin:0; color:#2e7d32;'>{final_n}</h2>\n",
        "                <p style='margin:0; color:#1b5e20;'>Observations</p>\n",
        "            </div>\n",
        "            <div style='background:#e3f2fd; padding:15px; border-radius:8px; flex:1; text-align:center;'>\n",
        "                <h2 style='margin:0; color:#1565c0;'>{final_papers}</h2>\n",
        "                <p style='margin:0; color:#0d47a1;'>Studies</p>\n",
        "            </div>\n",
        "            <div style='background:#fff3e0; padding:15px; border-radius:8px; flex:1; text-align:center;'>\n",
        "                <h2 style='margin:0; color:#e65100;'>{initial_obs - final_n}</h2>\n",
        "                <p style='margin:0; color:#bf360c;'>Removed</p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='padding:10px; border-left:4px solid #2E86AB; background:#f8f9fa;'>\n",
        "            <b>‚úÖ Status:</b> Calculation complete using <b>{es_config['effect_label']}</b>.<br>\n",
        "            Data is ready for Meta-Analysis.\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(html_sum))\n",
        "\n",
        "        # Stats Summary\n",
        "        if not df.empty:\n",
        "            desc = df[effect_col].describe()\n",
        "            print(f\"\\nüìä {es_config['effect_label']} Statistics:\")\n",
        "            print(f\"   Mean:   {desc['mean']:.4f}\")\n",
        "            print(f\"   Median: {desc['50%']:.4f}\")\n",
        "            print(f\"   Min:    {desc['min']:.4f}\")\n",
        "            print(f\"   Max:    {desc['max']:.4f}\")\n",
        "            print(f\"   StdDev: {desc['std']:.4f}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No valid data remaining.\")\n",
        "\n",
        "    # 2. DIAGNOSTICS TAB\n",
        "    with tab_diag:\n",
        "        clear_output()\n",
        "        display(HTML(\"<b>üîç Processing Log:</b>\"))\n",
        "        for line in log_diag:\n",
        "            display(HTML(line))\n",
        "\n",
        "        if not df.empty:\n",
        "            # Outliers\n",
        "            q1, q3 = df[effect_col].quantile([0.25, 0.75])\n",
        "            iqr = q3 - q1\n",
        "            outliers = df[(df[effect_col] < q1 - 1.5*iqr) | (df[effect_col] > q3 + 1.5*iqr)]\n",
        "\n",
        "            display(HTML(\"<br><b>‚ö†Ô∏è Outlier Check (IQR Method):</b>\"))\n",
        "            if len(outliers) > 0:\n",
        "                print(f\"   Found {len(outliers)} potential outliers.\")\n",
        "                print(f\"   Range: {outliers[effect_col].min():.2f} to {outliers[effect_col].max():.2f}\")\n",
        "            else:\n",
        "                print(\"   No statistical outliers detected.\")\n",
        "\n",
        "    # 3. DETAILED STATS TAB\n",
        "    with tab_stats:\n",
        "        clear_output()\n",
        "        if not df.empty:\n",
        "            # Create a nice summary table\n",
        "            stats_df = pd.DataFrame({\n",
        "                'Effect Size': df[effect_col].describe(),\n",
        "                'Variance': df[var_col].describe(),\n",
        "                'Standard Error': df[se_col].describe(),\n",
        "                'Weight (Fixed)': df['w_fixed'].describe()\n",
        "            })\n",
        "            display(stats_df.round(4))\n",
        "\n",
        "            print(\"\\nüìã Preview (First 5 rows):\")\n",
        "            cols_show = ['id', 'xe', 'xc', 'ne', 'nc', effect_col, se_col]\n",
        "            display(df[cols_show].head())\n",
        "\n",
        "    # 4. INTERPRETATION TAB\n",
        "    with tab_interp:\n",
        "        clear_output()\n",
        "        if not df.empty:\n",
        "            # Direction\n",
        "            n_pos = (df[effect_col] > 0).sum()\n",
        "            n_neg = (df[effect_col] < 0).sum()\n",
        "\n",
        "            # Magnitude (Cohen's benchmarks for g/d)\n",
        "            if effect_size_type in ['hedges_g', 'cohen_d']:\n",
        "                mag_small = ((df[effect_col].abs() >= 0.2) & (df[effect_col].abs() < 0.5)).sum()\n",
        "                mag_med = ((df[effect_col].abs() >= 0.5) & (df[effect_col].abs() < 0.8)).sum()\n",
        "                mag_large = (df[effect_col].abs() >= 0.8).sum()\n",
        "\n",
        "                mag_html = f\"\"\"\n",
        "                <br><b>üìè Magnitude (Cohen's Benchmarks):</b>\n",
        "                <ul>\n",
        "                    <li><b>Small (0.2-0.5):</b> {mag_small} ({mag_small/len(df):.1%})</li>\n",
        "                    <li><b>Medium (0.5-0.8):</b> {mag_med} ({mag_med/len(df):.1%})</li>\n",
        "                    <li><b>Large (>0.8):</b> {mag_large} ({mag_large/len(df):.1%})</li>\n",
        "                </ul>\n",
        "                \"\"\"\n",
        "            else:\n",
        "                mag_html = \"\"\n",
        "\n",
        "            html_interp = f\"\"\"\n",
        "            <div style='font-size:14px;'>\n",
        "                <h4>üìà Effect Direction</h4>\n",
        "                <ul>\n",
        "                    <li><b>Positive Effect:</b> {n_pos} studies ({n_pos/len(df):.1%})<br>\n",
        "                    <i>(Treatment > Control)</i></li>\n",
        "                    <li><b>Negative Effect:</b> {n_neg} studies ({n_neg/len(df):.1%})<br>\n",
        "                    <i>(Treatment < Control)</i></li>\n",
        "                </ul>\n",
        "\n",
        "                {mag_html}\n",
        "\n",
        "                <br><b>üéØ Precision Check</b>\n",
        "                <ul>\n",
        "                    <li><b>Mean CI Width:</b> {(df[ANALYSIS_CONFIG['ci_upper_col']] - df[ANALYSIS_CONFIG['ci_lower_col']]).mean():.4f}</li>\n",
        "                    <li><b>Zero Variance Studies:</b> {(df[var_col] == 0).sum()} (Removed)</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(html_interp))\n",
        "\n",
        "# --- 3. RUN ---\n",
        "run_calculation()\n",
        "display(tabs)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gZgcCHLi5f8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä Step 2: Overall Meta-Analysis (V2)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL: OVERALL META-ANALYSIS (DASHBOARD)\n",
        "# Purpose: Calculate pooled effects (Standard & 3-Level) and display as a dashboard.\n",
        "# Enhancement: Added publication-ready text template tab.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import datetime\n",
        "from scipy.stats import norm, chi2, t\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# --- 1. LAYOUT & WIDGETS ---\n",
        "tab_main = widgets.Output()\n",
        "tab_hetero = widgets.Output()\n",
        "tab_compare = widgets.Output()\n",
        "tab_settings = widgets.Output()\n",
        "tab_publication = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_main, tab_hetero, tab_compare, tab_settings, tab_publication])\n",
        "tabs.set_title(0, 'üìä Primary Result')\n",
        "tabs.set_title(1, 'üìâ Heterogeneity')\n",
        "tabs.set_title(2, '‚öñÔ∏è Model Comparison')\n",
        "tabs.set_title(3, '‚öôÔ∏è Settings')\n",
        "tabs.set_title(4, 'üìù Publication Text')\n",
        "\n",
        "# Settings Widgets\n",
        "method_options = ['REML', 'DL', 'ML', 'PM', 'SJ'] if 'calculate_tau_squared' in globals() else ['DL']\n",
        "tau_method_widget = widgets.Dropdown(options=method_options, value='REML' if 'REML' in method_options else 'DL', description='œÑ¬≤ Method:')\n",
        "use_kh_widget = widgets.Checkbox(value=True, description='Knapp-Hartung Correction')\n",
        "\n",
        "# --- 2. ENGINE: 3-LEVEL OPTIMIZER ---\n",
        "def _run_three_level_reml(df, effect_col, var_col):\n",
        "    \"\"\"Core 3-Level Optimizer.\"\"\"\n",
        "    grouped = df.groupby('id')\n",
        "    y_all = [g[effect_col].values for _, g in grouped]\n",
        "    v_all = [g[var_col].values for _, g in grouped]\n",
        "    N, M = len(df), len(y_all)\n",
        "\n",
        "    def nll(params):\n",
        "        tau2, sigma2 = params\n",
        "        if tau2 < 0 or sigma2 < 0: return np.inf\n",
        "        ll = 0; sum_S = 0; sum_Sy = 0; sum_ySy = 0\n",
        "        for i in range(M):\n",
        "            y, v = y_all[i], v_all[i]\n",
        "            A_inv = 1.0 / (v + sigma2)\n",
        "            sum_A_inv = np.sum(A_inv)\n",
        "            denom = 1 + tau2 * sum_A_inv\n",
        "\n",
        "            ll += np.sum(np.log(v + sigma2)) + np.log(denom)\n",
        "\n",
        "            w_y = A_inv * y - (tau2 * A_inv * np.sum(A_inv * y)) / denom\n",
        "            w_1 = A_inv - (tau2 * A_inv * sum_A_inv) / denom\n",
        "\n",
        "            sum_S += np.sum(w_1)\n",
        "            sum_Sy += np.sum(w_y)\n",
        "            sum_ySy += np.dot(y, w_y)\n",
        "\n",
        "        mu = sum_Sy / sum_S\n",
        "        resid = sum_ySy - 2*mu*sum_Sy + mu**2 * sum_S\n",
        "        return 0.5 * (ll + np.log(sum_S) + resid)\n",
        "\n",
        "    # Optimize\n",
        "    res = minimize(nll, [0.01, 0.01], bounds=[(1e-8, None)]*2, method='L-BFGS-B', options={'ftol':1e-9})\n",
        "    if not res.success: res = minimize(nll, [0.1, 0.1], bounds=[(1e-8, None)]*2, method='Nelder-Mead')\n",
        "\n",
        "    tau2, sigma2 = res.x\n",
        "\n",
        "    # Re-calc stats at optimum\n",
        "    sum_S = 0; sum_Sy = 0\n",
        "    for i in range(M):\n",
        "        y, v = y_all[i], v_all[i]\n",
        "        A_inv = 1.0 / (v + sigma2)\n",
        "        denom = 1 + tau2 * np.sum(A_inv)\n",
        "        w_y = A_inv * y - (tau2 * A_inv * np.sum(A_inv * y)) / denom\n",
        "        w_1 = A_inv - (tau2 * A_inv * np.sum(A_inv)) / denom\n",
        "        sum_S += np.sum(w_1)\n",
        "        sum_Sy += np.sum(w_y)\n",
        "\n",
        "    mu = sum_Sy / sum_S\n",
        "    se = np.sqrt(1.0 / sum_S)\n",
        "\n",
        "    total_var = tau2 + sigma2\n",
        "    icc_l3 = (tau2 / total_var * 100) if total_var > 0 else 0\n",
        "    icc_l2 = (sigma2 / total_var * 100) if total_var > 0 else 0\n",
        "\n",
        "    return {'mu': mu, 'se': se, 'tau2': tau2, 'sigma2': sigma2, 'icc_l3': icc_l3, 'icc_l2': icc_l2, 'n': N, 'm': M}\n",
        "\n",
        "# --- 2.5 PUBLICATION TEXT GENERATOR ---\n",
        "def generate_publication_text(mu_p, ci_lo_p, ci_hi_p, p_p, tau2_re, I2, Q, df_Q, p_Q, k_obs, k_studies,\n",
        "                               method, use_kh, res_3l, mu_fe, ci_lower_fixed, ci_upper_fixed,\n",
        "                               mu_re, ci_lo_re, ci_hi_re, es_config):\n",
        "    \"\"\"Generate publication-ready text\"\"\"\n",
        "\n",
        "    # Determine effect size type\n",
        "    es_type = es_config.get('type', 'effect size')\n",
        "    es_description = {\n",
        "        \"Hedges' g\": \"Effect sizes were calculated as Hedges' g, a standardized mean difference corrected for small sample bias.\",\n",
        "        'lnRR': \"Effect sizes were expressed as log response ratios (lnRR), calculated as the natural logarithm of the ratio between treatment and control group means.\",\n",
        "        'SMD': \"Effect sizes were calculated as standardized mean differences (SMD).\",\n",
        "        'Cohen\\'s d': \"Effect sizes were calculated as Cohen's d, a standardized mean difference.\"\n",
        "    }.get(es_type, f\"Effect sizes were calculated as {es_type}.\")\n",
        "\n",
        "    # Significance determination\n",
        "    sig_text = \"significant\" if p_p < 0.05 else \"non-significant\"\n",
        "    p_format = f\"< {p_p:.3f}\" if p_p < 0.001 else f\"= {p_p:.3f}\"\n",
        "\n",
        "    # Effect interpretation (can be customized by user)\n",
        "    if abs(mu_p) < 0.2:\n",
        "        effect_interp = \"indicating a negligible effect\"\n",
        "    elif abs(mu_p) < 0.5:\n",
        "        effect_interp = \"indicating a small effect\"\n",
        "    elif abs(mu_p) < 0.8:\n",
        "        effect_interp = \"indicating a moderate effect\"\n",
        "    else:\n",
        "        effect_interp = \"indicating a large effect\"\n",
        "\n",
        "    # Heterogeneity interpretation\n",
        "    if I2 < 25:\n",
        "        het_interp = \"indicating low heterogeneity\"\n",
        "    elif I2 < 50:\n",
        "        het_interp = \"indicating moderate heterogeneity\"\n",
        "    elif I2 < 75:\n",
        "        het_interp = \"indicating substantial heterogeneity\"\n",
        "    else:\n",
        "        het_interp = \"indicating considerable heterogeneity\"\n",
        "\n",
        "    # Build text\n",
        "    text = f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt; line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "<h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>Overall Meta-Analysis Results</h3>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "A total of <b>{k_obs}</b> effect sizes from <b>{k_studies}</b> independent studies were included in the meta-analysis. {es_description}\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "\"\"\"\n",
        "\n",
        "    # Primary result\n",
        "    if res_3l:\n",
        "        text += f\"\"\"The three-level random-effects meta-analysis revealed a <b>{sig_text}</b> overall effect (pooled effect = <b>{mu_p:.3f}</b>, 95% CI [{ci_lo_p:.3f}, {ci_hi_p:.3f}], <i>p</i> {p_format}), {effect_interp}. The three-level model was employed to account for the dependency structure arising from multiple effect sizes nested within studies.\n",
        "</p>\n",
        "\"\"\"\n",
        "        # Fold change for lnRR\n",
        "        if es_config.get('has_fold_change', False):\n",
        "            RR = np.exp(mu_p)\n",
        "            if mu_p >= 0:\n",
        "                fold_text = f\"{RR:.2f}√ó increase\"\n",
        "                pct = (RR - 1) * 100\n",
        "                pct_text = f\"{pct:.1f}% increase\"\n",
        "            else:\n",
        "                fold_text = f\"{1/RR:.2f}√ó decrease\"\n",
        "                pct = (1 - RR) * 100\n",
        "                pct_text = f\"{pct:.1f}% decrease\"\n",
        "            text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "This corresponds to a <b>{fold_text}</b> in the response variable (equivalent to a <b>{pct_text}</b>).\n",
        "</p>\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"The random-effects meta-analysis revealed a <b>{sig_text}</b> overall effect (pooled effect = <b>{mu_p:.3f}</b>, 95% CI [{ci_lo_p:.3f}, {ci_hi_p:.3f}], <i>p</i> {p_format}), {effect_interp}.\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    # Heterogeneity\n",
        "    text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "{'Substantial' if I2 >= 50 else 'Moderate' if I2 >= 25 else 'Low'} heterogeneity was observed among the effect sizes (<i>Q</i>({df_Q}) = {Q:.2f}, <i>p</i> < 0.001, <i>I</i>¬≤ = <b>{I2:.1f}%</b>, œÑ¬≤ = {tau2_re:.4f}), {het_interp}. The between-study variance (œÑ¬≤) was estimated at <b>{tau2_re:.4f}</b> using the <b>{method}</b> estimator.\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    # 3-Level variance decomposition\n",
        "    if res_3l:\n",
        "        text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "Variance decomposition in the three-level model indicated that <b>{res_3l['icc_l3']:.1f}%</b> of the total variance was attributable to between-study heterogeneity (œÑ¬≤ = {res_3l['tau2']:.4f}), while <b>{res_3l['icc_l2']:.1f}%</b> was due to within-study variance (œÉ¬≤ = {res_3l['sigma2']:.4f}), with the remaining variance attributable to sampling error.\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    # Statistical approach\n",
        "    text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "\"\"\"\n",
        "    if use_kh:\n",
        "        text += f\"\"\"Confidence intervals and <i>p</i>-values were adjusted using the Knapp-Hartung correction with a <i>t</i>-distribution (df = {df_Q}), which provides more conservative estimates appropriate for meta-analyses with fewer than 20 studies.\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"Confidence intervals were calculated using the normal distribution.\n",
        "\"\"\"\n",
        "    text += \"</p>\"\n",
        "\n",
        "    # Model comparison\n",
        "    if res_3l:\n",
        "        text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "For comparison, a standard two-level random-effects model yielded a similar pooled effect (pooled effect = <b>{mu_re:.3f}</b>, 95% CI [{ci_lo_re:.3f}, {ci_hi_re:.3f}]), though this model does not account for within-study dependencies. The three-level model is preferred as it provides more accurate uncertainty estimates when multiple effect sizes are extracted from the same study.\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    # Guidance\n",
        "    text += f\"\"\"\n",
        "<hr style='margin: 20px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; margin-top: 20px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "<ul style='margin-bottom: 0;'>\n",
        "<li>Adjust effect size interpretation based on your domain (small/medium/large effects may differ by field)</li>\n",
        "<li>Modify language to match your specific research question and context</li>\n",
        "<li>Add context-specific information about what the effect means in your field</li>\n",
        "<li>Include any relevant sensitivity analyses or publication bias assessments</li>\n",
        "<li>Consider discussing practical significance alongside statistical significance</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "<p style='margin: 0;'><b>üí° Tip:</b> You can copy this text directly into your manuscript. Select all (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C), and paste into your word processor. Most formatting will be preserved.</p>\n",
        "</div>\n",
        "\n",
        "</div>\"\"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# --- 3. MAIN ANALYSIS ---\n",
        "def run_analysis(change=None):\n",
        "    # Clear Tabs\n",
        "    for tab in [tab_main, tab_hetero, tab_compare, tab_settings, tab_publication]:\n",
        "        tab.clear_output()\n",
        "\n",
        "    # --- CONFIG CHECK ---\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        print(\"‚ùå ERROR: Config not found. Run Step 1 first.\")\n",
        "        return\n",
        "\n",
        "    eff_col = ANALYSIS_CONFIG.get('effect_col')\n",
        "    var_col = ANALYSIS_CONFIG.get('var_col')\n",
        "    es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "\n",
        "    # Load Data\n",
        "    if 'analysis_data' in ANALYSIS_CONFIG:\n",
        "        df_source = ANALYSIS_CONFIG['analysis_data']\n",
        "    elif 'data_filtered' in globals():\n",
        "        df_source = data_filtered\n",
        "    else:\n",
        "        print(\"‚ùå ERROR: No data found. Run Step 1 first.\")\n",
        "        return\n",
        "\n",
        "    if eff_col not in df_source.columns or var_col not in df_source.columns:\n",
        "        print(f\"‚ùå ERROR: Columns '{eff_col}' or '{var_col}' missing.\")\n",
        "        return\n",
        "\n",
        "    # Clean Data\n",
        "    df = df_source.dropna(subset=[eff_col, var_col]).copy()\n",
        "    df = df[df[var_col] > 0]\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(\"‚ùå ERROR: No valid data points remaining.\")\n",
        "        return\n",
        "\n",
        "    # --- A. STANDARD ANALYSIS ---\n",
        "    w_fe = 1 / df[var_col]\n",
        "    mu_fe = np.average(df[eff_col], weights=w_fe)\n",
        "    se_fe = np.sqrt(1 / np.sum(w_fe))\n",
        "    ci_lower_fixed = mu_fe - 1.96 * se_fe\n",
        "    ci_upper_fixed = mu_fe + 1.96 * se_fe\n",
        "\n",
        "    # Heterogeneity\n",
        "    Q = np.sum(w_fe * (df[eff_col] - mu_fe)**2)\n",
        "    df_Q = len(df) - 1\n",
        "    p_Q = 1 - chi2.cdf(Q, df_Q)\n",
        "    I2 = max(0, (Q - df_Q) / Q * 100) if Q > 0 else 0\n",
        "\n",
        "    # Random Effect\n",
        "    method = tau_method_widget.value\n",
        "    if 'calculate_tau_squared' in globals() and method != 'DL':\n",
        "        tau2_re, _ = calculate_tau_squared(df, eff_col, var_col, method=method)\n",
        "    else:\n",
        "        C = np.sum(w_fe) - np.sum(w_fe**2)/np.sum(w_fe)\n",
        "        tau2_re = max(0, (Q - df_Q) / C) if C > 0 else 0\n",
        "\n",
        "    w_re = 1 / (df[var_col] + tau2_re)\n",
        "    mu_re = np.average(df[eff_col], weights=w_re)\n",
        "    se_re = np.sqrt(1 / np.sum(w_re))\n",
        "\n",
        "    # Knapp-Hartung\n",
        "    use_kh = use_kh_widget.value\n",
        "    if use_kh and len(df) > 1:\n",
        "        q_re = np.sum(w_re * (df[eff_col] - mu_re)**2)\n",
        "        se_re = se_re * np.sqrt(max(1, q_re / df_Q))\n",
        "        dist = t(df_Q)\n",
        "    else:\n",
        "        dist = norm\n",
        "\n",
        "    ci_lo_re = mu_re - dist.ppf(0.975) * se_re\n",
        "    ci_hi_re = mu_re + dist.ppf(0.975) * se_re\n",
        "    p_re = 2 * (1 - dist.cdf(abs(mu_re / se_re)))\n",
        "\n",
        "    # --- B. 3-LEVEL ANALYSIS ---\n",
        "    k_obs, k_studies = len(df), df['id'].nunique()\n",
        "    res_3l = None\n",
        "    if k_obs > k_studies:\n",
        "        try:\n",
        "            res_3l = _run_three_level_reml(df, eff_col, var_col)\n",
        "            mu_3l, se_3l = res_3l['mu'], res_3l['se']\n",
        "            ci_lo_3l, ci_hi_3l = mu_3l - 1.96*se_3l, mu_3l + 1.96*se_3l\n",
        "            p_3l = 2*(1-norm.cdf(abs(mu_3l/se_3l)))\n",
        "        except: pass\n",
        "\n",
        "    # --- C. SAVE RESULTS ---\n",
        "    ANALYSIS_CONFIG['overall_results'] = {\n",
        "        'pooled_effect_fixed': mu_fe, 'pooled_SE_fixed': se_fe,\n",
        "        'ci_lower_fixed': ci_lower_fixed, 'ci_upper_fixed': ci_upper_fixed,\n",
        "        'pooled_effect_random': mu_re, 'pooled_SE_random_reported': se_re,\n",
        "        'ci_lower_random_reported': ci_lo_re, 'ci_upper_random_reported': ci_hi_re,\n",
        "        'p_value_random_reported': p_re,\n",
        "        'Qt': Q, 'I_squared': I2, 'tau_squared': tau2_re, 'k': k_obs, 'k_papers': k_studies,\n",
        "        'knapp_hartung': {'used': use_kh}\n",
        "    }\n",
        "    if res_3l:\n",
        "        ANALYSIS_CONFIG['three_level_results'] = {\n",
        "            'status': 'completed', 'pooled_effect': mu_3l, 'se': se_3l,\n",
        "            'ci_lower': ci_lo_3l, 'ci_upper': ci_hi_3l,\n",
        "            'tau_squared': res_3l['tau2'], 'sigma_squared': res_3l['sigma2']\n",
        "        }\n",
        "\n",
        "    # --- D. RENDER TABS ---\n",
        "    # Determine primary result\n",
        "    if res_3l:\n",
        "        mu_p, ci_lo_p, ci_hi_p, p_p = mu_3l, ci_lo_3l, ci_hi_3l, p_3l\n",
        "        model_label, note = \"3-Level REML (Robust)\", \"Adjusted for dependency.\"\n",
        "    else:\n",
        "        mu_p, ci_lo_p, ci_hi_p, p_p = mu_re, ci_lo_re, ci_hi_re, p_re\n",
        "        model_label, note = \"Random-Effects\", \"Standard meta-analysis.\"\n",
        "\n",
        "    with tab_main:\n",
        "        sig = \"***\" if p_p < 0.001 else \"**\" if p_p < 0.01 else \"*\" if p_p < 0.05 else \"ns\"\n",
        "        color = \"#28a745\" if p_p < 0.05 else \"#6c757d\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h2 style='color: #2c3e50; margin-bottom: 20px;'>{model_label}</h2>\n",
        "        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "            <h1 style='margin: 0; font-size: 3em; text-align: center;'>{mu_p:.3f}</h1>\n",
        "            <p style='margin: 10px 0 0 0; text-align: center; font-size: 1.2em;'>Pooled Effect Size {sig}</p>\n",
        "        </div>\n",
        "        <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-bottom: 20px;'>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #007bff;'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>95% Confidence Interval</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold;'>[{ci_lo_p:.3f}, {ci_hi_p:.3f}]</div>\n",
        "            </div>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid {color};'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>P-value</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold; color: {color};'>{p_p:.4g}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "        <div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px;'>\n",
        "            <p style='margin: 0;'><b>Model:</b> {model_label}</p>\n",
        "            <p style='margin: 5px 0 0 0;'><b>Note:</b> {note}</p>\n",
        "            <p style='margin: 5px 0 0 0;'><b>Studies:</b> k = {k_obs} observations from {k_studies} independent studies</p>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(html))\n",
        "\n",
        "    with tab_hetero:\n",
        "        het_color = \"#dc3545\" if I2 > 75 else \"#ffc107\" if I2 > 50 else \"#28a745\"\n",
        "        html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h2 style='color: #2c3e50;'>Heterogeneity Assessment</h2>\n",
        "        <div style='background-color: {het_color}; padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "            <h1 style='margin: 0; font-size: 2.5em;'>{I2:.1f}%</h1>\n",
        "            <p style='margin: 10px 0 0 0; font-size: 1.1em;'>I¬≤ Statistic</p>\n",
        "        </div>\n",
        "        <table style='width: 100%; border-collapse: collapse;'>\n",
        "            <tr style='background-color: #f8f9fa;'>\n",
        "                <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Statistic</th>\n",
        "                <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Value</th>\n",
        "                <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Interpretation</th>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Q-statistic</b></td>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'>{Q:.2f} (df = {df_Q})</td>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'>p < 0.001</td>\n",
        "            </tr>\n",
        "            <tr style='background-color: #f8f9fa;'>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'><b>I¬≤ (% variation due to heterogeneity)</b></td>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'>{I2:.1f}%</td>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'>{\"High\" if I2 > 75 else \"Substantial\" if I2 > 50 else \"Moderate\" if I2 > 25 else \"Low\"}</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'><b>œÑ¬≤ (between-study variance)</b></td>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'>{tau2_re:.4f}</td>\n",
        "                <td style='padding: 10px; border: 1px solid #dee2e6;'>Estimated using {method}</td>\n",
        "            </tr>\n",
        "        </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(html))\n",
        "\n",
        "    with tab_compare:\n",
        "        html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h2 style='color: #2c3e50;'>Model Comparison</h2>\n",
        "        <table style='width: 100%; border-collapse: collapse; margin-top: 20px;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left;'>Model</th>\n",
        "                    <th style='padding: 12px; text-align: center;'>Effect</th>\n",
        "                    <th style='padding: 12px; text-align: center;'>95% CI</th>\n",
        "                    <th style='padding: 12px; text-align: center;'>P-value</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Fixed-Effect</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{mu_fe:.3f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{ci_lower_fixed:.3f}, {ci_upper_fixed:.3f}]</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>-</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Random-Effects (2-Level)</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{mu_re:.3f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{ci_lo_re:.3f}, {ci_hi_re:.3f}]</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{p_re:.4g}</td>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "        if res_3l:\n",
        "            html += f\"\"\"\n",
        "                <tr style='background-color: #e7f3ff;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>3-Level REML ‚≠ê</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{mu_3l:.3f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{ci_lo_3l:.3f}, {ci_hi_3l:.3f}]</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{p_3l:.4g}</td>\n",
        "                </tr>\n",
        "            \"\"\"\n",
        "        html += \"\"\"\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "        if res_3l:\n",
        "            html += f\"\"\"\n",
        "            <div style='background-color: #d4edda; padding: 15px; border-radius: 5px; margin-top: 20px; border-left: 4px solid #28a745;'>\n",
        "                <p style='margin: 0;'><b>‚≠ê Recommended:</b> The 3-level model accounts for within-study dependencies ({res_3l['m']} studies, {res_3l['n']} effect sizes). Variance partition: {res_3l['icc_l3']:.1f}% between-study, {res_3l['icc_l2']:.1f}% within-study.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        html += \"</div>\"\n",
        "        display(HTML(html))\n",
        "\n",
        "    with tab_settings:\n",
        "        display(HTML(\"<h3>Analysis Settings</h3>\"))\n",
        "        display(HTML(\"<p>Configure œÑ¬≤ estimation method and statistical corrections:</p>\"))\n",
        "        display(tau_method_widget)\n",
        "        display(use_kh_widget)\n",
        "        run_button = widgets.Button(description='Re-run Analysis', button_style='primary', icon='refresh')\n",
        "        run_button.on_click(run_analysis)\n",
        "        display(run_button)\n",
        "\n",
        "        info = f\"\"\"\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-top: 20px;'>\n",
        "        <h4>Current Configuration:</h4>\n",
        "        <ul>\n",
        "        <li><b>œÑ¬≤ Method:</b> {method}</li>\n",
        "        <li><b>Knapp-Hartung:</b> {\"Enabled\" if use_kh else \"Disabled\"}</li>\n",
        "        <li><b>Effect Size Column:</b> {eff_col}</li>\n",
        "        <li><b>Variance Column:</b> {var_col}</li>\n",
        "        </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(info))\n",
        "\n",
        "    # --- E. PUBLICATION TEXT TAB ---\n",
        "    with tab_publication:\n",
        "        display(HTML(\"<h3 style='color: #2c3e50;'>üìù Publication-Ready Results Text</h3>\"))\n",
        "        display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "        pub_text = generate_publication_text(\n",
        "            mu_p, ci_lo_p, ci_hi_p, p_p, tau2_re, I2, Q, df_Q, p_Q, k_obs, k_studies,\n",
        "            method, use_kh, res_3l, mu_fe, ci_lower_fixed, ci_upper_fixed,\n",
        "            mu_re, ci_lo_re, ci_hi_re, es_config\n",
        "        )\n",
        "\n",
        "        display(HTML(pub_text))\n",
        "\n",
        "# Run on widget change\n",
        "tau_method_widget.observe(run_analysis, 'value')\n",
        "use_kh_widget.observe(run_analysis, 'value')\n",
        "\n",
        "# Display and run\n",
        "display(tabs)\n",
        "run_analysis()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_1W8e7YAqw-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä Step 2: Overall Meta-Analysis (v2.1 - with AIC Model Selection)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL: OVERALL META-ANALYSIS (DASHBOARD v3)\n",
        "# Purpose: Calculate pooled effects, Heterogeneity, and Model Fit (AIC/BIC)\n",
        "# Upgrade: Added AIC comparison to statistically justify the 3-level model.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import datetime\n",
        "from scipy.stats import norm, chi2, t\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# --- 1. LAYOUT & WIDGETS ---\n",
        "tab_main = widgets.Output()\n",
        "tab_hetero = widgets.Output()\n",
        "tab_compare = widgets.Output()\n",
        "tab_settings = widgets.Output()\n",
        "tab_publication = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_main, tab_hetero, tab_compare, tab_settings, tab_publication])\n",
        "tabs.set_title(0, 'üìä Primary Result')\n",
        "tabs.set_title(1, 'üìâ Heterogeneity')\n",
        "tabs.set_title(2, '‚öñÔ∏è Model Selection')\n",
        "tabs.set_title(3, '‚öôÔ∏è Settings')\n",
        "tabs.set_title(4, 'üìù Publication Text')\n",
        "\n",
        "# Settings Widgets\n",
        "method_options = ['REML', 'DL', 'ML']\n",
        "tau_method_widget = widgets.Dropdown(options=method_options, value='REML', description='œÑ¬≤ Method:')\n",
        "use_kh_widget = widgets.Checkbox(value=True, description='Knapp-Hartung Correction')\n",
        "\n",
        "# --- 2. ENGINES ---\n",
        "\n",
        "def calculate_2level_fit(df, effect_col, var_col, tau2):\n",
        "    \"\"\"Calculate LogLik and AIC for standard 2-level RE model.\"\"\"\n",
        "    y = df[effect_col].values\n",
        "    v = df[var_col].values\n",
        "    k = len(y)\n",
        "\n",
        "    # Weights\n",
        "    w = 1.0 / (v + tau2)\n",
        "    sum_w = np.sum(w)\n",
        "    mu = np.sum(w * y) / sum_w\n",
        "\n",
        "    # REML Log-Likelihood (approximate for comparison)\n",
        "    # LL = -0.5 * (sum(log(v+tau2)) + log(sum(w)) + sum(w*(y-mu)^2))\n",
        "    resid_sq = np.sum(w * (y - mu)**2)\n",
        "    ll = -0.5 * (np.sum(np.log(v + tau2)) + np.log(sum_w) + resid_sq)\n",
        "\n",
        "    # Params = 2 (mu, tau2)\n",
        "    aic = -2 * ll + 2 * 2\n",
        "    bic = -2 * ll + 2 * np.log(k)\n",
        "\n",
        "    return {'ll': ll, 'aic': aic, 'bic': bic}\n",
        "\n",
        "def _run_three_level_reml(df, effect_col, var_col):\n",
        "    \"\"\"Core 3-Level Optimizer with AIC calculation.\"\"\"\n",
        "    grouped = df.groupby('id')\n",
        "    y_all = [g[effect_col].values for _, g in grouped]\n",
        "    v_all = [g[var_col].values for _, g in grouped]\n",
        "    N, M = len(df), len(y_all)\n",
        "\n",
        "    def nll(params):\n",
        "        tau2, sigma2 = params\n",
        "        if tau2 < 0 or sigma2 < 0: return 1e10\n",
        "        ll = 0; sum_S = 0; sum_Sy = 0; sum_ySy = 0\n",
        "\n",
        "        for i in range(M):\n",
        "            y, v = y_all[i], v_all[i]\n",
        "            A_inv = 1.0 / (v + sigma2)\n",
        "            sum_A_inv = np.sum(A_inv)\n",
        "            denom = 1 + tau2 * sum_A_inv\n",
        "\n",
        "            ll += np.sum(np.log(v + sigma2)) + np.log(denom)\n",
        "\n",
        "            w_y = A_inv * y - (tau2 * A_inv * np.sum(A_inv * y)) / denom\n",
        "            w_1 = A_inv - (tau2 * A_inv * sum_A_inv) / denom\n",
        "\n",
        "            sum_S += np.sum(w_1)\n",
        "            sum_Sy += np.sum(w_y)\n",
        "            sum_ySy += np.dot(y, w_y)\n",
        "\n",
        "        mu = sum_Sy / sum_S\n",
        "        resid = sum_ySy - 2*mu*sum_Sy + mu**2 * sum_S\n",
        "        return 0.5 * (ll + np.log(sum_S) + resid)\n",
        "\n",
        "    # Optimize\n",
        "    res = minimize(nll, [0.01, 0.01], bounds=[(1e-8, None)]*2, method='L-BFGS-B', options={'ftol':1e-9})\n",
        "    if not res.success: res = minimize(nll, [0.1, 0.1], bounds=[(1e-8, None)]*2, method='Nelder-Mead')\n",
        "\n",
        "    tau2, sigma2 = res.x\n",
        "    nll_val = res.fun\n",
        "    log_lik = -nll_val\n",
        "\n",
        "    # AIC/BIC (Params = 3: mu, tau2, sigma2)\n",
        "    aic = 2*3 - 2*log_lik\n",
        "    bic = 3*np.log(N) - 2*log_lik\n",
        "\n",
        "    # Re-calc stats at optimum\n",
        "    sum_S = 0; sum_Sy = 0\n",
        "    for i in range(M):\n",
        "        y, v = y_all[i], v_all[i]\n",
        "        A_inv = 1.0 / (v + sigma2)\n",
        "        denom = 1 + tau2 * np.sum(A_inv)\n",
        "        w_y = A_inv * y - (tau2 * A_inv * np.sum(A_inv * y)) / denom\n",
        "        w_1 = A_inv - (tau2 * A_inv * np.sum(A_inv)) / denom\n",
        "        sum_S += np.sum(w_1)\n",
        "        sum_Sy += np.sum(w_y)\n",
        "\n",
        "    mu = sum_Sy / sum_S\n",
        "    se = np.sqrt(1.0 / sum_S)\n",
        "\n",
        "    total_var = tau2 + sigma2\n",
        "    icc_l3 = (tau2 / total_var * 100) if total_var > 0 else 0\n",
        "    icc_l2 = (sigma2 / total_var * 100) if total_var > 0 else 0\n",
        "\n",
        "    return {'mu': mu, 'se': se, 'tau2': tau2, 'sigma2': sigma2,\n",
        "            'icc_l3': icc_l3, 'icc_l2': icc_l2, 'n': N, 'm': M,\n",
        "            'aic': aic, 'bic': bic}\n",
        "\n",
        "# --- 3. MAIN ANALYSIS ---\n",
        "def run_analysis(change=None):\n",
        "    # Clear Tabs\n",
        "    for tab in [tab_main, tab_hetero, tab_compare, tab_settings, tab_publication]:\n",
        "        tab.clear_output()\n",
        "\n",
        "    # Config Check\n",
        "    if 'ANALYSIS_CONFIG' not in globals(): return\n",
        "    eff_col = ANALYSIS_CONFIG.get('effect_col')\n",
        "    var_col = ANALYSIS_CONFIG.get('var_col')\n",
        "\n",
        "    if 'analysis_data' in ANALYSIS_CONFIG: df = ANALYSIS_CONFIG['analysis_data'].copy()\n",
        "    elif 'data_filtered' in globals(): df = data_filtered.copy()\n",
        "    else: return\n",
        "\n",
        "    df = df.dropna(subset=[eff_col, var_col])\n",
        "    df = df[df[var_col] > 0]\n",
        "\n",
        "    # --- A. STANDARD ANALYSIS ---\n",
        "    w_fe = 1 / df[var_col]\n",
        "    mu_fe = np.average(df[eff_col], weights=w_fe)\n",
        "    se_fe = np.sqrt(1 / np.sum(w_fe))\n",
        "    ci_lower_fixed = mu_fe - 1.96 * se_fe\n",
        "    ci_upper_fixed = mu_fe + 1.96 * se_fe\n",
        "\n",
        "    # 2-Level Random Effects\n",
        "    # Simple DL estimator for speed/robustness in comparison\n",
        "    Q = np.sum(w_fe * (df[eff_col] - mu_fe)**2)\n",
        "    C = np.sum(w_fe) - np.sum(w_fe**2)/np.sum(w_fe)\n",
        "    tau2_dl = max(0, (Q - (len(df)-1)) / C)\n",
        "\n",
        "    # Calculate Fit for 2-Level\n",
        "    fit_2l = calculate_2level_fit(df, eff_col, var_col, tau2_dl)\n",
        "\n",
        "    w_re = 1 / (df[var_col] + tau2_dl)\n",
        "    mu_re = np.average(df[eff_col], weights=w_re)\n",
        "    se_re = np.sqrt(1 / np.sum(w_re))\n",
        "\n",
        "    # Knapp-Hartung\n",
        "    use_kh = use_kh_widget.value\n",
        "    df_Q = len(df) - 1\n",
        "    if use_kh and len(df) > 1:\n",
        "        q_re = np.sum(w_re * (df[eff_col] - mu_re)**2)\n",
        "        se_re_adj = se_re * np.sqrt(max(1, q_re / df_Q))\n",
        "        dist = t(df_Q)\n",
        "    else:\n",
        "        se_re_adj = se_re\n",
        "        dist = norm\n",
        "\n",
        "    ci_lo_re = mu_re - dist.ppf(0.975) * se_re_adj\n",
        "    ci_hi_re = mu_re + dist.ppf(0.975) * se_re_adj\n",
        "    p_re = 2 * (1 - dist.cdf(abs(mu_re / se_re_adj)))\n",
        "\n",
        "    # Heterogeneity Stats\n",
        "    p_Q = 1 - chi2.cdf(Q, df_Q)\n",
        "    I2 = max(0, (Q - df_Q) / Q * 100) if Q > 0 else 0\n",
        "\n",
        "    # --- B. 3-LEVEL ANALYSIS ---\n",
        "    res_3l = None\n",
        "    if len(df) > df['id'].nunique():\n",
        "        try:\n",
        "            res_3l = _run_three_level_reml(df, eff_col, var_col)\n",
        "            mu_3l, se_3l = res_3l['mu'], res_3l['se']\n",
        "            ci_lo_3l, ci_hi_3l = mu_3l - 1.96*se_3l, mu_3l + 1.96*se_3l\n",
        "            p_3l = 2*(1-norm.cdf(abs(mu_3l/se_3l)))\n",
        "        except: pass\n",
        "\n",
        "    # --- SAVE RESULTS ---\n",
        "    ANALYSIS_CONFIG['overall_results'] = {\n",
        "        'pooled_effect_fixed': mu_fe,\n",
        "        'pooled_effect_random': mu_re, 'pooled_SE_random_reported': se_re_adj,\n",
        "        'ci_lower_random_reported': ci_lo_re, 'ci_upper_random_reported': ci_hi_re,\n",
        "        'p_value_random_reported': p_re,\n",
        "        'Qt': Q, 'I_squared': I2, 'tau_squared': tau2_dl, 'k': len(df), 'k_papers': df['id'].nunique()\n",
        "    }\n",
        "    if res_3l:\n",
        "        ANALYSIS_CONFIG['three_level_results'] = {\n",
        "            'pooled_effect': res_3l['mu'], 'se': res_3l['se'],\n",
        "            'ci_lower': ci_lo_3l, 'ci_upper': ci_hi_3l,\n",
        "            'tau_squared': res_3l['tau2'], 'sigma_squared': res_3l['sigma2']\n",
        "        }\n",
        "\n",
        "    # --- C. RENDER TABS ---\n",
        "\n",
        "    # 1. PRIMARY RESULT\n",
        "    with tab_main:\n",
        "        mu_p, ci_lo_p, ci_hi_p, p_p = (mu_3l, ci_lo_3l, ci_hi_3l, p_3l) if res_3l else (mu_re, ci_lo_re, ci_hi_re, p_re)\n",
        "        model_label = \"3-Level REML (Robust)\" if res_3l else \"Random-Effects (2-Level)\"\n",
        "        sig = \"***\" if p_p < 0.001 else \"**\" if p_p < 0.01 else \"*\" if p_p < 0.05 else \"ns\"\n",
        "        color = \"#28a745\" if p_p < 0.05 else \"#6c757d\"\n",
        "\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h2 style='color: #2c3e50;'>{model_label}</h2>\n",
        "        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "            <h1 style='margin: 0; font-size: 3em; text-align: center;'>{mu_p:.3f}</h1>\n",
        "            <p style='margin: 10px 0 0 0; text-align: center; font-size: 1.2em;'>Pooled Effect Size {sig}</p>\n",
        "        </div>\n",
        "        <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px;'>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-left: 4px solid #007bff;'>\n",
        "                <div style='color: #6c757d;'>95% Confidence Interval</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold;'>[{ci_lo_p:.3f}, {ci_hi_p:.3f}]</div>\n",
        "            </div>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-left: 4px solid {color};'>\n",
        "                <div style='color: #6c757d;'>P-value</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold; color: {color};'>{p_p:.4g}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "    # 2. MODEL COMPARISON (UPDATED WITH AIC)\n",
        "    with tab_compare:\n",
        "        # Determine Winner\n",
        "        best_model = \"2-Level\"\n",
        "        if res_3l and res_3l['aic'] < fit_2l['aic'] - 2:\n",
        "            best_model = \"3-Level\"\n",
        "            delta_aic = fit_2l['aic'] - res_3l['aic']\n",
        "            msg = f\"The 3-Level model is better (ŒîAIC = {delta_aic:.1f}). Clustering is significant.\"\n",
        "            color_3l = \"#d4edda\"\n",
        "            color_2l = \"#fff\"\n",
        "            badge_3l = \"üèÜ Best Fit\"\n",
        "            badge_2l = \"\"\n",
        "        else:\n",
        "            msg = \"The 2-Level model is sufficient (AIC difference is small).\"\n",
        "            color_3l = \"#fff\"\n",
        "            color_2l = \"#d4edda\"\n",
        "            badge_2l = \"üèÜ Best Fit\"\n",
        "            badge_3l = \"\"\n",
        "\n",
        "        html_table = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h3 style='color: #2c3e50;'>Model Selection (AIC)</h3>\n",
        "        <p>{msg}</p>\n",
        "        <table style='width: 100%; border-collapse: collapse; margin-top: 10px;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left;'>Model</th>\n",
        "                    <th style='padding: 12px;'>Effect [95% CI]</th>\n",
        "                    <th style='padding: 12px;'>AIC</th>\n",
        "                    <th style='padding: 12px;'>Verdict</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: {color_2l};'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>2-Level Random-Effects</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{mu_re:.3f} [{ci_lo_re:.3f}, {ci_hi_re:.3f}]</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{fit_2l['aic']:.1f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{badge_2l}</td>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "        if res_3l:\n",
        "            html_table += f\"\"\"\n",
        "                <tr style='background-color: {color_3l};'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>3-Level REML (Nested)</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{res_3l['mu']:.3f} [{ci_lo_3l:.3f}, {ci_hi_3l:.3f}]</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{res_3l['aic']:.1f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{badge_3l}</td>\n",
        "                </tr>\n",
        "            \"\"\"\n",
        "        html_table += \"\"\"</tbody></table>\n",
        "        <p style='font-size: 0.9em; color: #666; margin-top: 10px;'>\n",
        "        <b>AIC (Akaike Information Criterion):</b> Lower is better. A difference > 2 usually indicates significant improvement.\n",
        "        </p></div>\"\"\"\n",
        "        display(HTML(html_table))\n",
        "\n",
        "    # 3. HETEROGENEITY\n",
        "    with tab_hetero:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h3>Heterogeneity Statistics</h3>\n",
        "        <table style='width: 100%; border-collapse: collapse;'>\n",
        "            <tr><td style='padding: 8px; border-bottom: 1px solid #eee;'><b>Q-statistic:</b></td><td style='padding: 8px; border-bottom: 1px solid #eee;'>{Q:.2f} (df={df_Q}, p={p_Q:.4g})</td></tr>\n",
        "            <tr><td style='padding: 8px; border-bottom: 1px solid #eee;'><b>I¬≤ (Total):</b></td><td style='padding: 8px; border-bottom: 1px solid #eee;'>{I2:.1f}%</td></tr>\n",
        "            <tr><td style='padding: 8px; border-bottom: 1px solid #eee;'><b>œÑ¬≤ (Between-Study):</b></td><td style='padding: 8px; border-bottom: 1px solid #eee;'>{res_3l['tau2'] if res_3l else tau2_dl:.4f}</td></tr>\n",
        "        \"\"\" + (f\"<tr><td style='padding: 8px; border-bottom: 1px solid #eee;'><b>œÉ¬≤ (Within-Study):</b></td><td style='padding: 8px; border-bottom: 1px solid #eee;'>{res_3l['sigma2']:.4f}</td></tr>\" if res_3l else \"\") + \"</table></div>\"))\n",
        "\n",
        "    # 4. PUBLICATION TEXT\n",
        "    with tab_publication:\n",
        "        aic_text = f\"Model selection based on AIC favored the {'three' if best_model == '3-Level' else 'two'}-level model (AIC = {res_3l['aic'] if best_model == '3-Level' else fit_2l['aic']:.1f}).\"\n",
        "\n",
        "        display(HTML(f\"\"\"\n",
        "        <h3>üìù Publication Text</h3>\n",
        "        <p style='font-family: serif; font-size: 1.1em; line-height: 1.6;'>\n",
        "        A random-effects meta-analysis was conducted. {aic_text} The pooled effect size was <b>{mu_p:.3f}</b> (95% CI [{ci_lo_p:.3f}, {ci_hi_p:.3f}], p {('< 0.001' if p_p < 0.001 else f'= {p_p:.3f}')}).\n",
        "        Significant heterogeneity was detected (I¬≤ = {I2:.1f}%, Q = {Q:.2f}, p < 0.001).\n",
        "        </p>\n",
        "        \"\"\"))\n",
        "\n",
        "# Run\n",
        "tau_method_widget.observe(run_analysis, 'value')\n",
        "use_kh_widget.observe(run_analysis, 'value')\n",
        "display(tabs)\n",
        "run_analysis()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VFT54sj4va8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üß™ R Validation: Effect Size Calculation (escalc)\n",
        "# =============================================================================\n",
        "# CELL: EFFECT SIZE VALIDATION\n",
        "# Purpose: Verify that Python's Hedges' g / lnRR calculation matches R's metafor::escalc\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"VALIDATION STEP 1: EFFECT SIZE CALCULATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Check Dependencies\n",
        "if 'ANALYSIS_CONFIG' not in globals() or 'analysis_data' not in ANALYSIS_CONFIG:\n",
        "    print(\"‚ùå Error: Please run the 'CALCULATE EFFECT SIZES' cell first.\")\n",
        "else:\n",
        "    # 2. Get Configuration\n",
        "    config = ANALYSIS_CONFIG\n",
        "    es_type = config['effect_size_type'] # 'hedges_g', 'lnRR', etc.\n",
        "    df_py = config['analysis_data'].copy()\n",
        "\n",
        "    effect_col = config['effect_col']\n",
        "    var_col = config['var_col']\n",
        "\n",
        "    print(f\"üîç Validating metric: {es_type}\")\n",
        "    print(f\"   Comparing Python columns ['{effect_col}', '{var_col}'] against R metafor::escalc...\")\n",
        "\n",
        "    # 3. Map Python ES type to R metafor \"measure\" argument\n",
        "    # ROM = Ratio of Means (lnRR), SMD = Std Mean Diff (Hedges' g)\n",
        "    r_measure_map = {\n",
        "        'lnRR': 'ROM',\n",
        "        'hedges_g': 'SMD',\n",
        "        'cohen_d': 'SMD', # Note: metafor defaults to Hedges' g for SMD. Cohen's d requires manual tweak, usually better to stick to Hedges.\n",
        "        'log_or': 'OR'\n",
        "    }\n",
        "\n",
        "    if es_type not in r_measure_map:\n",
        "        print(f\"‚ö†Ô∏è Warning: Validation for '{es_type}' not fully automated yet. Defaulting to SMD check.\")\n",
        "        r_measure = 'SMD'\n",
        "    else:\n",
        "        r_measure = r_measure_map[es_type]\n",
        "\n",
        "    # 4. Prepare Data for R\n",
        "    # We need raw columns: xe, sde, ne, xc, sdc, nc\n",
        "    raw_cols = ['xe', 'sde_imputed', 'ne', 'xc', 'sdc_imputed', 'nc']\n",
        "\n",
        "    # Check if imputed columns exist, otherwise use raw\n",
        "    if 'sde_imputed' not in df_py.columns:\n",
        "        raw_cols[1] = 'sde'\n",
        "        raw_cols[4] = 'sdc'\n",
        "\n",
        "    # Create subset for R\n",
        "    try:\n",
        "        df_r = df_py[raw_cols].copy()\n",
        "        # Rename to standard names for clarity in R script\n",
        "        df_r.columns = ['m1i', 'sd1i', 'n1i', 'm2i', 'sd2i', 'n2i']\n",
        "\n",
        "        # Push to R\n",
        "        ro.globalenv['dat_raw'] = df_r\n",
        "        ro.globalenv['r_measure'] = r_measure\n",
        "\n",
        "        # 5. Run R Script\n",
        "        r_script = \"\"\"\n",
        "        library(metafor)\n",
        "\n",
        "        # Calculate Effect Sizes\n",
        "        # vtype=\"LS\" is standard large-sample variance for SMD\n",
        "        res <- escalc(measure=r_measure,\n",
        "                      m1i=m1i, sd1i=sd1i, n1i=n1i,\n",
        "                      m2i=m2i, sd2i=sd2i, n2i=n2i,\n",
        "                      data=dat_raw)\n",
        "\n",
        "        list(yi = res$yi, vi = res$vi)\n",
        "        \"\"\"\n",
        "\n",
        "        r_res = ro.r(r_script)\n",
        "        r_yi = np.array(r_res.rx2('yi'))\n",
        "        r_vi = np.array(r_res.rx2('vi'))\n",
        "\n",
        "        # 6. Comparison\n",
        "        py_yi = df_py[effect_col].values\n",
        "        py_vi = df_py[var_col].values\n",
        "\n",
        "        # Calculate differences (handle NaNs)\n",
        "        diff_yi = np.abs(py_yi - r_yi)\n",
        "        diff_vi = np.abs(py_vi - r_vi)\n",
        "\n",
        "        max_diff_yi = np.nanmax(diff_yi)\n",
        "        max_diff_vi = np.nanmax(diff_vi)\n",
        "\n",
        "        # 7. Report\n",
        "        print(\"\\nüìä VALIDATION RESULTS:\")\n",
        "        print(f\"   Max Difference (Effect Size): {max_diff_yi:.2e}\")\n",
        "        print(f\"   Max Difference (Variance):    {max_diff_vi:.2e}\")\n",
        "\n",
        "        # Tolerance check\n",
        "        tolerance = 1e-5\n",
        "        if max_diff_yi < tolerance and max_diff_vi < tolerance:\n",
        "            print(\"\\n‚úÖ SUCCESS: Python calculation matches R metafor exactly.\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è CAUTION: Differences detected.\")\n",
        "            if es_type == 'hedges_g':\n",
        "                print(\"   Note: Small differences in Hedges' g often come from Gamma function approximations.\")\n",
        "                print(\"   Python uses scipy.special.gamma (exact), R might use an approximation for large N.\")\n",
        "\n",
        "            # Show first 5 discrepancies\n",
        "            print(\"\\n   First 5 Rows Comparison:\")\n",
        "            print(f\"   {'Python ES':<12} {'R ES':<12} | {'Python Var':<12} {'R Var':<12}\")\n",
        "            print(\"-\" * 55)\n",
        "            for i in range(min(5, len(py_yi))):\n",
        "                print(f\"   {py_yi[i]:<12.4f} {r_yi[i]:<12.4f} | {py_vi[i]:<12.4f} {r_vi[i]:<12.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Execution Error: {e}\")\n",
        "        print(\"   Ensure your data has columns: xe, sde, ne, xc, sdc, nc\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3-SS3pgC4UgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k_UgQywyi0vh"
      },
      "outputs": [],
      "source": [
        "#@title ‚öôÔ∏è Step 3a: Subgroup Analysis - Configuration (V2)\n",
        "\n",
        "# =============================================================================\n",
        "# SUBGROUP ANALYSIS CONFIGURATION (DASHBOARD VERSION)\n",
        "# Purpose: Configure moderator variables with organized tabbed interface\n",
        "# Dependencies: Step 2 (overall_results, analysis_data)\n",
        "# Outputs: ANALYSIS_CONFIG['subgroup_config']\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import datetime\n",
        "\n",
        "# --- 1. CREATE TAB LAYOUT ---\n",
        "tab_config = widgets.Output()\n",
        "tab_moderators = widgets.Output()\n",
        "tab_thresholds = widgets.Output()\n",
        "tab_details = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_config, tab_moderators, tab_thresholds, tab_details])\n",
        "tabs.set_title(0, 'üìã Configuration')\n",
        "tabs.set_title(1, 'üìä Moderator Preview')\n",
        "tabs.set_title(2, '‚öôÔ∏è Thresholds')\n",
        "tabs.set_title(3, 'üìù Details')\n",
        "\n",
        "# --- 2. WIDGETS ---\n",
        "analysis_type_widget = widgets.RadioButtons(\n",
        "    options=[('Single-Factor Analysis', 'single'), ('Two-Factor Analysis (Interaction)', 'two_way')],\n",
        "    value='single', description='', layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "moderator1_widget = None\n",
        "moderator2_widget = None\n",
        "\n",
        "min_papers_widget = widgets.IntSlider(\n",
        "    value=3, min=1, max=10, step=1, description='Min Papers:',\n",
        "    style={'description_width': '120px'}, layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "min_obs_widget = widgets.IntSlider(\n",
        "    value=5, min=2, max=20, step=1, description='Min Observations:',\n",
        "    style={'description_width': '120px'}, layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description='üíæ Save Configuration & Proceed',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='400px', height='50px'),\n",
        "    style={'font_weight': 'bold'},\n",
        "    tooltip='Click to save configuration for use in the next cell'\n",
        ")\n",
        "\n",
        "run_button_output = widgets.Output()\n",
        "status_output = widgets.Output()\n",
        "\n",
        "# --- 3. INITIALIZATION ---\n",
        "def initialize_configuration():\n",
        "    global moderator1_widget, moderator2_widget\n",
        "\n",
        "    with tab_details:\n",
        "        clear_output()\n",
        "        print(\"=\"*70)\n",
        "        print(\"INITIALIZATION & VALIDATION\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            effect_col = ANALYSIS_CONFIG['effect_col']\n",
        "            var_col = ANALYSIS_CONFIG['var_col']\n",
        "            es_config = ANALYSIS_CONFIG['es_config']\n",
        "            overall_results = ANALYSIS_CONFIG['overall_results']\n",
        "\n",
        "            print(\"‚úì Prerequisites Check:\")\n",
        "            print(f\"  ‚Ä¢ Effect: {es_config['effect_label']} ({es_config['effect_label_short']})\")\n",
        "            print(f\"  ‚Ä¢ Q: {overall_results['Qt']:.4f}, I¬≤: {overall_results['I_squared']:.2f}%\")\n",
        "        except KeyError as e:\n",
        "            print(f\"‚ùå ERROR: {e}\")\n",
        "            print(\"  Please run Step 2 first\")\n",
        "            raise\n",
        "\n",
        "        if 'analysis_data' not in globals():\n",
        "            # Check if it's stored in ANALYSIS_CONFIG instead (V2 format)\n",
        "            if 'analysis_data' in ANALYSIS_CONFIG:\n",
        "                print(\"‚úì Loading analysis_data from ANALYSIS_CONFIG\")\n",
        "                globals()['analysis_data'] = ANALYSIS_CONFIG['analysis_data']\n",
        "            else:\n",
        "                print(\"‚ùå ERROR: analysis_data not found\")\n",
        "                print(\"   Please ensure Step 2 (Overall Meta-Analysis) was executed\")\n",
        "                raise NameError(\"analysis_data not defined\")\n",
        "\n",
        "        k_total, k_papers = len(analysis_data), analysis_data['id'].nunique()\n",
        "        print(f\"\\n‚úì Dataset: {k_total} obs, {k_papers} papers, {k_total/k_papers:.2f} avg\")\n",
        "\n",
        "        if k_total < 10:\n",
        "            print(f\"‚ö†Ô∏è  WARNING: Limited data ({k_total} obs)\")\n",
        "        elif k_total < 20:\n",
        "            print(f\"‚ö†Ô∏è  CAUTION: Moderate data ({k_total} obs)\")\n",
        "\n",
        "        excluded = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc', 'id', 'sde_imputed', 'sdc_imputed',\n",
        "                   'cv_e', 'cv_c', 'sde_was_imputed', 'sdc_was_imputed',\n",
        "                   effect_col, var_col, ANALYSIS_CONFIG.get('se_col', ''), 'w_fixed', 'w_random', 'ci_width']\n",
        "\n",
        "        if es_config.get('has_fold_change'):\n",
        "            excluded.extend(['Response_Ratio', 'RR_CI_lower', 'RR_CI_upper', 'fold_change',\n",
        "                           'Percent_Change', 'Odds_Ratio', 'OR_CI_lower', 'OR_CI_upper'])\n",
        "\n",
        "        if 'hedges_g' in effect_col or 'cohen_d' in effect_col:\n",
        "            excluded.extend(['df', 'sp', 'sp_squared', 'cohen_d', 'hedges_j'])\n",
        "\n",
        "        excluded.extend([c for c in analysis_data.columns if 'CI_' in c or 'ci_' in c])\n",
        "\n",
        "        available_moderators = [\n",
        "            col for col in analysis_data.columns\n",
        "            if col not in excluded and analysis_data[col].dtype == 'object'\n",
        "            and analysis_data[col].notna().sum() > 0\n",
        "        ]\n",
        "\n",
        "        print(f\"\\n‚úì Found {len(available_moderators)} moderators:\")\n",
        "        for mod in available_moderators:\n",
        "            print(f\"  ‚Ä¢ {mod}: {analysis_data[mod].nunique()} categories\")\n",
        "\n",
        "        if not available_moderators:\n",
        "            print(\"‚ùå ERROR: No moderators found\")\n",
        "            raise ValueError(\"No moderators available\")\n",
        "\n",
        "        moderator1_widget = widgets.Dropdown(\n",
        "            options=available_moderators, value=available_moderators[0],\n",
        "            description='Moderator 1:', style={'description_width': '100px'},\n",
        "            layout=widgets.Layout(width='450px')\n",
        "        )\n",
        "\n",
        "        moderator2_widget = widgets.Dropdown(\n",
        "            options=['None'] + available_moderators, value='None',\n",
        "            description='Moderator 2:', style={'description_width': '100px'},\n",
        "            layout=widgets.Layout(width='450px')\n",
        "        )\n",
        "\n",
        "        analysis_type_widget.observe(update_all_tabs, names='value')\n",
        "        moderator1_widget.observe(update_all_tabs, names='value')\n",
        "        moderator2_widget.observe(update_all_tabs, names='value')\n",
        "        min_papers_widget.observe(update_thresholds_tab, names='value')\n",
        "        min_obs_widget.observe(update_thresholds_tab, names='value')\n",
        "        run_button.on_click(save_configuration)\n",
        "\n",
        "        print(\"\\n‚úì Initialized successfully\")\n",
        "        return available_moderators\n",
        "\n",
        "# --- 4. TAB UPDATES ---\n",
        "def update_config_tab(change=None):\n",
        "    # Clear any previous save messages\n",
        "    with status_output:\n",
        "        clear_output()\n",
        "\n",
        "    with tab_config:\n",
        "        clear_output()\n",
        "        analysis_type = analysis_type_widget.value\n",
        "\n",
        "        help_html = \"\"\"<div style='background:#e7f3ff; padding:12px; border-radius:6px; border-left:4px solid #0066cc; margin-bottom:15px;'>\n",
        "            <b>üìä Single-Factor Subgroup Analysis</b><br>\n",
        "            <span style='font-size:13px; color:#555;'>Test if effect varies across ONE moderator<br>\n",
        "            <b>Best for:</b> Primary hypotheses, 10+ obs/group</span></div>\"\"\" if analysis_type == 'single' else \"\"\"\n",
        "            <div style='background:#fff3cd; padding:12px; border-radius:6px; border-left:4px solid #ff9800; margin-bottom:15px;'>\n",
        "            <b>üìä Two-Factor Analysis (Interaction)</b><br>\n",
        "            <span style='font-size:13px; color:#555;'>Test combinations of TWO moderators<br>\n",
        "            <b>Requires:</b> 3-5 studies/combo, 20+ total obs</span></div>\"\"\"\n",
        "\n",
        "        display(HTML(\"<h3 style='margin-top:0;'>Configure Subgroup Analysis</h3>\"))\n",
        "        display(HTML(help_html))\n",
        "        display(HTML(\"<h4>1. Select Analysis Type</h4>\"))\n",
        "        display(analysis_type_widget)\n",
        "        display(HTML(\"<h4 style='margin-top:20px;'>2. Select Moderator(s)</h4>\"))\n",
        "        display(moderator1_widget)\n",
        "\n",
        "        if analysis_type == 'two_way':\n",
        "            display(moderator2_widget)\n",
        "\n",
        "        display(HTML(\"<h4 style='margin-top:20px;'>3. Set Quality Thresholds</h4>\"))\n",
        "        display(HTML(\"<p style='color:#666; font-size:13px;'>Adjust in <b>‚öôÔ∏è Thresholds</b> tab</p>\"))\n",
        "        display(widgets.HBox([\n",
        "            widgets.HTML(f\"<div style='padding:8px; background:#f0f0f0; border-radius:4px; margin-right:10px;'>\"\n",
        "                        f\"<b>Min Papers:</b> {min_papers_widget.value}</div>\"),\n",
        "            widgets.HTML(f\"<div style='padding:8px; background:#f0f0f0; border-radius:4px;'>\"\n",
        "                        f\"<b>Min Obs:</b> {min_obs_widget.value}</div>\")\n",
        "        ]))\n",
        "\n",
        "        display(HTML(\"<h4 style='margin-top:20px;'>4. Save Configuration</h4>\"))\n",
        "        display(HTML(\"<p style='color:#666; font-size:13px; margin-top:0;'>\"\n",
        "                    \"Click the button below to validate and save your configuration.<br>\"\n",
        "                    \"The configuration will be stored in <code>ANALYSIS_CONFIG['subgroup_config']</code> \"\n",
        "                    \"for use in the next cell.</p>\"))\n",
        "        with run_button_output:\n",
        "          run_button_output.clear_output()\n",
        "          display(run_button)\n",
        "\n",
        "        display(run_button)\n",
        "        display(status_output)\n",
        "\n",
        "def update_moderators_tab(change=None):\n",
        "    with tab_moderators:\n",
        "        clear_output()\n",
        "\n",
        "        if moderator1_widget is None:\n",
        "            print(\"Initializing...\")\n",
        "            return\n",
        "\n",
        "        mod1 = moderator1_widget.value\n",
        "        analysis_type = analysis_type_widget.value\n",
        "        mod2 = moderator2_widget.value if analysis_type == 'two_way' and moderator2_widget.value != 'None' else None\n",
        "\n",
        "        display(HTML(\"<h3 style='margin-top:0;'>Moderator Variable Preview</h3>\"))\n",
        "        display(HTML(f\"<h4>üìä {mod1}</h4>\"))\n",
        "\n",
        "        mod1_counts = analysis_data[mod1].value_counts().sort_index()\n",
        "\n",
        "        table_html = \"\"\"<table style='width:100%; border-collapse:collapse;'>\n",
        "            <tr style='background:#f0f0f0; border-bottom:2px solid #ddd;'>\n",
        "                <th style='text-align:left; padding:8px;'>Category</th>\n",
        "                <th style='text-align:right; padding:8px;'>Observations</th>\n",
        "                <th style='text-align:right; padding:8px;'>Papers</th>\n",
        "                <th style='text-align:right; padding:8px;'>Percent</th></tr>\"\"\"\n",
        "\n",
        "        for category, count in mod1_counts.items():\n",
        "            papers = analysis_data[analysis_data[mod1] == category]['id'].nunique()\n",
        "            pct = (count / len(analysis_data)) * 100\n",
        "            row_color = '#fff' if count >= 5 else '#fff3cd'\n",
        "            table_html += f\"\"\"<tr style='background:{row_color}; border-bottom:1px solid #eee;'>\n",
        "                <td style='padding:6px;'>{category}</td>\n",
        "                <td style='text-align:right; padding:6px;'><b>{count}</b></td>\n",
        "                <td style='text-align:right; padding:6px;'>{papers}</td>\n",
        "                <td style='text-align:right; padding:6px;'>{pct:.1f}%</td></tr>\"\"\"\n",
        "\n",
        "        table_html += \"</table>\"\n",
        "        display(HTML(table_html))\n",
        "\n",
        "        min_group = mod1_counts.min()\n",
        "        if min_group < 5:\n",
        "            display(HTML(f\"<div style='background:#fff3cd; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                        f\"‚ö†Ô∏è Smallest group: {min_group} obs - consider adjusting thresholds</div>\"))\n",
        "        else:\n",
        "            display(HTML(\"<div style='background:#d4edda; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                        \"‚úì All groups have ‚â•5 observations</div>\"))\n",
        "\n",
        "        if mod2:\n",
        "            display(HTML(f\"<h4 style='margin-top:25px;'>üìä {mod2}</h4>\"))\n",
        "            mod2_counts = analysis_data[mod2].value_counts().sort_index()\n",
        "\n",
        "            table2_html = \"\"\"<table style='width:100%; border-collapse:collapse;'>\n",
        "                <tr style='background:#f0f0f0; border-bottom:2px solid #ddd;'>\n",
        "                    <th style='text-align:left; padding:8px;'>Category</th>\n",
        "                    <th style='text-align:right; padding:8px;'>Observations</th>\n",
        "                    <th style='text-align:right; padding:8px;'>Papers</th>\n",
        "                    <th style='text-align:right; padding:8px;'>Percent</th></tr>\"\"\"\n",
        "\n",
        "            for category, count in mod2_counts.items():\n",
        "                papers = analysis_data[analysis_data[mod2] == category]['id'].nunique()\n",
        "                pct = (count / len(analysis_data)) * 100\n",
        "                table2_html += f\"\"\"<tr style='border-bottom:1px solid #eee;'>\n",
        "                    <td style='padding:6px;'>{category}</td>\n",
        "                    <td style='text-align:right; padding:6px;'><b>{count}</b></td>\n",
        "                    <td style='text-align:right; padding:6px;'>{papers}</td>\n",
        "                    <td style='text-align:right; padding:6px;'>{pct:.1f}%</td></tr>\"\"\"\n",
        "\n",
        "            table2_html += \"</table>\"\n",
        "            display(HTML(table2_html))\n",
        "\n",
        "            display(HTML(f\"<h4 style='margin-top:25px;'>üîÄ Combination Matrix: {mod1} √ó {mod2}</h4>\"))\n",
        "            crosstab = pd.crosstab(analysis_data[mod1], analysis_data[mod2], margins=True, margins_name='Total')\n",
        "            display(crosstab.style.background_gradient(cmap='Blues', subset=pd.IndexSlice[crosstab.index[:-1], crosstab.columns[:-1]]))\n",
        "\n",
        "            n_empty = (crosstab.iloc[:-1, :-1] == 0).sum().sum()\n",
        "            min_cell = crosstab.iloc[:-1, :-1].min().min()\n",
        "\n",
        "            if n_empty > 0:\n",
        "                display(HTML(f\"<div style='background:#f8d7da; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            f\"‚ö†Ô∏è {n_empty} empty combinations - will be excluded</div>\"))\n",
        "            elif min_cell < 3:\n",
        "                display(HTML(f\"<div style='background:#fff3cd; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            f\"‚ö†Ô∏è Min cell: {min_cell} - results may be unstable</div>\"))\n",
        "            elif min_cell < 5:\n",
        "                display(HTML(f\"<div style='background:#fff3cd; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            f\"‚ö†Ô∏è Some combinations limited (min: {min_cell})</div>\"))\n",
        "            else:\n",
        "                display(HTML(\"<div style='background:#d4edda; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            \"‚úì All combinations have ‚â•5 obs</div>\"))\n",
        "\n",
        "def update_thresholds_tab(change=None):\n",
        "    with tab_thresholds:\n",
        "        clear_output()\n",
        "\n",
        "        if moderator1_widget is None:\n",
        "            print(\"Initializing...\")\n",
        "            return\n",
        "\n",
        "        display(HTML(\"<h3 style='margin-top:0;'>Quality Thresholds & Impact Analysis</h3>\"))\n",
        "        display(HTML(\"\"\"<div style='background:#f8f9fa; padding:12px; border-radius:6px; margin-bottom:15px;'>\n",
        "            <b>Purpose:</b> Ensure sufficient data for reliable estimation<br>\n",
        "            <span style='font-size:13px; color:#555;'>Higher = more reliable but fewer subgroups</span></div>\"\"\"))\n",
        "\n",
        "        display(min_papers_widget)\n",
        "        display(min_obs_widget)\n",
        "        display(HTML(\"<h4 style='margin-top:25px;'>Impact on Data Retention</h4>\"))\n",
        "\n",
        "        mod1 = moderator1_widget.value\n",
        "        analysis_type = analysis_type_widget.value\n",
        "        mod2 = moderator2_widget.value if analysis_type == 'two_way' and moderator2_widget.value != 'None' else None\n",
        "        min_papers, min_obs = min_papers_widget.value, min_obs_widget.value\n",
        "\n",
        "        groups_meeting, groups_failing = [], []\n",
        "\n",
        "        if analysis_type == 'single':\n",
        "            for cat in analysis_data[mod1].dropna().unique():\n",
        "                group_data = analysis_data[analysis_data[mod1] == cat]\n",
        "                n_papers, n_obs = group_data['id'].nunique(), len(group_data)\n",
        "\n",
        "                if n_papers >= min_papers and n_obs >= min_obs:\n",
        "                    groups_meeting.append((cat, n_obs, n_papers))\n",
        "                else:\n",
        "                    groups_failing.append((cat, n_obs, n_papers))\n",
        "        else:\n",
        "            if mod2:\n",
        "                for cat1 in analysis_data[mod1].dropna().unique():\n",
        "                    for cat2 in analysis_data[mod2].dropna().unique():\n",
        "                        cell_data = analysis_data[(analysis_data[mod1] == cat1) & (analysis_data[mod2] == cat2)]\n",
        "                        n_papers, n_obs = cell_data['id'].nunique(), len(cell_data)\n",
        "\n",
        "                        if n_papers >= min_papers and n_obs >= min_obs:\n",
        "                            groups_meeting.append((f\"{cat1} √ó {cat2}\", n_obs, n_papers))\n",
        "                        elif n_obs > 0:\n",
        "                            groups_failing.append((f\"{cat1} √ó {cat2}\", n_obs, n_papers))\n",
        "\n",
        "        total_retained = sum(obs for _, obs, _ in groups_meeting)\n",
        "        retention_pct = (total_retained / len(analysis_data)) * 100\n",
        "\n",
        "        cards_html = f\"\"\"<div style='display:flex; gap:15px; margin-bottom:20px;'>\n",
        "            <div style='flex:1; background:#d4edda; padding:15px; border-radius:6px; text-align:center;'>\n",
        "                <div style='font-size:28px; font-weight:bold; color:#155724;'>{len(groups_meeting)}</div>\n",
        "                <div style='font-size:13px; color:#155724;'>Groups Meeting Criteria</div></div>\n",
        "            <div style='flex:1; background:#{'#f8d7da' if len(groups_failing) > 0 else '#e2e3e5'}; padding:15px; border-radius:6px; text-align:center;'>\n",
        "                <div style='font-size:28px; font-weight:bold; color:#{'#721c24' if len(groups_failing) > 0 else '#6c757d'};'>{len(groups_failing)}</div>\n",
        "                <div style='font-size:13px; color:#{'#721c24' if len(groups_failing) > 0 else '#6c757d'};'>Groups Excluded</div></div>\n",
        "            <div style='flex:1; background:#{'#d4edda' if retention_pct >= 75 else '#fff3cd' if retention_pct >= 50 else '#f8d7da'}; padding:15px; border-radius:6px; text-align:center;'>\n",
        "                <div style='font-size:28px; font-weight:bold;'>{retention_pct:.0f}%</div>\n",
        "                <div style='font-size:13px;'>Data Retained</div></div></div>\"\"\"\n",
        "        display(HTML(cards_html))\n",
        "\n",
        "        if groups_meeting:\n",
        "            display(HTML(\"<h4>‚úì Groups Meeting Criteria:</h4>\"))\n",
        "            meet_html = \"<ul style='margin-top:5px;'>\"\n",
        "            for cat, obs, papers in groups_meeting:\n",
        "                meet_html += f\"<li><b>{cat}:</b> {obs} obs, {papers} papers</li>\"\n",
        "            meet_html += \"</ul>\"\n",
        "            display(HTML(meet_html))\n",
        "\n",
        "        if groups_failing:\n",
        "            display(HTML(\"<h4 style='margin-top:20px;'>‚úó Groups Excluded:</h4>\"))\n",
        "            fail_html = \"<ul style='margin-top:5px; color:#721c24;'>\"\n",
        "            for cat, obs, papers in groups_failing:\n",
        "                reason = []\n",
        "                if papers < min_papers:\n",
        "                    reason.append(f\"papers: {papers}<{min_papers}\")\n",
        "                if obs < min_obs:\n",
        "                    reason.append(f\"obs: {obs}<{min_obs}\")\n",
        "                fail_html += f\"<li><b>{cat}:</b> {obs} obs, {papers} papers ({', '.join(reason)})</li>\"\n",
        "            fail_html += \"</ul>\"\n",
        "            display(HTML(fail_html))\n",
        "\n",
        "        if len(groups_meeting) < 2:\n",
        "            display(HTML(\"<div style='background:#f8d7da; padding:12px; border-radius:6px; margin-top:15px;'>\"\n",
        "                        \"üî¥ <b>ERROR:</b> Need ‚â•2 groups. Lower thresholds.</div>\"))\n",
        "        elif retention_pct < 50:\n",
        "            display(HTML(\"<div style='background:#fff3cd; padding:12px; border-radius:6px; margin-top:15px;'>\"\n",
        "                        \"‚ö†Ô∏è <b>WARNING:</b> <50% data retained. Consider lowering thresholds.</div>\"))\n",
        "\n",
        "def update_all_tabs(change=None):\n",
        "    update_config_tab()\n",
        "    update_moderators_tab()\n",
        "    update_thresholds_tab()\n",
        "\n",
        "# --- 5. SAVE CONFIGURATION ---\n",
        "def save_configuration(button):\n",
        "    with status_output:\n",
        "        clear_output()\n",
        "\n",
        "        analysis_type = analysis_type_widget.value\n",
        "        mod1 = moderator1_widget.value\n",
        "        mod2 = moderator2_widget.value if analysis_type == 'two_way' and moderator2_widget.value != 'None' else None\n",
        "        min_papers, min_obs = min_papers_widget.value, min_obs_widget.value\n",
        "\n",
        "        validation_errors = []\n",
        "\n",
        "        if analysis_type == 'two_way' and not mod2:\n",
        "            validation_errors.append(\"Two-way requires Moderator 2\")\n",
        "\n",
        "        if mod1 == mod2:\n",
        "            validation_errors.append(\"Moderators cannot be the same\")\n",
        "\n",
        "        valid_groups = []\n",
        "        if analysis_type == 'single':\n",
        "            for cat in analysis_data[mod1].dropna().unique():\n",
        "                group_data = analysis_data[analysis_data[mod1] == cat]\n",
        "                if group_data['id'].nunique() >= min_papers and len(group_data) >= min_obs:\n",
        "                    valid_groups.append(cat)\n",
        "        else:\n",
        "            if mod2:\n",
        "                for cat1 in analysis_data[mod1].dropna().unique():\n",
        "                    for cat2 in analysis_data[mod2].dropna().unique():\n",
        "                        cell_data = analysis_data[(analysis_data[mod1] == cat1) & (analysis_data[mod2] == cat2)]\n",
        "                        if cell_data['id'].nunique() >= min_papers and len(cell_data) >= min_obs:\n",
        "                            valid_groups.append((cat1, cat2))\n",
        "\n",
        "        if len(valid_groups) < 2:\n",
        "            validation_errors.append(f\"Only {len(valid_groups)} group(s) meet criteria. Need ‚â•2.\")\n",
        "\n",
        "        if validation_errors:\n",
        "            error_html = \"<div style='background:#f8d7da; padding:15px; border-radius:6px; border-left:4px solid #dc3545;'>\"\n",
        "            error_html += \"<h4 style='margin-top:0; color:#721c24;'>‚ùå Validation Failed</h4><ul style='margin-bottom:0; color:#721c24;'>\"\n",
        "            for err in validation_errors:\n",
        "                error_html += f\"<li>{err}</li>\"\n",
        "            error_html += \"</ul></div>\"\n",
        "            display(HTML(error_html))\n",
        "            return\n",
        "\n",
        "        if analysis_type == 'single':\n",
        "            retained_data = analysis_data[analysis_data[mod1].isin(valid_groups)]\n",
        "        else:\n",
        "            retained_data = analysis_data[analysis_data.apply(lambda row: (row[mod1], row[mod2]) in valid_groups, axis=1)]\n",
        "\n",
        "        retention_pct = (len(retained_data) / len(analysis_data)) * 100\n",
        "\n",
        "        ANALYSIS_CONFIG['subgroup_config'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'analysis_type': analysis_type,\n",
        "            'moderator1': mod1,\n",
        "            'moderator2': mod2,\n",
        "            'min_papers': min_papers,\n",
        "            'min_obs': min_obs,\n",
        "            'expected_groups': len(valid_groups),\n",
        "            'valid_groups_list': valid_groups,\n",
        "            'data_retained': len(retained_data),\n",
        "            'retention_pct': retention_pct,\n",
        "            'has_empty_cells': analysis_type == 'two_way' and mod2 and\n",
        "                               (pd.crosstab(analysis_data[mod1], analysis_data[mod2]) == 0).sum().sum() > 0,\n",
        "            'n_empty_cells': (pd.crosstab(analysis_data[mod1], analysis_data[mod2]) == 0).sum().sum()\n",
        "                            if analysis_type == 'two_way' and mod2 else 0\n",
        "        }\n",
        "\n",
        "        ANALYSIS_CONFIG['subgroup_config']['moderator1_info'] = {\n",
        "            'name': mod1,\n",
        "            'n_categories': analysis_data[mod1].nunique(),\n",
        "            'categories': sorted(analysis_data[mod1].dropna().unique().tolist())\n",
        "        }\n",
        "\n",
        "        if mod2:\n",
        "            ANALYSIS_CONFIG['subgroup_config']['moderator2_info'] = {\n",
        "                'name': mod2,\n",
        "                'n_categories': analysis_data[mod2].nunique(),\n",
        "                'categories': sorted(analysis_data[mod2].dropna().unique().tolist())\n",
        "            }\n",
        "\n",
        "        success_html = f\"\"\"<div style='background:#d4edda; padding:15px; border-radius:6px; border-left:4px solid #28a745;'>\n",
        "            <h4 style='margin-top:0; color:#155724;'>‚úì Configuration Saved Successfully</h4>\n",
        "            <table style='width:100%; margin-top:10px;'>\n",
        "                <tr><td><b>Analysis Type:</b></td><td>{analysis_type}</td></tr>\n",
        "                <tr><td><b>Primary Moderator:</b></td><td>{mod1}</td></tr>\n",
        "                {f'<tr><td><b>Secondary Moderator:</b></td><td>{mod2}</td></tr>' if mod2 else ''}\n",
        "                <tr><td><b>Valid Groups:</b></td><td>{len(valid_groups)}</td></tr>\n",
        "                <tr><td><b>Data Retained:</b></td><td>{len(retained_data)}/{len(analysis_data)} ({retention_pct:.1f}%)</td></tr>\n",
        "            </table>\n",
        "            <p style='margin:10px 0 0 0; color:#155724; font-size:14px;'><b>‚úÖ Ready! Proceed to the next cell to run the subgroup analysis.</b></p></div>\"\"\"\n",
        "        display(HTML(success_html))\n",
        "\n",
        "        with tab_details:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"‚úì CONFIGURATION SAVED\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            print(\"\\nConfiguration stored in ANALYSIS_CONFIG['subgroup_config']\")\n",
        "            print(\"Ready to proceed to subgroup analysis execution.\")\n",
        "\n",
        "# --- 6. INITIALIZE AND DISPLAY ---\n",
        "try:\n",
        "    available_mods = initialize_configuration()\n",
        "    update_all_tabs()\n",
        "    display(tabs)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Initialization failed: {e}\")\n",
        "    print(\"\\nPlease ensure:\")\n",
        "    print(\"  1. Step 2 (Overall Meta-Analysis) has been run\")\n",
        "    print(\"  2. ANALYSIS_CONFIG is properly configured\")\n",
        "    print(\"  3. analysis_data is available\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üß™ R Validation: Overall 3-Level Model\n",
        "# =============================================================================\n",
        "# CELL: OVERALL MODEL VALIDATION\n",
        "# Purpose: Verify 3-Level Random-Effects Model estimates against R (metafor::rma.mv)\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"VALIDATION STEP 2: OVERALL 3-LEVEL MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Check Dependencies\n",
        "if 'ANALYSIS_CONFIG' not in globals() or 'three_level_results' not in ANALYSIS_CONFIG:\n",
        "    print(\"‚ùå Error: Please run the 'OVERALL META-ANALYSIS' cell (Step 2) first.\")\n",
        "else:\n",
        "    # 2. Get Python Results\n",
        "    py_res = ANALYSIS_CONFIG['three_level_results']\n",
        "\n",
        "    # Get Data\n",
        "    if 'analysis_data' in ANALYSIS_CONFIG:\n",
        "        df_py = ANALYSIS_CONFIG['analysis_data'].copy()\n",
        "    else:\n",
        "        df_py = data_filtered.copy()\n",
        "\n",
        "    effect_col = ANALYSIS_CONFIG['effect_col']\n",
        "    var_col = ANALYSIS_CONFIG['var_col']\n",
        "\n",
        "    print(f\"üîç Validating Model: 3-Level Random-Effects (REML)\")\n",
        "    print(f\"   Structure: Effect ~ 1 | Study / Observation\")\n",
        "    print(f\"   Data: {len(df_py)} observations from {df_py['id'].nunique()} studies\")\n",
        "\n",
        "    # 3. Prepare Data for R\n",
        "    # We need to explicitly handle the ID column to ensure it's treated as a factor\n",
        "    df_r = df_py[['id', effect_col, var_col]].dropna()\n",
        "\n",
        "    ro.globalenv['df_python'] = df_r\n",
        "    ro.globalenv['eff_col'] = effect_col\n",
        "    ro.globalenv['var_col'] = var_col\n",
        "\n",
        "    # 4. Run R Script (rma.mv)\n",
        "    r_script = \"\"\"\n",
        "    library(metafor)\n",
        "\n",
        "    dat <- df_python\n",
        "\n",
        "    # Create row ID for Level 2 (Observation level)\n",
        "    dat$row_id <- 1:nrow(dat)\n",
        "\n",
        "    # Ensure Study ID is a factor for Level 3\n",
        "    dat$study_id <- as.factor(dat$id)\n",
        "\n",
        "    # Run 3-Level Model\n",
        "    # random = ~ 1 | study_id / row_id adds random intercepts for study and observation\n",
        "    res <- rma.mv(yi = dat[[eff_col]],\n",
        "                  V = dat[[var_col]],\n",
        "                  random = ~ 1 | study_id/row_id,\n",
        "                  data = dat,\n",
        "                  method = \"REML\")\n",
        "\n",
        "    list(\n",
        "        b = as.numeric(res$b),          # Pooled Effect\n",
        "        se = as.numeric(res$se),        # Standard Error\n",
        "        tau2 = res$sigma2[1],           # Level 3 Variance (Between-Study)\n",
        "        sigma2 = res$sigma2[2],         # Level 2 Variance (Within-Study)\n",
        "        pval = as.numeric(res$pval)     # P-value\n",
        "    )\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        r_res = ro.r(r_script)\n",
        "\n",
        "        # Extract R results\n",
        "        r_beta = r_res.rx2('b')[0]\n",
        "        r_se = r_res.rx2('se')[0]\n",
        "        r_tau2 = r_res.rx2('tau2')[0]\n",
        "        r_sigma2 = r_res.rx2('sigma2')[0]\n",
        "        r_pval = r_res.rx2('pval')[0]\n",
        "\n",
        "        # Extract Python results\n",
        "        py_beta = py_res['pooled_effect']\n",
        "        py_se = py_res['se']\n",
        "        py_tau2 = py_res['tau_squared']\n",
        "        py_sigma2 = py_res['sigma_squared']\n",
        "\n",
        "        # 5. Compare\n",
        "        print(\"\\nüìä VALIDATION RESULTS:\")\n",
        "        print(f\"{'Metric':<20} {'Python':<12} {'R (metafor)':<12} {'Diff':<12}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        def compare(label, py_val, r_val):\n",
        "            diff = abs(py_val - r_val)\n",
        "            print(f\"{label:<20} {py_val:<12.4f} {r_val:<12.4f} {diff:.2e}\")\n",
        "            return diff\n",
        "\n",
        "        d1 = compare(\"Pooled Effect\", py_beta, r_beta)\n",
        "        d2 = compare(\"Standard Error\", py_se, r_se)\n",
        "        d3 = compare(\"Tau¬≤ (L3 Var)\", py_tau2, r_tau2)\n",
        "        d4 = compare(\"Sigma¬≤ (L2 Var)\", py_sigma2, r_sigma2)\n",
        "\n",
        "        # 6. Check Pass/Fail\n",
        "        # Optimization results can vary slightly due to tolerance/algorithm differences\n",
        "        # We accept differences < 1e-3 for variances, < 1e-4 for effects\n",
        "        if d1 < 1e-4 and d2 < 1e-4 and d3 < 1e-3 and d4 < 1e-3:\n",
        "            print(\"\\n‚úÖ SUCCESS: 3-Level Model matches R.\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è CAUTION: Check discrepancies.\")\n",
        "            print(\"   Small differences in variance (Tau¬≤/Sigma¬≤) are common due to optimization algorithms\")\n",
        "            print(\"   (e.g., Nelder-Mead vs L-BFGS-B). If Effect/SE are close, the model is likely valid.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå R Execution Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XS25cvfO7CEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mVbKzKpRjeOi"
      },
      "source": [
        "#@title üî¨ Step 3b: Subgroup Analysis - Execution (V2)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL: SUBGROUP ANALYSIS WITH DASHBOARD\n",
        "# Purpose: Run three-level meta-analysis for each subgroup with organized output.\n",
        "# Enhancement: Uses tabbed interface for better readability.\n",
        "# Dependencies: Step 2 (Overall Meta-Analysis), Step 3a (Configuration)\n",
        "# Compatible with: Maintains same output structure as original for downstream cells\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.optimize import minimize, minimize_scalar\n",
        "from scipy.stats import norm, chi2\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import sys\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# --- 0. HELPER FUNCTIONS (FROM PREVIOUS CELLS) ---\n",
        "# Note: This cell expects calculate_tau_squared, _negative_log_likelihood_reml,\n",
        "# and _get_three_level_estimates to be defined from previous cells (4.5, 6.5)\n",
        "\n",
        "# If not already defined, provide fallbacks\n",
        "if '_negative_log_likelihood_reml' not in dir():\n",
        "    def _negative_log_likelihood_reml(params, y_all, v_all, N_total, M_studies):\n",
        "        \"\"\"Placeholder - should be defined in Cell 6.5\"\"\"\n",
        "        raise NotImplementedError(\"Please run Cell 6.5 first to define this function\")\n",
        "\n",
        "if '_get_three_level_estimates' not in dir():\n",
        "    def _get_three_level_estimates(params, y_all, v_all, N_total, M_studies):\n",
        "        \"\"\"Placeholder - should be defined in Cell 6.5\"\"\"\n",
        "        raise NotImplementedError(\"Please run Cell 6.5 first to define this function\")\n",
        "\n",
        "if 'calculate_tau_squared' not in dir():\n",
        "    def calculate_tau_squared(df, effect_col, var_col, method='REML'):\n",
        "        \"\"\"Fallback - should be defined in Cell 4.5\"\"\"\n",
        "        # Simple DL estimator as fallback\n",
        "        k = len(df)\n",
        "        if k < 2: return 0.0, {}\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "        wi = 1/vi\n",
        "        mu = np.average(yi, weights=wi)\n",
        "        Q = np.sum(wi * (yi - mu)**2)\n",
        "        C = np.sum(wi) - np.sum(wi**2)/np.sum(wi)\n",
        "        tau2 = max(0, (Q - (k-1)) / C) if C > 0 else 0\n",
        "        return tau2, {}\n",
        "\n",
        "def _run_three_level_reml_for_subgroup(analysis_data, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Main optimization function for a single subgroup.\n",
        "    Returns estimates or None on failure.\n",
        "    \"\"\"\n",
        "    grouped = analysis_data.groupby('id')\n",
        "    y_all = [group[effect_col].values for _, group in grouped]\n",
        "    v_all = [group[var_col].values for _, group in grouped]\n",
        "    N_total = len(analysis_data)\n",
        "    M_studies = len(y_all)\n",
        "    if M_studies < 2:\n",
        "        return None, None\n",
        "    try:\n",
        "        tau_sq_start, _ = calculate_tau_squared(analysis_data, effect_col, var_col, method='REML')\n",
        "    except Exception:\n",
        "        tau_sq_start = 0.01\n",
        "    initial_params = [max(0, tau_sq_start), 0.01]\n",
        "    bounds = [(0, None), (0, None)]\n",
        "\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        optimizer_result = minimize(\n",
        "            _negative_log_likelihood_reml,\n",
        "            x0=initial_params,\n",
        "            args=(y_all, v_all, N_total, M_studies),\n",
        "            method='L-BFGS-B',\n",
        "            bounds=bounds,\n",
        "            options={'ftol': 1e-10, 'gtol': 1e-6, 'maxiter': 500}\n",
        "        )\n",
        "    if not optimizer_result.success:\n",
        "        return None, None\n",
        "\n",
        "    final_estimates = _get_three_level_estimates(\n",
        "        optimizer_result.x, y_all, v_all, N_total, M_studies\n",
        "    )\n",
        "    return final_estimates, (y_all, v_all, N_total, M_studies)\n",
        "\n",
        "# --- 0.5 PUBLICATION TEXT GENERATOR FOR SUBGROUPS ---\n",
        "def generate_subgroup_publication_text(results_df, moderator1, moderator2, QM, df_QM, p_value_QM,\n",
        "                                       R_squared, Qt_overall, QE_sum, df_QE):\n",
        "    \"\"\"Generate publication-ready text for subgroup analysis\"\"\"\n",
        "\n",
        "    M_groups = len(results_df)\n",
        "    sig_QM = \"significant\" if p_value_QM < 0.05 else \"non-significant\"\n",
        "    p_format_QM = f\"< 0.001\" if p_value_QM < 0.001 else f\"= {p_value_QM:.3f}\"\n",
        "\n",
        "    # R¬≤ interpretation\n",
        "    if R_squared < 25:\n",
        "        r2_interp = \"low R¬≤ value suggests that this moderator explains only a small proportion of heterogeneity, and other unmeasured factors likely contribute to the observed variation in effect sizes\"\n",
        "    elif R_squared < 50:\n",
        "        r2_interp = \"moderate R¬≤ value indicates that this moderator partially explains the heterogeneity, though substantial unexplained variation remains\"\n",
        "    else:\n",
        "        r2_interp = \"high R¬≤ value indicates that this moderator is a substantial source of heterogeneity in the meta-analysis\"\n",
        "\n",
        "    # Build text\n",
        "    text = f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt; line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "<h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>Subgroup Analysis Results</h3>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "To explore sources of heterogeneity, we conducted a subgroup analysis based on <b>{moderator1}</b>\"\"\"\n",
        "\n",
        "    if moderator2:\n",
        "        text += f\"\"\" and <b>{moderator2}</b>. We examined the interaction between these two moderators\"\"\"\n",
        "\n",
        "    text += f\"\"\". The dataset included <b>{M_groups}</b> subgroups with sufficient data for analysis (minimum of 2 studies per subgroup).\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Overall Test for Subgroup Differences</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The test for subgroup differences was <b>{sig_QM}</b> (<i>Q</i><sub>M</sub>({df_QM}) = <b>{QM:.2f}</b>, <i>p</i> {p_format_QM}), \"\"\"\n",
        "\n",
        "    if p_value_QM < 0.05:\n",
        "        text += f\"\"\"indicating that the moderator variable significantly explained variation in effect sizes across studies. The moderator accounted for <b>{R_squared:.1f}%</b> of the total heterogeneity (R¬≤ = {R_squared:.1f}%).\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Heterogeneity Partitioning</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Heterogeneity was partitioned into between-group (<i>Q</i><sub>M</sub>({df_QM}) = {QM:.2f}) and within-group components (<i>Q</i><sub>E</sub>({df_QE}) = {QE_sum:.2f}) from the total heterogeneity (<i>Q</i><sub>T</sub>({Qt_overall - 1:.0f}) = {Qt_overall:.2f}). The {r2_interp}.\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Individual Subgroup Results</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Results by subgroup were as follows (Table 1):\n",
        "</p>\n",
        "\n",
        "<ul style='line-height: 2.0;'>\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"suggesting that the moderator variable did not significantly explain variation in effect sizes across studies. The moderator accounted for only <b>{R_squared:.1f}%</b> of the total heterogeneity (R¬≤ = {R_squared:.1f}%).\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Heterogeneity Partitioning</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Heterogeneity was partitioned into between-group (<i>Q</i><sub>M</sub>({df_QM}) = {QM:.2f}) and within-group components (<i>Q</i><sub>E</sub>({df_QE}) = {QE_sum:.2f}) from the total heterogeneity (<i>Q</i><sub>T</sub>({Qt_overall - 1:.0f}) = {Qt_overall:.2f}). The {r2_interp}.\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Individual Subgroup Results</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Results by subgroup were as follows (Table 1):\n",
        "</p>\n",
        "\n",
        "<ul style='line-height: 2.0;'>\n",
        "\"\"\"\n",
        "\n",
        "    # Individual subgroup results\n",
        "    for _, row in results_df.iterrows():\n",
        "        group_name = row['group']\n",
        "        k = int(row['k'])\n",
        "        n_papers = int(row['n_papers'])\n",
        "        effect = row['pooled_effect_re']\n",
        "        ci_l = row['ci_lower_re']\n",
        "        ci_h = row['ci_upper_re']\n",
        "        p_val = row['p_value_re']\n",
        "        I2 = row['I_squared']\n",
        "        tau2 = row['tau_squared']\n",
        "        sigma2 = row['sigma_squared']\n",
        "\n",
        "        sig_text = \"significant\" if p_val < 0.05 else \"non-significant\"\n",
        "        p_format = f\"< 0.001\" if p_val < 0.001 else f\"= {p_val:.3f}\"\n",
        "\n",
        "        het_text = \"with\" if I2 >= 50 else \"without\"\n",
        "\n",
        "        text += f\"\"\"<li><b>{group_name}:</b> Based on {k} effect sizes from {n_papers} studies, the pooled effect was <b>{effect:.3f}</b> (95% CI [{ci_l:.3f}, {ci_h:.3f}], <i>p</i> {p_format}), {het_text} substantial heterogeneity (<i>I</i>¬≤ = {I2:.1f}%, œÑ¬≤ = {tau2:.4f}, œÉ¬≤ = {sigma2:.4f}).</li>\n",
        "\"\"\"\n",
        "\n",
        "    text += \"</ul>\"\n",
        "\n",
        "    # Comparative statements\n",
        "    max_effect_row = results_df.loc[results_df['pooled_effect_re'].idxmax()]\n",
        "    min_effect_row = results_df.loc[results_df['pooled_effect_re'].idxmin()]\n",
        "\n",
        "    text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Comparative Interpretation</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The largest effect was observed for <b>{max_effect_row['group']}</b> ({max_effect_row['pooled_effect_re']:.3f}, 95% CI [{max_effect_row['ci_lower_re']:.3f}, {max_effect_row['ci_upper_re']:.3f}])\"\"\"\n",
        "\n",
        "    if M_groups > 1:\n",
        "        text += f\"\"\", while <b>{min_effect_row['group']}</b> showed the {'smallest' if min_effect_row['pooled_effect_re'] > 0 else 'most negative'} effect ({min_effect_row['pooled_effect_re']:.3f}, 95% CI [{min_effect_row['ci_lower_re']:.3f}, {min_effect_row['ci_upper_re']:.3f}])\"\"\"\n",
        "\n",
        "    text += \".\"\n",
        "    text += \"</p>\"\n",
        "\n",
        "    # Interpretation based on Q_M significance\n",
        "    if p_value_QM < 0.05:\n",
        "        text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "These results demonstrate that <b>{moderator1}</b>\"\"\"\n",
        "        if moderator2:\n",
        "            text += f\"\"\" and <b>{moderator2}</b>\"\"\"\n",
        "        text += f\"\"\" is an important moderator of the outcome, with differential effects observed across subgroups. [<i>Add mechanistic explanation or theoretical context specific to your research domain</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "Although numerical differences were observed among subgroups, these differences were not statistically significant. This suggests that <b>{moderator1}</b>\"\"\"\n",
        "        if moderator2:\n",
        "            text += f\"\"\" and <b>{moderator2}</b>\"\"\"\n",
        "        text += f\"\"\" may not be a primary driver of heterogeneity in this meta-analysis, or that insufficient statistical power limits our ability to detect subgroup differences. [<i>Consider discussing alternative explanations or limitations</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    # Within-subgroup heterogeneity\n",
        "    avg_I2 = results_df['I_squared'].mean()\n",
        "\n",
        "    text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Within-Subgroup Heterogeneity</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "\"\"\"\n",
        "\n",
        "    if avg_I2 >= 50:\n",
        "        text += f\"\"\"Substantial heterogeneity remained within subgroups on average (<i>Q</i><sub>E</sub> = {QE_sum:.2f}), indicating that additional moderators not examined in this analysis likely contribute to variation in effect sizes. Future research should investigate [<i>suggest other potential moderators based on your domain knowledge</i>].\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"Residual heterogeneity within subgroups was low to moderate on average, suggesting that the moderator variable successfully captured much of the systematic variation in effect sizes.\n",
        "\"\"\"\n",
        "\n",
        "    text += \"\"\"</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Statistical Methods</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Each subgroup analysis employed a three-level random-effects model to account for the nested structure of effect sizes within studies, providing robust estimates that accommodate within-study dependencies. All analyses were conducted using [<i>specify your software/package</i>].\n",
        "</p>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 25px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>üìä Table 1. Summary of Subgroup Analysis Results</h4>\n",
        "<table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "<thead style='background-color: #34495e; color: white;'>\n",
        "<tr>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Subgroup</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>k</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Studies</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Effect</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>95% CI</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>p</i>-value</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>I</i>¬≤</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "\"\"\"\n",
        "\n",
        "    for idx, row in results_df.iterrows():\n",
        "        bg_color = \"#f8f9fa\" if idx % 2 == 0 else \"white\"\n",
        "        sig_style = \"font-weight: bold;\" if row['p_value_re'] < 0.05 else \"\"\n",
        "\n",
        "        text += f\"\"\"<tr style='background-color: {bg_color};'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>{row['group']}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{int(row['k'])}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{int(row['n_papers'])}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center; {sig_style}'>{row['pooled_effect_re']:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{row['ci_lower_re']:.3f}, {row['ci_upper_re']:.3f}]</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{row['p_value_re']:.3g}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{row['I_squared']:.1f}%</td>\n",
        "</tr>\n",
        "\"\"\"\n",
        "\n",
        "    text += f\"\"\"</tbody>\n",
        "</table>\n",
        "<p style='margin-top: 10px; font-size: 0.9em; color: #6c757d;'><i>Note:</i> k = number of effect sizes; Studies = number of independent studies; CI = confidence interval; <i>I</i>¬≤ = heterogeneity statistic.</p>\n",
        "</div>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; margin-top: 20px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "<ul style='margin-bottom: 0;'>\n",
        "<li>Customize subgroup descriptions based on your specific moderator variables and research context</li>\n",
        "<li>Add domain-specific interpretations of why certain subgroups show different effects</li>\n",
        "<li>Include relevant post-hoc pairwise comparisons if appropriate for your analysis</li>\n",
        "<li>Discuss potential confounding factors or limitations (e.g., unbalanced sample sizes across subgroups)</li>\n",
        "<li>Link findings to your theoretical framework or prior research in the field</li>\n",
        "<li>Consider conducting sensitivity analyses to test the robustness of subgroup differences</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "<p style='margin: 0;'><b>üí° Tip:</b> Select all text (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C), and paste into your word processor. Most formatting will be preserved. Edit the [<i>bracketed notes</i>] to add your specific interpretations.</p>\n",
        "</div>\n",
        "\n",
        "</div>\"\"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# --- 1. LAYOUT & WIDGETS ---\n",
        "tab_results = widgets.Output()\n",
        "tab_hetero = widgets.Output()\n",
        "tab_details = widgets.Output()\n",
        "tab_config = widgets.Output()\n",
        "tab_publication = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_results, tab_hetero, tab_details, tab_config, tab_publication])\n",
        "tabs.set_title(0, 'üìä Results Summary')\n",
        "tabs.set_title(1, 'üìâ Heterogeneity')\n",
        "tabs.set_title(2, 'üîç Subgroup Details')\n",
        "tabs.set_title(3, '‚öôÔ∏è Configuration')\n",
        "tabs.set_title(4, 'üìù Publication Text')\n",
        "\n",
        "# --- 2. MAIN ANALYSIS FUNCTION ---\n",
        "def run_subgroup_analysis():\n",
        "    \"\"\"Main analysis engine that populates all tabs\"\"\"\n",
        "\n",
        "    # Clear all tabs\n",
        "    for tab in [tab_results, tab_hetero, tab_details, tab_config, tab_publication]:\n",
        "        tab.clear_output()\n",
        "\n",
        "    # --- TAB 4: CONFIGURATION (Display first for context) ---\n",
        "    with tab_config:\n",
        "        display(HTML(\"<h3>‚öôÔ∏è Analysis Configuration</h3>\"))\n",
        "\n",
        "        try:\n",
        "            if 'ANALYSIS_CONFIG' not in globals():\n",
        "                display(HTML(\"<div style='color: red;'>‚ùå ANALYSIS_CONFIG not found. Run previous cells first.</div>\"))\n",
        "                return\n",
        "\n",
        "            # Load configuration\n",
        "            config_html = \"<div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;'>\"\n",
        "            config_html += f\"<b>Timestamp:</b> {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>\"\n",
        "\n",
        "            if 'subgroup_config' in ANALYSIS_CONFIG:\n",
        "                sc = ANALYSIS_CONFIG['subgroup_config']\n",
        "                config_html += f\"<b>Analysis Type:</b> {sc['analysis_type']}<br>\"\n",
        "                config_html += f\"<b>Moderator 1:</b> {sc['moderator1']}<br>\"\n",
        "                if sc.get('moderator2'):\n",
        "                    config_html += f\"<b>Moderator 2:</b> {sc['moderator2']}<br>\"\n",
        "                config_html += f\"<b>Number of Subgroups:</b> {len(sc['valid_groups_list'])}<br>\"\n",
        "\n",
        "            if 'effect_col' in ANALYSIS_CONFIG:\n",
        "                config_html += f\"<b>Effect Column:</b> {ANALYSIS_CONFIG['effect_col']}<br>\"\n",
        "                config_html += f\"<b>Variance Column:</b> {ANALYSIS_CONFIG['var_col']}<br>\"\n",
        "\n",
        "            config_html += \"</div>\"\n",
        "            display(HTML(config_html))\n",
        "\n",
        "            # Check prerequisites\n",
        "            required = ['overall_results', 'three_level_results', 'subgroup_config']\n",
        "            missing = [k for k in required if k not in ANALYSIS_CONFIG]\n",
        "\n",
        "            if missing:\n",
        "                display(HTML(f\"<div style='color: red;'>‚ùå Missing: {', '.join(missing)}</div>\"))\n",
        "                display(HTML(\"<p>Please run:</p><ul><li>Step 2: Overall Meta-Analysis</li><li>Step 3a: Subgroup Configuration</li></ul>\"))\n",
        "                return\n",
        "\n",
        "            display(HTML(\"<div style='color: green;'>‚úÖ All prerequisites met</div>\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            display(HTML(f\"<div style='color: red;'>‚ùå Configuration Error: {e}</div>\"))\n",
        "            return\n",
        "\n",
        "    # --- MAIN ANALYSIS ---\n",
        "    try:\n",
        "        # Load data\n",
        "        if 'analysis_data' in globals():\n",
        "            analysis_data = globals()['analysis_data'].copy()\n",
        "        elif 'data_filtered' in globals():\n",
        "            analysis_data = globals()['data_filtered'].copy()\n",
        "        else:\n",
        "            with tab_results:\n",
        "                display(HTML(\"<div style='color: red;'>‚ùå Data not found</div>\"))\n",
        "            return\n",
        "\n",
        "        # Load configuration\n",
        "        effect_col = ANALYSIS_CONFIG['effect_col']\n",
        "        var_col = ANALYSIS_CONFIG['var_col']\n",
        "        es_config = ANALYSIS_CONFIG['es_config']\n",
        "        overall_results = ANALYSIS_CONFIG['overall_results']\n",
        "        subgroup_config = ANALYSIS_CONFIG['subgroup_config']\n",
        "\n",
        "        analysis_type = subgroup_config['analysis_type']\n",
        "        moderator1 = subgroup_config['moderator1']\n",
        "        moderator2 = subgroup_config.get('moderator2')\n",
        "        valid_groups_list = subgroup_config['valid_groups_list']\n",
        "\n",
        "        # Clean moderator columns\n",
        "        analysis_data[moderator1] = analysis_data[moderator1].astype(str).str.strip()\n",
        "        if moderator2:\n",
        "            analysis_data[moderator2] = analysis_data[moderator2].astype(str).str.strip()\n",
        "\n",
        "        # --- TAB 3: SUBGROUP DETAILS (Stream progress) ---\n",
        "        with tab_details:\n",
        "            display(HTML(\"<h3>üîç Subgroup Analysis Progress</h3>\"))\n",
        "            details_output = widgets.Output()\n",
        "            display(details_output)\n",
        "\n",
        "        subgroup_results_list = []\n",
        "        total_Q_within_fe = 0.0\n",
        "\n",
        "        # Analyze each subgroup\n",
        "        for idx, group_item in enumerate(valid_groups_list, 1):\n",
        "            with tab_details:\n",
        "                with details_output:\n",
        "                    # Get group data\n",
        "                    if analysis_type == 'single':\n",
        "                        group_name = str(group_item)\n",
        "                        group_data = analysis_data[analysis_data[moderator1] == group_name].copy()\n",
        "                    else:\n",
        "                        group_tuple = group_item\n",
        "                        group_name = f\"{group_tuple[0]} x {group_tuple[1]}\"\n",
        "                        group_data = analysis_data[\n",
        "                            (analysis_data[moderator1] == group_tuple[0]) &\n",
        "                            (analysis_data[moderator2] == group_tuple[1])\n",
        "                        ].copy()\n",
        "\n",
        "                    print(f\"\\n{'='*60}\")\n",
        "                    print(f\"Subgroup {idx}/{len(valid_groups_list)}: {group_name}\")\n",
        "                    print(f\"{'='*60}\")\n",
        "\n",
        "                    k_group = len(group_data)\n",
        "                    n_papers_group = group_data['id'].nunique()\n",
        "                    print(f\"üìä Observations: {k_group} | Studies: {n_papers_group}\")\n",
        "\n",
        "                    if k_group < 2 or n_papers_group < 2:\n",
        "                        print(\"‚ö†Ô∏è  Skipping (insufficient data)\")\n",
        "                        continue\n",
        "\n",
        "                    # Run 3-level model\n",
        "                    print(\"üîÑ Running three-level REML optimization...\")\n",
        "                    estimates, _ = _run_three_level_reml_for_subgroup(group_data, effect_col, var_col)\n",
        "\n",
        "                    if estimates is None:\n",
        "                        print(\"‚ùå Optimization failed\")\n",
        "                        continue\n",
        "\n",
        "                    # Extract results\n",
        "                    mu_re = estimates['mu']\n",
        "                    se_re = estimates['se_mu']\n",
        "                    var_re = estimates['var_mu']\n",
        "                    ci_lower_re = mu_re - 1.96 * se_re\n",
        "                    ci_upper_re = mu_re + 1.96 * se_re\n",
        "                    p_value_re = 2 * (1 - norm.cdf(abs(mu_re / se_re)))\n",
        "                    tau_sq_re = estimates['tau_sq']\n",
        "                    sigma_sq_re = estimates['sigma_sq']\n",
        "\n",
        "                    # Calculate I-squared\n",
        "                    mean_v_i = np.mean(group_data[var_col])\n",
        "                    total_variance_est = tau_sq_re + sigma_sq_re + mean_v_i\n",
        "                    I_squared_re = ((tau_sq_re + sigma_sq_re) / total_variance_est) * 100 if total_variance_est > 0 else 0\n",
        "\n",
        "                    # FE model for Q-statistics\n",
        "                    w_fe = 1 / group_data[var_col]\n",
        "                    sum_w_fe = w_fe.sum()\n",
        "                    pooled_effect_fe = (w_fe * group_data[effect_col]).sum() / sum_w_fe\n",
        "                    Q_within_group = (w_fe * (group_data[effect_col] - pooled_effect_fe)**2).sum()\n",
        "                    total_Q_within_fe += Q_within_group\n",
        "\n",
        "                    # Fold change (if applicable)\n",
        "                    if es_config.get('has_fold_change', False):\n",
        "                        RR = np.exp(mu_re)\n",
        "                        fold_change_re = RR if mu_re >= 0 else -1/RR\n",
        "                    else:\n",
        "                        fold_change_re = np.nan\n",
        "\n",
        "                    print(f\"‚úÖ Pooled Effect: {mu_re:.4f} [{ci_lower_re:.4f}, {ci_upper_re:.4f}]\")\n",
        "                    print(f\"   p-value: {p_value_re:.4g} | I¬≤: {I_squared_re:.1f}%\")\n",
        "                    print(f\"   œÑ¬≤: {tau_sq_re:.4f} | œÉ¬≤: {sigma_sq_re:.4f}\")\n",
        "\n",
        "                    # Store results\n",
        "                    result_dict = {\n",
        "                        'group': group_name,\n",
        "                        'k': k_group,\n",
        "                        'n_papers': n_papers_group,\n",
        "                        'pooled_effect_re': mu_re,\n",
        "                        'pooled_se_re': se_re,\n",
        "                        'pooled_var_re': var_re,\n",
        "                        'ci_lower_re': ci_lower_re,\n",
        "                        'ci_upper_re': ci_upper_re,\n",
        "                        'p_value_re': p_value_re,\n",
        "                        'I_squared': I_squared_re,\n",
        "                        'tau_squared': tau_sq_re,\n",
        "                        'sigma_squared': sigma_sq_re,\n",
        "                        'fold_change_re': fold_change_re,\n",
        "                        'Q_within': Q_within_group,\n",
        "                        'df_Q': k_group - 1\n",
        "                    }\n",
        "\n",
        "                    if analysis_type == 'two_way':\n",
        "                        result_dict[moderator1] = group_tuple[0]\n",
        "                        result_dict[moderator2] = group_tuple[1]\n",
        "\n",
        "                    subgroup_results_list.append(result_dict)\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame(subgroup_results_list)\n",
        "\n",
        "        if results_df.empty:\n",
        "            with tab_results:\n",
        "                display(HTML(\"<div style='color: red;'>‚ùå No subgroups were successfully analyzed</div>\"))\n",
        "            return\n",
        "\n",
        "        # --- HETEROGENEITY PARTITIONING ---\n",
        "        Qt_overall = overall_results['Qt']\n",
        "        k_overall = overall_results['k']\n",
        "        Qe_sum = results_df['Q_within'].sum()\n",
        "        df_Qe = results_df['df_Q'].sum()\n",
        "        M_groups = len(results_df)\n",
        "        df_QM = M_groups - 1\n",
        "        QM = max(0, Qt_overall - Qe_sum)\n",
        "        p_value_QM = 1 - chi2.cdf(QM, df_QM) if df_QM > 0 else np.nan\n",
        "        R_squared = max(0, (QM / Qt_overall) * 100) if Qt_overall > 0 else 0\n",
        "\n",
        "        # --- TAB 1: RESULTS SUMMARY ---\n",
        "        with tab_results:\n",
        "            display(HTML(\"<h3>üìä Subgroup Analysis Results</h3>\"))\n",
        "\n",
        "            # Summary stats\n",
        "            summary_html = \"<div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px; margin: 10px 0;'>\"\n",
        "            summary_html += f\"<b>Moderator:</b> {moderator1}\"\n",
        "            if moderator2:\n",
        "                summary_html += f\" √ó {moderator2}\"\n",
        "            summary_html += f\"<br><b>Subgroups Analyzed:</b> {len(results_df)}<br>\"\n",
        "            summary_html += f\"<b>Test for Subgroup Differences:</b> Q<sub>M</sub> = {QM:.2f} (df={df_QM}, p = {p_value_QM:.4g})<br>\"\n",
        "            summary_html += f\"<b>Variance Explained (R¬≤):</b> {R_squared:.1f}%\"\n",
        "            summary_html += \"</div>\"\n",
        "            display(HTML(summary_html))\n",
        "\n",
        "            # Results table\n",
        "            table_html = \"<table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\"\n",
        "            table_html += \"<thead style='background-color: #f8f9fa;'><tr>\"\n",
        "            table_html += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: left;'>Subgroup</th>\"\n",
        "            table_html += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>k</th>\"\n",
        "            table_html += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>Studies</th>\"\n",
        "            table_html += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>Effect</th>\"\n",
        "            table_html += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>95% CI</th>\"\n",
        "            table_html += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>p-value</th>\"\n",
        "            table_html += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>I¬≤</th>\"\n",
        "            table_html += \"</tr></thead><tbody>\"\n",
        "\n",
        "            for _, row in results_df.iterrows():\n",
        "                sig = \"***\" if row['p_value_re'] < 0.001 else \"**\" if row['p_value_re'] < 0.01 else \"*\" if row['p_value_re'] < 0.05 else \"\"\n",
        "                sig_style = \"font-weight: bold; color: #28a745;\" if sig else \"\"\n",
        "\n",
        "                table_html += \"<tr>\"\n",
        "                table_html += f\"<td style='border: 1px solid #dee2e6; padding: 8px;'>{row['group']}</td>\"\n",
        "                table_html += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{row['k']}</td>\"\n",
        "                table_html += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{row['n_papers']}</td>\"\n",
        "                table_html += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center; {sig_style}'>{row['pooled_effect_re']:.3f} {sig}</td>\"\n",
        "                table_html += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>[{row['ci_lower_re']:.3f}, {row['ci_upper_re']:.3f}]</td>\"\n",
        "                table_html += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{row['p_value_re']:.4g}</td>\"\n",
        "                table_html += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{row['I_squared']:.1f}%</td>\"\n",
        "                table_html += \"</tr>\"\n",
        "\n",
        "            table_html += \"</tbody></table>\"\n",
        "            display(HTML(table_html))\n",
        "\n",
        "            # Significance legend\n",
        "            legend = \"<div style='font-size: 0.9em; color: #6c757d; margin-top: 10px;'>\"\n",
        "            legend += \"*** p < 0.001; ** p < 0.01; * p < 0.05\"\n",
        "            legend += \"</div>\"\n",
        "            display(HTML(legend))\n",
        "\n",
        "        # --- TAB 2: HETEROGENEITY ---\n",
        "        with tab_hetero:\n",
        "            display(HTML(\"<h3>üìâ Heterogeneity Partitioning</h3>\"))\n",
        "\n",
        "            # Explanation\n",
        "            explanation = \"<div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;'>\"\n",
        "            explanation += \"<p><b>Understanding Heterogeneity Decomposition:</b></p>\"\n",
        "            explanation += \"<ul>\"\n",
        "            explanation += \"<li><b>Q<sub>T</sub> (Total):</b> Overall heterogeneity across all studies</li>\"\n",
        "            explanation += \"<li><b>Q<sub>M</sub> (Between-Groups):</b> Heterogeneity explained by the moderator</li>\"\n",
        "            explanation += \"<li><b>Q<sub>E</sub> (Within-Groups):</b> Residual heterogeneity within subgroups</li>\"\n",
        "            explanation += \"<li><b>R¬≤:</b> Proportion of total heterogeneity explained by the moderator</li>\"\n",
        "            explanation += \"</ul></div>\"\n",
        "            display(HTML(explanation))\n",
        "\n",
        "            # Q-statistics table\n",
        "            q_table = \"<table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\"\n",
        "            q_table += \"<thead style='background-color: #f8f9fa;'><tr>\"\n",
        "            q_table += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: left;'>Component</th>\"\n",
        "            q_table += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>Q</th>\"\n",
        "            q_table += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>df</th>\"\n",
        "            q_table += \"<th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>p-value</th>\"\n",
        "            q_table += \"</tr></thead><tbody>\"\n",
        "\n",
        "            q_table += \"<tr>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px;'><b>Total (Q<sub>T</sub>)</b></td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{Qt_overall:.2f}</td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{k_overall-1}</td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>‚Äî</td>\"\n",
        "            q_table += \"</tr>\"\n",
        "\n",
        "            sig_qm = \"***\" if p_value_QM < 0.001 else \"**\" if p_value_QM < 0.01 else \"*\" if p_value_QM < 0.05 else \"ns\"\n",
        "            sig_style = \"font-weight: bold; color: #28a745;\" if sig_qm != \"ns\" else \"\"\n",
        "\n",
        "            q_table += \"<tr style='background-color: #e7f3ff;'>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px;'><b>Between-Groups (Q<sub>M</sub>)</b></td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center; {sig_style}'>{QM:.2f}</td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{df_QM}</td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center; {sig_style}'>{p_value_QM:.4g} {sig_qm}</td>\"\n",
        "            q_table += \"</tr>\"\n",
        "\n",
        "            q_table += \"<tr>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px;'><b>Within-Groups (Q<sub>E</sub>)</b></td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{Qe_sum:.2f}</td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{df_Qe}</td>\"\n",
        "            q_table += f\"<td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>‚Äî</td>\"\n",
        "            q_table += \"</tr>\"\n",
        "\n",
        "            q_table += \"</tbody></table>\"\n",
        "            display(HTML(q_table))\n",
        "\n",
        "            # R-squared interpretation\n",
        "            r2_html = \"<div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; margin: 10px 0;'>\"\n",
        "            r2_html += f\"<p style='margin: 0; font-size: 1.1em;'><b>Variance Explained (R¬≤): {R_squared:.1f}%</b></p>\"\n",
        "            r2_html += f\"<p style='margin: 5px 0 0 0;'>The moderator <b>{moderator1}</b>\"\n",
        "            if moderator2:\n",
        "                r2_html += f\" √ó <b>{moderator2}</b>\"\n",
        "            r2_html += f\" explains {R_squared:.1f}% of the total heterogeneity.\"\n",
        "\n",
        "            if R_squared < 25:\n",
        "                r2_html += \" <span style='color: #856404;'>(Low explanatory power)</span>\"\n",
        "            elif R_squared < 50:\n",
        "                r2_html += \" <span style='color: #856404;'>(Moderate explanatory power)</span>\"\n",
        "            else:\n",
        "                r2_html += \" <span style='color: #155724;'>(High explanatory power)</span>\"\n",
        "\n",
        "            r2_html += \"</p></div>\"\n",
        "            display(HTML(r2_html))\n",
        "\n",
        "        # --- SAVE RESULTS ---\n",
        "        ANALYSIS_CONFIG['subgroup_results'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'results_df': results_df,\n",
        "            'analysis_type': analysis_type,\n",
        "            'moderator1': moderator1,\n",
        "            'moderator2': moderator2,\n",
        "            'Qt_overall': Qt_overall,\n",
        "            'QM': QM,\n",
        "            'Qe': Qe_sum,\n",
        "            'df_QM': df_QM,\n",
        "            'df_Qe': df_Qe,\n",
        "            'p_value_QM': p_value_QM,\n",
        "            'R_squared': R_squared\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "        # --- PUBLICATION TEXT TAB ---\n",
        "        with tab_publication:\n",
        "            display(HTML(\"<h3 style='color: #2c3e50;'>üìù Publication-Ready Results Text</h3>\"))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "            pub_text = generate_subgroup_publication_text(\n",
        "                results_df, moderator1, moderator2, QM, df_QM, p_value_QM,\n",
        "                R_squared, Qt_overall, Qe_sum, df_Qe\n",
        "            )\n",
        "\n",
        "            display(HTML(pub_text))\n",
        "\n",
        "        with tab_details:\n",
        "            with details_output:\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(\"‚úÖ ANALYSIS COMPLETE\")\n",
        "                print(f\"{'='*60}\")\n",
        "                print(\"Results saved to ANALYSIS_CONFIG['subgroup_results']\")\n",
        "                print(\"‚ñ∂Ô∏è  Ready for next step: Forest Plot visualization\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_html = f\"<div style='color: red; background-color: #f8d7da; padding: 15px; border-radius: 5px; margin: 10px 0;'>\"\n",
        "        error_html += f\"<b>‚ùå Error:</b> {type(e).__name__}<br>\"\n",
        "        error_html += f\"<b>Message:</b> {str(e)}<br>\"\n",
        "        error_html += f\"<pre>{traceback.format_exc()}</pre>\"\n",
        "        error_html += \"</div>\"\n",
        "        with tab_results:\n",
        "            display(HTML(error_html))\n",
        "\n",
        "# --- 3. INITIAL CHECK & DISPLAY ---\n",
        "try:\n",
        "    # Display tabs immediately\n",
        "    display(tabs)\n",
        "\n",
        "    # Run analysis\n",
        "    run_subgroup_analysis()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Initialization Error: {e}\")\n",
        "    traceback.print_exc()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title R Validation for Subgroup Analysis (Robust)\n",
        "# =============================================================================\n",
        "# CELL: R VALIDATION FOR SUBGROUP ANALYSIS\n",
        "# Purpose: Verify 3-Level Subgroup estimates against R's metafor package.\n",
        "# Fix: Returns vectors from R instead of DataFrames to prevent conversion errors.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "\n",
        "# --- 1. Prepare Data & Config ---\n",
        "if 'ANALYSIS_CONFIG' not in globals() or 'subgroup_results' not in ANALYSIS_CONFIG:\n",
        "    print(\"‚ùå Error: Subgroup results not found. Please run Cell 8 first.\")\n",
        "else:\n",
        "    subgroup_config = ANALYSIS_CONFIG['subgroup_results']\n",
        "\n",
        "    # Get moderator info\n",
        "    moderator1 = subgroup_config['moderator1']\n",
        "    moderator2 = subgroup_config['moderator2']\n",
        "    analysis_type = subgroup_config['analysis_type']\n",
        "\n",
        "    # Get columns\n",
        "    eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "    var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "\n",
        "    # Get Data\n",
        "    if 'analysis_data' in globals(): df_sub_check = analysis_data.copy()\n",
        "    elif 'data_filtered' in globals(): df_sub_check = data_filtered.copy()\n",
        "    else: df_sub_check = None\n",
        "\n",
        "    if df_sub_check is not None:\n",
        "        print(f\"üöÄ Running R Validation for Subgroup Analysis...\")\n",
        "        print(f\"   Moderator: {moderator1}\" + (f\" x {moderator2}\" if moderator2 else \"\"))\n",
        "        print(f\"   Effect: {eff_col}, Variance: {var_col}\")\n",
        "\n",
        "        # Create combined group column\n",
        "        if analysis_type == 'two_way' and moderator2:\n",
        "            df_sub_check['subgroup_id'] = df_sub_check[moderator1].astype(str) + \" x \" + df_sub_check[moderator2].astype(str)\n",
        "            py_results = subgroup_config['results_df'].set_index('group')\n",
        "        else:\n",
        "            df_sub_check['subgroup_id'] = df_sub_check[moderator1].astype(str)\n",
        "            py_results = subgroup_config['results_df'].set_index('group')\n",
        "\n",
        "        # Clean data for R\n",
        "        df_r = df_sub_check[['id', eff_col, var_col, 'subgroup_id']].dropna()\n",
        "        df_r = df_r[df_r[var_col] > 0]\n",
        "\n",
        "        # Filter to valid groups\n",
        "        valid_groups = py_results.index.tolist()\n",
        "        df_r = df_r[df_r['subgroup_id'].isin(valid_groups)]\n",
        "\n",
        "        ro.globalenv['df_python'] = df_r\n",
        "        ro.globalenv['eff_col_name'] = eff_col\n",
        "        ro.globalenv['var_col_name'] = var_col\n",
        "\n",
        "        # --- 2. R Script (Vectorized Return) ---\n",
        "        r_script = \"\"\"\n",
        "        library(metafor)\n",
        "\n",
        "        dat <- df_python\n",
        "        dat$rows <- 1:nrow(dat)\n",
        "        dat$study_id <- as.factor(dat$id)\n",
        "\n",
        "        # Get unique subgroups\n",
        "        groups <- unique(dat$subgroup_id)\n",
        "        n_groups <- length(groups)\n",
        "\n",
        "        # Pre-allocate vectors (safer than building dataframe row-by-row)\n",
        "        out_groups <- character(n_groups)\n",
        "        out_ests <- numeric(n_groups)\n",
        "        out_tau2s <- numeric(n_groups)\n",
        "        out_valid <- logical(n_groups)\n",
        "\n",
        "        # Loop through subgroups\n",
        "        for (i in 1:n_groups) {\n",
        "            g <- groups[i]\n",
        "            sub_dat <- dat[dat$subgroup_id == g, ]\n",
        "\n",
        "            out_groups[i] <- g\n",
        "\n",
        "            # Skip if too small\n",
        "            if (nrow(sub_dat) < 2) {\n",
        "                out_valid[i] <- FALSE\n",
        "                next\n",
        "            }\n",
        "\n",
        "            # Run 3-Level Model\n",
        "            skip <- FALSE\n",
        "            tryCatch({\n",
        "                res <- rma.mv(yi=sub_dat[[eff_col_name]], V=sub_dat[[var_col_name]],\n",
        "                              random = ~ 1 | study_id/rows,\n",
        "                              data=sub_dat,\n",
        "                              control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\"))\n",
        "\n",
        "                out_ests[i] <- res$b[1]\n",
        "                out_tau2s[i] <- res$sigma2[1]\n",
        "                out_valid[i] <- TRUE\n",
        "            }, error=function(e) {\n",
        "                out_valid[i] <<- FALSE\n",
        "            })\n",
        "        }\n",
        "\n",
        "        # Return as a simple list of vectors\n",
        "        list(\n",
        "            groups = out_groups,\n",
        "            ests = out_ests,\n",
        "            tau2s = out_tau2s,\n",
        "            valid = out_valid\n",
        "        )\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Run R\n",
        "            r_list = ro.r(r_script)\n",
        "\n",
        "            # Extract vectors\n",
        "            r_groups = list(r_list.rx2('groups'))\n",
        "            r_ests = list(r_list.rx2('ests'))\n",
        "            r_valid = list(r_list.rx2('valid'))\n",
        "\n",
        "            print(\"\\n\" + \"=\"*85)\n",
        "            print(f\"{'Subgroup':<35} {'Python Effect':<15} {'R Effect':<15} {'Diff':<15}\")\n",
        "            print(\"=\"*85)\n",
        "\n",
        "            matches = 0\n",
        "            warnings_count = 0\n",
        "\n",
        "            for i, group_name in enumerate(r_groups):\n",
        "                if not r_valid[i]:\n",
        "                    continue\n",
        "\n",
        "                r_est = r_ests[i]\n",
        "\n",
        "                if group_name in py_results.index:\n",
        "                    py_est = py_results.loc[group_name, 'pooled_effect_re']\n",
        "                    diff = abs(py_est - r_est)\n",
        "\n",
        "                    print(f\"{group_name[:35]:<35} {py_est:<15.4f} {r_est:<15.4f} {diff:.2e}\")\n",
        "\n",
        "                    if diff < 1e-3:\n",
        "                        matches += 1\n",
        "                    else:\n",
        "                        warnings_count += 1\n",
        "                else:\n",
        "                    print(f\"{group_name[:35]:<35} {'N/A':<15} {r_est:<15.4f} {'(Not in Py)'}\")\n",
        "\n",
        "            print(\"-\" * 85)\n",
        "            if warnings_count == 0 and matches > 0:\n",
        "                print(\"‚úÖ PASSED: All subgroups match R results.\")\n",
        "            elif matches > 0:\n",
        "                print(f\"‚ö†Ô∏è  CHECK: {warnings_count} subgroups differ > 0.001. (Likely optimizer tolerance differences).\")\n",
        "            else:\n",
        "                print(\"‚ùå FAIL: No matching subgroups found.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå R Execution Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LuZ_Qf9uP5Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä Cell 9: Dynamic Forest Plot (Fixed)\n",
        "# =============================================================================\n",
        "# CELL 9: PUBLICATION-READY FOREST PLOT\n",
        "# Purpose: Create customizable forest plots for meta-analysis results\n",
        "# Fix: Updated result keys to match the robust Cell 6 output.\n",
        "# =============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import datetime\n",
        "from matplotlib.patches import Patch, Rectangle\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# --- 1. LOAD CONFIGURATION ---\n",
        "print(\"=\"*70)\n",
        "print(\"FOREST PLOT CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in locals() and 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"ANALYSIS_CONFIG not found.\")\n",
        "\n",
        "    subgroup_results = ANALYSIS_CONFIG.get('subgroup_results', {})\n",
        "    overall_results = ANALYSIS_CONFIG['overall_results']\n",
        "    es_config = ANALYSIS_CONFIG['es_config']\n",
        "\n",
        "    # Determine if we have subgroup analysis\n",
        "    has_subgroups = bool(subgroup_results) and 'results_df' in subgroup_results\n",
        "\n",
        "    if has_subgroups:\n",
        "        analysis_type = subgroup_results['analysis_type']\n",
        "        moderator1 = subgroup_results['moderator1']\n",
        "        moderator2 = subgroup_results.get('moderator2', None)\n",
        "        results_df = subgroup_results['results_df']\n",
        "\n",
        "        # Set dynamic defaults\n",
        "        if analysis_type == 'two_way':\n",
        "            default_title = f'Forest Plot: {moderator1} √ó {moderator2}'\n",
        "            default_y_label = moderator2\n",
        "        else:\n",
        "            default_title = f'Forest Plot: {moderator1}'\n",
        "            default_y_label = moderator1\n",
        "    else:\n",
        "        # Overall only (no subgroups)\n",
        "        analysis_type = 'overall_only'\n",
        "        default_title = 'Forest Plot: Overall Effect'\n",
        "        default_y_label = 'Study'\n",
        "        moderator1 = None\n",
        "        moderator2 = None\n",
        "\n",
        "    default_x_label = es_config.get('effect_label', \"Effect Size\")\n",
        "\n",
        "    print(f\"‚úì Analysis type: {analysis_type}\")\n",
        "    print(f\"‚úì Has subgroups: {has_subgroups}\")\n",
        "    print(f\"‚úì Configuration loaded successfully\")\n",
        "\n",
        "except (KeyError, NameError) as e:\n",
        "    print(f\"‚ùå ERROR: Failed to load configuration: {e}\")\n",
        "    print(\"   Please run Cell 6 (overall analysis) first\")\n",
        "    raise\n",
        "\n",
        "# --- 2. DEFINE CUSTOMIZATION WIDGETS ---\n",
        "\n",
        "# ========== TAB 1: PLOT STYLE ==========\n",
        "style_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Plot Style & Layout</h3>\")\n",
        "\n",
        "model_widget = widgets.Dropdown(\n",
        "    options=[('Random-Effects', 'RE'), ('Fixed-Effects', 'FE')],\n",
        "    value='RE',\n",
        "    description='Model:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "width_widget = widgets.FloatSlider(\n",
        "    value=8.0, min=6.0, max=14.0, step=0.5,\n",
        "    description='Plot Width (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "height_widget = widgets.FloatSlider(\n",
        "    value=0.4, min=0.2, max=1.0, step=0.05,\n",
        "    description='Height per Row (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "title_fontsize_widget = widgets.IntSlider(\n",
        "    value=12, min=8, max=18, step=1,\n",
        "    description='Title Font Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "label_fontsize_widget = widgets.IntSlider(\n",
        "    value=11, min=8, max=16, step=1,\n",
        "    description='Axis Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "tick_fontsize_widget = widgets.IntSlider(\n",
        "    value=9, min=6, max=14, step=1,\n",
        "    description='Tick Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_fontsize_widget = widgets.IntSlider(\n",
        "    value=8, min=6, max=12, step=1,\n",
        "    description='Annotation Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "color_scheme_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Grayscale (Publication)', 'gray'),\n",
        "        ('Color (Presentation)', 'color'),\n",
        "        ('Black & White Only', 'bw')\n",
        "    ],\n",
        "    value='gray',\n",
        "    description='Color Scheme:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "marker_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Circle/Diamond (‚óè/‚óÜ)', 'circle_diamond'),\n",
        "        ('Square/Diamond (‚ñ†/‚óÜ)', 'square_diamond'),\n",
        "        ('Circle/Star (‚óè/‚òÖ)', 'circle_star')\n",
        "    ],\n",
        "    value='circle_diamond',\n",
        "    description='Marker Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "ci_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Solid Line', 'solid'),\n",
        "        ('Dashed Line', 'dashed'),\n",
        "        ('Solid with Caps', 'caps')\n",
        "    ],\n",
        "    value='solid',\n",
        "    description='CI Line Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    style_header,\n",
        "    model_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Dimensions:</b>\"),\n",
        "    width_widget,\n",
        "    height_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Typography:</b>\"),\n",
        "    title_fontsize_widget,\n",
        "    label_fontsize_widget,\n",
        "    tick_fontsize_widget,\n",
        "    annot_fontsize_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Visual Style:</b>\"),\n",
        "    color_scheme_widget,\n",
        "    marker_style_widget,\n",
        "    ci_style_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 2: TEXT & LABELS ==========\n",
        "text_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Text & Labels</h3>\")\n",
        "\n",
        "show_title_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Plot Title',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "title_widget = widgets.Text(\n",
        "    value=default_title,\n",
        "    description='Plot Title:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "xlabel_widget = widgets.Text(\n",
        "    value=default_x_label,\n",
        "    description='X-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "ylabel_widget = widgets.Text(\n",
        "    value=default_y_label,\n",
        "    description='Y-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "show_ylabel_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Y-Axis Label',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "text_tab = widgets.VBox([\n",
        "    text_header,\n",
        "    show_title_widget,\n",
        "    title_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    xlabel_widget,\n",
        "    show_ylabel_widget,\n",
        "    ylabel_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 3: ANNOTATIONS ==========\n",
        "annot_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Annotations</h3>\")\n",
        "\n",
        "show_k_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show k (observations)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_papers_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show paper count',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_fold_change_widget = widgets.Checkbox(\n",
        "    value=es_config.get('has_fold_change', False),\n",
        "    description='Show Fold-Change',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_pos_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Right of CI', 'right'),\n",
        "        ('Above Marker', 'above'),\n",
        "        ('Below Marker', 'below')\n",
        "    ],\n",
        "    value='right',\n",
        "    description='Position:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-1.0, max=1.0, step=0.05,\n",
        "    description='H-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    readout_format='.2f'\n",
        ")\n",
        "\n",
        "group_label_box = widgets.VBox()\n",
        "# Group label widgets (always defined, conditionally displayed)\n",
        "group_label_h_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-2.0, max=2.0, step=0.1,\n",
        "    description='Group H-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "group_label_v_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-5.0, max=5.0, step=0.5,\n",
        "    description='Group V-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "group_label_fontsize_widget = widgets.IntSlider(\n",
        "    value=10, min=6, max=20, step=1,\n",
        "    description='Group Fontsize:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Only display group label widgets for two-way analysis\n",
        "if has_subgroups and analysis_type == 'two_way':\n",
        "    group_label_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h4>Group Label Positioning (Two-Way Only)</h4>\"),\n",
        "        group_label_h_offset_widget,\n",
        "        group_label_v_offset_widget,\n",
        "        group_label_fontsize_widget\n",
        "    ])\n",
        "else:\n",
        "    group_label_box = widgets.VBox()\n",
        "\n",
        "\n",
        "annot_tab = widgets.VBox([\n",
        "    annot_header,\n",
        "    widgets.HTML(\"<b>Show in Annotations:</b>\"),\n",
        "    show_k_widget,\n",
        "    show_papers_widget,\n",
        "    show_fold_change_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Position:</b>\"),\n",
        "    annot_pos_widget,\n",
        "    annot_offset_widget,\n",
        "    group_label_box\n",
        "])\n",
        "\n",
        "# ========== TAB 4: AXES & SCALE ==========\n",
        "axes_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Axes & Scaling</h3>\")\n",
        "\n",
        "auto_scale_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Auto-Scale X-Axis',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "x_min_widget = widgets.FloatText(\n",
        "    value=-2.0,\n",
        "    description='X-Min:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "x_max_widget = widgets.FloatText(\n",
        "    value=2.0,\n",
        "    description='X-Max:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "manual_scale_box = widgets.HBox([x_min_widget, x_max_widget])\n",
        "\n",
        "def toggle_manual_scale(change):\n",
        "    if change['new']:\n",
        "        x_min_widget.layout.visibility = 'hidden'\n",
        "        x_max_widget.layout.visibility = 'hidden'\n",
        "    else:\n",
        "        x_min_widget.layout.visibility = 'visible'\n",
        "        x_max_widget.layout.visibility = 'visible'\n",
        "\n",
        "auto_scale_widget.observe(toggle_manual_scale, names='value')\n",
        "\n",
        "show_grid_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Grid',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "grid_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Dashed (Light)', 'dashed_light'),\n",
        "        ('Dotted (Light)', 'dotted_light'),\n",
        "        ('Solid (Light)', 'solid_light')\n",
        "    ],\n",
        "    value='dashed_light',\n",
        "    description='Grid Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_null_line_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Null Effect Line',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_fold_axis_widget = widgets.Checkbox(\n",
        "    value=es_config.get('has_fold_change', False) and show_fold_change_widget.value,\n",
        "    description='Show Fold-Change Axis (Top)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "axes_tab = widgets.VBox([\n",
        "    axes_header,\n",
        "    auto_scale_widget,\n",
        "    manual_scale_box,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Grid & Reference Lines:</b>\"),\n",
        "    show_grid_widget,\n",
        "    grid_style_widget,\n",
        "    show_null_line_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    show_fold_axis_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 5: EXPORT OPTIONS ==========\n",
        "export_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Export Options</h3>\")\n",
        "\n",
        "save_pdf_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PDF',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "save_png_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PNG',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "png_dpi_widget = widgets.IntSlider(\n",
        "    value=300, min=150, max=600, step=50,\n",
        "    description='PNG DPI:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "filename_prefix_widget = widgets.Text(\n",
        "    value='ForestPlot',\n",
        "    description='Filename Prefix:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "transparent_bg_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Transparent Background',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    export_header,\n",
        "    save_pdf_widget,\n",
        "    save_png_widget,\n",
        "    png_dpi_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    filename_prefix_widget,\n",
        "    transparent_bg_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 6: LABEL EDITOR ==========\n",
        "label_editor_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Label Editor</h3>\")\n",
        "label_editor_desc = widgets.HTML(\n",
        "    \"<p style='color: #666;'><i>Customize display names for all groups and subgroups in the plot</i></p>\"\n",
        ")\n",
        "\n",
        "print(f\"\\nüîç Identifying labels for editor...\")\n",
        "\n",
        "unique_labels = set()\n",
        "label_widgets_dict = {}\n",
        "\n",
        "try:\n",
        "    if has_subgroups:\n",
        "        if analysis_type == 'single':\n",
        "            unique_labels.update(results_df['group'].astype(str).unique())\n",
        "        else:  # two_way\n",
        "            unique_labels.update(results_df[moderator1].astype(str).unique())\n",
        "            unique_labels.update(results_df[moderator2].astype(str).unique())\n",
        "\n",
        "    unique_labels.add('Overall')\n",
        "    sorted_labels = sorted(list(unique_labels))\n",
        "\n",
        "    print(f\"  ‚úì Found {len(sorted_labels)} unique labels\")\n",
        "\n",
        "    label_editor_widgets = []\n",
        "    for label in sorted_labels:\n",
        "        widget_label = f\"Overall Effect:\" if label == 'Overall' else f\"{label}:\"\n",
        "        text_widget = widgets.Text(\n",
        "            value=str(label),\n",
        "            description=widget_label,\n",
        "            layout=widgets.Layout(width='500px'),\n",
        "            style={'description_width': '200px'}\n",
        "        )\n",
        "        label_editor_widgets.append(text_widget)\n",
        "        label_widgets_dict[str(label)] = text_widget\n",
        "\n",
        "    label_editor_tab = widgets.VBox([\n",
        "        label_editor_header,\n",
        "        label_editor_desc,\n",
        "        widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "        widgets.HTML(\n",
        "            \"<p><b>Instructions:</b> Edit the text on the right to change how labels appear in the plot. \"\n",
        "            \"The original coded names are shown on the left.</p>\"\n",
        "        ),\n",
        "        widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "        *label_editor_widgets\n",
        "    ])\n",
        "\n",
        "    print(f\"  ‚úì Label editor created\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ö†Ô∏è  Error creating label editor: {e}\")\n",
        "    label_editor_tab = widgets.VBox([\n",
        "        label_editor_header,\n",
        "        widgets.HTML(\"<p style='color: red;'>Error creating label editor.</p>\")\n",
        "    ])\n",
        "    label_widgets_dict = {}\n",
        "\n",
        "# ========== CREATE TAB WIDGET ==========\n",
        "tab_children = [style_tab, text_tab, annot_tab, axes_tab, export_tab, label_editor_tab]\n",
        "tab = widgets.Tab(children=tab_children)\n",
        "tab.set_title(0, 'üé® Style')\n",
        "tab.set_title(1, 'üìù Text')\n",
        "tab.set_title(2, 'üè∑Ô∏è Annotations')\n",
        "tab.set_title(3, 'üìè Axes')\n",
        "tab.set_title(4, 'üíæ Export')\n",
        "tab.set_title(5, '‚úèÔ∏è Labels')\n",
        "\n",
        "# --- 3. DEFINE PLOT GENERATION FUNCTION ---\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "def generate_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING FOREST PLOT\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            # --- GET WIDGET VALUES ---\n",
        "            plot_model = model_widget.value\n",
        "            plot_width = width_widget.value\n",
        "            height_per_row = height_widget.value\n",
        "            title_fontsize = title_fontsize_widget.value\n",
        "            label_fontsize = label_fontsize_widget.value\n",
        "            tick_fontsize = tick_fontsize_widget.value\n",
        "            annot_fontsize = annot_fontsize_widget.value\n",
        "            color_scheme = color_scheme_widget.value\n",
        "            marker_style = marker_style_widget.value\n",
        "            ci_style = ci_style_widget.value\n",
        "\n",
        "            show_title = show_title_widget.value\n",
        "            graph_title = title_widget.value\n",
        "            x_label = xlabel_widget.value\n",
        "            show_ylabel = show_ylabel_widget.value\n",
        "            y_label = ylabel_widget.value\n",
        "\n",
        "            show_k = show_k_widget.value\n",
        "            show_papers = show_papers_widget.value\n",
        "            show_fold_change = show_fold_change_widget.value\n",
        "            annot_pos = annot_pos_widget.value\n",
        "            annot_offset = annot_offset_widget.value\n",
        "\n",
        "            auto_scale = auto_scale_widget.value\n",
        "            x_min_manual = x_min_widget.value\n",
        "            x_max_manual = x_max_widget.value\n",
        "            show_grid = show_grid_widget.value\n",
        "            grid_style = grid_style_widget.value\n",
        "            show_null_line = show_null_line_widget.value\n",
        "            show_fold_axis = show_fold_axis_widget.value\n",
        "\n",
        "            save_pdf = save_pdf_widget.value\n",
        "            save_png = save_png_widget.value\n",
        "            png_dpi = png_dpi_widget.value\n",
        "            filename_prefix = filename_prefix_widget.value\n",
        "            transparent_bg = transparent_bg_widget.value\n",
        "\n",
        "            # Group label offsets (two-way only)\n",
        "            if has_subgroups and analysis_type == 'two_way':\n",
        "                group_label_h_offset = group_label_h_offset_widget.value\n",
        "                group_label_v_offset = group_label_v_offset_widget.value\n",
        "                group_label_fontsize = group_label_fontsize_widget.value\n",
        "            else:\n",
        "                group_label_h_offset = 0\n",
        "                group_label_v_offset = 0\n",
        "                group_label_fontsize = 10\n",
        "\n",
        "            # --- BUILD LABEL MAPPING FROM EDITOR ---\n",
        "            label_mapping = {}\n",
        "            for original_label, widget in label_widgets_dict.items():\n",
        "                custom_label = widget.value\n",
        "                label_mapping[original_label] = custom_label\n",
        "                label_mapping[str(original_label)] = custom_label\n",
        "\n",
        "            print(f\"üìä Configuration:\")\n",
        "            print(f\"  Model: {plot_model}\")\n",
        "            print(f\"  Dimensions: {plot_width}\\\" √ó auto\")\n",
        "            print(f\"  Color scheme: {color_scheme}\")\n",
        "            print(f\"  Has subgroups: {has_subgroups}\")\n",
        "\n",
        "            # Show custom labels if any were changed\n",
        "            changed_labels = {k: v for k, v in label_mapping.items() if k != v}\n",
        "            if changed_labels:\n",
        "                print(f\"\\nüìù Custom labels ({len(changed_labels)} changed):\")\n",
        "                for orig, custom in list(changed_labels.items())[:5]:\n",
        "                    print(f\"  '{orig}' ‚Üí '{custom}'\")\n",
        "                if len(changed_labels) > 5:\n",
        "                    print(f\"  ... and {len(changed_labels)-5} more\")\n",
        "\n",
        "            overall_label_text = label_mapping.get('Overall', 'Overall Effect')\n",
        "\n",
        "            # --- DETERMINE COLUMN NAMES BASED ON MODEL ---\n",
        "            if plot_model == 'FE':\n",
        "                effect_col = 'pooled_effect_fe'\n",
        "                se_col = 'pooled_se_fe'\n",
        "                ci_lower_col = 'ci_lower_fe'\n",
        "                ci_upper_col = 'ci_upper_fe'\n",
        "                fold_col = 'fold_change_fe'\n",
        "\n",
        "                overall_effect_key = 'pooled_effect_fixed'\n",
        "                overall_se_key = 'pooled_SE_fixed'\n",
        "                overall_ci_lower_key = 'ci_lower_fixed'\n",
        "                overall_ci_upper_key = 'ci_upper_fixed'\n",
        "                overall_fold_key = 'pooled_fold_fixed' # Assuming this exists\n",
        "            else:  # RE\n",
        "                effect_col = 'pooled_effect_re'\n",
        "                se_col = 'pooled_se_re'\n",
        "                ci_lower_col = 'ci_lower_re'\n",
        "                ci_upper_col = 'ci_upper_re'\n",
        "                fold_col = 'fold_change_re'\n",
        "\n",
        "                overall_effect_key = 'pooled_effect_random'\n",
        "                # FIX: Use keys that exist in Cell 6 output\n",
        "                overall_se_key = 'pooled_SE_random_reported'\n",
        "                overall_ci_lower_key = 'ci_lower_random_reported'\n",
        "                overall_ci_upper_key = 'ci_upper_random_reported'\n",
        "                overall_fold_key = 'pooled_fold_random'\n",
        "\n",
        "            # --- PREPARE DATA ---\n",
        "            if has_subgroups:\n",
        "                plot_df_subgroups = results_df.copy()\n",
        "\n",
        "                plot_df_subgroups = plot_df_subgroups.rename(columns={\n",
        "                    effect_col: 'EffectSize',\n",
        "                    se_col: 'SE',\n",
        "                    ci_lower_col: 'CI_Lower',\n",
        "                    ci_upper_col: 'CI_Upper',\n",
        "                    fold_col: 'FoldChange',\n",
        "                    'k': 'k',\n",
        "                    'n_papers': 'nPapers'\n",
        "                })\n",
        "\n",
        "                if analysis_type == 'two_way':\n",
        "                    plot_df_subgroups['GroupVar'] = plot_df_subgroups[moderator1].astype(str)\n",
        "                    plot_df_subgroups['LabelVar'] = plot_df_subgroups[moderator2].astype(str)\n",
        "                else:  # single\n",
        "                    plot_df_subgroups['GroupVar'] = 'Subgroup'\n",
        "                    plot_df_subgroups['LabelVar'] = plot_df_subgroups['group'].astype(str)\n",
        "\n",
        "                required_cols = ['GroupVar', 'LabelVar', 'k', 'nPapers',\n",
        "                               'EffectSize', 'SE', 'CI_Lower', 'CI_Upper', 'FoldChange']\n",
        "                plot_df_subgroups = plot_df_subgroups[required_cols]\n",
        "                plot_df_subgroups.dropna(subset=['EffectSize', 'SE'], inplace=True)\n",
        "\n",
        "                print(f\"  Subgroups: {len(plot_df_subgroups)}\")\n",
        "            else:\n",
        "                plot_df_subgroups = pd.DataFrame(columns=[\n",
        "                    'GroupVar', 'LabelVar', 'k', 'nPapers',\n",
        "                    'EffectSize', 'SE', 'CI_Lower', 'CI_Upper', 'FoldChange'\n",
        "                ])\n",
        "\n",
        "            # --- ADD OVERALL EFFECT ---\n",
        "            overall_effect_val = overall_results[overall_effect_key]\n",
        "            # FIX: Safely get values or default to Z-test version if reported missing\n",
        "            overall_se_val = overall_results.get(overall_se_key, overall_results.get('pooled_SE_random_Z'))\n",
        "            overall_ci_lower_val = overall_results.get(overall_ci_lower_key, overall_results.get('ci_lower_random_Z'))\n",
        "            overall_ci_upper_val = overall_results.get(overall_ci_upper_key, overall_results.get('ci_upper_random_Z'))\n",
        "\n",
        "            overall_k_val = overall_results['k']\n",
        "            overall_papers_val = overall_results['k_papers']\n",
        "            overall_fold_val = overall_results.get(overall_fold_key, np.nan)\n",
        "\n",
        "            overall_row = pd.DataFrame([{\n",
        "                'GroupVar': 'Overall',\n",
        "                'LabelVar': 'Overall',\n",
        "                'k': overall_k_val,\n",
        "                'nPapers': overall_papers_val,\n",
        "                'EffectSize': overall_effect_val,\n",
        "                'SE': overall_se_val,\n",
        "                'CI_Lower': overall_ci_lower_val,\n",
        "                'CI_Upper': overall_ci_upper_val,\n",
        "                'FoldChange': overall_fold_val\n",
        "            }])\n",
        "\n",
        "            print(f\"  Overall: k={overall_k_val}, papers={overall_papers_val}\")\n",
        "\n",
        "            # --- COMBINE DATA (OVERALL ON TOP) ---\n",
        "            plot_df = pd.concat([overall_row, plot_df_subgroups], ignore_index=True)\n",
        "\n",
        "            plot_df['SortKey_Group'] = plot_df['GroupVar'].apply(\n",
        "                lambda x: 'AAAAA' if x == 'Overall' else str(x)\n",
        "            )\n",
        "            plot_df['SortKey_Label'] = plot_df['LabelVar'].apply(\n",
        "                lambda x: 'AAAAA' if x == 'Overall' else str(x)\n",
        "            )\n",
        "            plot_df.sort_values(by=['SortKey_Group', 'SortKey_Label'], inplace=True)\n",
        "            plot_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "            if plot_df.empty:\n",
        "                print(\"‚ùå ERROR: No data to plot\")\n",
        "                return\n",
        "\n",
        "            print(f\"  Total rows: {len(plot_df)}\")\n",
        "\n",
        "            # --- CALCULATE PLOT DIMENSIONS ---\n",
        "            num_rows = len(plot_df)\n",
        "            y_positions = np.arange(num_rows)\n",
        "\n",
        "            base_height = 2.5\n",
        "            plot_height = max(base_height, num_rows * height_per_row + 1.5)\n",
        "\n",
        "            y_margin_top = 0.75\n",
        "            y_margin_bottom = 0.75\n",
        "            y_lim_bottom = y_positions[0] - y_margin_bottom\n",
        "            y_lim_top = y_positions[-1] + y_margin_top\n",
        "\n",
        "            # --- Y-TICK LABELS (USE CUSTOM MAPPING) ---\n",
        "            y_tick_labels = []\n",
        "            for i, row in plot_df.iterrows():\n",
        "                if row['GroupVar'] == 'Overall':\n",
        "                    y_tick_labels.append(overall_label_text)\n",
        "                else:\n",
        "                    original_label = str(row['LabelVar'])\n",
        "                    display_label = label_mapping.get(original_label, original_label)\n",
        "                    y_tick_labels.append(display_label)\n",
        "\n",
        "            # --- CALCULATE X-AXIS LIMITS (FIXED - USE ALL DATA) ---\n",
        "            min_ci = plot_df['CI_Lower'].min()\n",
        "            max_ci = plot_df['CI_Upper'].max()\n",
        "            min_effect = plot_df['EffectSize'].min()\n",
        "            max_effect = plot_df['EffectSize'].max()\n",
        "\n",
        "            plot_min = min(min_ci, 0)\n",
        "            plot_max = max(max_ci, 0)\n",
        "            x_range = plot_max - plot_min\n",
        "\n",
        "            if x_range == 0:\n",
        "                x_range = 1\n",
        "\n",
        "            print(f\"\\nüìè Data range:\")\n",
        "            print(f\"  Effect sizes: [{min_effect:.3f}, {max_effect:.3f}]\")\n",
        "            print(f\"  CI range: [{min_ci:.3f}, {max_ci:.3f}]\")\n",
        "            print(f\"  Plot range: [{plot_min:.3f}, {plot_max:.3f}]\")\n",
        "\n",
        "            # --- ESTIMATE ANNOTATION SPACE NEEDED ---\n",
        "            max_k = int(plot_df['k'].max())\n",
        "            max_np = int(plot_df['nPapers'].max()) if 'nPapers' in plot_df.columns else 0\n",
        "\n",
        "            annot_parts = []\n",
        "            if show_k:\n",
        "                annot_parts.append(f\"k={max_k}\")\n",
        "            if show_papers:\n",
        "                annot_parts.append(f\"({max_np})\")\n",
        "            if show_fold_change and es_config.get('has_fold_change', False):\n",
        "                max_fold = plot_df['FoldChange'].abs().max() if 'FoldChange' in plot_df.columns else 10\n",
        "                annot_parts.append(f\"[-{max_fold:.2f}√ó]\")\n",
        "\n",
        "            example_annot = \" \".join(annot_parts) if annot_parts else \"k=100 (10)\"\n",
        "\n",
        "            char_width_fraction = (annot_fontsize / 8.0) * 0.006\n",
        "            annot_space_fraction = len(example_annot) * char_width_fraction\n",
        "\n",
        "            print(f\"  Annotation example: '{example_annot}' ({len(example_annot)} chars)\")\n",
        "\n",
        "            # --- CALCULATE SPACE FOR GROUP LABELS (TWO-WAY) ---\n",
        "            group_label_space = 0\n",
        "            if has_subgroups and analysis_type == 'two_way':\n",
        "                max_group_len = 0\n",
        "                for group_val in plot_df[plot_df['GroupVar'] != 'Overall']['GroupVar'].unique():\n",
        "                    custom_label = label_mapping.get(str(group_val), str(group_val))\n",
        "                    max_group_len = max(max_group_len, len(custom_label))\n",
        "\n",
        "                char_width_group = (group_label_fontsize / 8.0) * 0.006\n",
        "                group_label_space = max_group_len * char_width_group\n",
        "\n",
        "                print(f\"  Group label max: {max_group_len} chars\")\n",
        "\n",
        "            # --- AUTO-SCALE CALCULATION ---\n",
        "            if auto_scale:\n",
        "                left_padding = 0.05\n",
        "                annot_distance = 0.015\n",
        "                right_padding = 0.03\n",
        "\n",
        "                total_right_fraction = (annot_distance +\n",
        "                                       annot_space_fraction +\n",
        "                                       group_label_space +\n",
        "                                       right_padding)\n",
        "\n",
        "                x_min_auto = plot_min - x_range * left_padding\n",
        "                x_max_auto = plot_max + x_range * (total_right_fraction / (1 - total_right_fraction))\n",
        "\n",
        "                x_limits = (x_min_auto, x_max_auto)\n",
        "                print(f\"  X-axis (auto): [{x_min_auto:.3f}, {x_max_auto:.3f}]\")\n",
        "            else:\n",
        "                x_limits = (x_min_manual, x_max_manual)\n",
        "                print(f\"  X-axis (manual): [{x_min_manual:.3f}, {x_max_manual:.3f}]\")\n",
        "\n",
        "            # --- DETERMINE COLORS AND MARKERS ---\n",
        "            if color_scheme == 'gray':\n",
        "                subgroup_color = 'dimgray'\n",
        "                overall_color = 'black'\n",
        "                ci_color_subgroup = 'gray'\n",
        "                ci_color_overall = 'black'\n",
        "            elif color_scheme == 'color':\n",
        "                subgroup_color = '#4A90E2'\n",
        "                overall_color = '#E74C3C'\n",
        "                ci_color_subgroup = '#4A90E2'\n",
        "                ci_color_overall = '#E74C3C'\n",
        "            else:  # bw\n",
        "                subgroup_color = 'black'\n",
        "                overall_color = 'black'\n",
        "                ci_color_subgroup = 'black'\n",
        "                ci_color_overall = 'black'\n",
        "\n",
        "            if marker_style == 'circle_diamond':\n",
        "                subgroup_marker = 'o'\n",
        "                overall_marker = 'D'\n",
        "            elif marker_style == 'square_diamond':\n",
        "                subgroup_marker = 's'\n",
        "                overall_marker = 'D'\n",
        "            else:  # circle_star\n",
        "                subgroup_marker = 'o'\n",
        "                overall_marker = '*'\n",
        "\n",
        "            subgroup_marker_size = 6\n",
        "            overall_marker_size = 8\n",
        "            subgroup_ci_width = 1.5\n",
        "            overall_ci_width = 2.0\n",
        "\n",
        "            if ci_style == 'solid':\n",
        "                capsize = 0\n",
        "            elif ci_style == 'dashed':\n",
        "                capsize = 0\n",
        "            else:  # caps\n",
        "                capsize = 4\n",
        "\n",
        "            # --- CREATE FIGURE ---\n",
        "            fig, ax = plt.subplots(figsize=(plot_width, plot_height))\n",
        "\n",
        "            if transparent_bg:\n",
        "                fig.patch.set_alpha(0)\n",
        "                ax.patch.set_alpha(0)\n",
        "\n",
        "            print(f\"\\nüé® Plotting {num_rows} rows...\")\n",
        "\n",
        "            # --- PLOT DATA POINTS AND ERROR BARS ---\n",
        "            for i, row in plot_df.iterrows():\n",
        "                is_overall = (row['GroupVar'] == 'Overall')\n",
        "\n",
        "                marker = overall_marker if is_overall else subgroup_marker\n",
        "                msize = overall_marker_size if is_overall else subgroup_marker_size\n",
        "                color = overall_color if is_overall else subgroup_color\n",
        "                ci_color = ci_color_overall if is_overall else ci_color_subgroup\n",
        "                ci_width = overall_ci_width if is_overall else subgroup_ci_width\n",
        "                zorder = 5 if is_overall else 3\n",
        "\n",
        "                linestyle = '-' if ci_style != 'dashed' else '--'\n",
        "\n",
        "                ax.errorbar(\n",
        "                    x=row['EffectSize'],\n",
        "                    y=y_positions[i],\n",
        "                    xerr=[[row['EffectSize'] - row['CI_Lower']],\n",
        "                          [row['CI_Upper'] - row['EffectSize']]],\n",
        "                    fmt='none',\n",
        "                    capsize=capsize,\n",
        "                    color=ci_color,\n",
        "                    linewidth=ci_width,\n",
        "                    linestyle=linestyle,\n",
        "                    alpha=0.9,\n",
        "                    zorder=zorder-1\n",
        "                )\n",
        "\n",
        "                ax.plot(\n",
        "                    row['EffectSize'],\n",
        "                    y_positions[i],\n",
        "                    marker=marker,\n",
        "                    markersize=msize,\n",
        "                    markerfacecolor=color,\n",
        "                    markeredgecolor='black' if color_scheme != 'bw' else 'black',\n",
        "                    markeredgewidth=1.0,\n",
        "                    linestyle='none',\n",
        "                    zorder=zorder\n",
        "                )\n",
        "\n",
        "            # --- SET AXIS LIMITS FIRST ---\n",
        "            ax.set_xlim(x_limits[0], x_limits[1])\n",
        "            ax.set_ylim(y_lim_top, y_lim_bottom)  # Inverted\n",
        "\n",
        "            final_xlims = ax.get_xlim()\n",
        "            final_xrange = final_xlims[1] - final_xlims[0]\n",
        "\n",
        "            print(f\"  Final X-axis: [{final_xlims[0]:.3f}, {final_xlims[1]:.3f}]\")\n",
        "\n",
        "            # --- ADD ANNOTATIONS ---\n",
        "            print(f\"  Adding annotations...\")\n",
        "\n",
        "            annot_x_offset = annot_distance * final_xrange\n",
        "\n",
        "            for i, row in plot_df.iterrows():\n",
        "                is_overall = (row['GroupVar'] == 'Overall')\n",
        "                font_weight = 'bold' if is_overall else 'normal'\n",
        "\n",
        "                annot_parts = []\n",
        "                if show_k:\n",
        "                    annot_parts.append(f\"k={int(row['k'])}\")\n",
        "                if show_papers and pd.notna(row['nPapers']):\n",
        "                    annot_parts.append(f\"({int(row['nPapers'])})\")\n",
        "                if show_fold_change and pd.notna(row['FoldChange']) and es_config.get('has_fold_change', False):\n",
        "                    fold_sign = \"+\" if row['FoldChange'] > 0 else \"\"\n",
        "                    annot_parts.append(f\"[{fold_sign}{row['FoldChange']:.2f}√ó]\")\n",
        "\n",
        "                annotation_text = \" \".join(annot_parts) if annot_parts else \"\"\n",
        "\n",
        "                if annotation_text:\n",
        "                    if annot_pos == 'right':\n",
        "                        x_pos = row['CI_Upper'] + annot_x_offset + (annot_offset * final_xrange * 0.1)\n",
        "                        y_pos = y_positions[i]\n",
        "                        va = 'center'\n",
        "                        ha = 'left'\n",
        "                    elif annot_pos == 'above':\n",
        "                        x_pos = row['EffectSize'] + (annot_offset * final_xrange * 0.1)\n",
        "                        y_pos = y_positions[i] - 0.2\n",
        "                        va = 'bottom'\n",
        "                        ha = 'center'\n",
        "                    else:  # below\n",
        "                        x_pos = row['EffectSize'] + (annot_offset * final_xrange * 0.1)\n",
        "                        y_pos = y_positions[i] + 0.2\n",
        "                        va = 'top'\n",
        "                        ha = 'center'\n",
        "\n",
        "                    ax.text(\n",
        "                        x_pos, y_pos,\n",
        "                        annotation_text,\n",
        "                        va=va, ha=ha,\n",
        "                        fontsize=annot_fontsize,\n",
        "                        fontweight=font_weight,\n",
        "                        clip_on=False\n",
        "                    )\n",
        "\n",
        "            # --- ADD GROUP LABELS (TWO-WAY) ---\n",
        "            if has_subgroups and analysis_type == 'two_way':\n",
        "                print(f\"  Adding group labels...\")\n",
        "\n",
        "                current_group = None\n",
        "                first_subgroup_idx = 1 if 'Overall' in plot_df['GroupVar'].values else 0\n",
        "                group_label_x_base = final_xlims[1] - (right_padding * final_xrange)\n",
        "\n",
        "                for i, row in plot_df.iterrows():\n",
        "                    group_val = str(row['GroupVar'])\n",
        "\n",
        "                    if group_val != 'Overall' and group_val != current_group:\n",
        "                        if i > first_subgroup_idx:\n",
        "                            ax.axhline(\n",
        "                                y=y_positions[i] - 0.5,\n",
        "                                color='darkgray',\n",
        "                                linewidth=0.8,\n",
        "                                linestyle='-',\n",
        "                                xmin=0.01,\n",
        "                                xmax=0.99,\n",
        "                                zorder=1\n",
        "                            )\n",
        "\n",
        "                        group_indices = plot_df[plot_df['GroupVar'] == group_val].index\n",
        "                        label_y = (y_positions[group_indices[0]] + y_positions[group_indices[-1]]) / 2.0\n",
        "\n",
        "                        label_x = group_label_x_base + (group_label_h_offset * final_xrange * 0.05)\n",
        "                        label_y = label_y + group_label_v_offset\n",
        "\n",
        "                        display_group_label = label_mapping.get(group_val, group_val)\n",
        "\n",
        "                        ax.text(\n",
        "                            label_x, label_y,\n",
        "                            display_group_label,\n",
        "                            va='center',\n",
        "                            ha='right',\n",
        "                            fontweight='bold',\n",
        "                            fontsize=group_label_fontsize,\n",
        "                            color='black',\n",
        "                            clip_on=False\n",
        "                        )\n",
        "\n",
        "                        current_group = group_val\n",
        "\n",
        "            # --- ADD SEPARATOR LINE BELOW OVERALL ---\n",
        "            if len(plot_df) > 1:\n",
        "                separator_y = y_positions[0] + 0.5\n",
        "                ax.axhline(\n",
        "                    y=separator_y,\n",
        "                    color='black',\n",
        "                    linewidth=1.5,\n",
        "                    linestyle='-'\n",
        "                )\n",
        "\n",
        "            # --- CUSTOMIZE AXES ---\n",
        "            print(f\"  Customizing axes...\")\n",
        "\n",
        "            if show_null_line:\n",
        "                ax.axvline(\n",
        "                    x=0,\n",
        "                    color='black',\n",
        "                    linestyle='-',\n",
        "                    linewidth=1.5,\n",
        "                    alpha=0.8,\n",
        "                    zorder=1\n",
        "                )\n",
        "\n",
        "            ax.set_xlabel(x_label, fontsize=label_fontsize, fontweight='bold')\n",
        "            if show_ylabel:\n",
        "                ax.set_ylabel(y_label, fontsize=label_fontsize, fontweight='bold')\n",
        "\n",
        "            if show_title:\n",
        "                ax.set_title(graph_title, fontweight='bold', fontsize=title_fontsize, pad=15)\n",
        "\n",
        "            ax.set_yticks(y_positions)\n",
        "            ax.set_yticklabels(y_tick_labels, fontsize=tick_fontsize)\n",
        "            ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
        "\n",
        "            if show_grid:\n",
        "                if grid_style == 'dashed_light':\n",
        "                    ax.grid(axis='x', alpha=0.3, linestyle='--', linewidth=0.5)\n",
        "                elif grid_style == 'dotted_light':\n",
        "                    ax.grid(axis='x', alpha=0.3, linestyle=':', linewidth=0.5)\n",
        "                else:  # solid_light\n",
        "                    ax.grid(axis='x', alpha=0.2, linestyle='-', linewidth=0.5)\n",
        "\n",
        "            # --- ADD FOLD-CHANGE AXIS (TOP) ---\n",
        "            if show_fold_axis and es_config.get('has_fold_change', False):\n",
        "                print(f\"  Adding fold-change axis...\")\n",
        "\n",
        "                ax2 = ax.twiny()\n",
        "\n",
        "                fold_ticks_lnRR = np.array([-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2])\n",
        "                fold_ticks_RR = np.exp(fold_ticks_lnRR)\n",
        "\n",
        "                valid_mask = ((fold_ticks_lnRR >= final_xlims[0]) &\n",
        "                             (fold_ticks_lnRR <= final_xlims[1]))\n",
        "                fold_ticks_lnRR = fold_ticks_lnRR[valid_mask]\n",
        "                fold_ticks_RR = fold_ticks_RR[valid_mask]\n",
        "\n",
        "                ax2.set_xlim(final_xlims[0], final_xlims[1])\n",
        "                ax2.set_xticks(fold_ticks_lnRR)\n",
        "\n",
        "                fold_labels = []\n",
        "                for rr in fold_ticks_RR:\n",
        "                    if rr < 1:\n",
        "                        fold_labels.append(f\"{1/rr:.1f}√ó ‚Üì\")\n",
        "                    elif rr > 1:\n",
        "                        fold_labels.append(f\"{rr:.1f}√ó ‚Üë\")\n",
        "                    else:\n",
        "                        fold_labels.append(\"1√ó\")\n",
        "\n",
        "                ax2.set_xticklabels(fold_labels, fontsize=tick_fontsize)\n",
        "                ax2.set_xlabel(\"Fold-Change\", fontsize=label_fontsize, fontweight='bold')\n",
        "\n",
        "            # --- FINALIZE PLOT ---\n",
        "            fig.tight_layout()\n",
        "\n",
        "            # --- SAVE FILES ---\n",
        "            print(f\"\\nüíæ Saving files...\")\n",
        "\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            base_filename = f\"{filename_prefix}_{plot_model}_{timestamp}\"\n",
        "\n",
        "            saved_files = []\n",
        "\n",
        "            if save_pdf:\n",
        "                pdf_filename = f\"{base_filename}.pdf\"\n",
        "                fig.savefig(pdf_filename, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(pdf_filename)\n",
        "                print(f\"  ‚úì {pdf_filename}\")\n",
        "\n",
        "            if save_png:\n",
        "                png_filename = f\"{base_filename}.png\"\n",
        "                fig.savefig(png_filename, dpi=png_dpi, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(png_filename)\n",
        "                print(f\"  ‚úì {png_filename} (DPI: {png_dpi})\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"\\n\" + \"=\"*70)\n",
        "            print(\"‚úÖ FOREST PLOT COMPLETE\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Files: {', '.join(saved_files)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå ERROR: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# --- 4. CREATE BUTTON AND DISPLAY ---\n",
        "plot_button = widgets.Button(\n",
        "    description='üìä Generate Forest Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold', 'font_size': '14px'}\n",
        ")\n",
        "\n",
        "plot_button.on_click(generate_plot)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ FOREST PLOT INTERFACE READY\")\n",
        "print(\"=\"*70)\n",
        "print(\"üëÜ Customize your plot using the tabs above, then click Generate\")\n",
        "print(\"\\nüìù Tips:\")\n",
        "print(\"  ‚Ä¢ Use the 'Labels' tab to rename coded variables\")\n",
        "print(\"  ‚Ä¢ Auto-scale considers ALL data points for proper spacing\")\n",
        "print(\"  ‚Ä¢ Annotations and group labels will fit within the plot\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>üìä Forest Plot Generator</h3>\"),\n",
        "    widgets.HTML(\"<p style='color: #666;'>Create publication-ready forest plots with full customization</p>\"),\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    tab,\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    plot_button,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "setn8oR1bA_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öôÔ∏è Cell 9.5: High-Precision Regression Engine (Final Robust)\n",
        "# =============================================================================\n",
        "# CELL: REGRESSION ENGINE (Stability + Range Fix)\n",
        "# Purpose: Core math for 3-Level Meta-Regression\n",
        "# Fix: Added large-variance start points and matrix jitter for stability.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from scipy.optimize import minimize\n",
        "import statsmodels.api as sm\n",
        "\n",
        "def _run_three_level_reml_regression_v2(analysis_data, moderator_col, effect_col, var_col):\n",
        "    \"\"\"Main optimizer with Expanded Search Range.\"\"\"\n",
        "    grouped = analysis_data.groupby('id')\n",
        "    y_all, v_all, X_all = [], [], []\n",
        "\n",
        "    for _, group in grouped:\n",
        "        y_all.append(group[effect_col].values)\n",
        "        v_all.append(group[var_col].values)\n",
        "        X_i = sm.add_constant(group[moderator_col].values, prepend=True)\n",
        "        X_all.append(X_i)\n",
        "\n",
        "    N_total = len(analysis_data)\n",
        "    M_studies = len(y_all)\n",
        "    p_params = 2\n",
        "\n",
        "    # --- STRATEGY: Broad Global Search ---\n",
        "    # We include 'large' variance start points (5.0, 10.0) to catch cases\n",
        "    # like yours where Tau^2 is ~4.25\n",
        "    start_points = [\n",
        "        [0.1, 0.1],   # Standard small\n",
        "        [1.0, 0.1],   # Medium Between\n",
        "        [5.0, 0.1],   # Large Between (Targeting your data)\n",
        "        [10.0, 0.5],  # Very Large\n",
        "        [0.01, 1.0]   # Large Within\n",
        "    ]\n",
        "\n",
        "    best_res = None\n",
        "    best_fun = np.inf\n",
        "\n",
        "    for start in start_points:\n",
        "        res = minimize(\n",
        "            _neg_log_lik_reml_reg, x0=start,\n",
        "            args=(y_all, v_all, X_all, N_total, M_studies, p_params),\n",
        "            method='L-BFGS-B', bounds=[(1e-8, None), (1e-8, None)],\n",
        "            options={'ftol': 1e-10}\n",
        "        )\n",
        "        if res.success and res.fun < best_fun:\n",
        "            best_fun = res.fun\n",
        "            best_res = res\n",
        "\n",
        "    if not best_res:\n",
        "        # If all fail, try one last desperate run with Nelder-Mead from a safe point\n",
        "        best_res = minimize(\n",
        "            _neg_log_lik_reml_reg, x0=[1.0, 1.0],\n",
        "            args=(y_all, v_all, X_all, N_total, M_studies, p_params),\n",
        "            method='Nelder-Mead', bounds=[(1e-8, None), (1e-8, None)]\n",
        "        )\n",
        "\n",
        "    if not best_res.success and not best_res.message:\n",
        "         return None, None, None\n",
        "\n",
        "    # 2. Polishing (Nelder-Mead)\n",
        "    final_res = minimize(\n",
        "        _neg_log_lik_reml_reg, x0=best_res.x,\n",
        "        args=(y_all, v_all, X_all, N_total, M_studies, p_params),\n",
        "        method='Nelder-Mead', bounds=[(1e-8, None), (1e-8, None)],\n",
        "        options={'xatol': 1e-10, 'fatol': 1e-10}\n",
        "    )\n",
        "\n",
        "    final_est = _get_three_level_regression_estimates_v2(\n",
        "        final_res.x, y_all, v_all, X_all, N_total, M_studies, p_params\n",
        "    )\n",
        "\n",
        "    return final_est, (N_total, M_studies, p_params), final_res\n",
        "\n",
        "print(\"‚úÖ High-Precision Regression Engine Ready (Robust Mode).\")"
      ],
      "metadata": {
        "id": "60kRs3ZqgEdZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìà Cell 10: Meta-Regression (OLD delete?)\n",
        "# =============================================================================\n",
        "# CELL 10: META-REGRESSION UI\n",
        "# Purpose: Run regression with automatic fallback for constant moderators.\n",
        "# Fix: Solved DataFrameGroupBy.apply deprecation warning.\n",
        "# =============================================================================\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from scipy.stats import t, norm\n",
        "from scipy.optimize import minimize_scalar\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# --- 1. HELPER: Standard Random-Effects Regression (2-Level) ---\n",
        "def _run_aggregated_re_regression(agg_df, moderator_col, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Runs a standard Random-Effects Meta-Regression (2-Level).\n",
        "    Used when the moderator is constant within studies.\n",
        "    \"\"\"\n",
        "    # 1. Define REML Objective for 2-Level Model\n",
        "    y = agg_df[effect_col].values\n",
        "    v = agg_df[var_col].values\n",
        "    X = sm.add_constant(agg_df[moderator_col].values)\n",
        "\n",
        "    def re_nll(tau2):\n",
        "        if tau2 < 0: tau2 = 0\n",
        "        weights = 1.0 / (v + tau2)\n",
        "\n",
        "        # WLS to get betas for this tau2\n",
        "        try:\n",
        "            wls = sm.WLS(y, X, weights=weights).fit()\n",
        "            betas = wls.params\n",
        "            resid = y - wls.fittedvalues\n",
        "\n",
        "            # REML Log-Likelihood\n",
        "            ll = -0.5 * (np.sum(np.log(v + tau2)) +\n",
        "                         np.log(np.linalg.det(X.T @ np.diag(weights) @ X)) +\n",
        "                         np.sum((resid**2) * weights))\n",
        "            return -ll\n",
        "        except:\n",
        "            return np.inf\n",
        "\n",
        "    # 2. Optimize Tau2\n",
        "    res = minimize_scalar(re_nll, bounds=(0, 100), method='bounded')\n",
        "    tau2_est = res.x\n",
        "\n",
        "    # 3. Final Fit\n",
        "    weights_final = 1.0 / (v + tau2_est)\n",
        "    final_model = sm.WLS(y, X, weights=weights_final).fit()\n",
        "\n",
        "    return {\n",
        "        'betas': final_model.params,\n",
        "        'se_betas': final_model.bse,\n",
        "        'p_values': final_model.pvalues,\n",
        "        'tau_sq': tau2_est,\n",
        "        'model_type': 'Aggregated Random-Effects (2-Level)',\n",
        "        'n_obs': len(agg_df),\n",
        "        'resid_df': final_model.df_resid\n",
        "    }\n",
        "\n",
        "# --- 2. DATA LOADING & PREP ---\n",
        "def get_potential_moderators(df):\n",
        "    valid_mods = []\n",
        "    exclude = ['id', 'w_fixed', 'w_random']\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        exclude.extend([\n",
        "            ANALYSIS_CONFIG.get('effect_col'),\n",
        "            ANALYSIS_CONFIG.get('var_col'),\n",
        "            ANALYSIS_CONFIG.get('se_col')\n",
        "        ])\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in exclude or col is None: continue\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            if df[col].nunique() > 1: valid_mods.append(col)\n",
        "        elif df[col].dtype == 'object':\n",
        "            try:\n",
        "                nums = pd.to_numeric(df[col], errors='coerce')\n",
        "                if nums.notna().sum() >= 3 and nums.nunique() > 1:\n",
        "                    valid_mods.append(col)\n",
        "            except: pass\n",
        "    return sorted(list(set(valid_mods)))\n",
        "\n",
        "def get_analysis_data():\n",
        "    if 'analysis_data' in globals(): return analysis_data\n",
        "    elif 'data_filtered' in globals(): return data_filtered\n",
        "    else: return None\n",
        "\n",
        "# --- 3. WIDGET SETUP ---\n",
        "df_reg = get_analysis_data()\n",
        "reg_options = get_potential_moderators(df_reg) if df_reg is not None else ['Data not loaded']\n",
        "if not reg_options: reg_options = ['No numeric moderators found']\n",
        "\n",
        "moderator_widget = widgets.Dropdown(\n",
        "    options=reg_options, description='Moderator:',\n",
        "    style={'description_width': 'initial'}, layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "run_reg_btn = widgets.Button(description=\"‚ñ∂ Run Meta-Regression\", button_style='success')\n",
        "reg_output = widgets.Output()\n",
        "\n",
        "def run_regression(b):\n",
        "    global ANALYSIS_CONFIG\n",
        "    with reg_output:\n",
        "        clear_output()\n",
        "        mod_col = moderator_widget.value\n",
        "        df_working = get_analysis_data()\n",
        "\n",
        "        if df_working is None: print(\"‚ùå Error: Data not found.\"); return\n",
        "        if mod_col in ['No numeric moderators found', 'Data not loaded']: print(\"‚ùå Error: No valid moderator.\"); return\n",
        "\n",
        "        if 'ANALYSIS_CONFIG' in globals():\n",
        "            effect_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "            var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "        else:\n",
        "            effect_col = 'hedges_g'; var_col = 'Vg'\n",
        "\n",
        "        print(f\"üöÄ Running Meta-Regression on '{mod_col}'...\")\n",
        "\n",
        "        # Data Prep\n",
        "        reg_df = df_working.copy()\n",
        "        reg_df[mod_col] = pd.to_numeric(reg_df[mod_col], errors='coerce')\n",
        "        reg_df = reg_df.dropna(subset=[mod_col, effect_col, var_col]).copy()\n",
        "        reg_df = reg_df[reg_df[var_col] > 0]\n",
        "\n",
        "        if len(reg_df) < 3: print(f\"‚ùå Error: Not enough data (n={len(reg_df)}).\"); return\n",
        "\n",
        "        # --- CHECK FOR CONSTANT MODERATOR ---\n",
        "        studies_with_variation = reg_df.groupby('id')[mod_col].nunique()\n",
        "        varying_studies = (studies_with_variation > 1).sum()\n",
        "\n",
        "        # LOGIC BRANCH\n",
        "        if varying_studies == 0:\n",
        "            print(f\"\\n‚ö†Ô∏è  WARNING: '{mod_col}' is constant within every study.\")\n",
        "            print(f\"   üîÑ SWITCHING STRATEGY: Aggregating data to study level...\")\n",
        "\n",
        "            # Aggregate Data\n",
        "            reg_df['wi'] = 1 / reg_df[var_col]\n",
        "\n",
        "            # --- FIX FOR PANDAS DEPRECATION WARNING ---\n",
        "            def agg_func(x):\n",
        "                return pd.Series({\n",
        "                    effect_col: np.average(x[effect_col], weights=x['wi']),\n",
        "                    var_col: 1 / np.sum(x['wi']),\n",
        "                    mod_col: x[mod_col].iloc[0]\n",
        "                })\n",
        "\n",
        "            try:\n",
        "                # New pandas (>2.2) requires include_groups=False\n",
        "                agg_df = reg_df.groupby('id').apply(agg_func, include_groups=False).reset_index()\n",
        "            except TypeError:\n",
        "                # Older pandas compatibility\n",
        "                agg_df = reg_df.groupby('id').apply(agg_func).reset_index()\n",
        "            # ------------------------------------------\n",
        "\n",
        "            print(f\"   ‚úì Aggregated {len(reg_df)} observations into {len(agg_df)} studies.\")\n",
        "\n",
        "            # Run Simplified 2-Level Regression\n",
        "            res = _run_aggregated_re_regression(agg_df, mod_col, effect_col, var_col)\n",
        "\n",
        "            beta0, beta1 = res['betas']\n",
        "            se0, se1 = res['se_betas']\n",
        "            p0, p1 = res['p_values']\n",
        "            tau_sq = res['tau_sq']\n",
        "            sigma_sq = 0.0 # Not applicable in 2-level aggregation\n",
        "            df_resid = res['resid_df']\n",
        "            t_stat = beta1 / se1\n",
        "\n",
        "            # Create fake covariance matrix for plotting downstream (Cell 11)\n",
        "            var_betas_robust = np.array([[se0**2, 0], [0, se1**2]])\n",
        "\n",
        "            # Update reg_df for plotting to be the AGGREGATED data\n",
        "            reg_df_for_plot = agg_df\n",
        "\n",
        "        else:\n",
        "            # Run Full 3-Level Regression\n",
        "            if '_run_three_level_reml_regression_v2' not in globals():\n",
        "                 print(\"‚ùå Error: Run Cell 9.5 first.\")\n",
        "                 return\n",
        "\n",
        "            est, _, _ = _run_three_level_reml_regression_v2(reg_df, mod_col, effect_col, var_col)\n",
        "\n",
        "            if not est: print(\"‚ùå Optimization Failed.\"); return\n",
        "\n",
        "            beta0, beta1 = est['betas']\n",
        "            se0, se1 = est['se_betas']\n",
        "            m_studies = reg_df['id'].nunique()\n",
        "            df_resid = max(1, m_studies - 2)\n",
        "            t_stat = beta1 / se1\n",
        "            p1 = 2 * (1 - t.cdf(abs(t_stat), df_resid))\n",
        "            p0 = 2 * (1 - t.cdf(abs(beta0/se0), df_resid)) # Approx\n",
        "            tau_sq = est['tau_sq']\n",
        "            sigma_sq = est['sigma_sq']\n",
        "            var_betas_robust = est['var_betas']\n",
        "            reg_df_for_plot = reg_df\n",
        "\n",
        "        # --- REPORTING ---\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"META-REGRESSION RESULTS (Moderator: {mod_col})\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"\\nModel Type: {res.get('model_type', '3-Level Cluster-Robust') if 'res' in locals() else '3-Level Cluster-Robust'}\")\n",
        "        print(f\"  ‚Ä¢ Studies (k): {reg_df['id'].nunique()}\")\n",
        "        print(f\"  ‚Ä¢ Observations used: {len(reg_df_for_plot)}\")\n",
        "        print(f\"  ‚Ä¢ Tau¬≤ (Between-Study): {tau_sq:.5f}\")\n",
        "        if sigma_sq > 0: print(f\"  ‚Ä¢ Sigma¬≤ (Within-Study): {sigma_sq:.5f}\")\n",
        "\n",
        "        print(f\"\\nCoefficients:\")\n",
        "        print(f\"  {'Term':<15} {'Estimate':<10} {'SE':<10} {'t-value':<10} {'p-value':<10}\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"  {'Intercept':<15} {beta0:<10.4f} {se0:<10.4f} {beta0/se0:<10.3f} {p0:<10.4f}\")\n",
        "        print(f\"  {mod_col[:15]:<15} {beta1:<10.4f} {se1:<10.4f} {t_stat:<10.3f} {p1:<10.4f}\")\n",
        "\n",
        "        if p1 < 0.05: print(f\"\\n‚úÖ Significant relationship detected (p < 0.05).\")\n",
        "        else: print(f\"\\nChecking for relationship... Not significant (p >= 0.05).\")\n",
        "\n",
        "        if 'ANALYSIS_CONFIG' not in globals(): ANALYSIS_CONFIG = {}\n",
        "        ANALYSIS_CONFIG['meta_regression_RVE_results'] = {\n",
        "            'reg_df': reg_df_for_plot, 'moderator_col_name': mod_col, 'effect_col': effect_col,\n",
        "            'betas': [beta0, beta1], 'var_betas_robust': var_betas_robust,\n",
        "            'std_errors_robust': [se0, se1], 'p_slope': p1,\n",
        "            'R_squared_adj': 0, 'df_robust': df_resid\n",
        "        }\n",
        "        ANALYSIS_CONFIG['var_col'] = var_col\n",
        "\n",
        "run_reg_btn.on_click(run_regression)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>üìä Meta-Regression</h3>\"),\n",
        "    moderator_widget,\n",
        "    run_reg_btn,\n",
        "    reg_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EFR7_UHAgGCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-wrDhm1mjeOl"
      },
      "source": [
        "#@title üìà Cell 10: Meta-Regression V2 (Dashboard)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL: META-REGRESSION WITH DASHBOARD\n",
        "# Purpose: Run meta-regression with organized, publication-ready output.\n",
        "# Enhancement: Tabbed interface for results, diagnostics, details, and publication text.\n",
        "# Note: Use the dedicated plot cell for visualization (allows full customization).\n",
        "# =============================================================================\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from scipy.stats import t, norm, chi2\n",
        "from scipy.optimize import minimize_scalar\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# --- 1. LAYOUT & WIDGETS ---\n",
        "tab_results = widgets.Output()\n",
        "tab_diagnostics = widgets.Output()\n",
        "tab_details = widgets.Output()\n",
        "tab_publication = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_results, tab_diagnostics, tab_details, tab_publication])\n",
        "tabs.set_title(0, 'üìä Results')\n",
        "tabs.set_title(1, 'üîç Diagnostics')\n",
        "tabs.set_title(2, '‚öôÔ∏è Model Details')\n",
        "tabs.set_title(3, 'üìù Publication Text')\n",
        "\n",
        "# --- 2. HELPER FUNCTIONS ---\n",
        "\n",
        "def _run_aggregated_re_regression(agg_df, moderator_col, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Runs a standard Random-Effects Meta-Regression (2-Level).\n",
        "    Used when the moderator is constant within studies.\n",
        "    \"\"\"\n",
        "    y = agg_df[effect_col].values\n",
        "    v = agg_df[var_col].values\n",
        "    X = sm.add_constant(agg_df[moderator_col].values)\n",
        "\n",
        "    def re_nll(tau2):\n",
        "        if tau2 < 0: tau2 = 0\n",
        "        weights = 1.0 / (v + tau2)\n",
        "        try:\n",
        "            wls = sm.WLS(y, X, weights=weights).fit()\n",
        "            betas = wls.params\n",
        "            resid = y - wls.fittedvalues\n",
        "            ll = -0.5 * (np.sum(np.log(v + tau2)) +\n",
        "                         np.log(np.linalg.det(X.T @ np.diag(weights) @ X)) +\n",
        "                         np.sum((resid**2) * weights))\n",
        "            return -ll\n",
        "        except:\n",
        "            return np.inf\n",
        "\n",
        "    res = minimize_scalar(re_nll, bounds=(0, 100), method='bounded')\n",
        "    tau2_est = res.x\n",
        "\n",
        "    weights_final = 1.0 / (v + tau2_est)\n",
        "    final_model = sm.WLS(y, X, weights=weights_final).fit()\n",
        "\n",
        "    return {\n",
        "        'betas': final_model.params,\n",
        "        'se_betas': final_model.bse,\n",
        "        'p_values': final_model.pvalues,\n",
        "        'tau_sq': tau2_est,\n",
        "        'model_type': 'Aggregated Random-Effects (2-Level)',\n",
        "        'n_obs': len(agg_df),\n",
        "        'resid_df': final_model.df_resid,\n",
        "        'fitted': final_model.fittedvalues,\n",
        "        'resid': final_model.resid_pearson,\n",
        "        'model': final_model\n",
        "    }\n",
        "\n",
        "def get_potential_moderators(df):\n",
        "    valid_mods = []\n",
        "    exclude = ['id', 'w_fixed', 'w_random']\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        exclude.extend([\n",
        "            ANALYSIS_CONFIG.get('effect_col'),\n",
        "            ANALYSIS_CONFIG.get('var_col'),\n",
        "            ANALYSIS_CONFIG.get('se_col')\n",
        "        ])\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in exclude or col is None: continue\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            if df[col].nunique() > 1: valid_mods.append(col)\n",
        "        elif df[col].dtype == 'object':\n",
        "            try:\n",
        "                nums = pd.to_numeric(df[col], errors='coerce')\n",
        "                if nums.notna().sum() >= 3 and nums.nunique() > 1:\n",
        "                    valid_mods.append(col)\n",
        "            except: pass\n",
        "    return sorted(list(set(valid_mods)))\n",
        "\n",
        "def get_analysis_data():\n",
        "    if 'analysis_data' in globals(): return analysis_data\n",
        "    elif 'data_filtered' in globals(): return data_filtered\n",
        "    else: return None\n",
        "\n",
        "def calculate_r_squared(tau2_null, tau2_model):\n",
        "    \"\"\"Calculate pseudo R-squared for variance explained\"\"\"\n",
        "    if tau2_null <= 0:\n",
        "        return 0.0\n",
        "    r2 = max(0, (tau2_null - tau2_model) / tau2_null * 100)\n",
        "    return r2\n",
        "\n",
        "def calculate_influence_diagnostics(model_results, reg_df, moderator_col, effect_col, var_col):\n",
        "    \"\"\"Calculate Cook's distance and other influence metrics\"\"\"\n",
        "    try:\n",
        "        n = len(reg_df)\n",
        "        # For aggregated models, use statsmodels diagnostics\n",
        "        if 'model' in model_results:\n",
        "            from statsmodels.stats.outliers_influence import OLSInfluence\n",
        "            influence = OLSInfluence(model_results['model'])\n",
        "            cooks_d = influence.cooks_distance[0]\n",
        "            return {\n",
        "                'cooks_d': cooks_d,\n",
        "                'has_influential': np.any(cooks_d > 4/n)\n",
        "            }\n",
        "        else:\n",
        "            # For 3-level, calculate manually\n",
        "            return {'cooks_d': np.zeros(n), 'has_influential': False}\n",
        "    except:\n",
        "        return {'cooks_d': np.zeros(len(reg_df)), 'has_influential': False}\n",
        "\n",
        "def generate_publication_text(mod_col, beta0, beta1, se0, se1, p0, p1, ci0, ci1,\n",
        "                               tau2, sigma2, k_studies, n_obs, model_type,\n",
        "                               r2, resid_het, df_resid):\n",
        "    \"\"\"Generate publication-ready text for meta-regression\"\"\"\n",
        "\n",
        "    sig_text = \"significantly predicted\" if p1 < 0.05 else \"did not significantly predict\"\n",
        "    p_format = f\"< 0.001\" if p1 < 0.001 else f\"= {p1:.3f}\"\n",
        "    direction = \"increased\" if beta1 > 0 else \"decreased\"\n",
        "\n",
        "    # Model type description\n",
        "    if \"2-Level\" in model_type or \"Aggregated\" in model_type:\n",
        "        model_desc = \"two-level aggregated random-effects meta-regression\"\n",
        "        variance_note = f\"Between-study variance (œÑ¬≤) was estimated at {tau2:.4f}.\"\n",
        "        cluster_note = \"\"\n",
        "    else:\n",
        "        model_desc = \"three-level random-effects meta-regression with cluster-robust variance estimation\"\n",
        "        variance_note = f\"Between-study variance (œÑ¬≤) was {tau2:.4f} and within-study variance (œÉ¬≤) was {sigma2:.4f}.\"\n",
        "        cluster_note = \" Cluster-robust standard errors were computed to account for the nested structure of effect sizes within studies.\"\n",
        "\n",
        "    # Residual heterogeneity interpretation\n",
        "    if resid_het < 25:\n",
        "        het_text = \"low\"\n",
        "        het_interp = \"suggesting that the moderator successfully captured most of the systematic variation in effect sizes\"\n",
        "    elif resid_het < 50:\n",
        "        het_text = \"moderate\"\n",
        "        het_interp = \"suggesting that additional unmeasured factors may contribute to the variation in effect sizes\"\n",
        "    else:\n",
        "        het_text = \"substantial\"\n",
        "        het_interp = \"indicating that additional moderators not examined in this analysis likely contribute to variation in effect sizes\"\n",
        "\n",
        "    text = f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt; line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "<h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>Meta-Regression Results</h3>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "We conducted a meta-regression to examine whether <b>{mod_col}</b> moderated the effect sizes. A {model_desc} was employed to account for dependencies in the data.{cluster_note} The analysis included <b>k = {k_studies}</b> studies with <b>n = {n_obs}</b> effect sizes.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The moderator <b>{sig_text}</b> effect sizes (Œ≤‚ÇÅ = <b>{beta1:.3f}</b>, SE = {se1:.3f}, <i>t</i>({df_resid}) = {beta1/se1:.2f}, <i>p</i> {p_format}, 95% CI [{ci1[0]:.3f}, {ci1[1]:.3f}]). \"\"\"\n",
        "\n",
        "    if p1 < 0.05:\n",
        "        text += f\"\"\"For every one-unit increase in {mod_col}, the effect size {direction} by <b>{abs(beta1):.3f}</b> units on average.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "This finding suggests that <b>{mod_col}</b> is an important moderator of the outcome. \"\"\"\n",
        "        if r2 > 0:\n",
        "            text += f\"\"\"The moderator explained <b>{r2:.1f}%</b> of the between-study heterogeneity. \"\"\"\n",
        "        text += f\"\"\"[<i>Add domain-specific interpretation: Why might {mod_col} influence the effect? Link to theory or prior research.</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"The relationship between {mod_col} and effect sizes was not statistically significant.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "No significant linear relationship was detected between <b>{mod_col}</b> and effect sizes, suggesting that {mod_col} may not be a primary source of heterogeneity in this meta-analysis. \"\"\"\n",
        "        if k_studies < 10:\n",
        "            text += f\"\"\"However, the small number of studies (k = {k_studies}) may have limited statistical power to detect a relationship. \"\"\"\n",
        "        text += f\"\"\"[<i>Discuss alternative explanations: Could the relationship be non-linear? Are there confounding factors? Should subgroup analysis be considered?</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    text += f\"\"\"\n",
        "<p style='text-align: justify;'>\n",
        "{variance_note} Residual heterogeneity remained <b>{het_text}</b> (œÑ¬≤<sub>residual</sub> = {tau2:.4f}\"\"\"\n",
        "\n",
        "    if resid_het > 0:\n",
        "        text += f\"\"\", <i>I</i>¬≤<sub>residual</sub> = {resid_het:.1f}%\"\"\"\n",
        "\n",
        "    text += f\"\"\"), {het_interp}.\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Statistical Methods</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "All meta-regression analyses were conducted using {model_desc}. Restricted maximum likelihood (REML) was used to estimate variance components. The intercept (Œ≤‚ÇÄ = {beta0:.3f}, 95% CI [{ci0[0]:.3f}, {ci0[1]:.3f}]) represents the expected effect size when {mod_col} equals zero. Confidence intervals and <i>p</i>-values were based on a <i>t</i>-distribution with {df_resid} degrees of freedom.\n",
        "</p>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 25px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>üìä Table 1. Meta-Regression Coefficients</h4>\n",
        "<table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "<thead style='background-color: #34495e; color: white;'>\n",
        "<tr>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Predictor</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Œ≤</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>SE</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>t</i></th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>df</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>p</i>-value</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>95% CI</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Intercept</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{beta0:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{se0:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{beta0/se0:.2f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{df_resid}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{\"<0.001\" if p0 < 0.001 else f\"{p0:.3f}\"}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{ci0[0]:.3f}, {ci0[1]:.3f}]</td>\n",
        "</tr>\n",
        "<tr style='background-color: white;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'><b>{mod_col}</b></td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center; {\"font-weight: bold;\" if p1 < 0.05 else \"\"}'>{beta1:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{se1:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{beta1/se1:.2f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{df_resid}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center; {\"font-weight: bold;\" if p1 < 0.05 else \"\"}'>{\"<0.001\" if p1 < 0.001 else f\"{p1:.3f}\"}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{ci1[0]:.3f}, {ci1[1]:.3f}]</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "<p style='margin-top: 10px; font-size: 0.9em; color: #6c757d;'><i>Note:</i> Results from {model_desc}. k = number of studies; n = number of effect sizes; œÑ¬≤ = between-study variance\"\"\"\n",
        "\n",
        "    if sigma2 > 0:\n",
        "        text += f\"\"\"; œÉ¬≤ = within-study variance\"\"\"\n",
        "\n",
        "    text += f\"\"\".</p>\n",
        "</div>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; margin-top: 20px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "<ul style='margin-bottom: 0;'>\n",
        "<li>Customize the interpretation based on your specific research domain and theoretical framework</li>\n",
        "<li>Add context about why {mod_col} might theoretically influence the effect sizes</li>\n",
        "<li>Discuss the practical significance of the slope magnitude (not just statistical significance)</li>\n",
        "<li>Consider whether the relationship might be non-linear (quadratic, threshold effects, etc.)</li>\n",
        "<li>Link findings to prior research or meta-analyses in your field</li>\n",
        "<li>If non-significant, discuss statistical power and whether a larger sample might detect an effect</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "<p style='margin: 0;'><b>üí° Tip:</b> Select all text (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C), and paste into your word processor. Edit the [<i>bracketed notes</i>] to add your domain-specific interpretations. Delete sections not relevant to your journal's requirements.</p>\n",
        "</div>\n",
        "\n",
        "</div>\"\"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# --- 3. WIDGET SETUP ---\n",
        "df_reg = get_analysis_data()\n",
        "reg_options = get_potential_moderators(df_reg) if df_reg is not None else ['Data not loaded']\n",
        "if not reg_options: reg_options = ['No numeric moderators found']\n",
        "\n",
        "moderator_widget = widgets.Dropdown(\n",
        "    options=reg_options, description='Moderator:',\n",
        "    style={'description_width': 'initial'}, layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "run_reg_btn = widgets.Button(description=\"‚ñ∂ Run Meta-Regression\", button_style='success', icon='play')\n",
        "\n",
        "# --- 4. MAIN ANALYSIS FUNCTION ---\n",
        "def run_regression(b):\n",
        "    global ANALYSIS_CONFIG\n",
        "\n",
        "    # Clear all tabs\n",
        "    for tab in [tab_results, tab_diagnostics, tab_details, tab_publication]:\n",
        "        tab.clear_output()\n",
        "\n",
        "    mod_col = moderator_widget.value\n",
        "    df_working = get_analysis_data()\n",
        "\n",
        "    if df_working is None:\n",
        "        with tab_results:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå Error: Data not found. Run Step 1 first.</div>\"))\n",
        "        return\n",
        "\n",
        "    if mod_col in ['No numeric moderators found', 'Data not loaded']:\n",
        "        with tab_results:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå Error: No valid moderator selected.</div>\"))\n",
        "        return\n",
        "\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        effect_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "        var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "    else:\n",
        "        effect_col = 'hedges_g'\n",
        "        var_col = 'Vg'\n",
        "\n",
        "    # Data Prep\n",
        "    reg_df = df_working.copy()\n",
        "    reg_df[mod_col] = pd.to_numeric(reg_df[mod_col], errors='coerce')\n",
        "    reg_df = reg_df.dropna(subset=[mod_col, effect_col, var_col]).copy()\n",
        "    reg_df = reg_df[reg_df[var_col] > 0]\n",
        "\n",
        "    if len(reg_df) < 3:\n",
        "        with tab_results:\n",
        "            display(HTML(f\"<div style='color: red;'>‚ùå Error: Insufficient data (n={len(reg_df)}). Need at least 3 observations.</div>\"))\n",
        "        return\n",
        "\n",
        "    # Check for constant moderator\n",
        "    studies_with_variation = reg_df.groupby('id')[mod_col].nunique()\n",
        "    varying_studies = (studies_with_variation > 1).sum()\n",
        "\n",
        "    # Run appropriate model\n",
        "    if varying_studies == 0:\n",
        "        # Aggregate to study level\n",
        "        reg_df['wi'] = 1 / reg_df[var_col]\n",
        "\n",
        "        def agg_func(x):\n",
        "            return pd.Series({\n",
        "                effect_col: np.average(x[effect_col], weights=x['wi']),\n",
        "                var_col: 1 / np.sum(x['wi']),\n",
        "                mod_col: x[mod_col].iloc[0]\n",
        "            })\n",
        "\n",
        "        try:\n",
        "            agg_df = reg_df.groupby('id').apply(agg_func, include_groups=False).reset_index()\n",
        "        except TypeError:\n",
        "            agg_df = reg_df.groupby('id').apply(agg_func).reset_index()\n",
        "\n",
        "        # Run 2-level regression\n",
        "        res = _run_aggregated_re_regression(agg_df, mod_col, effect_col, var_col)\n",
        "\n",
        "        beta0, beta1 = res['betas']\n",
        "        se0, se1 = res['se_betas']\n",
        "        p0, p1 = res['p_values']\n",
        "        tau_sq = res['tau_sq']\n",
        "        sigma_sq = 0.0\n",
        "        df_resid = res['resid_df']\n",
        "        model_type = res['model_type']\n",
        "        fitted = res['fitted']\n",
        "        resid = res['resid']\n",
        "\n",
        "        var_betas_robust = np.array([[se0**2, 0], [0, se1**2]])\n",
        "        reg_df_for_plot = agg_df\n",
        "\n",
        "    else:\n",
        "        # Run 3-level regression\n",
        "        if '_run_three_level_reml_regression_v2' not in globals():\n",
        "            with tab_results:\n",
        "                display(HTML(\"<div style='color: red;'>‚ùå Error: Run Cell 9.5 (High-Precision Regression Engine) first.</div>\"))\n",
        "            return\n",
        "\n",
        "        est, _, _ = _run_three_level_reml_regression_v2(reg_df, mod_col, effect_col, var_col)\n",
        "\n",
        "        if not est:\n",
        "            with tab_results:\n",
        "                display(HTML(\"<div style='color: red;'>‚ùå Optimization Failed.</div>\"))\n",
        "            return\n",
        "\n",
        "        beta0, beta1 = est['betas']\n",
        "        se0, se1 = est['se_betas']\n",
        "        m_studies = reg_df['id'].nunique()\n",
        "        df_resid = max(1, m_studies - 2)\n",
        "        t_stat = beta1 / se1\n",
        "        p1 = 2 * (1 - t.cdf(abs(t_stat), df_resid))\n",
        "        p0 = 2 * (1 - t.cdf(abs(beta0/se0), df_resid))\n",
        "        tau_sq = est['tau_sq']\n",
        "        sigma_sq = est['sigma_sq']\n",
        "        var_betas_robust = est['var_betas']\n",
        "        model_type = \"3-Level Cluster-Robust\"\n",
        "        reg_df_for_plot = reg_df\n",
        "\n",
        "        # Calculate fitted and residuals for 3-level\n",
        "        X_mod = reg_df[mod_col].values\n",
        "        fitted = beta0 + beta1 * X_mod\n",
        "        resid = reg_df[effect_col].values - fitted\n",
        "\n",
        "    # Calculate confidence intervals\n",
        "    t_crit = t.ppf(0.975, df_resid)\n",
        "    ci0 = [beta0 - t_crit * se0, beta0 + t_crit * se0]\n",
        "    ci1 = [beta1 - t_crit * se1, beta1 + t_crit * se1]\n",
        "\n",
        "    # Calculate R-squared (need null model tau2)\n",
        "    # Simple approximation: use overall heterogeneity if available\n",
        "    if 'overall_results' in ANALYSIS_CONFIG:\n",
        "        tau2_null = ANALYSIS_CONFIG['overall_results'].get('tau_squared', tau_sq)\n",
        "    else:\n",
        "        tau2_null = tau_sq\n",
        "\n",
        "    r2 = calculate_r_squared(tau2_null, tau_sq)\n",
        "\n",
        "    # Residual heterogeneity (approximate I¬≤)\n",
        "    if tau_sq > 0:\n",
        "        mean_v = np.mean(reg_df_for_plot[var_col])\n",
        "        total_var = tau_sq + sigma_sq + mean_v\n",
        "        resid_i2 = ((tau_sq + sigma_sq) / total_var) * 100 if total_var > 0 else 0\n",
        "    else:\n",
        "        resid_i2 = 0\n",
        "\n",
        "    k_studies = reg_df['id'].nunique()\n",
        "    n_obs = len(reg_df_for_plot)\n",
        "\n",
        "    # Calculate influence diagnostics\n",
        "    influence_metrics = calculate_influence_diagnostics(\n",
        "        res if varying_studies == 0 else {},\n",
        "        reg_df_for_plot, mod_col, effect_col, var_col\n",
        "    )\n",
        "\n",
        "    # --- TAB 1: RESULTS ---\n",
        "    with tab_results:\n",
        "        sig = \"***\" if p1 < 0.001 else \"**\" if p1 < 0.01 else \"*\" if p1 < 0.05 else \"ns\"\n",
        "        color = \"#28a745\" if p1 < 0.05 else \"#6c757d\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h2 style='color: #2c3e50; margin-bottom: 20px;'>Meta-Regression: {mod_col}</h2>\n",
        "\n",
        "        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "            <div style='text-align: center;'>\n",
        "                <div style='font-size: 0.9em; margin-bottom: 10px;'>SLOPE COEFFICIENT (Œ≤‚ÇÅ)</div>\n",
        "                <h1 style='margin: 0; font-size: 3em;'>{beta1:.4f}</h1>\n",
        "                <p style='margin: 10px 0 0 0; font-size: 1.2em;'>{sig}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-bottom: 20px;'>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #007bff;'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>95% Confidence Interval</div>\n",
        "                <div style='font-size: 1.3em; font-weight: bold;'>[{ci1[0]:.4f}, {ci1[1]:.4f}]</div>\n",
        "            </div>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid {color};'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>P-value</div>\n",
        "                <div style='font-size: 1.3em; font-weight: bold; color: {color};'>{p1:.4g}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "            <p style='margin: 0; font-size: 1.05em;'>\n",
        "                For every 1-unit increase in <b>{mod_col}</b>, the effect size {'<b>increases</b>' if beta1 > 0 else '<b>decreases</b>'} by <b>{abs(beta1):.4f}</b> units.\n",
        "                {'This relationship is <b style=\"color: #28a745;\">statistically significant</b>.' if p1 < 0.05 else 'This relationship is <b>not statistically significant</b>.'}\n",
        "            </p>\n",
        "        </div>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Coefficient Table</h3>\n",
        "        <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Term</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Estimate (Œ≤)</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>SE</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>t-value</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>p-value</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>95% CI</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Intercept</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{beta0:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{se0:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{beta0/se0:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{p0:.4g}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{ci0[0]:.4f}, {ci0[1]:.4f}]</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>{mod_col}</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6; {\"font-weight: bold; color: #28a745;\" if p1 < 0.05 else \"\"}'>{beta1:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{se1:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{beta1/se1:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6; {\"font-weight: bold; color: #28a745;\" if p1 < 0.05 else \"\"}'>{p1:.4g}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{ci1[0]:.4f}, {ci1[1]:.4f}]</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Model Summary</h3>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "            <p style='margin: 5px 0;'><b>Model Type:</b> {model_type}</p>\n",
        "            <p style='margin: 5px 0;'><b>Studies (k):</b> {k_studies}</p>\n",
        "            <p style='margin: 5px 0;'><b>Observations (n):</b> {n_obs}</p>\n",
        "            <p style='margin: 5px 0;'><b>Degrees of Freedom:</b> {df_resid}</p>\n",
        "            <p style='margin: 5px 0;'><b>Between-Study Variance (œÑ¬≤):</b> {tau_sq:.4f}</p>\n",
        "            \"\"\"\n",
        "\n",
        "        if sigma_sq > 0:\n",
        "            html += f\"<p style='margin: 5px 0;'><b>Within-Study Variance (œÉ¬≤):</b> {sigma_sq:.4f}</p>\"\n",
        "\n",
        "        if r2 > 0:\n",
        "            html += f\"<p style='margin: 5px 0;'><b>Variance Explained (R¬≤):</b> {r2:.1f}%</p>\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Residual I¬≤:</b> {resid_i2:.1f}%</p>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "            <p style='margin: 0;'><b>üìä Next Step:</b> Use the dedicated plot cell to visualize this regression relationship with full customization options.</p>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(html))\n",
        "\n",
        "    # --- TAB 2: DIAGNOSTICS ---\n",
        "    with tab_diagnostics:\n",
        "        display(HTML(\"<h3 style='color: #2c3e50;'>üîç Model Diagnostics</h3>\"))\n",
        "\n",
        "        # Residuals summary\n",
        "        resid_std = resid / np.sqrt(np.var(resid))\n",
        "\n",
        "        diag_html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Residual Analysis</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'><b>Residual Range:</b> [{np.min(resid):.4f}, {np.max(resid):.4f}]</p>\n",
        "            <p style='margin: 5px 0;'><b>Mean Residual:</b> {np.mean(resid):.4f} (should be ‚âà 0)</p>\n",
        "            <p style='margin: 5px 0;'><b>SD of Residuals:</b> {np.std(resid):.4f}</p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Influence Diagnostics</h4>\n",
        "        \"\"\"\n",
        "\n",
        "        if influence_metrics['has_influential']:\n",
        "            influential_indices = np.where(influence_metrics['cooks_d'] > 4/n_obs)[0]\n",
        "            diag_html += f\"\"\"\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-bottom: 20px;'>\n",
        "                <p style='margin: 0;'><b>‚ö†Ô∏è Warning:</b> {len(influential_indices)} potentially influential observation(s) detected (Cook's D > {4/n_obs:.4f}).</p>\n",
        "                <p style='margin: 10px 0 0 0;'>Influential points: {', '.join(map(str, influential_indices))}</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            diag_html += \"\"\"\n",
        "            <div style='background-color: #d4edda; padding: 15px; border-radius: 5px; border-left: 4px solid #28a745; margin-bottom: 20px;'>\n",
        "                <p style='margin: 0;'><b>‚úì Good:</b> No highly influential observations detected.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        diag_html += f\"\"\"\n",
        "        <h4 style='color: #34495e;'>Heterogeneity Assessment</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'><b>Residual Heterogeneity (I¬≤):</b> {resid_i2:.1f}%</p>\n",
        "            \"\"\"\n",
        "\n",
        "        if r2 > 0:\n",
        "            diag_html += f\"<p style='margin: 5px 0;'><b>Heterogeneity Explained (R¬≤):</b> {r2:.1f}%</p>\"\n",
        "\n",
        "        diag_html += f\"\"\"\n",
        "            <p style='margin: 10px 0 0 0;'><i>Lower residual heterogeneity suggests the moderator explains variation well.</i></p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Model Assumptions</h4>\n",
        "        <table style='width: 100%; border-collapse: collapse;'>\n",
        "            <thead style='background-color: #f8f9fa;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Assumption</th>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Assessment</th>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Status</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Linearity</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Check scatter plot in dedicated plot cell</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>‚ö†Ô∏è Visual check needed</td>\n",
        "                </tr>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Independence</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>{'Cluster-robust SE used' if sigma_sq > 0 else 'Aggregated to study level'}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>‚úì Accounted for</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Normality</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Residuals approximately normal (t-distribution)</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>‚úì Assumed</td>\n",
        "                </tr>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Homoscedasticity</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Weighted by inverse variance</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>‚úì Weighted regression</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "\n",
        "        <div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px; margin-top: 20px;'>\n",
        "            <p style='margin: 0;'><b>üí° Recommendation:</b> Use the dedicated plot cell to create residual plots and visually assess linearity and homoscedasticity assumptions.</p>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(diag_html))\n",
        "\n",
        "    # --- TAB 3: MODEL DETAILS ---\n",
        "    with tab_details:\n",
        "        display(HTML(\"<h3 style='color: #2c3e50;'>‚öôÔ∏è Model Details & Specifications</h3>\"))\n",
        "\n",
        "        details_html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Model Specification</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px; font-family: monospace;'>\n",
        "            \"\"\"\n",
        "\n",
        "        if sigma_sq > 0:\n",
        "            details_html += f\"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Three-Level Model:</b></p>\n",
        "            <p style='margin: 5px 0; padding-left: 20px;'>y<sub>ij</sub> = Œ≤‚ÇÄ + Œ≤‚ÇÅX<sub>i</sub> + u<sub>i</sub> + e<sub>ij</sub></p>\n",
        "            <p style='margin: 5px 0; padding-left: 20px;'>where:</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ y<sub>ij</sub> = effect size j in study i</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ X<sub>i</sub> = moderator value for study i</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ u<sub>i</sub> ~ N(0, œÑ¬≤) = between-study random effect</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ e<sub>ij</sub> ~ N(0, œÉ¬≤) = within-study random effect</p>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            details_html += f\"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Two-Level Aggregated Model:</b></p>\n",
        "            <p style='margin: 5px 0; padding-left: 20px;'>y<sub>i</sub> = Œ≤‚ÇÄ + Œ≤‚ÇÅX<sub>i</sub> + u<sub>i</sub></p>\n",
        "            <p style='margin: 5px 0; padding-left: 20px;'>where:</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ y<sub>i</sub> = aggregated effect size for study i</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ X<sub>i</sub> = moderator value for study i</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ u<sub>i</sub> ~ N(0, œÑ¬≤) = between-study random effect</p>\n",
        "            <p style='margin: 10px 0 0 0;'><i>Note: Data aggregated to study level because moderator was constant within studies.</i></p>\n",
        "            \"\"\"\n",
        "\n",
        "        details_html += f\"\"\"\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Variance-Covariance Matrix</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <table style='margin: 10px auto; border-collapse: collapse;'>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas_robust[0,0]:.6f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas_robust[0,1]:.6f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas_robust[1,0]:.6f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas_robust[1,1]:.6f}</td>\n",
        "                </tr>\n",
        "            </table>\n",
        "            <p style='margin: 10px 0 0 0; text-align: center; font-size: 0.9em;'><i>Var(Œ≤‚ÇÄ) and Var(Œ≤‚ÇÅ) on diagonal; Cov(Œ≤‚ÇÄ,Œ≤‚ÇÅ) on off-diagonal</i></p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Variance Components</h4>\n",
        "        <table style='width: 100%; border-collapse: collapse; margin-bottom: 20px;'>\n",
        "            <thead style='background-color: #f8f9fa;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Component</th>\n",
        "                    <th style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>Value</th>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Description</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>œÑ¬≤</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tau_sq:.4f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Between-study variance (residual)</td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "\n",
        "        if sigma_sq > 0:\n",
        "            details_html += f\"\"\"\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>œÉ¬≤</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{sigma_sq:.4f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Within-study variance</td>\n",
        "                </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        details_html += f\"\"\"\n",
        "            </tbody>\n",
        "        </table>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Degrees of Freedom</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'><b>df:</b> {df_resid}</p>\n",
        "            <p style='margin: 5px 0;'><b>Calculation:</b> \"\"\"\n",
        "\n",
        "        if sigma_sq > 0:\n",
        "            details_html += f\"Number of studies (k = {k_studies}) - Number of parameters (2) = {df_resid}\"\n",
        "        else:\n",
        "            details_html += f\"Number of observations (n = {n_obs}) - Number of parameters (2) = {df_resid}\"\n",
        "\n",
        "        details_html += f\"\"\"</p>\n",
        "            <p style='margin: 10px 0 0 0;'><i>Used for t-distribution in hypothesis testing and confidence intervals</i></p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Standard Error Details</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            \"\"\"\n",
        "\n",
        "        if sigma_sq > 0:\n",
        "            details_html += \"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Cluster-Robust Standard Errors</b></p>\n",
        "            <p style='margin: 5px 0;'>Standard errors account for clustering of effect sizes within studies, providing more conservative estimates when multiple effect sizes come from the same study.</p>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            details_html += \"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Standard Random-Effects Standard Errors</b></p>\n",
        "            <p style='margin: 5px 0;'>Standard errors from aggregated two-level model. Data was aggregated to study level because the moderator was constant within each study.</p>\n",
        "            \"\"\"\n",
        "\n",
        "        details_html += f\"\"\"\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Data Summary</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "            <p style='margin: 5px 0;'><b>Original data:</b> {len(df_working)} observations</p>\n",
        "            <p style='margin: 5px 0;'><b>After cleaning:</b> {len(reg_df)} observations</p>\n",
        "            <p style='margin: 5px 0;'><b>Used in analysis:</b> {n_obs} {'studies' if varying_studies == 0 else 'observations'}</p>\n",
        "            <p style='margin: 5px 0;'><b>Moderator range:</b> [{reg_df_for_plot[mod_col].min():.3f}, {reg_df_for_plot[mod_col].max():.3f}]</p>\n",
        "            <p style='margin: 5px 0;'><b>Effect size range:</b> [{reg_df_for_plot[effect_col].min():.3f}, {reg_df_for_plot[effect_col].max():.3f}]</p>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(details_html))\n",
        "\n",
        "    # --- TAB 4: PUBLICATION TEXT ---\n",
        "    with tab_publication:\n",
        "        display(HTML(\"<h3 style='color: #2c3e50;'>üìù Publication-Ready Results Text</h3>\"))\n",
        "        display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "        pub_text = generate_publication_text(\n",
        "            mod_col, beta0, beta1, se0, se1, p0, p1, ci0, ci1,\n",
        "            tau_sq, sigma_sq, k_studies, n_obs, model_type,\n",
        "            r2, resid_i2, df_resid\n",
        "        )\n",
        "\n",
        "        display(HTML(pub_text))\n",
        "\n",
        "    # --- SAVE RESULTS ---\n",
        "    if 'ANALYSIS_CONFIG' not in globals(): ANALYSIS_CONFIG = {}\n",
        "    ANALYSIS_CONFIG['meta_regression_RVE_results'] = {\n",
        "        'reg_df': reg_df_for_plot,\n",
        "        'moderator_col_name': mod_col,\n",
        "        'effect_col': effect_col,\n",
        "        'betas': [beta0, beta1],\n",
        "        'var_betas_robust': var_betas_robust,\n",
        "        'std_errors_robust': [se0, se1],\n",
        "        'p_slope': p1,\n",
        "        'R_squared_adj': r2,\n",
        "        'df_robust': df_resid,\n",
        "        'fitted': fitted,\n",
        "        'resid': resid\n",
        "    }\n",
        "    ANALYSIS_CONFIG['var_col'] = var_col\n",
        "\n",
        "run_reg_btn.on_click(run_regression)\n",
        "\n",
        "# --- 5. DISPLAY UI ---\n",
        "display(HTML(\"<h3>üìä Meta-Regression Analysis (V2)</h3>\"))\n",
        "display(HTML(\"<p style='color: #6c757d;'>Select a moderator variable and run the analysis. Results will appear in organized tabs below.</p>\"))\n",
        "display(widgets.VBox([moderator_widget, run_reg_btn]))\n",
        "display(tabs)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìà META-REGRESSION PLOT (Cluster-Robust)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 11 (REPLACEMENT): META-REGRESSION PLOT\n",
        "# Purpose: Visualize the meta-regression results from Cell 10\n",
        "# Method: Creates a bubble plot with cluster-robust confidence bands\n",
        "# Dependencies: Cell 10 (meta_regression_RVE_results)\n",
        "# Outputs: Publication-ready plot (PDF/PNG)\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import t\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import sys\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# --- 1. WIDGET DEFINITIONS ---\n",
        "# Initialize lists\n",
        "available_color_moderators = ['None']\n",
        "analysis_data_init = None\n",
        "default_x_label = \"Moderator\"\n",
        "default_y_label = \"Effect Size\"\n",
        "default_title = \"Meta-Regression Plot\"\n",
        "label_widgets_dict = {} # Dictionary to store label widgets\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"ANALYSIS_CONFIG not found\")\n",
        "\n",
        "    if 'analysis_data' in globals():\n",
        "        analysis_data_init = analysis_data.copy()\n",
        "    elif 'data_filtered' in globals():\n",
        "        analysis_data_init = data_filtered.copy()\n",
        "    else:\n",
        "        raise ValueError(\"No data found\")\n",
        "\n",
        "    if 'meta_regression_RVE_results' in ANALYSIS_CONFIG:\n",
        "        reg_results = ANALYSIS_CONFIG['meta_regression_RVE_results']\n",
        "        es_config = ANALYSIS_CONFIG['es_config']\n",
        "        default_x_label = reg_results['moderator_col_name']\n",
        "        default_y_label = es_config['effect_label']\n",
        "        default_title = f\"Meta-Regression: {default_y_label} vs. {default_x_label}\"\n",
        "\n",
        "    # Find categorical moderators for color AND labels\n",
        "    excluded_cols = [\n",
        "        ANALYSIS_CONFIG.get('effect_col'), ANALYSIS_CONFIG.get('var_col'),\n",
        "        ANALYSIS_CONFIG.get('se_col'), 'w_fixed', 'w_random', 'id',\n",
        "        'xe', 'sde', 'ne', 'xc', 'sdc', 'nc',\n",
        "        ANALYSIS_CONFIG.get('ci_lower_col'), ANALYSIS_CONFIG.get('ci_upper_col')\n",
        "    ]\n",
        "    excluded_cols = [col for col in excluded_cols if col is not None]\n",
        "\n",
        "    categorical_cols = analysis_data_init.select_dtypes(include=['object', 'category']).columns\n",
        "    available_color_moderators.extend([\n",
        "        col for col in categorical_cols\n",
        "        if col not in excluded_cols and analysis_data_init[col].nunique() <= 10\n",
        "    ])\n",
        "\n",
        "    # *** NEW: Find all unique labels for the Label Editor ***\n",
        "    all_categorical_labels = set()\n",
        "    for col in available_color_moderators:\n",
        "        if col != 'None' and col in analysis_data_init.columns:\n",
        "            # Add the column name itself (e.g., \"Crop\")\n",
        "            all_categorical_labels.add(col)\n",
        "            # Add all unique values in that column (e.g., \"B\", \"C\", \"R\", \"W\")\n",
        "            all_categorical_labels.update(analysis_data_init[col].astype(str).str.strip().unique())\n",
        "\n",
        "    # Remove any empty strings\n",
        "    all_categorical_labels.discard('')\n",
        "    all_categorical_labels.discard('nan')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Initialization Error: {e}. Please run previous cells.\")\n",
        "\n",
        "\n",
        "# --- Widget Interface ---\n",
        "header = widgets.HTML(\n",
        "    \"<h3 style='color: #2E86AB;'>Meta-Regression Plot Setup</h3>\"\n",
        "    \"<p style='color: #666;'><i>Visualize the relationship between moderator and effect size</i></p>\"\n",
        ")\n",
        "\n",
        "# ========== TAB 1: PLOT STYLE ==========\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Plot Title:',\n",
        "                            layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "xlabel_widget = widgets.Text(value=default_x_label, description='X-Axis Label:',\n",
        "                             layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "ylabel_widget = widgets.Text(value=default_y_label, description='Y-Axis Label:',\n",
        "                             layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "width_widget = widgets.FloatSlider(value=8.0, min=5.0, max=14.0, step=0.5, description='Plot Width (in):',\n",
        "                                   continuous_update=False, style={'description_width': '120px'},\n",
        "                                   layout=widgets.Layout(width='450px'))\n",
        "height_widget = widgets.FloatSlider(value=6.0, min=4.0, max=12.0, step=0.5, description='Plot Height (in):',\n",
        "                                    continuous_update=False, style={'description_width': '120px'},\n",
        "                                    layout=widgets.Layout(width='450px'))\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Size</h4>\"),\n",
        "    show_title_widget, title_widget, xlabel_widget, ylabel_widget, width_widget, height_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 2: DATA POINTS ==========\n",
        "color_mod_widget = widgets.Dropdown(options=available_color_moderators, value='None', description='Color By:',\n",
        "                                    style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "point_color_widget = widgets.Dropdown(options=['gray', 'blue', 'red', 'green', 'purple', 'orange'], value='gray',\n",
        "                                      description='Point Color:', style={'description_width': '120px'},\n",
        "                                      layout=widgets.Layout(width='450px'))\n",
        "bubble_base_widget = widgets.IntSlider(value=20, min=0, max=200, step=10, description='Min Bubble Size:',\n",
        "                                       continuous_update=False, style={'description_width': '120px'},\n",
        "                                       layout=widgets.Layout(width='450px'))\n",
        "bubble_range_widget = widgets.IntSlider(value=800, min=100, max=2000, step=100, description='Max Bubble Size:',\n",
        "                                        continuous_update=False, style={'description_width': '120px'},\n",
        "                                        layout=widgets.Layout(width='450px'))\n",
        "bubble_alpha_widget = widgets.FloatSlider(value=0.6, min=0.1, max=1.0, step=0.1, description='Transparency:',\n",
        "                                          continuous_update=False, style={'description_width': '120px'},\n",
        "                                          layout=widgets.Layout(width='450px'))\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Points</h4>\"),\n",
        "    color_mod_widget, point_color_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Bubble Size (by precision):</b>\"),\n",
        "    bubble_base_widget, bubble_range_widget, bubble_alpha_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 3: REGRESSION LINE ==========\n",
        "show_ci_widget = widgets.Checkbox(value=True, description='Show 95% Confidence Band', indent=False)\n",
        "line_color_widget = widgets.Dropdown(options=['red', 'blue', 'black', 'green', 'purple'], value='red',\n",
        "                                     description='Line Color:', style={'description_width': '120px'},\n",
        "                                     layout=widgets.Layout(width='450px'))\n",
        "line_width_widget = widgets.FloatSlider(value=2.0, min=0.5, max=5.0, step=0.5, description='Line Width:',\n",
        "                                        continuous_update=False, style={'description_width': '120px'},\n",
        "                                        layout=widgets.Layout(width='450px'))\n",
        "ci_alpha_widget = widgets.FloatSlider(value=0.3, min=0.1, max=0.8, step=0.1, description='CI Transparency:',\n",
        "                                      continuous_update=False, style={'description_width': '120px'},\n",
        "                                      layout=widgets.Layout(width='450px'))\n",
        "show_equation_widget = widgets.Checkbox(value=True, description='Show Regression Equation & P-value', indent=False)\n",
        "show_r2_widget = widgets.Checkbox(value=True, description='Show R¬≤ Value', indent=False)\n",
        "\n",
        "regline_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Regression Line</h4>\"),\n",
        "    line_color_widget, line_width_widget, show_ci_widget, ci_alpha_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    show_equation_widget, show_r2_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 4: LAYOUT & EXPORT ==========\n",
        "show_grid_widget = widgets.Checkbox(value=True, description='Show Grid', indent=False)\n",
        "show_null_line_widget = widgets.Checkbox(value=True, description='Show Null Effect Line (y=0)', indent=False)\n",
        "legend_loc_widget = widgets.Dropdown(options=['best', 'upper right', 'upper left', 'lower left', 'lower right'],\n",
        "                                     value='best', description='Legend Position:',\n",
        "                                     style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "legend_fontsize_widget = widgets.IntSlider(value=10, min=6, max=14, step=1, description='Legend Font:',\n",
        "                                           continuous_update=False, style={'description_width': '120px'},\n",
        "                                           layout=widgets.Layout(width='450px'))\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "png_dpi_widget = widgets.IntSlider(value=300, min=150, max=600, step=50, description='PNG DPI:',\n",
        "                                   continuous_update=False, style={'description_width': '120px'},\n",
        "                                   layout=widgets.Layout(width='450px'))\n",
        "filename_prefix_widget = widgets.Text(value='MetaRegression_Plot', description='Filename Prefix:',\n",
        "                                      layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "transparent_bg_widget = widgets.Checkbox(value=False, description='Transparent Background', indent=False)\n",
        "\n",
        "layout_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Layout & Legend</h4>\"),\n",
        "    show_grid_widget, show_null_line_widget, legend_loc_widget, legend_fontsize_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Export</h4>\"),\n",
        "    save_pdf_widget, save_png_widget, png_dpi_widget, filename_prefix_widget, transparent_bg_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 5: LABELS (NEW) ==========\n",
        "label_editor_widgets = []\n",
        "for label in sorted(list(all_categorical_labels)):\n",
        "    text_widget = widgets.Text(\n",
        "        value=str(label),\n",
        "        description=f\"{label}:\",\n",
        "        layout=widgets.Layout(width='500px'),\n",
        "        style={'description_width': '200px'}\n",
        "    )\n",
        "    label_editor_widgets.append(text_widget)\n",
        "    label_widgets_dict[str(label)] = text_widget # Store widget by its original name\n",
        "\n",
        "label_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Edit Plot Labels</h4>\"),\n",
        "    widgets.HTML(\"<p style='color: #666;'><i>Rename raw data values (e.g., 'W') to publication-ready labels (e.g., 'Wheat').</i></p>\"),\n",
        "    *label_editor_widgets\n",
        "])\n",
        "\n",
        "\n",
        "# --- Assemble Tabs ---\n",
        "tab = widgets.Tab(children=[style_tab, points_tab, regline_tab, layout_tab, label_tab])\n",
        "tab.set_title(0, 'üé® Style'); tab.set_title(1, '‚ö´ Points'); tab.set_title(2, 'üìà Regression')\n",
        "tab.set_title(3, 'üíæ Layout/Export'); tab.set_title(4, '‚úèÔ∏è Labels')\n",
        "\n",
        "run_plot_button = widgets.Button(\n",
        "    description='üìä Generate Regression Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# --- 2. PLOTTING FUNCTION ---\n",
        "@run_plot_button.on_click\n",
        "def generate_regression_plot(b):\n",
        "    \"\"\"Generate meta-regression scatter plot with regression line\"\"\"\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(\"=\"*70)\n",
        "        print(\"GENERATING CLUSTER-ROBUST META-REGRESSION PLOT\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            # --- 1. Load Data & Config ---\n",
        "            print(\"STEP 1: LOADING RESULTS FROM CELL 10\")\n",
        "            print(\"---------------------------------\")\n",
        "            if 'meta_regression_RVE_results' not in ANALYSIS_CONFIG:\n",
        "                raise ValueError(\"No meta-regression results found. Please re-run Cell 10.\")\n",
        "\n",
        "            reg_results = ANALYSIS_CONFIG['meta_regression_RVE_results']\n",
        "            es_config = ANALYSIS_CONFIG['es_config']\n",
        "\n",
        "            plot_data = reg_results['reg_df'].copy()\n",
        "            moderator_col = reg_results['moderator_col_name']\n",
        "            effect_col = reg_results['effect_col']\n",
        "            var_col = ANALYSIS_CONFIG['var_col']\n",
        "\n",
        "            b0, b1 = reg_results['betas']\n",
        "            var_betas_robust = reg_results['var_betas_robust']\n",
        "            R_sq = reg_results['R_squared_adj']\n",
        "            p_slope = reg_results['p_slope']\n",
        "            df_robust = reg_results['df_robust']\n",
        "\n",
        "            print(f\"  ‚úì Loaded results for moderator: {moderator_col}\")\n",
        "            print(f\"  ‚úì Found {len(plot_data)} data points to plot.\")\n",
        "\n",
        "            # --- 2. Get Widget Values (*** FIX: ADDED .value TO ALL ***) ---\n",
        "            show_title = show_title_widget.value\n",
        "            graph_title = title_widget.value\n",
        "            x_label = xlabel_widget.value\n",
        "            y_label = ylabel_widget.value\n",
        "            plot_width = width_widget.value\n",
        "            plot_height = height_widget.value\n",
        "\n",
        "            color_mod_name = color_mod_widget.value\n",
        "            point_color = point_color_widget.value\n",
        "            bubble_base = bubble_base_widget.value\n",
        "            bubble_range = bubble_range_widget.value\n",
        "            bubble_alpha = bubble_alpha_widget.value\n",
        "\n",
        "            show_ci = show_ci_widget.value\n",
        "            line_color = line_color_widget.value\n",
        "            line_width = line_width_widget.value\n",
        "            ci_alpha = ci_alpha_widget.value\n",
        "            show_equation = show_equation_widget.value\n",
        "            show_r2 = show_r2_widget.value\n",
        "\n",
        "            show_grid = show_grid_widget.value\n",
        "            show_null_line = show_null_line_widget.value\n",
        "            legend_loc = legend_loc_widget.value\n",
        "            legend_fontsize = legend_fontsize_widget.value\n",
        "\n",
        "            save_pdf = save_pdf_widget.value\n",
        "            save_png = save_png_widget.value\n",
        "            png_dpi = png_dpi_widget.value\n",
        "            filename_prefix = filename_prefix_widget.value\n",
        "            transparent_bg = transparent_bg_widget.value\n",
        "            # *** END FIX ***\n",
        "\n",
        "            print(f\"\\nüìä Configuration:\")\n",
        "            print(f\"  Plot size: {plot_width}\\\\\\\" √ó {plot_height}\\\\\\\"\")\n",
        "            print(f\"  Color by: {color_mod_name}\")\n",
        "\n",
        "            # --- 2b. Build Label Mapping ---\n",
        "            label_mapping = {orig: w.value for orig, w in label_widgets_dict.items()}\n",
        "\n",
        "            # --- 3. Prepare Data for Plotting ---\n",
        "            print(\"\\nSTEP 2: PREPARING PLOT DATA\")\n",
        "            print(\"---------------------------------\")\n",
        "\n",
        "            if 'weights' not in plot_data.columns:\n",
        "                tau_sq_overall = ANALYSIS_CONFIG['overall_results']['tau_squared']\n",
        "                plot_data['weights'] = 1 / (plot_data[var_col] + tau_sq_overall)\n",
        "\n",
        "            min_w = plot_data['weights'].min()\n",
        "            max_w = plot_data['weights'].max()\n",
        "\n",
        "            if max_w > min_w:\n",
        "                plot_data['BubbleSize'] = bubble_base + (\n",
        "                    ((plot_data['weights'] - min_w) / (max_w - min_w)) * bubble_range\n",
        "                )\n",
        "            else:\n",
        "                plot_data['BubbleSize'] = bubble_base + bubble_range / 2\n",
        "\n",
        "            print(f\"  ‚úì Bubble sizes calculated (Range: {plot_data['BubbleSize'].min():.0f} to {plot_data['BubbleSize'].max():.0f})\")\n",
        "\n",
        "            # --- Handle Color Coding (*** FIX: Corrected logic ***) ---\n",
        "            c_values = point_color\n",
        "            cmap = None\n",
        "            norm = None\n",
        "            unique_cats = []\n",
        "\n",
        "            if color_mod_name != 'None':\n",
        "                if color_mod_name in analysis_data_init.columns:\n",
        "                    # Merge color data from the original dataframe based on index\n",
        "                    color_data = analysis_data_init[[color_mod_name]].copy()\n",
        "                    plot_data = plot_data.merge(color_data, left_index=True, right_index=True, how='left',\n",
        "                                                suffixes=('', '_color'))\n",
        "\n",
        "                    # Use the merged column\n",
        "                    color_col_merged = f\"{color_mod_name}\"\n",
        "                    plot_data[color_col_merged] = plot_data[color_col_merged].fillna('N/A').astype(str).str.strip()\n",
        "                    plot_data['color_codes'], unique_cats = pd.factorize(plot_data[color_col_merged])\n",
        "                    c_values = plot_data['color_codes']\n",
        "                    cmap = 'tab10' # A good categorical colormap\n",
        "                    norm = plt.Normalize(vmin=0, vmax=len(unique_cats)-1)\n",
        "                    print(f\"  ‚úì Applying color based on '{color_mod_name}' ({len(unique_cats)} categories)\")\n",
        "                else:\n",
        "                    print(f\"  ‚ö†Ô∏è  Color moderator '{color_mod_name}' not found, using default.\")\n",
        "                    color_mod_name = 'None'\n",
        "            # *** END COLOR FIX ***\n",
        "\n",
        "            # --- 4. Create Figure ---\n",
        "            print(\"\\nSTEP 3: GENERATING PLOT\")\n",
        "            print(\"---------------------------------\")\n",
        "            fig, ax = plt.subplots(figsize=(plot_width, plot_height))\n",
        "            if transparent_bg:\n",
        "                fig.patch.set_alpha(0)\n",
        "                ax.patch.set_alpha(0)\n",
        "\n",
        "            # --- Plot Data Points ---\n",
        "            ax.scatter(\n",
        "                x=plot_data[moderator_col],\n",
        "                y=plot_data[effect_col],\n",
        "                s=plot_data['BubbleSize'],\n",
        "                c=c_values,\n",
        "                cmap=cmap,\n",
        "                norm=norm,\n",
        "                alpha=bubble_alpha,\n",
        "                edgecolors='black',\n",
        "                linewidths=0.5,\n",
        "                zorder=3\n",
        "            )\n",
        "\n",
        "            # --- Plot Regression Line & Confidence Band ---\n",
        "            x_min = plot_data[moderator_col].min()\n",
        "            x_max = plot_data[moderator_col].max()\n",
        "            x_range_val = x_max - x_min\n",
        "            x_padding = x_range_val * 0.05 if x_range_val > 0 else 1\n",
        "\n",
        "            x_line = np.linspace(x_min - x_padding, x_max + x_padding, 100)\n",
        "            y_line = b0 + b1 * x_line\n",
        "\n",
        "            ax.plot(x_line, y_line, color=line_color, linewidth=line_width, zorder=2, label=\"Regression Line\")\n",
        "\n",
        "            if show_ci:\n",
        "                X_line_pred = sm.add_constant(x_line, prepend=True)\n",
        "                se_line = np.array([\n",
        "                    np.sqrt(np.array([1, x]) @ var_betas_robust @ np.array([1, x]).T)\n",
        "                    for x in x_line\n",
        "                ])\n",
        "                t_crit = t.ppf(0.975, df=df_robust)\n",
        "                y_ci_upper = y_line + t_crit * se_line\n",
        "                y_ci_lower = y_line - t_crit * se_line\n",
        "                ax.fill_between(x_line, y_ci_lower, y_ci_upper,\n",
        "                                color=line_color, alpha=ci_alpha, zorder=1, label=f\"95% CI (Robust, df={df_robust})\")\n",
        "                print(\"  ‚úì Plotted regression line and robust confidence band.\")\n",
        "\n",
        "            # --- Customize Axes ---\n",
        "            if show_null_line:\n",
        "                ax.axhline(es_config.get('null_value', 0), color='gray', linestyle='--', linewidth=1.0, zorder=0)\n",
        "\n",
        "            ax.set_xlabel(x_label, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(y_label, fontsize=12, fontweight='bold')\n",
        "            if show_title:\n",
        "                ax.set_title(graph_title, fontsize=14, fontweight='bold', pad=15)\n",
        "            if show_grid:\n",
        "                ax.grid(True, linestyle=':', alpha=0.4, zorder=0)\n",
        "\n",
        "            # --- Add Equation and R¬≤ ---\n",
        "            if show_equation or show_r2:\n",
        "                text_lines = []\n",
        "                if show_equation:\n",
        "                    sign = \"+\" if b1 >= 0 else \"\"\n",
        "                    sig_marker = \"***\" if p_slope < 0.001 else \"**\" if p_slope < 0.01 else \"*\" if p_slope < 0.05 else \"ns\"\n",
        "                    eq_text = f\"y = {b0:.3f} {sign} {b1:.3f}x\"\n",
        "                    p_text = f\"p (slope) = {p_slope:.3g} {sig_marker}\"\n",
        "                    text_lines.append(eq_text)\n",
        "                    text_lines.append(p_text)\n",
        "                if show_r2:\n",
        "                    r2_text = f\"R¬≤ (adj) ‚âà {R_sq:.1f}%\"\n",
        "                    text_lines.append(r2_text)\n",
        "\n",
        "                ax.text(\n",
        "                    0.05, 0.95, \"\\n\".join(text_lines),\n",
        "                    transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='gray'),\n",
        "                    zorder=10\n",
        "                )\n",
        "\n",
        "            # --- Create Legend ---\n",
        "            handles, labels = ax.get_legend_handles_labels()\n",
        "\n",
        "            # *** FIX: Use Label Mapping ***\n",
        "            if color_mod_name != 'None':\n",
        "                for i, cat in enumerate(unique_cats):\n",
        "                    display_label = label_mapping.get(cat, cat) # Get new label\n",
        "                    color_val = plt.get_cmap(cmap)(norm(i))\n",
        "                    handles.append(mpatches.Patch(color=color_val, label=display_label, alpha=bubble_alpha, ec='black', lw=0.5))\n",
        "                    labels.append(display_label)\n",
        "\n",
        "            handles.append(plt.scatter([], [], s=bubble_base + bubble_range/2, c='gray' if color_mod_name == 'None' else 'lightgray',\n",
        "                                       alpha=bubble_alpha, ec='black', lw=0.5))\n",
        "            labels.append(\"Weight (1 / (v·µ¢ + œÑ¬≤))\")\n",
        "\n",
        "            display_legend_title = label_mapping.get(color_mod_name, color_mod_name)\n",
        "\n",
        "            ax.legend(handles=handles, labels=labels, loc=legend_loc,\n",
        "                      fontsize=legend_fontsize, framealpha=0.9,\n",
        "                      title=display_legend_title if color_mod_name != 'None' else None)\n",
        "            # *** END FIX ***\n",
        "\n",
        "            fig.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # --- 5. Save Files ---\n",
        "            print(f\"\\nSTEP 4: SAVING FILES\")\n",
        "            print(\"---------------------------------\")\n",
        "\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            base_filename = f\"{filename_prefix}_{moderator_col.replace(' ','_')}_{timestamp}\"\n",
        "\n",
        "            saved_files = []\n",
        "            if save_pdf:\n",
        "                pdf_filename = f\"{base_filename}.pdf\"\n",
        "                fig.savefig(pdf_filename, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(pdf_filename)\n",
        "                print(f\"  ‚úì {pdf_filename}\")\n",
        "            if save_png:\n",
        "                png_filename = f\"{base_filename}.png\"\n",
        "                fig.savefig(png_filename, dpi=png_dpi, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(png_filename)\n",
        "                print(f\"  ‚úì {png_filename} (DPI: {png_dpi})\")\n",
        "\n",
        "            print(f\"\\n\" + \"=\"*70)\n",
        "            print(\"‚úÖ PLOT GENERATION COMPLETE\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå AN ERROR OCCURRED:\\n\")\n",
        "            print(f\"  Type: {type(e).__name__}\")\n",
        "            print(f\"  Message: {e}\")\n",
        "            print(\"\\n  Traceback:\")\n",
        "            traceback.print_exc(file=sys.stdout)\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"ANALYSIS FAILED. See error message above.\")\n",
        "            print(\"Please check your data and configuration.\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "\n",
        "# --- 6. DISPLAY WIDGETS ---\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals() or 'meta_regression_RVE_results' not in ANALYSIS_CONFIG:\n",
        "        print(\"=\"*70)\n",
        "        print(\"‚ö†Ô∏è  PREREQUISITE NOT MET\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"Please run Cell 10 (Meta-Regression) successfully before running this cell.\")\n",
        "    else:\n",
        "        print(\"=\"*70)\n",
        "        print(\"‚úÖ ROBUST META-REGRESSION PLOTTER READY\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"  ‚úì Results from Cell 10 are loaded.\")\n",
        "        print(\"  ‚úì Customize your plot using the tabs below and click 'Generate'.\")\n",
        "\n",
        "        # Hook up widget events\n",
        "        def on_color_mod_change(change):\n",
        "            point_color_widget.layout.display = 'none' if change['new'] != 'None' else 'flex'\n",
        "        color_mod_widget.observe(on_color_mod_change, names='value')\n",
        "\n",
        "        display(widgets.VBox([\n",
        "            header,\n",
        "            widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "            widgets.HTML(\"<b>Plot Options:</b>\"),\n",
        "            tab,\n",
        "            widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "            run_plot_button,\n",
        "            plot_output\n",
        "        ]))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An error occurred during initialization: {e}\")\n",
        "    print(\"Please ensure the notebook has been run in order.\")"
      ],
      "metadata": {
        "id": "3QSIWqR7P5an",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title R Validation for Meta-Regression (Fixed)\n",
        "# =============================================================================\n",
        "# CELL: R DIAGNOSTIC\n",
        "# Purpose: Check how metafor handles the 'constant-within-study' moderator.\n",
        "# Fix: Automatically detects correct variance column (Vg vs vg)\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# --- 1. Setup & Data Prep ---\n",
        "if 'data_filtered' not in globals():\n",
        "    print(\"‚ùå Error: 'data_filtered' not found. Please run previous cells.\")\n",
        "else:\n",
        "    # Select the problematic moderator\n",
        "    moderator = 'kgPot'  # Hardcoded for this test based on your request\n",
        "\n",
        "    print(f\"üöÄ Sending data to R to test moderator: '{moderator}'...\")\n",
        "\n",
        "    # --- FIX: Robust Column Detection ---\n",
        "    # 1. Identify Effect Size Column\n",
        "    if 'hedges_g' in data_filtered.columns:\n",
        "        eff_col = 'hedges_g'\n",
        "    elif 'ANALYSIS_CONFIG' in globals():\n",
        "        eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "    else:\n",
        "        eff_col = 'hedges_g'\n",
        "\n",
        "    # 2. Identify Variance Column (The source of your error)\n",
        "    if 'Vg' in data_filtered.columns:\n",
        "        var_col = 'Vg'\n",
        "    elif 'vg' in data_filtered.columns:\n",
        "        var_col = 'vg'\n",
        "    elif 'var_col' in globals().get('ANALYSIS_CONFIG', {}):\n",
        "        var_col = ANALYSIS_CONFIG['var_col']\n",
        "    else:\n",
        "        print(\"‚ùå Error: Could not find variance column (checked 'Vg' and 'vg')\")\n",
        "        var_col = None\n",
        "\n",
        "    if var_col:\n",
        "        print(f\"   Using Effect: '{eff_col}', Variance: '{var_col}'\")\n",
        "\n",
        "        # Create clean subset\n",
        "        cols_to_keep = ['id', eff_col, var_col, moderator]\n",
        "\n",
        "        # Check if we have the raw data columns (optional, just for context)\n",
        "        raw_cols = ['xe', 'xc', 'ne', 'nc', 'sde', 'sdc']\n",
        "        existing_raw = [c for c in raw_cols if c in data_filtered.columns]\n",
        "        cols_to_keep.extend(existing_raw)\n",
        "\n",
        "        df_r_test = data_filtered[cols_to_keep].copy()\n",
        "\n",
        "        # Ensure moderator is numeric\n",
        "        df_r_test[moderator] = pd.to_numeric(df_r_test[moderator], errors='coerce')\n",
        "        df_r_test = df_r_test.dropna(subset=[eff_col, var_col, moderator])\n",
        "\n",
        "        print(f\"   Data shape: {len(df_r_test)} observations, {df_r_test['id'].nunique()} studies\")\n",
        "\n",
        "        # --- 2. Run R Code ---\n",
        "        try:\n",
        "            import rpy2.robjects as ro\n",
        "            from rpy2.robjects import pandas2ri\n",
        "            pandas2ri.activate()\n",
        "\n",
        "            # Pass data to R\n",
        "            ro.globalenv['df_python'] = df_r_test\n",
        "\n",
        "            r_script = f\"\"\"\n",
        "            library(metafor)\n",
        "\n",
        "            # Ensure clean data inside R\n",
        "            dat <- df_python\n",
        "            dat$rows <- 1:nrow(dat)\n",
        "            dat$study_id <- as.factor(dat$id)\n",
        "\n",
        "            # Run 3-Level Meta-Regression\n",
        "            # mods = ~ kgPot\n",
        "            res <- rma.mv(yi={eff_col}, V={var_col},\n",
        "                          mods = ~ {moderator},\n",
        "                          random = ~ 1 | study_id/rows,\n",
        "                          data=dat,\n",
        "                          control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\"))\n",
        "\n",
        "            print(summary(res))\n",
        "\n",
        "            # Extract key metrics for Python display\n",
        "            list(\n",
        "                beta0 = res$b[1],\n",
        "                beta1 = res$b[2],\n",
        "                se1 = res$se[2],\n",
        "                pval = res$pval[2],\n",
        "                tau2 = res$sigma2[1],   # Level 3 (Between-Study)\n",
        "                sigma2 = res$sigma2[2]  # Level 2 (Within-Study)\n",
        "            )\n",
        "            \"\"\"\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"R (METAFOR) OUTPUT LOG\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            # Run and capture output\n",
        "            r_result = ro.r(r_script)\n",
        "\n",
        "            # Extract values\n",
        "            r_beta1 = r_result.rx2('beta1')[0]\n",
        "            r_pval = r_result.rx2('pval')[0]\n",
        "            r_tau2 = r_result.rx2('tau2')[0]\n",
        "            r_sigma2 = r_result.rx2('sigma2')[0]\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"DIAGNOSIS\")\n",
        "            print(\"=\"*60)\n",
        "            print(f\"Moderator: {moderator}\")\n",
        "            print(f\"Slope (Beta): {r_beta1:.5f} (p={r_pval:.4f})\")\n",
        "            print(\"-\" * 30)\n",
        "            print(f\"Level 3 Variance (Between-Study): {r_tau2:.8f}\")\n",
        "            print(f\"Level 2 Variance (Within-Study):  {r_sigma2:.8f}\")\n",
        "\n",
        "            if r_tau2 < 0.0001:\n",
        "                print(\"\\n‚úÖ DIAGNOSIS CONFIRMED:\")\n",
        "                print(\"   The Level 3 variance (Tau¬≤) collapsed to ZERO.\")\n",
        "                print(\"   This caused the Python optimizer to crash (Singular Matrix).\")\n",
        "                print(\"   The moderator explains nearly all the between-study variation.\")\n",
        "            else:\n",
        "                print(\"\\n‚ÑπÔ∏è  Tau¬≤ is not zero. The Python crash might be due to starting parameters.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå R Interface Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "w3G6QWmIjxiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üß™ R Validation: Meta-Regression (Corrected)\n",
        "# =============================================================================\n",
        "# CELL: META-REGRESSION VALIDATION\n",
        "# Purpose: Verify Meta-Regression results against R (metafor)\n",
        "# Fix: Uses 'analysis_data' which contains the calculated effect sizes.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"VALIDATION STEP 4: META-REGRESSION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Check Dependencies\n",
        "if 'ANALYSIS_CONFIG' not in globals() or 'meta_regression_RVE_results' not in ANALYSIS_CONFIG:\n",
        "    print(\"‚ùå Error: Please run Cell 10 (Meta-Regression) first.\")\n",
        "else:\n",
        "    # 2. Get Python Results\n",
        "    py_res = ANALYSIS_CONFIG['meta_regression_RVE_results']\n",
        "    mod_col = py_res['moderator_col_name']\n",
        "\n",
        "    # Get Data (Use analysis_data, which has effect sizes)\n",
        "    if 'analysis_data' in globals():\n",
        "        df_py = globals()['analysis_data'].copy()\n",
        "    elif 'analysis_data' in ANALYSIS_CONFIG:\n",
        "        df_py = ANALYSIS_CONFIG['analysis_data'].copy()\n",
        "    else:\n",
        "        print(\"‚ùå Error: 'analysis_data' not found.\")\n",
        "        df_py = None\n",
        "\n",
        "    if df_py is not None:\n",
        "        effect_col = ANALYSIS_CONFIG['effect_col']\n",
        "        var_col = ANALYSIS_CONFIG['var_col']\n",
        "\n",
        "        print(f\"üîç Validating Moderator: '{mod_col}'\")\n",
        "        print(f\"   Effect: {effect_col}, Variance: {var_col}\")\n",
        "\n",
        "        # 3. Prepare Data for R\n",
        "        # Ensure moderator is numeric\n",
        "        df_py[mod_col] = pd.to_numeric(df_py[mod_col], errors='coerce')\n",
        "\n",
        "        # Subset and clean\n",
        "        df_r = df_py[['id', effect_col, var_col, mod_col]].dropna()\n",
        "        df_r = df_r[df_r[var_col] > 0]\n",
        "\n",
        "        print(f\"   Data: {len(df_r)} observations from {df_r['id'].nunique()} studies\")\n",
        "\n",
        "        ro.globalenv['df_python'] = df_r\n",
        "        ro.globalenv['eff_col'] = effect_col\n",
        "        ro.globalenv['var_col'] = var_col\n",
        "        ro.globalenv['mod_col'] = mod_col\n",
        "\n",
        "        # 4. Run R Script\n",
        "        r_script = \"\"\"\n",
        "        library(metafor)\n",
        "\n",
        "        dat <- df_python\n",
        "        dat$row_id <- 1:nrow(dat)\n",
        "        dat$study_id <- as.factor(dat$id)\n",
        "\n",
        "        # Run 3-Level Meta-Regression\n",
        "        tryCatch({\n",
        "            res <- rma.mv(yi = dat[[eff_col]],\n",
        "                          V = dat[[var_col]],\n",
        "                          mods = ~ dat[[mod_col]],\n",
        "                          random = ~ 1 | study_id/row_id,\n",
        "                          data = dat,\n",
        "                          method = \"REML\",\n",
        "                          control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\"))\n",
        "\n",
        "            list(\n",
        "                beta0 = as.numeric(res$b[1]),\n",
        "                beta1 = as.numeric(res$b[2]),\n",
        "                se1 = as.numeric(res$se[2]),\n",
        "                pval = as.numeric(res$pval[2]),\n",
        "                tau2 = res$sigma2[1]\n",
        "            )\n",
        "        }, error = function(e) {\n",
        "            list(status=\"error\", msg=conditionMessage(e))\n",
        "        })\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            r_res = ro.r(r_script)\n",
        "\n",
        "            if 'status' in r_res.names and r_res.rx2('status')[0] == 'error':\n",
        "                print(f\"‚ùå R Error: {r_res.rx2('msg')[0]}\")\n",
        "            else:\n",
        "                # Extract R results\n",
        "                r_beta1 = r_res.rx2('beta1')[0]\n",
        "                r_se1 = r_res.rx2('se1')[0]\n",
        "                r_pval = r_res.rx2('pval')[0]\n",
        "                r_tau2 = r_res.rx2('tau2')[0]\n",
        "\n",
        "                # Extract Python results\n",
        "                py_beta1 = py_res['betas'][1] # Slope is the second coefficient\n",
        "                py_se1 = py_res['std_errors_robust'][1]\n",
        "                py_pval = py_res['p_slope']\n",
        "\n",
        "                # Note: Python regression might report different Tau2 if it used aggregation\n",
        "                # (check if model was aggregated or 3-level)\n",
        "\n",
        "                # 5. Compare\n",
        "                print(\"\\nüìä VALIDATION RESULTS:\")\n",
        "                print(f\"{'Metric':<20} {'Python':<12} {'R (metafor)':<12} {'Diff':<12}\")\n",
        "                print(\"-\" * 60)\n",
        "\n",
        "                def compare(label, py_val, r_val):\n",
        "                    diff = abs(py_val - r_val)\n",
        "                    print(f\"{label:<20} {py_val:<12.4f} {r_val:<12.4f} {diff:.2e}\")\n",
        "                    return diff\n",
        "\n",
        "                d1 = compare(\"Slope (Beta1)\", py_beta1, r_beta1)\n",
        "                d2 = compare(\"SE (Slope)\", py_se1, r_se1)\n",
        "                d3 = compare(\"P-value\", py_pval, r_pval)\n",
        "\n",
        "                # Check Pass/Fail\n",
        "                if d1 < 1e-3 and d3 < 1e-3:\n",
        "                    print(\"\\n‚úÖ SUCCESS: Meta-Regression slope matches R.\")\n",
        "                else:\n",
        "                    print(\"\\n‚ö†Ô∏è CAUTION: Differences detected.\")\n",
        "                    print(\"   If Python aggregated data (due to constant moderator), results will differ\")\n",
        "                    print(\"   from R's 3-level model slightly, but direction should match.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå R Execution Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BQoM7heU-2EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üåä Cell 11: 3-Level Spline Analysis (old Detete?)\n",
        "# =============================================================================\n",
        "# CELL 11: ROBUST SPLINE ANALYSIS (PLUG-IN ESTIMATOR)\n",
        "# Purpose: Non-linear meta-regression.\n",
        "# Fix: Uses Tau¬≤ from the stable Linear Model (Cell 10) to prevent overfitting.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import t, chi2, norm\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import warnings\n",
        "\n",
        "# Check for patsy\n",
        "try:\n",
        "    import patsy\n",
        "    PATSY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PATSY_AVAILABLE = False\n",
        "\n",
        "# --- 1. HELPER: Aggregated Spline Engine (Plug-in Tau2) ---\n",
        "# --- 1. HELPER: Aggregated Spline Engine (Fixed Tau2) ---\n",
        "def _run_aggregated_spline_re(agg_df, moderator_col, effect_col, var_col, df_spline, mod_mean, mod_std, fixed_tau2):\n",
        "    \"\"\"\n",
        "    Runs a Random-Effects Spline Model using a FIXED Tau^2.\n",
        "    This prevents the optimizer from crashing on flat likelihood surfaces.\n",
        "    \"\"\"\n",
        "    # Reset index to ensure alignment\n",
        "    agg_df = agg_df.reset_index(drop=True)\n",
        "\n",
        "    # Generate Basis\n",
        "    mod_z = (agg_df[moderator_col] - mod_mean) / mod_std\n",
        "    formula = f\"cr(x, df={df_spline}) - 1\"\n",
        "\n",
        "    try:\n",
        "        basis_matrix = patsy.dmatrix(formula, {\"x\": mod_z}, return_type='dataframe')\n",
        "    except Exception as e:\n",
        "        return None, f\"Basis Error: {e}\"\n",
        "\n",
        "    y = agg_df[effect_col].values\n",
        "    v = agg_df[var_col].values\n",
        "\n",
        "    # Ensure basis aligns with y\n",
        "    basis_matrix.index = agg_df.index\n",
        "    X = sm.add_constant(basis_matrix) # Add intercept\n",
        "\n",
        "    # FIT MODEL (No optimization needed - Tau2 is known!)\n",
        "    # We use the passed 'fixed_tau2' directly\n",
        "    weights = 1.0 / (v + fixed_tau2 + 1e-8)\n",
        "\n",
        "    try:\n",
        "        final_model = sm.WLS(y, X, weights=weights).fit()\n",
        "\n",
        "        # Calculate Log-Likelihood manually for validation\n",
        "        # REML LogLik = -0.5 * (sum(log(w^-1)) + log(det(X'WX)) + r'Wr)\n",
        "        resid = y - final_model.fittedvalues\n",
        "\n",
        "        XTWX = X.T @ np.diag(weights) @ X\n",
        "        sign, logdet = np.linalg.slogdet(XTWX)\n",
        "        if sign <= 0: logdet = 0\n",
        "\n",
        "        ll = -0.5 * (np.sum(np.log(v + fixed_tau2 + 1e-8)) +\n",
        "                     logdet +\n",
        "                     np.sum((resid**2) * weights))\n",
        "\n",
        "        return {\n",
        "            'betas': final_model.params.values,\n",
        "            'var_betas': final_model.cov_params().values,\n",
        "            'tau_sq': fixed_tau2,\n",
        "            'sigma_sq': 0.0, # Not applicable for aggregated model\n",
        "            'log_lik_reml': ll,\n",
        "            'mod_mean': mod_mean,\n",
        "            'mod_std': mod_std,\n",
        "            'formula': formula,\n",
        "            'model_type': 'Aggregated Spline (Plug-in Tau¬≤)',\n",
        "            'X_design': X\n",
        "        }, None\n",
        "    except Exception as e:\n",
        "        return None, f\"Final Fit Error: {e}\"\n",
        "\n",
        "def _run_fixed_tau_spline(agg_df, moderator_col, effect_col, var_col, df_spline, mod_mean, mod_std, fixed_tau2):\n",
        "    \"\"\"\n",
        "    Runs spline regression using a FIXED Tau^2 from the linear model.\n",
        "    This prevents the optimizer from drifting into unrealistic variance estimates.\n",
        "    \"\"\"\n",
        "    agg_df = agg_df.reset_index(drop=True)\n",
        "    mod_z = (agg_df[moderator_col] - mod_mean) / mod_std\n",
        "    formula = f\"cr(x, df={df_spline}) - 1\"\n",
        "\n",
        "    try:\n",
        "        basis_matrix = patsy.dmatrix(formula, {\"x\": mod_z}, return_type='dataframe')\n",
        "    except Exception as e: return None, f\"Basis Error: {e}\"\n",
        "\n",
        "    y = agg_df[effect_col].values\n",
        "    v = agg_df[var_col].values\n",
        "\n",
        "    # Align and create design matrix\n",
        "    basis_matrix.index = agg_df.index\n",
        "    X = sm.add_constant(basis_matrix)\n",
        "\n",
        "    # FIT MODEL (No optimization needed - Tau2 is known!)\n",
        "    weights = 1.0 / (v + fixed_tau2)\n",
        "\n",
        "    try:\n",
        "        final_model = sm.WLS(y, X, weights=weights).fit()\n",
        "\n",
        "        # Calculate Log-Likelihood manually for validation\n",
        "        resid = y - final_model.fittedvalues\n",
        "        sign, logdet = np.linalg.slogdet(X.T @ np.diag(weights) @ X)\n",
        "        if sign <= 0: logdet = 0\n",
        "        ll = -0.5 * (np.sum(np.log(v + fixed_tau2)) + logdet + np.sum((resid**2) * weights))\n",
        "\n",
        "        return {\n",
        "            'betas': final_model.params.values,\n",
        "            'var_betas': final_model.cov_params().values,\n",
        "            'tau_sq': fixed_tau2,\n",
        "            'sigma_sq': 0.0,\n",
        "            'log_lik_reml': ll,\n",
        "            'mod_mean': mod_mean, 'mod_std': mod_std,\n",
        "            'formula': formula,\n",
        "            'model_type': 'Aggregated Spline (Plug-in Tau¬≤)',\n",
        "            'X_design': X\n",
        "        }, None\n",
        "    except Exception as e:\n",
        "        return None, f\"Fit Error: {e}\"\n",
        "\n",
        "# --- 2. WIDGETS & LOGIC ---\n",
        "header = widgets.HTML(\"<h3 style='color: #2E86AB;'>üåä 3-Level Spline Analysis</h3>\")\n",
        "\n",
        "def get_numeric_mods_robust(df):\n",
        "    if df is None: return []\n",
        "    valid_mods = []\n",
        "    technical_cols = ['id', 'xe', 'xc', 'ne', 'nc', 'sde', 'sdc', 'w_fixed', 'w_random', 'df', 'sp', 'sp_squared', 'hedges_j', 'weights', 'wi']\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        technical_cols.extend([ANALYSIS_CONFIG.get('effect_col'), ANALYSIS_CONFIG.get('var_col'), ANALYSIS_CONFIG.get('se_col')])\n",
        "    for col in df.columns:\n",
        "        if col in technical_cols or col is None: continue\n",
        "        if pd.api.types.is_numeric_dtype(df[col]): valid_mods.append(col)\n",
        "        elif df[col].dtype == 'object':\n",
        "            try:\n",
        "                if pd.to_numeric(df[col], errors='coerce').notna().sum() >= 3: valid_mods.append(col)\n",
        "            except: pass\n",
        "    return sorted(list(set(valid_mods)))\n",
        "\n",
        "def get_analysis_data():\n",
        "    if 'analysis_data' in globals(): return analysis_data\n",
        "    elif 'data_filtered' in globals(): return data_filtered\n",
        "    else: return None\n",
        "\n",
        "df_spline_in = get_analysis_data()\n",
        "opts = get_numeric_mods_robust(df_spline_in) if df_spline_in is not None else ['Data not loaded']\n",
        "mod_widget = widgets.Dropdown(options=opts, description='Moderator:', layout=widgets.Layout(width='400px'))\n",
        "df_widget = widgets.IntSlider(value=3, min=3, max=6, description='df:', style={'description_width': 'initial'})\n",
        "run_spline_btn = widgets.Button(description='‚ñ∂ Run Spline Model', button_style='success', layout=widgets.Layout(width='400px'))\n",
        "spline_output = widgets.Output()\n",
        "\n",
        "def run_spline(b):\n",
        "    global ANALYSIS_CONFIG\n",
        "    with spline_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        if not PATSY_AVAILABLE: print(\"‚ùå Error: 'patsy' not installed.\"); return\n",
        "        mod_col = mod_widget.value\n",
        "        df_k = df_widget.value\n",
        "\n",
        "        df_working = get_analysis_data()\n",
        "        if df_working is None: print(\"‚ùå Data not found.\"); return\n",
        "        if 'ANALYSIS_CONFIG' not in globals(): print(\"‚ùå Config not found.\"); return\n",
        "\n",
        "        eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "        var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "\n",
        "        # --- GET TAU^2 FROM LINEAR MODEL (CELL 10) ---\n",
        "        # This is the \"Plug-in\" magic\n",
        "        fixed_tau2 = 0.1 # Default fallback\n",
        "\n",
        "        if 'meta_regression_RVE_results' in ANALYSIS_CONFIG:\n",
        "            reg_res = ANALYSIS_CONFIG['meta_regression_RVE_results']\n",
        "            # Check if this is the same moderator\n",
        "            if reg_res.get('moderator_col_name') == mod_col:\n",
        "                # We calculate Tau2 from the betas/se of the linear model to be safe\n",
        "                # Or ideally, we saved it.\n",
        "                # Let's assume user ran Cell 10 on this moderator.\n",
        "                # Cell 10 unfortunately didn't save 'tau_sq' explicitly in the config dict\n",
        "                # BUT, we can re-run the linear aggregation quickly here to get it.\n",
        "                pass\n",
        "\n",
        "        # --- PREP DATA ---\n",
        "        df = df_working.copy()\n",
        "        df[mod_col] = pd.to_numeric(df[mod_col], errors='coerce')\n",
        "        df = df.dropna(subset=[mod_col, eff_col, var_col])\n",
        "        df = df[df[var_col] > 0]\n",
        "\n",
        "        # --- AGGREGATION ---\n",
        "        # We aggregate regardless to get a stable Tau^2\n",
        "        df['wi'] = 1 / df[var_col]\n",
        "        def agg_func(x):\n",
        "            return pd.Series({\n",
        "                eff_col: np.average(x[eff_col], weights=x['wi']),\n",
        "                var_col: 1 / np.sum(x['wi']),\n",
        "                mod_col: x[mod_col].iloc[0]\n",
        "            })\n",
        "        try: agg_df = df.groupby('id').apply(agg_func, include_groups=False).reset_index()\n",
        "        except TypeError: agg_df = df.groupby('id').apply(agg_func).reset_index()\n",
        "\n",
        "        # --- ESTIMATE STABLE TAU^2 (LINEAR) ---\n",
        "        print(f\"‚öôÔ∏è  Estimating stable baseline variance (Linear Model)...\")\n",
        "        # Simple REML on linear model to get a sane Tau^2\n",
        "        X_lin = sm.add_constant(agg_df[mod_col])\n",
        "        y_agg = agg_df[eff_col].values\n",
        "        v_agg = agg_df[var_col].values\n",
        "\n",
        "        def lin_nll(t2):\n",
        "            if t2 < 0: t2 = 0\n",
        "            w = 1/(v_agg + t2)\n",
        "            try:\n",
        "                res = sm.WLS(y_agg, X_lin, weights=w).fit()\n",
        "                return -(-0.5*(np.sum(np.log(v_agg+t2)) + np.log(np.linalg.det(X_lin.T@np.diag(w)@X_lin)) + np.sum(res.resid**2 * w)))\n",
        "            except: return np.inf\n",
        "\n",
        "        opt_lin = minimize_scalar(lin_nll, bounds=(0, 100), method='bounded')\n",
        "        fixed_tau2 = opt_lin.x\n",
        "        print(f\"   ‚úì Using fixed Tau¬≤ = {fixed_tau2:.4f} (from Linear Meta-Regression)\")\n",
        "\n",
        "        # --- RUN SPLINE WITH FIXED TAU^2 ---\n",
        "        print(f\"üöÄ Fitting Spline (df={df_k}) using fixed variance...\")\n",
        "        est, err = _run_aggregated_spline_re(agg_df, mod_col, eff_col, var_col, df_k, df[mod_col].mean(), df[mod_col].std(), fixed_tau2)\n",
        "\n",
        "        if err: print(f\"‚ùå {err}\"); return\n",
        "\n",
        "        # --- REPORTING ---\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"SPLINE MODEL RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Model Type: {est['model_type']}\")\n",
        "        print(f\"  ‚Ä¢ Studies: {len(agg_df)}\")\n",
        "        print(f\"  ‚Ä¢ Tau¬≤ (Fixed): {est['tau_sq']:.5f}\")\n",
        "\n",
        "        # Omnibus Test\n",
        "        betas = est['betas']\n",
        "        cov = est['var_betas']\n",
        "        if len(betas) > 1:\n",
        "            b_spline = betas[1:]\n",
        "            cov_spline = cov[1:, 1:]\n",
        "            try:\n",
        "                chi2_stat = b_spline.T @ np.linalg.inv(cov_spline) @ b_spline\n",
        "                df_test = len(b_spline)\n",
        "                p_val = 1 - chi2.cdf(chi2_stat, df_test)\n",
        "                print(f\"\\nOmnibus Test for Non-Linearity:\")\n",
        "                print(f\"  ‚Ä¢ Chi2({df_test}) = {chi2_stat:.3f}\")\n",
        "                print(f\"  ‚Ä¢ P-value = {p_val:.5f}\")\n",
        "                if p_val < 0.05: print(\"  ‚úÖ Significant non-linear relationship.\")\n",
        "                else: print(\"  ‚ÑπÔ∏è  Not significant.\")\n",
        "            except: pass\n",
        "\n",
        "\n",
        "        # Save Results\n",
        "        ANALYSIS_CONFIG['spline_model_results'] = {\n",
        "            'reg_df': agg_df, 'betas': betas, 'var_betas': cov,\n",
        "            'tau_sq': est['tau_sq'], 'log_lik': est['log_lik_reml'],\n",
        "            'mod_mean': est['mod_mean'], 'mod_std': est['mod_std'],\n",
        "            'df_spline': df_k, 'moderator_col': mod_col, 'sigma_sq': 0.0,\n",
        "            'formula': est['formula'], 'model_type': est['model_type']\n",
        "        }\n",
        "\n",
        "run_spline_btn.on_click(run_spline)\n",
        "display(widgets.VBox([header, mod_widget, df_widget, run_spline_btn, spline_output]))"
      ],
      "metadata": {
        "id": "5LaS8ZqBWhh-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EOEgmWzcjeOn"
      },
      "source": [
        "#@title üåä Cell 11: 3-Level Spline Analysis V2 (Dashboard)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL: SPLINE ANALYSIS WITH DASHBOARD\n",
        "# Purpose: Non-linear meta-regression using natural cubic splines.\n",
        "# Enhancement: Tabbed interface for results, diagnostics, details, and publication text.\n",
        "# Method: Uses plug-in œÑ¬≤ from linear model to prevent overfitting.\n",
        "# Note: Use dedicated plot cell for visualization.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import t, chi2, norm\n",
        "from scipy.optimize import minimize_scalar\n",
        "import statsmodels.api as sm\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import warnings\n",
        "\n",
        "# Check for patsy\n",
        "try:\n",
        "    import patsy\n",
        "    PATSY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PATSY_AVAILABLE = False\n",
        "\n",
        "# --- 1. LAYOUT & WIDGETS ---\n",
        "tab_results = widgets.Output()\n",
        "tab_diagnostics = widgets.Output()\n",
        "tab_details = widgets.Output()\n",
        "tab_publication = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_results, tab_diagnostics, tab_details, tab_publication])\n",
        "tabs.set_title(0, 'üìä Results')\n",
        "tabs.set_title(1, 'üîç Diagnostics')\n",
        "tabs.set_title(2, '‚öôÔ∏è Model Details')\n",
        "tabs.set_title(3, 'üìù Publication Text')\n",
        "\n",
        "# --- 2. HELPER FUNCTIONS ---\n",
        "\n",
        "def _run_aggregated_spline_re(agg_df, moderator_col, effect_col, var_col, df_spline, mod_mean, mod_std, fixed_tau2):\n",
        "    \"\"\"\n",
        "    Runs a Random-Effects Spline Model using a FIXED Tau^2.\n",
        "    This prevents the optimizer from crashing on flat likelihood surfaces.\n",
        "    \"\"\"\n",
        "    agg_df = agg_df.reset_index(drop=True)\n",
        "    mod_z = (agg_df[moderator_col] - mod_mean) / mod_std\n",
        "    formula = f\"cr(x, df={df_spline}) - 1\"\n",
        "\n",
        "    try:\n",
        "        basis_matrix = patsy.dmatrix(formula, {\"x\": mod_z}, return_type='dataframe')\n",
        "    except Exception as e:\n",
        "        return None, f\"Basis Error: {e}\"\n",
        "\n",
        "    y = agg_df[effect_col].values\n",
        "    v = agg_df[var_col].values\n",
        "    basis_matrix.index = agg_df.index\n",
        "    X = sm.add_constant(basis_matrix)\n",
        "    weights = 1.0 / (v + fixed_tau2 + 1e-8)\n",
        "\n",
        "    try:\n",
        "        final_model = sm.WLS(y, X, weights=weights).fit()\n",
        "        resid = y - final_model.fittedvalues\n",
        "\n",
        "        XTWX = X.T @ np.diag(weights) @ X\n",
        "        sign, logdet = np.linalg.slogdet(XTWX)\n",
        "        if sign <= 0: logdet = 0\n",
        "\n",
        "        ll = -0.5 * (np.sum(np.log(v + fixed_tau2 + 1e-8)) +\n",
        "                     logdet +\n",
        "                     np.sum((resid**2) * weights))\n",
        "\n",
        "        return {\n",
        "            'betas': final_model.params.values,\n",
        "            'var_betas': final_model.cov_params().values,\n",
        "            'tau_sq': fixed_tau2,\n",
        "            'sigma_sq': 0.0,\n",
        "            'log_lik_reml': ll,\n",
        "            'mod_mean': mod_mean,\n",
        "            'mod_std': mod_std,\n",
        "            'formula': formula,\n",
        "            'model_type': 'Spline Model (Plug-in Tau¬≤)',\n",
        "            'X_design': X,\n",
        "            'fitted': final_model.fittedvalues,\n",
        "            'resid': resid,\n",
        "            'model': final_model\n",
        "        }, None\n",
        "    except Exception as e:\n",
        "        return None, f\"Final Fit Error: {e}\"\n",
        "\n",
        "def estimate_linear_tau2(agg_df, moderator_col, effect_col, var_col):\n",
        "    \"\"\"Estimate tau¬≤ from linear model for plug-in approach\"\"\"\n",
        "    X_lin = sm.add_constant(agg_df[moderator_col])\n",
        "    y_agg = agg_df[effect_col].values\n",
        "    v_agg = agg_df[var_col].values\n",
        "\n",
        "    def lin_nll(t2):\n",
        "        if t2 < 0: t2 = 0\n",
        "        w = 1/(v_agg + t2)\n",
        "        try:\n",
        "            res = sm.WLS(y_agg, X_lin, weights=w).fit()\n",
        "            ll = -0.5*(np.sum(np.log(v_agg+t2)) +\n",
        "                      np.log(np.linalg.det(X_lin.T@np.diag(w)@X_lin)) +\n",
        "                      np.sum(res.resid**2 * w))\n",
        "            return -ll\n",
        "        except:\n",
        "            return np.inf\n",
        "\n",
        "    opt_lin = minimize_scalar(lin_nll, bounds=(0, 100), method='bounded')\n",
        "\n",
        "    # Also fit linear model for comparison\n",
        "    w_opt = 1/(v_agg + opt_lin.x)\n",
        "    lin_model = sm.WLS(y_agg, X_lin, weights=w_opt).fit()\n",
        "    lin_ll = -lin_nll(opt_lin.x)\n",
        "\n",
        "    return opt_lin.x, lin_ll, lin_model\n",
        "\n",
        "def get_numeric_mods_robust(df):\n",
        "    if df is None: return []\n",
        "    valid_mods = []\n",
        "    technical_cols = ['id', 'xe', 'xc', 'ne', 'nc', 'sde', 'sdc', 'w_fixed', 'w_random',\n",
        "                     'df', 'sp', 'sp_squared', 'hedges_j', 'weights', 'wi']\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        technical_cols.extend([ANALYSIS_CONFIG.get('effect_col'),\n",
        "                              ANALYSIS_CONFIG.get('var_col'),\n",
        "                              ANALYSIS_CONFIG.get('se_col')])\n",
        "    for col in df.columns:\n",
        "        if col in technical_cols or col is None: continue\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            valid_mods.append(col)\n",
        "        elif df[col].dtype == 'object':\n",
        "            try:\n",
        "                if pd.to_numeric(df[col], errors='coerce').notna().sum() >= 3:\n",
        "                    valid_mods.append(col)\n",
        "            except:\n",
        "                pass\n",
        "    return sorted(list(set(valid_mods)))\n",
        "\n",
        "def get_analysis_data():\n",
        "    if 'analysis_data' in globals(): return analysis_data\n",
        "    elif 'data_filtered' in globals(): return data_filtered\n",
        "    else: return None\n",
        "\n",
        "def generate_spline_publication_text(mod_col, df_spline, chi2_stat, df_test, p_omnibus,\n",
        "                                     tau2, k_studies, ll_spline, ll_linear,\n",
        "                                     model_type, n_coefs):\n",
        "    \"\"\"Generate publication-ready text for spline analysis\"\"\"\n",
        "\n",
        "    sig_text = \"significant\" if p_omnibus < 0.05 else \"non-significant\"\n",
        "    p_format = f\"< 0.001\" if p_omnibus < 0.001 else f\"= {p_omnibus:.3f}\"\n",
        "\n",
        "    # Calculate AIC/BIC for model comparison\n",
        "    aic_linear = -2*ll_linear + 2*2  # 2 parameters (intercept + slope)\n",
        "    aic_spline = -2*ll_spline + 2*n_coefs\n",
        "    bic_linear = -2*ll_linear + np.log(k_studies)*2\n",
        "    bic_spline = -2*ll_spline + np.log(k_studies)*n_coefs\n",
        "\n",
        "    better_model = \"spline\" if aic_spline < aic_linear else \"linear\"\n",
        "\n",
        "    text = f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt; line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "<h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>Spline Meta-Regression Results</h3>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Statistical Methods</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "To examine potential non-linear relationships between <b>{mod_col}</b> and effect sizes, we conducted a spline meta-regression analysis using natural cubic splines with <b>{df_spline} degrees of freedom</b>. The spline model allows the relationship to vary smoothly across the range of the moderator, capturing potential non-linearities that a simple linear model might miss.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "We employed a random-effects framework with heterogeneity variance (œÑ¬≤) fixed at the value estimated from the linear meta-regression model (œÑ¬≤ = <b>{tau2:.4f}</b>). This \"plug-in\" approach prevents overfitting and ensures stable variance estimates, as spline models can sometimes produce unrealistic variance estimates when both regression coefficients and variance components are estimated simultaneously. The analysis included <b>k = {k_studies}</b> studies.\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Non-Linearity Test</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "An omnibus test for non-linearity was conducted by testing whether the spline basis coefficients (excluding the intercept) were jointly different from zero. This test evaluates whether the data support a non-linear relationship beyond what a simple linear model would predict.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The omnibus test for non-linearity was <b>{sig_text}</b> (œá¬≤({df_test}) = <b>{chi2_stat:.2f}</b>, <i>p</i> {p_format}). \"\"\"\n",
        "\n",
        "    if p_omnibus < 0.05:\n",
        "        text += f\"\"\"This indicates that the relationship between {mod_col} and effect sizes exhibits <b>significant non-linear patterns</b>. The spline model provides a better fit to the data compared to a simple linear model.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "[<i>Describe the nature of the non-linearity based on visual inspection of the spline plot: Does the effect increase then plateau? Is there a threshold effect? Are there diminishing returns? Quadratic pattern? Provide domain-specific interpretation.</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"This suggests that a simple linear relationship may adequately describe the association between {mod_col} and effect sizes. While we fitted a flexible spline model, the data do not provide strong evidence for non-linear patterns.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The lack of significant non-linearity could indicate that: (1) the relationship is genuinely linear across the observed range of {mod_col}, (2) sample size may be insufficient to detect subtle non-linear patterns, or (3) the range of {mod_col} values may be too narrow to reveal non-linear trends. [<i>Add domain-specific interpretation based on your theoretical expectations.</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    # Model comparison section\n",
        "    text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Model Comparison</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "We compared the spline model to a simpler linear meta-regression using information criteria. The Akaike Information Criterion (AIC) penalizes model complexity while rewarding fit, with lower values indicating better models.\n",
        "</p>\n",
        "\n",
        "<div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 15px 0;'>\n",
        "<p style='margin: 5px 0;'><b>Linear Model:</b> AIC = {aic_linear:.2f}, BIC = {bic_linear:.2f}</p>\n",
        "<p style='margin: 5px 0;'><b>Spline Model:</b> AIC = {aic_spline:.2f}, BIC = {bic_spline:.2f}</p>\n",
        "<p style='margin: 5px 0;'><b>Preferred Model:</b> {better_model.capitalize()} (lower AIC)</p>\n",
        "</div>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "{'The spline model provides a better fit (lower AIC), supporting the presence of non-linear patterns.' if better_model == 'spline' else 'The linear model is preferred (lower AIC), suggesting that added complexity of the spline does not substantially improve model fit.'}\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Practical Implications</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "[<i>Discuss what these findings mean for your research domain. For example:</i>]\n",
        "</p>\n",
        "\n",
        "<ul style='line-height: 2.0;'>\n",
        "<li><i>If non-linear:</i> \"The non-linear relationship suggests that the effect of {mod_col} varies across its range. [Describe pattern: e.g., 'Effects are strongest at moderate levels', 'There appears to be a threshold at X value', 'Diminishing returns are observed at higher levels']\"</li>\n",
        "<li><i>If linear:</i> \"The linear relationship suggests a consistent, proportional association between {mod_col} and outcomes across its observed range.\"</li>\n",
        "<li><i>Implications for practice:</i> \"These findings suggest that [practical recommendations based on the shape of the relationship]\"</li>\n",
        "</ul>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Model Specification</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The spline model was fitted as: y<sub>i</sub> = Œ≤‚ÇÄ + f({mod_col}<sub>i</sub>) + u<sub>i</sub>, where f(¬∑) represents the natural cubic spline function with {df_spline} degrees of freedom, and u<sub>i</sub> ~ N(0, œÑ¬≤) represents between-study random effects. The moderator was standardized (mean-centered and scaled) before spline basis generation to improve numerical stability.\n",
        "</p>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 25px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>üìä Table 1. Spline Model Summary</h4>\n",
        "<table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "<thead style='background-color: #34495e; color: white;'>\n",
        "<tr>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Statistic</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Value</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Number of studies (k)</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{k_studies}</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Spline degrees of freedom</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{df_spline}</td>\n",
        "</tr>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Between-study variance (œÑ¬≤)</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{tau2:.4f}</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Omnibus test for non-linearity</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>œá¬≤({df_test}) = {chi2_stat:.2f}, <i>p</i> {p_format}</td>\n",
        "</tr>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Model comparison (vs. linear)</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{better_model.capitalize()} model preferred</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "</div>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; margin-top: 20px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "<ul style='margin-bottom: 0;'>\n",
        "<li>Examine the spline plot (dedicated plot cell) to understand the shape of the non-linear relationship</li>\n",
        "<li>Identify key features: thresholds, plateaus, peaks, or inflection points</li>\n",
        "<li>Compare spline predictions to linear predictions to see where they diverge</li>\n",
        "<li>Consider whether non-linearity has practical significance beyond statistical significance</li>\n",
        "<li>Link the pattern to theoretical mechanisms in your field</li>\n",
        "<li>Discuss whether the observed range of {mod_col} is sufficient to reveal the full non-linear pattern</li>\n",
        "<li>Consider sensitivity to df choice (try df=3, 4, 5 to see if pattern is robust)</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "<p style='margin: 0;'><b>üí° Tip:</b> Select all text (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C), and paste into your word processor. Edit the [<i>bracketed notes</i>] to add your specific interpretations of the non-linear pattern.</p>\n",
        "</div>\n",
        "\n",
        "</div>\"\"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# --- 3. UI WIDGETS ---\n",
        "df_spline_in = get_analysis_data()\n",
        "opts = get_numeric_mods_robust(df_spline_in) if df_spline_in is not None else ['Data not loaded']\n",
        "\n",
        "mod_widget = widgets.Dropdown(\n",
        "    options=opts,\n",
        "    description='Moderator:',\n",
        "    layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "df_widget = widgets.IntSlider(\n",
        "    value=3,\n",
        "    min=3,\n",
        "    max=6,\n",
        "    description='Spline df:',\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "run_spline_btn = widgets.Button(\n",
        "    description='‚ñ∂ Run Spline Analysis',\n",
        "    button_style='success',\n",
        "    icon='play'\n",
        ")\n",
        "\n",
        "# --- 4. MAIN ANALYSIS FUNCTION ---\n",
        "def run_spline(b):\n",
        "    global ANALYSIS_CONFIG\n",
        "\n",
        "    # Clear all tabs\n",
        "    for tab in [tab_results, tab_diagnostics, tab_details, tab_publication]:\n",
        "        tab.clear_output()\n",
        "\n",
        "    if not PATSY_AVAILABLE:\n",
        "        with tab_results:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå Error: 'patsy' package not installed. Install with: pip install patsy</div>\"))\n",
        "        return\n",
        "\n",
        "    mod_col = mod_widget.value\n",
        "    df_k = df_widget.value\n",
        "\n",
        "    df_working = get_analysis_data()\n",
        "    if df_working is None:\n",
        "        with tab_results:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå Error: Data not found. Run Step 1 first.</div>\"))\n",
        "        return\n",
        "\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        with tab_results:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå Error: Config not found. Run Step 1 first.</div>\"))\n",
        "        return\n",
        "\n",
        "    eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "    var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "\n",
        "    # Prep data\n",
        "    df = df_working.copy()\n",
        "    df[mod_col] = pd.to_numeric(df[mod_col], errors='coerce')\n",
        "    df = df.dropna(subset=[mod_col, eff_col, var_col])\n",
        "    df = df[df[var_col] > 0]\n",
        "\n",
        "    if len(df) < 3:\n",
        "        with tab_results:\n",
        "            display(HTML(f\"<div style='color: red;'>‚ùå Error: Insufficient data (n={len(df)}). Need at least 3 observations.</div>\"))\n",
        "        return\n",
        "\n",
        "    # Aggregate\n",
        "    df['wi'] = 1 / df[var_col]\n",
        "    def agg_func(x):\n",
        "        return pd.Series({\n",
        "            eff_col: np.average(x[eff_col], weights=x['wi']),\n",
        "            var_col: 1 / np.sum(x['wi']),\n",
        "            mod_col: x[mod_col].iloc[0]\n",
        "        })\n",
        "\n",
        "    try:\n",
        "        agg_df = df.groupby('id').apply(agg_func, include_groups=False).reset_index()\n",
        "    except TypeError:\n",
        "        agg_df = df.groupby('id').apply(agg_func).reset_index()\n",
        "\n",
        "    # Estimate tau¬≤ from linear model\n",
        "    fixed_tau2, ll_linear, lin_model = estimate_linear_tau2(agg_df, mod_col, eff_col, var_col)\n",
        "\n",
        "    # Run spline model\n",
        "    est, err = _run_aggregated_spline_re(\n",
        "        agg_df, mod_col, eff_col, var_col, df_k,\n",
        "        df[mod_col].mean(), df[mod_col].std(), fixed_tau2\n",
        "    )\n",
        "\n",
        "    if err:\n",
        "        with tab_results:\n",
        "            display(HTML(f\"<div style='color: red;'>‚ùå {err}</div>\"))\n",
        "        return\n",
        "\n",
        "    # Calculate omnibus test\n",
        "    betas = est['betas']\n",
        "    cov = est['var_betas']\n",
        "\n",
        "    if len(betas) > 1:\n",
        "        b_spline = betas[1:]\n",
        "        cov_spline = cov[1:, 1:]\n",
        "        try:\n",
        "            chi2_stat = b_spline.T @ np.linalg.inv(cov_spline) @ b_spline\n",
        "            df_test = len(b_spline)\n",
        "            p_omnibus = 1 - chi2.cdf(chi2_stat, df_test)\n",
        "        except:\n",
        "            chi2_stat = 0\n",
        "            df_test = 0\n",
        "            p_omnibus = 1.0\n",
        "    else:\n",
        "        chi2_stat = 0\n",
        "        df_test = 0\n",
        "        p_omnibus = 1.0\n",
        "\n",
        "    k_studies = len(agg_df)\n",
        "    ll_spline = est['log_lik_reml']\n",
        "\n",
        "    # Calculate AICs\n",
        "    aic_linear = -2*ll_linear + 2*2\n",
        "    aic_spline = -2*ll_spline + 2*len(betas)\n",
        "\n",
        "    # --- TAB 1: RESULTS ---\n",
        "    with tab_results:\n",
        "        sig = \"***\" if p_omnibus < 0.001 else \"**\" if p_omnibus < 0.01 else \"*\" if p_omnibus < 0.05 else \"ns\"\n",
        "        color = \"#28a745\" if p_omnibus < 0.05 else \"#6c757d\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h2 style='color: #2c3e50; margin-bottom: 20px;'>Spline Meta-Regression: {mod_col}</h2>\n",
        "\n",
        "        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "            <div style='text-align: center;'>\n",
        "                <div style='font-size: 0.9em; margin-bottom: 10px;'>OMNIBUS TEST FOR NON-LINEARITY</div>\n",
        "                <h1 style='margin: 0; font-size: 2.5em;'>{\"Significant\" if p_omnibus < 0.05 else \"Not Significant\"}</h1>\n",
        "                <p style='margin: 10px 0 0 0; font-size: 1.2em;'>p {p_omnibus:.4g} {sig}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-bottom: 20px;'>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #007bff;'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>Chi-Square Statistic</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold;'>œá¬≤({df_test}) = {chi2_stat:.2f}</div>\n",
        "            </div>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid {color};'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>P-value</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold; color: {color};'>{p_omnibus:.4g}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "            <p style='margin: 0; font-size: 1.05em;'>\n",
        "                \"\"\"\n",
        "\n",
        "        if p_omnibus < 0.05:\n",
        "            html += f\"\"\"The relationship between <b>{mod_col}</b> and effect sizes exhibits <b style='color: #28a745;'>significant non-linear patterns</b>.\n",
        "                A flexible spline model fits the data better than a simple linear relationship.\n",
        "                Examine the spline plot to understand the nature of this non-linearity.\"\"\"\n",
        "        else:\n",
        "            html += f\"\"\"No significant evidence of non-linearity was detected.\n",
        "                A simple linear relationship may adequately describe the association between <b>{mod_col}</b> and effect sizes.\n",
        "                The added complexity of the spline model does not significantly improve fit.\"\"\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "            </p>\n",
        "        </div>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Model Comparison</h3>\n",
        "        <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Model</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Parameters</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Log-Likelihood</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>AIC</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Preferred</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Linear</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>2</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{ll_linear:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{aic_linear:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{\"‚úì\" if aic_linear < aic_spline else \"\"}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Spline (df={df_k})</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{len(betas)}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{ll_spline:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{aic_spline:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{\"‚úì\" if aic_spline < aic_linear else \"\"}</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Model Summary</h3>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "            <p style='margin: 5px 0;'><b>Model Type:</b> {est['model_type']}</p>\n",
        "            <p style='margin: 5px 0;'><b>Studies (k):</b> {k_studies}</p>\n",
        "            <p style='margin: 5px 0;'><b>Spline Degrees of Freedom:</b> {df_k}</p>\n",
        "            <p style='margin: 5px 0;'><b>Number of Coefficients:</b> {len(betas)} (1 intercept + {len(betas)-1} spline terms)</p>\n",
        "            <p style='margin: 5px 0;'><b>Between-Study Variance (œÑ¬≤):</b> {fixed_tau2:.4f} (fixed from linear model)</p>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "            <p style='margin: 0;'><b>üìä Next Step:</b> Use the dedicated spline plot cell to visualize the non-linear relationship and identify key features (thresholds, plateaus, etc.).</p>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(html))\n",
        "\n",
        "    # --- TAB 2: DIAGNOSTICS ---\n",
        "    with tab_diagnostics:\n",
        "        display(HTML(\"<h3 style='color: #2c3e50;'>üîç Model Diagnostics</h3>\"))\n",
        "\n",
        "        resid = est['resid']\n",
        "        fitted = est['fitted']\n",
        "\n",
        "        diag_html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Model Fit Assessment</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'><b>Log-Likelihood (Spline):</b> {ll_spline:.2f}</p>\n",
        "            <p style='margin: 5px 0;'><b>Log-Likelihood (Linear):</b> {ll_linear:.2f}</p>\n",
        "            <p style='margin: 5px 0;'><b>Improvement:</b> {ll_spline - ll_linear:.2f}</p>\n",
        "            <p style='margin: 10px 0 0 0;'><i>Positive values indicate spline fits better</i></p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Residual Analysis</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'><b>Residual Range:</b> [{np.min(resid):.4f}, {np.max(resid):.4f}]</p>\n",
        "            <p style='margin: 5px 0;'><b>Mean Residual:</b> {np.mean(resid):.4f} (should be ‚âà 0)</p>\n",
        "            <p style='margin: 5px 0;'><b>SD of Residuals:</b> {np.std(resid):.4f}</p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Non-Linearity Evidence</h4>\n",
        "        \"\"\"\n",
        "\n",
        "        if p_omnibus < 0.05:\n",
        "            diag_html += f\"\"\"\n",
        "            <div style='background-color: #d4edda; padding: 15px; border-radius: 5px; border-left: 4px solid #28a745; margin-bottom: 20px;'>\n",
        "                <p style='margin: 0;'><b>‚úì Strong Evidence:</b> Omnibus test indicates significant non-linearity (p = {p_omnibus:.4g}).</p>\n",
        "                <p style='margin: 10px 0 0 0;'>The spline model captures patterns that the linear model misses.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        elif p_omnibus < 0.10:\n",
        "            diag_html += f\"\"\"\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-bottom: 20px;'>\n",
        "                <p style='margin: 0;'><b>‚ö†Ô∏è Marginal Evidence:</b> Omnibus test shows marginal significance (p = {p_omnibus:.4g}).</p>\n",
        "                <p style='margin: 10px 0 0 0;'>Consider examining the plot for visual evidence of non-linearity.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            diag_html += f\"\"\"\n",
        "            <div style='background-color: #f8d7da; padding: 15px; border-radius: 5px; border-left: 4px solid #dc3545; margin-bottom: 20px;'>\n",
        "                <p style='margin: 0;'><b>‚úó No Evidence:</b> Omnibus test does not support non-linearity (p = {p_omnibus:.4g}).</p>\n",
        "                <p style='margin: 10px 0 0 0;'>A linear model may be more appropriate.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        diag_html += f\"\"\"\n",
        "        <h4 style='color: #34495e;'>Degrees of Freedom Usage</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'><b>Spline df:</b> {df_k}</p>\n",
        "            <p style='margin: 5px 0;'><b>Total parameters:</b> {len(betas)} (including intercept)</p>\n",
        "            <p style='margin: 5px 0;'><b>Effective df used:</b> {df_test} (for non-linearity test)</p>\n",
        "            <p style='margin: 10px 0 0 0;'><i>Lower df = simpler curve; higher df = more flexible curve</i></p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Model Selection Recommendation</h4>\n",
        "        \"\"\"\n",
        "\n",
        "        better_aic = aic_spline < aic_linear\n",
        "\n",
        "        if p_omnibus < 0.05 and better_aic:\n",
        "            diag_html += \"\"\"\n",
        "            <div style='background-color: #d4edda; padding: 15px; border-radius: 5px; border-left: 4px solid #28a745;'>\n",
        "                <p style='margin: 0;'><b>‚úì Recommendation: Use Spline Model</b></p>\n",
        "                <p style='margin: 10px 0 0 0;'>Both the omnibus test and AIC support the spline model. The non-linear relationship is well-supported by the data.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        elif p_omnibus >= 0.05 and not better_aic:\n",
        "            diag_html += \"\"\"\n",
        "            <div style='background-color: #d4edda; padding: 15px; border-radius: 5px; border-left: 4px solid #28a745;'>\n",
        "                <p style='margin: 0;'><b>‚úì Recommendation: Use Linear Model</b></p>\n",
        "                <p style='margin: 10px 0 0 0;'>Both the omnibus test and AIC favor the simpler linear model. There is no strong evidence for non-linearity.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            diag_html += \"\"\"\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107;'>\n",
        "                <p style='margin: 0;'><b>‚ö†Ô∏è Recommendation: Mixed Evidence</b></p>\n",
        "                <p style='margin: 10px 0 0 0;'>The omnibus test and AIC give conflicting signals. Examine the plot carefully and consider domain knowledge when choosing between models.</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        diag_html += \"\"\"\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(diag_html))\n",
        "\n",
        "    # --- TAB 3: MODEL DETAILS ---\n",
        "    with tab_details:\n",
        "        display(HTML(\"<h3 style='color: #2c3e50;'>‚öôÔ∏è Model Details & Specifications</h3>\"))\n",
        "\n",
        "        details_html = f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Spline Specification</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px; font-family: monospace;'>\n",
        "            <p style='margin: 5px 0;'><b>Model:</b> Natural Cubic Spline</p>\n",
        "            <p style='margin: 5px 0;'><b>Degrees of Freedom:</b> {df_k}</p>\n",
        "            <p style='margin: 5px 0;'><b>Basis Function:</b> {est['formula']}</p>\n",
        "            <p style='margin: 5px 0;'><b>Moderator Standardization:</b> z = (x - {est['mod_mean']:.3f}) / {est['mod_std']:.3f}</p>\n",
        "            <p style='margin: 10px 0 0 0;'><i>Natural cubic splines are linear beyond the boundary knots, preventing unrealistic extrapolation.</i></p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Model Equation</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px; font-family: monospace;'>\n",
        "            <p style='margin: 5px 0;'>y<sub>i</sub> = Œ≤‚ÇÄ + Œ£ Œ≤<sub>j</sub> ¬∑ B<sub>j</sub>(z<sub>i</sub>) + u<sub>i</sub></p>\n",
        "            <p style='margin: 5px 0; padding-left: 20px;'>where:</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ y<sub>i</sub> = effect size for study i</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ B<sub>j</sub>(z) = spline basis functions (j = 1,...,{df_k})</p>\n",
        "            <p style='margin: 5px 0; padding-left: 40px;'>‚Ä¢ u<sub>i</sub> ~ N(0, œÑ¬≤) = between-study random effect</p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Coefficient Estimates</h4>\n",
        "        <table style='width: 100%; border-collapse: collapse; margin-bottom: 20px;'>\n",
        "            <thead style='background-color: #f8f9fa;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Term</th>\n",
        "                    <th style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>Coefficient</th>\n",
        "                    <th style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>SE</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "        \"\"\"\n",
        "\n",
        "        se_betas = np.sqrt(np.diag(cov))\n",
        "        for i, (beta, se) in enumerate(zip(betas, se_betas)):\n",
        "            term_name = \"Intercept\" if i == 0 else f\"Spline Basis {i}\"\n",
        "            bg = \"#f8f9fa\" if i % 2 == 0 else \"white\"\n",
        "            details_html += f\"\"\"\n",
        "                <tr style='background-color: {bg};'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>{term_name}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{beta:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{se:.4f}</td>\n",
        "                </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        details_html += f\"\"\"\n",
        "            </tbody>\n",
        "        </table>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Variance Components</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'><b>œÑ¬≤ (Between-Study Variance):</b> {fixed_tau2:.4f}</p>\n",
        "            <p style='margin: 5px 0;'><b>Source:</b> Fixed from linear meta-regression (plug-in approach)</p>\n",
        "            <p style='margin: 10px 0 0 0;'><i>Using fixed œÑ¬≤ prevents overfitting and ensures stable estimates. The spline model optimizes only the regression coefficients, not the variance.</i></p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Why Plug-In œÑ¬≤?</h4>\n",
        "        <div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <p style='margin: 5px 0;'>The \"plug-in\" approach fixes œÑ¬≤ at the value from the linear model instead of re-estimating it. This prevents:</p>\n",
        "            <ul style='margin: 10px 0;'>\n",
        "                <li><b>Overfitting:</b> Spline models can artificially reduce œÑ¬≤ by fitting noise</li>\n",
        "                <li><b>Numerical instability:</b> Simultaneous estimation of spline coefficients and variance can fail</li>\n",
        "                <li><b>Unrealistic estimates:</b> œÑ¬≤ may collapse to zero or explode to infinity</li>\n",
        "            </ul>\n",
        "            <p style='margin: 5px 0;'>This is a conservative, stable approach recommended for spline meta-regression.</p>\n",
        "        </div>\n",
        "\n",
        "        <h4 style='color: #34495e;'>Data Summary</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "            <p style='margin: 5px 0;'><b>Original observations:</b> {len(df)}</p>\n",
        "            <p style='margin: 5px 0;'><b>Aggregated to studies:</b> {k_studies}</p>\n",
        "            <p style='margin: 5px 0;'><b>Moderator range:</b> [{agg_df[mod_col].min():.3f}, {agg_df[mod_col].max():.3f}]</p>\n",
        "            <p style='margin: 5px 0;'><b>Effect size range:</b> [{agg_df[eff_col].min():.3f}, {agg_df[eff_col].max():.3f}]</p>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(details_html))\n",
        "\n",
        "    # --- TAB 4: PUBLICATION TEXT ---\n",
        "    with tab_publication:\n",
        "        display(HTML(\"<h3 style='color: #2c3e50;'>üìù Publication-Ready Results Text</h3>\"))\n",
        "        display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "        pub_text = generate_spline_publication_text(\n",
        "            mod_col, df_k, chi2_stat, df_test, p_omnibus,\n",
        "            fixed_tau2, k_studies, ll_spline, ll_linear,\n",
        "            est['model_type'], len(betas)\n",
        "        )\n",
        "\n",
        "        display(HTML(pub_text))\n",
        "\n",
        "    # --- SAVE RESULTS ---\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        ANALYSIS_CONFIG = {}\n",
        "\n",
        "    ANALYSIS_CONFIG['spline_model_results'] = {\n",
        "        'reg_df': agg_df,\n",
        "        'betas': betas,\n",
        "        'var_betas': cov,\n",
        "        'tau_sq': fixed_tau2,\n",
        "        'sigma_sq': 0.0,\n",
        "        'log_lik': ll_spline,\n",
        "        'mod_mean': est['mod_mean'],\n",
        "        'mod_std': est['mod_std'],\n",
        "        'df_spline': df_k,\n",
        "        'moderator_col': mod_col,\n",
        "        'formula': est['formula'],\n",
        "        'model_type': est['model_type'],\n",
        "        'omnibus_chi2': chi2_stat,\n",
        "        'omnibus_df': df_test,\n",
        "        'omnibus_p': p_omnibus,\n",
        "        'fitted': fitted,\n",
        "        'resid': resid\n",
        "    }\n",
        "\n",
        "run_spline_btn.on_click(run_spline)\n",
        "\n",
        "# --- 5. DISPLAY UI ---\n",
        "display(HTML(\"<h3>üåä Spline Meta-Regression Analysis (V2)</h3>\"))\n",
        "display(HTML(\"<p style='color: #6c757d;'>Test for non-linear relationships using natural cubic splines. Results appear in organized tabs below.</p>\"))\n",
        "display(widgets.VBox([mod_widget, df_widget, run_spline_btn]))\n",
        "display(tabs)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä Cell 11b: Publication-Ready Spline Plot (Full Feature)\n",
        "# =============================================================================\n",
        "# CELL 11b: ADVANCED SPLINE PLOTTER\n",
        "# Purpose: Visualize results from Cell 11 with full customization.\n",
        "# Features: Tabs for Style, Points, Curve, Layout, and Label Editing.\n",
        "# Compatibility: Works with the new Robust/Aggregated Spline results.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import t\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import traceback\n",
        "import patsy\n",
        "\n",
        "# --- 1. INITIALIZATION & CONFIG LOADING ---\n",
        "available_color_moderators = ['None']\n",
        "analysis_data_init = None\n",
        "default_x_label = \"Moderator\"\n",
        "default_y_label = \"Effect Size\"\n",
        "default_title = \"Natural Cubic Spline Analysis\"\n",
        "label_widgets_dict = {}\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"ANALYSIS_CONFIG not found\")\n",
        "\n",
        "    # Get data for dropdowns\n",
        "    if 'analysis_data' in globals():\n",
        "        analysis_data_init = analysis_data.copy()\n",
        "    elif 'data_filtered' in globals():\n",
        "        analysis_data_init = data_filtered.copy()\n",
        "    else:\n",
        "        # Fallback to reg_df if main data missing\n",
        "        if 'spline_model_results' in ANALYSIS_CONFIG:\n",
        "            analysis_data_init = ANALYSIS_CONFIG['spline_model_results']['reg_df'].copy()\n",
        "\n",
        "    # Load Defaults from Results\n",
        "    if 'spline_model_results' in ANALYSIS_CONFIG:\n",
        "        spline_results = ANALYSIS_CONFIG['spline_model_results']\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        default_x_label = spline_results.get('moderator_col', 'Moderator')\n",
        "        default_y_label = es_config.get('effect_label', 'Effect Size')\n",
        "        default_title = f\"Spline Regression: {default_y_label} vs. {default_x_label}\"\n",
        "\n",
        "    # Identify Categorical Moderators for Coloring\n",
        "    if analysis_data_init is not None:\n",
        "        excluded_cols = [\n",
        "            ANALYSIS_CONFIG.get('effect_col'), ANALYSIS_CONFIG.get('var_col'),\n",
        "            ANALYSIS_CONFIG.get('se_col'), 'w_fixed', 'w_random', 'id',\n",
        "            'xe', 'sde', 'ne', 'xc', 'sdc', 'nc'\n",
        "        ]\n",
        "\n",
        "        for col in analysis_data_init.columns:\n",
        "            if col in excluded_cols or col is None: continue\n",
        "            # Check if categorical (object or category) and reasonable size\n",
        "            if analysis_data_init[col].dtype == 'object' or isinstance(analysis_data_init[col].dtype, pd.CategoricalDtype):\n",
        "                if analysis_data_init[col].nunique() <= 15: # Limit to reasonable number of colors\n",
        "                    available_color_moderators.append(col)\n",
        "\n",
        "    # Find unique labels for Editor\n",
        "    all_categorical_labels = set()\n",
        "    for col in available_color_moderators:\n",
        "        if col != 'None' and col in analysis_data_init.columns:\n",
        "            all_categorical_labels.add(col)\n",
        "            unique_vals = analysis_data_init[col].astype(str).str.strip().unique()\n",
        "            all_categorical_labels.update(unique_vals)\n",
        "\n",
        "    all_categorical_labels.discard('')\n",
        "    all_categorical_labels.discard('nan')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Initialization Warning: {e}\")\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# === TAB 1: STYLE ===\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_x_label, description='X Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_y_label, description='Y Label:', layout=widgets.Layout(width='450px'))\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=5.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False)\n",
        "height_widget = widgets.FloatSlider(value=6.0, min=4.0, max=12.0, step=0.5, description='Height (in):', continuous_update=False)\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Dimensions</h4>\"),\n",
        "    show_title_widget, title_widget,\n",
        "    xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    width_widget, height_widget\n",
        "])\n",
        "\n",
        "# === TAB 2: POINTS ===\n",
        "show_points_widget = widgets.Checkbox(value=True, description='Show Data Points', indent=False)\n",
        "color_mod_widget = widgets.Dropdown(options=available_color_moderators, value='None', description='Color By:', layout=widgets.Layout(width='400px'))\n",
        "point_color_widget = widgets.Dropdown(options=['gray', 'steelblue', 'black', 'red', 'green', 'purple'], value='gray', description='Color:')\n",
        "point_size_widget = widgets.IntSlider(value=40, min=10, max=150, step=5, description='Size:')\n",
        "point_alpha_widget = widgets.FloatSlider(value=0.5, min=0.1, max=1.0, step=0.1, description='Opacity:')\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Points</h4>\"),\n",
        "    show_points_widget,\n",
        "    color_mod_widget,\n",
        "    point_color_widget,\n",
        "    point_size_widget,\n",
        "    point_alpha_widget\n",
        "])\n",
        "\n",
        "# === TAB 3: CURVE ===\n",
        "curve_color_widget = widgets.Dropdown(options=['blue', 'red', 'black', 'green', 'purple'], value='blue', description='Line Color:')\n",
        "curve_width_widget = widgets.FloatSlider(value=2.5, min=0.5, max=6.0, step=0.5, description='Line Width:')\n",
        "show_ci_widget = widgets.Checkbox(value=True, description='Show 95% Confidence Band', indent=False)\n",
        "ci_alpha_widget = widgets.FloatSlider(value=0.15, min=0.05, max=0.5, step=0.05, description='CI Opacity:')\n",
        "show_stats_widget = widgets.Checkbox(value=True, description='Show Stats (P-value/R¬≤)', indent=False)\n",
        "\n",
        "curve_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Spline Curve</h4>\"),\n",
        "    curve_color_widget, curve_width_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    show_ci_widget, ci_alpha_widget,\n",
        "    show_stats_widget\n",
        "])\n",
        "\n",
        "# === TAB 4: LAYOUT ===\n",
        "show_grid_widget = widgets.Checkbox(value=True, description='Show Grid', indent=False)\n",
        "show_null_line_widget = widgets.Checkbox(value=True, description='Show Null Line (y=0)', indent=False)\n",
        "legend_loc_widget = widgets.Dropdown(options=['best', 'upper right', 'upper left', 'lower right', 'lower left', 'none'], value='best', description='Legend:')\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "filename_prefix_widget = widgets.Text(value='Spline_Plot', description='Filename:', layout=widgets.Layout(width='300px'))\n",
        "\n",
        "layout_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Layout & Export</h4>\"),\n",
        "    show_grid_widget, show_null_line_widget, legend_loc_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    save_pdf_widget, save_png_widget, filename_prefix_widget\n",
        "])\n",
        "\n",
        "# === TAB 5: LABELS (Dynamic) ===\n",
        "label_editor_widgets = []\n",
        "label_widgets_dict = {}\n",
        "\n",
        "if all_categorical_labels:\n",
        "    for label in sorted(list(all_categorical_labels)):\n",
        "        w = widgets.Text(value=str(label), description=f\"{label}:\", layout=widgets.Layout(width='400px'))\n",
        "        label_editor_widgets.append(w)\n",
        "        label_widgets_dict[str(label)] = w\n",
        "else:\n",
        "    label_editor_widgets.append(widgets.Label(\"No categorical labels found to edit.\"))\n",
        "\n",
        "labels_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Label Editor</h4>\"),\n",
        "    widgets.HTML(\"<i>Rename data categories for the legend:</i>\"),\n",
        "    *label_editor_widgets\n",
        "])\n",
        "\n",
        "# Assemble Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, points_tab, curve_tab, layout_tab, labels_tab])\n",
        "tabs.set_title(0, 'üé® Style')\n",
        "tabs.set_title(1, '‚ö´ Points')\n",
        "tabs.set_title(2, 'üåä Curve')\n",
        "tabs.set_title(3, 'üíæ Layout')\n",
        "tabs.set_title(4, '‚úèÔ∏è Labels')\n",
        "\n",
        "run_plot_btn = widgets.Button(\n",
        "    description='üìä Generate Spline Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# --- 3. PLOTTING LOGIC ---\n",
        "def generate_spline_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        try:\n",
        "            # 1. Load Results\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'spline_model_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"‚ùå Error: Please run the Spline Analysis (Cell 11) first.\")\n",
        "                return\n",
        "\n",
        "            res = ANALYSIS_CONFIG['spline_model_results']\n",
        "            df = res['reg_df'].copy() # Dataframe used in model\n",
        "\n",
        "            # Extract Model info\n",
        "            betas = res['betas']\n",
        "            cov = res['var_betas']\n",
        "            formula = res['formula']\n",
        "            mod_mean = res['mod_mean']\n",
        "            mod_std = res['mod_std']\n",
        "            mod_col = res['moderator_col']\n",
        "            eff_col = ANALYSIS_CONFIG['effect_col']\n",
        "\n",
        "            # 2. Re-calculate Curve (High Resolution)\n",
        "            x_min, x_max = df[mod_col].min(), df[mod_col].max()\n",
        "            padding = (x_max - x_min) * 0.05\n",
        "            x_grid = np.linspace(x_min - padding, x_max + padding, 200)\n",
        "            x_grid_z = (x_grid - mod_mean) / mod_std\n",
        "\n",
        "            # Generate Basis for Grid\n",
        "            try:\n",
        "                # We need to match the column structure of the model\n",
        "                # The model might have dropped columns (collinearity), so we need to be careful.\n",
        "                pred_matrix = patsy.dmatrix(formula, {\"x\": x_grid_z}, return_type='dataframe')\n",
        "                X_pred_full = sm.add_constant(pred_matrix)\n",
        "\n",
        "                # Filter columns to match what the model used\n",
        "                # If 'kept_cols' or similar isn't saved, we assume simple match by length or name if possible\n",
        "                # But simpler: matrix multiplication handles it if shapes match\n",
        "                # Check shape\n",
        "                if X_pred_full.shape[1] != len(betas):\n",
        "                    # Try to align by column names if available, otherwise simple slice\n",
        "                    if hasattr(res, 'get') and res.get('X_design_cols') is not None:\n",
        "                        # Robust matching using saved column names\n",
        "                        cols = res['X_design_cols']\n",
        "                        # Make sure X_pred_full has these columns (it should if formula is same)\n",
        "                        # Note: patsy names might differ slightly if not careful, but usually stable\n",
        "                        X_pred = X_pred_full.values[:, :len(betas)] # Fallback\n",
        "                    else:\n",
        "                         # Fallback: Assume the first K columns are the ones kept\n",
        "                         X_pred = X_pred_full.values[:, :len(betas)]\n",
        "                else:\n",
        "                    X_pred = X_pred_full.values\n",
        "\n",
        "                # Calculate\n",
        "                y_pred = X_pred @ betas\n",
        "                pred_var = np.sum((X_pred @ cov) * X_pred, axis=1)\n",
        "                pred_se = np.sqrt(pred_var)\n",
        "\n",
        "                ci_lower = y_pred - 1.96 * pred_se\n",
        "                ci_upper = y_pred + 1.96 * pred_se\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error calculating curve: {e}\")\n",
        "                print(\"   (Did the model structure change?)\")\n",
        "                return\n",
        "\n",
        "            # 3. Prepare Plot\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, height_widget.value))\n",
        "\n",
        "            # Handle Colors & Labels\n",
        "            color_col = color_mod_widget.value\n",
        "            label_map = {k: v.value for k, v in label_widgets_dict.items()}\n",
        "\n",
        "            # --- Plot Points ---\n",
        "            if show_points_widget.value:\n",
        "                if color_col != 'None' and color_col in analysis_data_init.columns:\n",
        "                    # Merge color data back if not in reg_df (reg_df might be aggregated)\n",
        "                    # If aggregated, we might lose the categorical info unless we merge back by ID\n",
        "                    # For simplicity, we try to use what's in df\n",
        "\n",
        "                    # Check if color_col exists in df, if not, try merge\n",
        "                    plot_df = df\n",
        "                    if color_col not in plot_df.columns:\n",
        "                        # Try to recover color info from initial data\n",
        "                        # This assumes 1-to-1 mapping if aggregated\n",
        "                        temp_merge = analysis_data_init[['id', color_col]].drop_duplicates()\n",
        "                        plot_df = plot_df.merge(temp_merge, on='id', how='left')\n",
        "\n",
        "                    # Get unique categories\n",
        "                    categories = plot_df[color_col].dropna().unique()\n",
        "                    cmap = plt.get_cmap('tab10')\n",
        "\n",
        "                    for i, cat in enumerate(categories):\n",
        "                        cat_str = str(cat)\n",
        "                        display_label = label_map.get(cat_str, cat_str)\n",
        "                        mask = plot_df[color_col] == cat\n",
        "\n",
        "                        ax.scatter(plot_df.loc[mask, mod_col], plot_df.loc[mask, eff_col],\n",
        "                                  color=cmap(i % 10), alpha=point_alpha_widget.value,\n",
        "                                  s=point_size_widget.value, label=display_label,\n",
        "                                  edgecolors='k', linewidth=0.5)\n",
        "\n",
        "                    # Legend title\n",
        "                    legend_title = label_map.get(color_col, color_col)\n",
        "\n",
        "                else:\n",
        "                    # Single color\n",
        "                    ax.scatter(df[mod_col], df[eff_col],\n",
        "                              color=point_color_widget.value, alpha=point_alpha_widget.value,\n",
        "                              s=point_size_widget.value, label='Observations',\n",
        "                              edgecolors='k', linewidth=0.5)\n",
        "                    legend_title = None\n",
        "\n",
        "            # --- Plot Curve ---\n",
        "            ax.plot(x_grid, y_pred, color=curve_color_widget.value,\n",
        "                   linewidth=curve_width_widget.value, label='Spline Fit')\n",
        "\n",
        "            if show_ci_widget.value:\n",
        "                ax.fill_between(x_grid, ci_lower, ci_upper,\n",
        "                               color=curve_color_widget.value, alpha=ci_alpha_widget.value,\n",
        "                               label='95% CI')\n",
        "\n",
        "            # --- Decoration ---\n",
        "            if show_null_line_widget.value:\n",
        "                ax.axhline(0, color='black', linestyle=':', linewidth=1.5, alpha=0.6)\n",
        "\n",
        "            if show_grid_widget.value:\n",
        "                ax.grid(True, linestyle=':', alpha=0.4)\n",
        "\n",
        "            if show_title_widget.value:\n",
        "                ax.set_title(title_widget.value, fontsize=14, fontweight='bold', pad=15)\n",
        "\n",
        "            ax.set_xlabel(xlabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(ylabel_widget.value, fontsize=12, fontweight='bold')\n",
        "\n",
        "            if legend_loc_widget.value != 'none':\n",
        "                ax.legend(loc=legend_loc_widget.value, title=legend_title, frameon=True, fancybox=True)\n",
        "\n",
        "            # Stats annotation\n",
        "            if show_stats_widget.value:\n",
        "                # Try to get stats from results\n",
        "                p_val = res.get('f_pvalue', None)\n",
        "                tau2 = res.get('tau_sq', None)\n",
        "\n",
        "                stats_text = []\n",
        "                if p_val is not None:\n",
        "                    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"ns\"\n",
        "                    stats_text.append(f\"P-value: {p_val:.4g} {sig}\")\n",
        "                if tau2 is not None:\n",
        "                    stats_text.append(f\"œÑ¬≤: {tau2:.3f}\")\n",
        "\n",
        "                if stats_text:\n",
        "                    ax.text(0.05, 0.95, \"\\n\".join(stats_text), transform=ax.transAxes,\n",
        "                           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- Export ---\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M%S\")\n",
        "            fn = filename_prefix_widget.value\n",
        "\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.pdf\")\n",
        "\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.png\", dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.png\")\n",
        "\n",
        "            plt.show()\n",
        "            print(f\"‚úÖ Plot Generated (n={len(df)})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Plotting Error: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_plot_btn.on_click(generate_spline_plot)\n",
        "\n",
        "\n",
        "# Header\n",
        "header = widgets.HTML(\"\"\"\n",
        "    <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>\n",
        "        <h2 style='color: white; margin: 0; text-align: center;'>\n",
        "            üìä Cell 11b: Publication-Ready Spline Plot\n",
        "        </h2>\n",
        "        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0; text-align: center; font-size: 14px;'>\n",
        "            Visualize spline analysis results with full customization\n",
        "        </p>\n",
        "    </div>\n",
        "\"\"\")\n",
        "\n",
        "# --- 4. DISPLAY ---\n",
        "display(widgets.VBox([\n",
        "    header,\n",
        "    tabs,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    run_plot_btn,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "V67vPDlUC9aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title R Validation for Spline Analysis (Journal Proof)\n",
        "# =============================================================================\n",
        "# CELL: JOURNAL-GRADE VALIDATION\n",
        "# Purpose: Prove that Python's Spline Optimizer matches R's metafor exactly.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "import patsy\n",
        "pandas2ri.activate()\n",
        "\n",
        "if 'ANALYSIS_CONFIG' not in globals() or 'spline_model_results' not in ANALYSIS_CONFIG:\n",
        "    print(\"‚ùå Error: Run Spline Analysis (Cell 11) first.\")\n",
        "else:\n",
        "    res_py = ANALYSIS_CONFIG['spline_model_results']\n",
        "    df_orig = res_py['reg_df']\n",
        "    eff_col = ANALYSIS_CONFIG['effect_col']\n",
        "    var_col = ANALYSIS_CONFIG['var_col']\n",
        "\n",
        "    print(\"üöÄ Running R Validation for Spline Model...\")\n",
        "    print(f\"   Model Type: {res_py.get('model_type', 'Unknown')}\")\n",
        "\n",
        "    # 1. Reconstruct Basis\n",
        "    mod_z = (df_orig[res_py['moderator_col']] - res_py['mod_mean']) / res_py['mod_std']\n",
        "    formula = res_py['formula']\n",
        "    basis_matrix = patsy.dmatrix(formula, {\"x\": mod_z}, return_type='dataframe')\n",
        "\n",
        "    # 2. Prepare Data for R\n",
        "    df_r = df_orig[['id', eff_col, var_col]].copy()\n",
        "    spline_cols = []\n",
        "    for i in range(basis_matrix.shape[1]):\n",
        "        col_name = f'spline_basis_{i+1}'\n",
        "        df_r[col_name] = basis_matrix.iloc[:, i].values\n",
        "        spline_cols.append(col_name)\n",
        "\n",
        "    ro.globalenv['df_python'] = df_r\n",
        "    ro.globalenv['eff_col_name'] = eff_col\n",
        "    ro.globalenv['var_col_name'] = var_col\n",
        "    mods_formula = \" + \".join(spline_cols)\n",
        "\n",
        "    # 3. R Script\n",
        "    r_script = f\"\"\"\n",
        "    library(metafor)\n",
        "    dat <- df_python\n",
        "    is_aggregated <- nrow(dat) == length(unique(dat$id))\n",
        "\n",
        "    if (is_aggregated) {{\n",
        "        res <- rma(yi={eff_col}, vi={var_col}, mods = ~ {mods_formula},\n",
        "                   data=dat, method=\"REML\",\n",
        "                   control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\"))\n",
        "        tau2 <- res$tau2\n",
        "        sigma2 <- 0\n",
        "    }} else {{\n",
        "        dat$rows <- 1:nrow(dat)\n",
        "        res <- rma.mv(yi={eff_col}, V={var_col}, mods = ~ {mods_formula},\n",
        "                      random = ~ 1 | id/rows, data=dat, method=\"REML\",\n",
        "                      control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\"))\n",
        "        tau2 <- res$sigma2[1]\n",
        "        sigma2 <- res$sigma2[2]\n",
        "    }}\n",
        "    list(ll = as.numeric(logLik(res)), tau2 = tau2, sigma2 = sigma2)\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        r_res = ro.r(r_script)\n",
        "        r_ll = r_res.rx2('ll')[0]\n",
        "        r_tau2 = r_res.rx2('tau2')[0]\n",
        "        r_sigma2 = r_res.rx2('sigma2')[0]\n",
        "\n",
        "        py_ll = res_py['log_lik']\n",
        "        py_tau2 = res_py['tau_sq']\n",
        "        py_sigma2 = res_py.get('sigma_sq', 0.0)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"VALIDATION REPORT (JOURNAL PROOF)\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"{'Metric':<20} {'Python':<12} {'R (metafor)':<12} {'Diff':<12}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        def diff(a, b): return f\"{abs(a-b):.2e}\"\n",
        "        print(f\"{'Log-Likelihood':<20} {py_ll:<12.4f} {r_ll:<12.4f} {diff(py_ll, r_ll):<12}\")\n",
        "        print(f\"{'Tau¬≤ (L3)':<20} {py_tau2:<12.4f} {r_tau2:<12.4f} {diff(py_tau2, r_tau2):<12}\")\n",
        "\n",
        "        if res_py.get('model_type', '').startswith('3-Level'):\n",
        "             print(f\"{'Sigma¬≤ (L2)':<20} {py_sigma2:<12.4f} {r_sigma2:<12.4f} {diff(py_sigma2, r_sigma2):<12}\")\n",
        "\n",
        "        if abs(py_ll - r_ll) < 0.1:\n",
        "            print(\"\\n‚úÖ PERFECT MATCH: Python results are validated against R.\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è  CHECK: Minor differences found.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå R Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MJFTW9U5Fa8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üß™ R Validation: Spline Analysis (Fitted Values)\n",
        "# =============================================================================\n",
        "# CELL: SPLINE VALIDATION (ROBUST)\n",
        "# Purpose: Verify Spline Model by comparing PREDICTED VALUES (Curve).\n",
        "# Method: Bypasses coefficient mismatches by checking if X*Beta is identical.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "import patsy\n",
        "import statsmodels.api as sm\n",
        "pandas2ri.activate()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"VALIDATION STEP 5: SPLINE ANALYSIS (FITTED VALUES)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if 'ANALYSIS_CONFIG' not in globals() or 'spline_model_results' not in ANALYSIS_CONFIG:\n",
        "    print(\"‚ùå Error: Run Spline Analysis (Cell 11) first.\")\n",
        "else:\n",
        "    res_py = ANALYSIS_CONFIG['spline_model_results']\n",
        "    df_agg = res_py['reg_df'].copy()\n",
        "\n",
        "    eff_col = ANALYSIS_CONFIG['effect_col']\n",
        "    var_col = ANALYSIS_CONFIG['var_col']\n",
        "\n",
        "    print(f\"üöÄ Sending Design Matrix to R...\")\n",
        "\n",
        "    # 1. Reconstruct Python's Design Matrix (X)\n",
        "    mod_z = (df_agg[res_py['moderator_col']] - res_py['mod_mean']) / res_py['mod_std']\n",
        "    formula = res_py['formula']\n",
        "    basis_matrix = patsy.dmatrix(formula, {\"x\": mod_z}, return_type='dataframe')\n",
        "\n",
        "    # Add intercept explicitly to match Python's model\n",
        "    X_py = sm.add_constant(basis_matrix)\n",
        "\n",
        "    # 2. Prepare Data for R\n",
        "    # We create a dataframe containing Y, V, and ALL columns of X\n",
        "    df_r = df_agg[['id', eff_col, var_col]].copy()\n",
        "\n",
        "    # Add X columns to df_r\n",
        "    # Column 0 is Intercept ('const'), Columns 1..k are basis\n",
        "    x_cols = []\n",
        "    for i in range(X_py.shape[1]):\n",
        "        col_name = f'X{i}'\n",
        "        df_r[col_name] = X_py.iloc[:, i].values\n",
        "        x_cols.append(col_name)\n",
        "\n",
        "    ro.globalenv['df_python'] = df_r\n",
        "    ro.globalenv['eff_col_name'] = eff_col\n",
        "    ro.globalenv['var_col_name'] = var_col\n",
        "    ro.globalenv['fixed_tau2'] = res_py['tau_sq']\n",
        "\n",
        "    # Formula: yi ~ X0 + X1 + ... - 1 (Remove R's default intercept, use ours)\n",
        "    mods_formula = \" + \".join(x_cols) + \" - 1\"\n",
        "\n",
        "    # 3. R Script\n",
        "    r_script = f\"\"\"\n",
        "    library(metafor)\n",
        "    dat <- df_python\n",
        "\n",
        "    # Fit model using EXACT SAME design matrix columns\n",
        "    # We use intercept=FALSE (-1) because X0 is the intercept\n",
        "    res <- rma(yi={eff_col}, vi={var_col}, mods = ~ {mods_formula},\n",
        "               data=dat, method=\"REML\",\n",
        "               tau2=fixed_tau2)\n",
        "\n",
        "    list(\n",
        "        fitted = as.numeric(fitted(res)),\n",
        "        tau2 = res$tau2\n",
        "    )\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        r_res = ro.r(r_script)\n",
        "        r_fitted = np.array(r_res.rx2('fitted'))\n",
        "\n",
        "        # Python Fitted Values\n",
        "        # If saved in results, use them. If not, calculate X @ beta\n",
        "        if 'fitted' in res_py:\n",
        "            py_fitted = res_py['fitted']\n",
        "        else:\n",
        "            py_betas = res_py['betas']\n",
        "            py_fitted = X_py.values @ py_betas\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"VALIDATION REPORT (CURVE MATCH)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Compare Fitted Values\n",
        "        diff = np.abs(py_fitted - r_fitted)\n",
        "        max_diff = np.max(diff)\n",
        "        mean_diff = np.mean(diff)\n",
        "\n",
        "        print(f\"Max Difference in Predicted Curve:  {max_diff:.2e}\")\n",
        "        print(f\"Mean Difference in Predicted Curve: {mean_diff:.2e}\")\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "        # Show first 5 comparisons\n",
        "        print(f\"{'Obs':<5} {'Py Pred':<12} {'R Pred':<12} {'Diff':<12}\")\n",
        "        for i in range(min(5, len(py_fitted))):\n",
        "            print(f\"{i:<5} {py_fitted[i]:<12.4f} {r_fitted[i]:<12.4f} {diff[i]:.2e}\")\n",
        "\n",
        "        if max_diff < 1e-4:\n",
        "            print(\"\\n‚úÖ SUCCESS: Spline Curve matches R perfectly.\")\n",
        "            print(\"   (Coefficient mismatches were due to parameterization redundancy, which is now resolved.)\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è  CHECK: Curve still differs. This implies a data mismatch.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå R Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "00cZkSubBfuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TskkmGjojeOp"
      },
      "source": [
        "#@title üìâ Step 5: Publication Bias Diagnostics V2 (Dashboard)\n",
        "\n",
        "# =============================================================================\n",
        "# CELL: PUBLICATION BIAS DIAGNOSTICS WITH DASHBOARD\n",
        "# Purpose: Test for publication bias using Egger's test and Trim-and-Fill\n",
        "# Enhancement: Tabbed interface for organized results and publication text\n",
        "# Note: Use Cells 12b and 14b for visualizations (funnel plots)\n",
        "# Variables preserved for plotting cells: funnel_results, trimfill_results\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import norm, t, rankdata\n",
        "import statsmodels.api as sm\n",
        "import datetime\n",
        "from scipy.optimize import minimize\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import warnings\n",
        "\n",
        "# --- 1. LAYOUT & WIDGETS ---\n",
        "tab_egger = widgets.Output()\n",
        "tab_trimfill = widgets.Output()\n",
        "tab_combined = widgets.Output()\n",
        "tab_publication = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_egger, tab_trimfill, tab_combined, tab_publication])\n",
        "tabs.set_title(0, 'üìä Egger\\'s Test')\n",
        "tabs.set_title(1, 'üìâ Trim-and-Fill')\n",
        "tabs.set_title(2, 'üîç Combined Assessment')\n",
        "tabs.set_title(3, 'üìù Publication Text')\n",
        "\n",
        "# --- 2. HELPER FUNCTIONS ---\n",
        "\n",
        "def _neg_log_lik_reml_reg(params, y_all, v_all, X_all, N_total, M_studies, p_params):\n",
        "    est = _get_three_level_regression_estimates_v2(params, y_all, v_all, X_all, N_total, M_studies, p_params)\n",
        "    return -est['log_lik_reml']\n",
        "\n",
        "def _run_robust_eggers_test(analysis_data, effect_col, var_col, se_col):\n",
        "    \"\"\"Runs Egger's Test using 3-Level Meta-Regression on SE.\"\"\"\n",
        "    grouped = analysis_data.groupby('id')\n",
        "    y_all, v_all, X_all = [], [], []\n",
        "\n",
        "    for _, group in grouped:\n",
        "        y_all.append(group[effect_col].values)\n",
        "        v_all.append(group[var_col].values)\n",
        "        X_i = sm.add_constant(group[se_col].values, prepend=True)\n",
        "        X_all.append(X_i)\n",
        "\n",
        "    N_total = len(analysis_data)\n",
        "    M_studies = len(y_all)\n",
        "    p_params = 2\n",
        "\n",
        "    # Optimization\n",
        "    best_res = None\n",
        "    best_fun = np.inf\n",
        "    start_points = [[0.1, 0.1], [1.0, 0.1], [5.0, 0.1]]\n",
        "\n",
        "    for start in start_points:\n",
        "        res = minimize(_neg_log_lik_reml_reg, x0=start, args=(y_all, v_all, X_all, N_total, M_studies, p_params),\n",
        "                       method='L-BFGS-B', bounds=[(1e-8, None), (1e-8, None)], options={'ftol': 1e-10})\n",
        "        if res.success and res.fun < best_fun:\n",
        "            best_fun = res.fun\n",
        "            best_res = res\n",
        "\n",
        "    if not best_res:\n",
        "        return None\n",
        "\n",
        "    final_res = minimize(_neg_log_lik_reml_reg, x0=best_res.x, args=(y_all, v_all, X_all, N_total, M_studies, p_params),\n",
        "                         method='Nelder-Mead', options={'xatol': 1e-10, 'fatol': 1e-10})\n",
        "\n",
        "    return _get_three_level_regression_estimates_v2(final_res.x, y_all, v_all, X_all, N_total, M_studies, p_params)\n",
        "\n",
        "def trimfill_analysis(data, effect_col, var_col, estimator='L0', side='auto', max_iter=100):\n",
        "    \"\"\"Duval & Tweedie Trim-and-Fill Method.\"\"\"\n",
        "    yi = data[effect_col].values\n",
        "    vi = data[var_col].values\n",
        "    ni = len(yi)\n",
        "\n",
        "    sort_indices = np.argsort(yi)\n",
        "    yi = yi[sort_indices]\n",
        "    vi = vi[sort_indices]\n",
        "\n",
        "    if side == 'auto':\n",
        "        wi = 1/vi\n",
        "        pooled_fe = np.sum(wi * yi) / np.sum(wi)\n",
        "        skew = np.sum(wi * (yi - pooled_fe)**3)\n",
        "        side = 'left' if skew > 0 else 'right'\n",
        "\n",
        "    k0 = 0\n",
        "    iter_safe = 0\n",
        "\n",
        "    while iter_safe < max_iter:\n",
        "        n_curr = ni - k0\n",
        "\n",
        "        if side == 'left':\n",
        "            yi_curr = yi[:n_curr]\n",
        "            vi_curr = vi[:n_curr]\n",
        "        else:\n",
        "            yi_curr = yi[k0:]\n",
        "            vi_curr = vi[k0:]\n",
        "\n",
        "        wi_curr = 1 / vi_curr\n",
        "        pooled_fe = np.sum(wi_curr * yi_curr) / np.sum(wi_curr)\n",
        "\n",
        "        residuals = yi - pooled_fe\n",
        "        signed_res = residuals if side == 'left' else -residuals\n",
        "        abs_res = np.abs(signed_res)\n",
        "        ranks = rankdata(abs_res, method='average')\n",
        "\n",
        "        pos_ranks = np.where(signed_res > 0, ranks, 0)\n",
        "        Sn = np.sum(pos_ranks)\n",
        "\n",
        "        k0_new = int(round((4 * Sn - ni * (ni + 1)) / (2 * ni - 1)))\n",
        "        k0_new = max(0, k0_new)\n",
        "\n",
        "        if k0_new == k0:\n",
        "            break\n",
        "\n",
        "        k0 = k0_new\n",
        "        k0 = min(k0, ni - 2)\n",
        "        iter_safe += 1\n",
        "\n",
        "    if k0 > 0:\n",
        "        if side == 'left':\n",
        "            idx_fill = slice(ni - k0, ni)\n",
        "        else:\n",
        "            idx_fill = slice(0, k0)\n",
        "\n",
        "        yi_excess = yi[idx_fill]\n",
        "        vi_excess = vi[idx_fill]\n",
        "\n",
        "        yi_filled = 2 * pooled_fe - yi_excess\n",
        "        vi_filled = vi_excess\n",
        "\n",
        "        yi_final = np.concatenate([yi, yi_filled])\n",
        "        vi_final = np.concatenate([vi, vi_filled])\n",
        "    else:\n",
        "        yi_final = yi\n",
        "        vi_final = vi\n",
        "        yi_filled = []\n",
        "        vi_filled = []\n",
        "\n",
        "    wi_final = 1 / vi_final\n",
        "    pooled_final = np.sum(wi_final * yi_final) / np.sum(wi_final)\n",
        "    var_final = 1 / np.sum(wi_final)\n",
        "    se_final = np.sqrt(var_final)\n",
        "\n",
        "    wi_orig = 1 / vi\n",
        "    pooled_orig = np.sum(wi_orig * yi) / np.sum(wi_orig)\n",
        "    se_orig = np.sqrt(1 / np.sum(wi_orig))\n",
        "\n",
        "    return {\n",
        "        'k0': k0,\n",
        "        'side': side,\n",
        "        'pooled_original': pooled_orig,\n",
        "        'se_original': se_orig,\n",
        "        'ci_lower_original': pooled_orig - 1.96*se_orig,\n",
        "        'ci_upper_original': pooled_orig + 1.96*se_orig,\n",
        "        'pooled_filled': pooled_final,\n",
        "        'se_filled': se_final,\n",
        "        'ci_lower_filled': pooled_final - 1.96*se_final,\n",
        "        'ci_upper_filled': pooled_final + 1.96*se_final,\n",
        "        'yi_filled': yi_filled,\n",
        "        'vi_filled': vi_filled if k0 > 0 else [],\n",
        "        'yi_combined': yi_final,\n",
        "        'vi_combined': vi_final\n",
        "    }\n",
        "\n",
        "def generate_publication_bias_text(egger_result, tf_result, n_studies):\n",
        "    \"\"\"Generate publication-ready text for publication bias assessment\"\"\"\n",
        "\n",
        "    egger_p = egger_result['p_value']\n",
        "    egger_int = egger_result['intercept']\n",
        "    egger_se = egger_result['se']\n",
        "\n",
        "    k0 = tf_result['k0']\n",
        "    side = tf_result['side']\n",
        "    orig_effect = tf_result['pooled_original']\n",
        "    adj_effect = tf_result['pooled_filled']\n",
        "\n",
        "    egger_sig = egger_p < 0.05\n",
        "    tf_bias = k0 > 0\n",
        "\n",
        "    # Significance text\n",
        "    egger_sig_text = \"significant\" if egger_sig else \"non-significant\"\n",
        "    p_format = f\"< 0.001\" if egger_p < 0.001 else f\"= {egger_p:.3f}\"\n",
        "\n",
        "    text = f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt; line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "<h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>Publication Bias Assessment</h3>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "We assessed potential publication bias using two complementary methods: Egger's regression test for funnel plot asymmetry and the Duval and Tweedie trim-and-fill procedure.\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Egger's Regression Test</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Egger's regression test evaluates funnel plot asymmetry by regressing effect sizes on their standard errors, with the intercept testing for asymmetry. We employed a three-level meta-regression model to account for the nested structure of effect sizes within studies, providing robust estimates that accommodate within-study dependencies.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The Egger's test intercept was <b>{egger_sig_text}</b> (Œ≤‚ÇÄ = {egger_int:.3f}, SE = {egger_se:.3f}, <i>p</i> {p_format}). \"\"\"\n",
        "\n",
        "    if egger_sig:\n",
        "        text += f\"\"\"This indicates <b>significant funnel plot asymmetry</b>, suggesting potential publication bias or other sources of small-study effects. The {'positive' if egger_int > 0 else 'negative'} intercept suggests that smaller studies tend to report {'larger' if egger_int > 0 else 'smaller'} effect sizes than larger studies.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "However, it is important to note that funnel plot asymmetry can arise from sources other than publication bias, including genuine heterogeneity, chance, or differences in methodological quality between small and large studies. [<i>Consider discussing which alternative explanation(s) might apply to your meta-analysis.</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"This suggests <b>no significant funnel plot asymmetry</b>, providing little evidence of publication bias based on this test. The symmetry of effect sizes across studies of different sizes supports the validity of the meta-analytic findings.\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "    # Trim-and-fill section\n",
        "    text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Trim-and-Fill Analysis</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The trim-and-fill method (Duval & Tweedie, 2000) provides a non-parametric approach to estimating the number of studies missing due to publication bias. The procedure iteratively trims the most extreme small studies from the {'positive' if side == 'right' else 'negative'} side of the funnel plot, re-computes the pooled effect, and then adds (fills) imputed mirror-image studies to restore funnel plot symmetry.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "\"\"\"\n",
        "\n",
        "    if k0 == 0:\n",
        "        text += f\"\"\"The trim-and-fill procedure estimated <b>zero missing studies</b> (k‚ÇÄ = 0), suggesting no asymmetry in the distribution of effect sizes. The pooled effect estimate remained unchanged at {orig_effect:.3f} (95% CI [{tf_result['ci_lower_original']:.3f}, {tf_result['ci_upper_original']:.3f}]).\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "This result is consistent with low risk of publication bias and suggests that the observed pooled effect size is robust to selective reporting.\n",
        "</p>\n",
        "\"\"\"\n",
        "    else:\n",
        "        pct_change = abs((adj_effect - orig_effect) / orig_effect) * 100 if orig_effect != 0 else 0\n",
        "        direction_change = \"decreased\" if adj_effect < orig_effect else \"increased\"\n",
        "\n",
        "        text += f\"\"\"The trim-and-fill procedure estimated <b>{k0} potentially missing studies</b> on the {side} side of the funnel plot. After imputing these missing studies, the adjusted pooled effect was {adj_effect:.3f} (95% CI [{tf_result['ci_lower_filled']:.3f}, {tf_result['ci_upper_filled']:.3f}]), compared to the original estimate of {orig_effect:.3f} (95% CI [{tf_result['ci_lower_original']:.3f}, {tf_result['ci_upper_original']:.3f}]).\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The pooled effect {direction_change} by <b>{abs(adj_effect - orig_effect):.3f}</b> units ({pct_change:.1f}% relative change) after adjustment. \"\"\"\n",
        "\n",
        "        if pct_change > 20:\n",
        "            text += f\"\"\"This substantial change suggests that publication bias, if present, could have a meaningful impact on the meta-analytic conclusions. The adjusted estimate should be considered as a sensitivity analysis, though it should be noted that trim-and-fill can sometimes overestimate the number of missing studies.\n",
        "\"\"\"\n",
        "        elif pct_change > 10:\n",
        "            text += f\"\"\"This moderate change suggests some potential impact of publication bias on the pooled estimate, though the direction and significance of the effect remain {'' if adj_effect * orig_effect > 0 else 'un'}consistent between original and adjusted estimates.\n",
        "\"\"\"\n",
        "        else:\n",
        "            text += f\"\"\"This small change suggests that publication bias, if present, has minimal impact on the meta-analytic conclusions. The robustness of the pooled estimate to adjustment increases confidence in the findings.\n",
        "\"\"\"\n",
        "\n",
        "        text += \"</p>\"\n",
        "\n",
        "    # Combined interpretation\n",
        "    text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Combined Interpretation</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "\"\"\"\n",
        "\n",
        "    if egger_sig and tf_bias:\n",
        "        text += f\"\"\"Both Egger's test and the trim-and-fill procedure suggest potential publication bias. Egger's test detected significant asymmetry (p {p_format}), and trim-and-fill estimated {k0} missing studies. This convergent evidence warrants cautious interpretation of the meta-analytic findings. \"\"\"\n",
        "        if k0 > 0:\n",
        "            pct_change = abs((adj_effect - orig_effect) / orig_effect) * 100 if orig_effect != 0 else 0\n",
        "            if pct_change > 10:\n",
        "                text += f\"\"\"Given the substantial adjustment to the pooled effect ({pct_change:.1f}% change), we recommend reporting both the original and adjusted estimates and considering the adjusted estimate in sensitivity analyses.\n",
        "\"\"\"\n",
        "            else:\n",
        "                text += f\"\"\"However, the modest change in the pooled effect ({pct_change:.1f}%) suggests the main conclusions are relatively robust to potential publication bias.\n",
        "\"\"\"\n",
        "    elif egger_sig or tf_bias:\n",
        "        which_test = \"Egger's test\" if egger_sig else \"trim-and-fill\"\n",
        "        text += f\"\"\"The evidence for publication bias is mixed. {which_test.capitalize()} suggests potential bias, but the other test does not. This inconsistency could reflect differences in what these tests detect (asymmetry vs. missing studies) or limited statistical power. We recommend interpreting results with appropriate caution and considering whether other factors (heterogeneity, methodological quality) might explain any observed asymmetry.\n",
        "\"\"\"\n",
        "    else:\n",
        "        text += f\"\"\"Neither Egger's test nor trim-and-fill provided evidence of publication bias. The non-significant Egger's intercept (p {p_format}) and absence of estimated missing studies (k‚ÇÄ = 0) both suggest low risk of selective reporting. These results support the validity and robustness of the meta-analytic findings.\n",
        "\"\"\"\n",
        "\n",
        "    text += \"</p>\"\n",
        "\n",
        "    # Recommendations\n",
        "    text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Recommendations</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Publication bias assessments should be interpreted in context with other factors:\n",
        "</p>\n",
        "\n",
        "<ul style='line-height: 2.0;'>\n",
        "<li><b>Sample size:</b> With k = {n_studies} studies, statistical power to detect publication bias is {'adequate' if n_studies >= 10 else 'limited' if n_studies >= 5 else 'very limited'}.</li>\n",
        "<li><b>Heterogeneity:</b> High heterogeneity can create asymmetry independent of publication bias.</li>\n",
        "<li><b>Study quality:</b> Smaller studies may differ systematically in design or quality.</li>\n",
        "<li><b>Registry searching:</b> {'Evidence from trial registries or grey literature could strengthen confidence in the absence of bias.' if not (egger_sig or tf_bias) else 'Searching trial registries and grey literature is recommended to identify potential unpublished studies.'}</li>\n",
        "</ul>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "[<i>Add domain-specific discussion: Are there known reporting biases in this field? Were efforts made to locate unpublished data? Are funnel plots shown in the manuscript?</i>]\n",
        "</p>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 25px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>üìä Table 1. Publication Bias Assessment Summary</h4>\n",
        "<table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "<thead style='background-color: #34495e; color: white;'>\n",
        "<tr>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Test</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Statistic</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>p-value</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Interpretation</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Egger's Test</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>Œ≤‚ÇÄ = {egger_int:.3f} (SE = {egger_se:.3f})</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{\"<0.001\" if egger_p < 0.001 else f\"{egger_p:.3f}\"}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>{\"Significant asymmetry\" if egger_sig else \"No significant asymmetry\"}</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Trim-and-Fill</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>k‚ÇÄ = {k0} ({side} side)</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>‚Äî</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>{\"Missing studies detected\" if k0 > 0 else \"No missing studies\"}</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 15px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>üìä Table 2. Effect Size Estimates</h4>\n",
        "<table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "<thead style='background-color: #34495e; color: white;'>\n",
        "<tr>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Model</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Pooled Effect</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>95% CI</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Change</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Original</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{orig_effect:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{tf_result['ci_lower_original']:.3f}, {tf_result['ci_upper_original']:.3f}]</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>‚Äî</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Trim-and-Fill Adjusted</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{adj_effect:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{tf_result['ci_lower_filled']:.3f}, {tf_result['ci_upper_filled']:.3f}]</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{adj_effect - orig_effect:+.3f}</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "<p style='margin-top: 10px; font-size: 0.9em; color: #6c757d;'><i>Note:</i> Negative change indicates adjusted effect is smaller than original.</p>\n",
        "</div>\n",
        "\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; margin-top: 20px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "<ul style='margin-bottom: 0;'>\n",
        "<li>Customize interpretation based on your specific research domain and context</li>\n",
        "<li>Consider whether alternative explanations for asymmetry are plausible</li>\n",
        "<li>Discuss efforts to locate unpublished studies (registries, grey literature)</li>\n",
        "<li>Mention funnel plots if included in your manuscript (Cells 12b and 14b)</li>\n",
        "<li>If bias is detected, discuss impact on conclusions and consider sensitivity analyses</li>\n",
        "<li>Link to pre-registration or protocol if available</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "<p style='margin: 0;'><b>üí° Tip:</b> Select all text (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C), and paste into your word processor. Use Cells 12b and 14b to generate funnel plots for your manuscript figures.</p>\n",
        "</div>\n",
        "\n",
        "</div>\"\"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# --- 3. MAIN ANALYSIS FUNCTION ---\n",
        "def run_publication_bias_analysis():\n",
        "    \"\"\"Run both Egger's test and Trim-and-Fill\"\"\"\n",
        "\n",
        "    # Clear all tabs\n",
        "    for tab in [tab_egger, tab_trimfill, tab_combined, tab_publication]:\n",
        "        tab.clear_output()\n",
        "\n",
        "    # Check prerequisites\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        with tab_egger:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå ANALYSIS_CONFIG not found. Run Step 1 first.</div>\"))\n",
        "        return\n",
        "\n",
        "    if 'three_level_results' not in ANALYSIS_CONFIG:\n",
        "        with tab_egger:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå Three-level results not found. Run Step 2 first.</div>\"))\n",
        "        return\n",
        "\n",
        "    effect_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "    var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "    se_col = ANALYSIS_CONFIG.get('se_col', 'SE_g')\n",
        "\n",
        "    if 'analysis_data' in ANALYSIS_CONFIG:\n",
        "        df_plot = ANALYSIS_CONFIG['analysis_data']\n",
        "    elif 'data_filtered' in globals():\n",
        "        df_plot = data_filtered\n",
        "    else:\n",
        "        with tab_egger:\n",
        "            display(HTML(\"<div style='color: red;'>‚ùå No analysis data found.</div>\"))\n",
        "        return\n",
        "\n",
        "    n_obs = len(df_plot)\n",
        "    n_studies = df_plot['id'].nunique()\n",
        "\n",
        "    # --- RUN EGGER'S TEST ---\n",
        "    egger_est = None\n",
        "    try:\n",
        "        egger_est = _run_robust_eggers_test(df_plot, effect_col, var_col, se_col)\n",
        "\n",
        "        if egger_est:\n",
        "            intercept = egger_est['betas'][0]\n",
        "            slope_val = egger_est['betas'][1] #added for validation\n",
        "            se_intercept = egger_est['se_betas'][0]\n",
        "            t_stat = intercept / se_intercept\n",
        "            df = egger_est.get('df', 100)\n",
        "            p_value = 2 * (1 - t.cdf(abs(t_stat), df))\n",
        "\n",
        "            # Save results (CRITICAL for plotting cell 12b)\n",
        "            ANALYSIS_CONFIG['funnel_results'] = {\n",
        "                'beta_slope': slope_val,\n",
        "                'timestamp': datetime.datetime.now(),\n",
        "                'intercept': intercept,\n",
        "                'se': se_intercept,\n",
        "                'p_value': p_value,\n",
        "                'estimates': egger_est\n",
        "            }\n",
        "\n",
        "            # --- TAB 1: EGGER'S TEST ---\n",
        "            with tab_egger:\n",
        "                sig = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
        "                color = \"#dc3545\" if p_value < 0.05 else \"#28a745\"\n",
        "\n",
        "                html = f\"\"\"\n",
        "                <div style='padding: 20px;'>\n",
        "                <h2 style='color: #2c3e50; margin-bottom: 20px;'>Egger's Regression Test for Funnel Plot Asymmetry</h2>\n",
        "\n",
        "                <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "                    <div style='text-align: center;'>\n",
        "                        <div style='font-size: 0.9em; margin-bottom: 10px;'>ASYMMETRY TEST</div>\n",
        "                        <h1 style='margin: 0; font-size: 2.5em;'>{\"Significant\" if p_value < 0.05 else \"Not Significant\"}</h1>\n",
        "                        <p style='margin: 10px 0 0 0; font-size: 1.2em;'>p {p_value:.4g} {sig}</p>\n",
        "                    </div>\n",
        "                </div>\n",
        "\n",
        "                <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-bottom: 20px;'>\n",
        "                    <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #007bff;'>\n",
        "                        <div style='color: #6c757d; font-size: 0.9em;'>Intercept (Œ≤‚ÇÄ)</div>\n",
        "                        <div style='font-size: 1.5em; font-weight: bold;'>{intercept:.4f}</div>\n",
        "                        <div style='color: #6c757d; font-size: 0.85em; margin-top: 5px;'>SE = {se_intercept:.4f}</div>\n",
        "                    </div>\n",
        "                    <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid {color};'>\n",
        "                        <div style='color: #6c757d; font-size: 0.9em;'>P-value</div>\n",
        "                        <div style='font-size: 1.5em; font-weight: bold; color: {color};'>{p_value:.4g}</div>\n",
        "                        <div style='color: #6c757d; font-size: 0.85em; margin-top: 5px;'>t({df}) = {t_stat:.2f}</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "\n",
        "                <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "                    <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "                    <p style='margin: 0; font-size: 1.05em;'>\n",
        "                \"\"\"\n",
        "\n",
        "                if p_value < 0.05:\n",
        "                    html += f\"\"\"<b style='color: #dc3545;'>‚ö†Ô∏è Significant funnel plot asymmetry detected.</b><br>\n",
        "                        This suggests potential publication bias or other sources of small-study effects.\n",
        "                        Smaller studies tend to report {'larger' if intercept > 0 else 'smaller'} effect sizes than larger studies.\n",
        "                        <br><br>However, asymmetry can also arise from genuine heterogeneity, methodological differences, or chance.\"\"\"\n",
        "                elif p_value < 0.10:\n",
        "                    html += f\"\"\"<b style='color: #ffc107;'>‚ö° Marginal evidence of asymmetry (p < 0.10).</b><br>\n",
        "                        Some suggestion of funnel plot asymmetry. Consider examining the funnel plot visually (Cell 12b).\"\"\"\n",
        "                else:\n",
        "                    html += f\"\"\"<b style='color: #28a745;'>‚úì No significant funnel plot asymmetry.</b><br>\n",
        "                        Little evidence of publication bias based on Egger's test. The distribution of effect sizes appears symmetric across study sizes.\"\"\"\n",
        "\n",
        "                html += f\"\"\"\n",
        "                    </p>\n",
        "                </div>\n",
        "\n",
        "                <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Test Details</h3>\n",
        "                <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                    <p style='margin: 5px 0;'><b>Method:</b> Three-level meta-regression (robust to within-study dependencies)</p>\n",
        "                    <p style='margin: 5px 0;'><b>Predictor:</b> Standard error (SE)</p>\n",
        "                    <p style='margin: 5px 0;'><b>Outcome:</b> Effect size</p>\n",
        "                    <p style='margin: 5px 0;'><b>Sample:</b> {n_obs} observations from {n_studies} studies</p>\n",
        "                    <p style='margin: 5px 0;'><b>Degrees of Freedom:</b> {df}</p>\n",
        "                </div>\n",
        "\n",
        "                <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "                    <p style='margin: 0;'><b>üìä Next Step:</b> Use Cell 12b to generate the funnel plot for visual inspection of asymmetry.</p>\n",
        "                </div>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "                display(HTML(html))\n",
        "\n",
        "    except Exception as e:\n",
        "        with tab_egger:\n",
        "            display(HTML(f\"<div style='color: red;'>‚ùå Error running Egger's test: {e}</div>\"))\n",
        "\n",
        "    # --- RUN TRIM-AND-FILL ---\n",
        "    tf_res = None\n",
        "    try:\n",
        "        tf_res = trimfill_analysis(df_plot, effect_col, var_col, side='auto')\n",
        "\n",
        "        # Save results (CRITICAL for plotting cell 14b)\n",
        "        ANALYSIS_CONFIG['trimfill_results'] = tf_res\n",
        "\n",
        "        # --- TAB 2: TRIM-AND-FILL ---\n",
        "        with tab_trimfill:\n",
        "            k0 = tf_res['k0']\n",
        "            color = \"#dc3545\" if k0 > 0 else \"#28a745\"\n",
        "            pct_change = abs((tf_res['pooled_filled'] - tf_res['pooled_original']) / tf_res['pooled_original']) * 100 if tf_res['pooled_original'] != 0 else 0\n",
        "\n",
        "            html = f\"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h2 style='color: #2c3e50; margin-bottom: 20px;'>Trim-and-Fill Analysis</h2>\n",
        "\n",
        "            <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; margin-bottom: 10px;'>ESTIMATED MISSING STUDIES</div>\n",
        "                    <h1 style='margin: 0; font-size: 3em;'>{k0}</h1>\n",
        "                    <p style='margin: 10px 0 0 0; font-size: 1.2em;'>{tf_res['side'].capitalize()} side</p>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "                <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "                <p style='margin: 0; font-size: 1.05em;'>\n",
        "            \"\"\"\n",
        "\n",
        "            if k0 == 0:\n",
        "                html += \"\"\"<b style='color: #28a745;'>‚úì No missing studies detected.</b><br>\n",
        "                    The funnel plot appears symmetric. No evidence of publication bias via trim-and-fill.\"\"\"\n",
        "            else:\n",
        "                html += f\"\"\"<b style='color: #dc3545;'>‚ö†Ô∏è {k0} potentially missing studies estimated.</b><br>\n",
        "                    After imputation, the effect changes by {pct_change:.1f}%. This suggests {'substantial' if pct_change > 20 else 'moderate' if pct_change > 10 else 'minimal'} potential impact of publication bias.\"\"\"\n",
        "\n",
        "            html += f\"\"\"\n",
        "                </p>\n",
        "            </div>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Effect Size Comparison</h3>\n",
        "            <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "                <thead style='background-color: #2c3e50; color: white;'>\n",
        "                    <tr>\n",
        "                        <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Estimate</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Effect</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>SE</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>95% CI</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr style='background-color: #f8f9fa;'>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Original</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_res['pooled_original']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_res['se_original']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{tf_res['ci_lower_original']:.4f}, {tf_res['ci_upper_original']:.4f}]</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Adjusted</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_res['pooled_filled']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_res['se_filled']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{tf_res['ci_lower_filled']:.4f}, {tf_res['ci_upper_filled']:.4f}]</td>\n",
        "                    </tr>\n",
        "                    <tr style='background-color: #fff3cd;'>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Change</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;'>{tf_res['pooled_filled'] - tf_res['pooled_original']:+.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>‚Äî</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{pct_change:.1f}% change</td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Method Details</h3>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                <p style='margin: 5px 0;'><b>Method:</b> Duval & Tweedie L0 estimator</p>\n",
        "                <p style='margin: 5px 0;'><b>Side:</b> {tf_res['side'].capitalize()} (automatically detected)</p>\n",
        "                <p style='margin: 5px 0;'><b>Original studies:</b> {n_obs} observations from {n_studies} studies</p>\n",
        "                <p style='margin: 5px 0;'><b>Imputed studies:</b> {k0}</p>\n",
        "                <p style='margin: 5px 0;'><b>Total after filling:</b> {n_obs + k0}</p>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "                <p style='margin: 0;'><b>üìä Next Step:</b> Use Cell 14b to visualize the trim-and-fill funnel plot showing original and imputed studies.</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "            display(HTML(html))\n",
        "\n",
        "    except Exception as e:\n",
        "        with tab_trimfill:\n",
        "            display(HTML(f\"<div style='color: red;'>‚ùå Error running Trim-and-Fill: {e}</div>\"))\n",
        "\n",
        "    # --- TAB 3: COMBINED ASSESSMENT ---\n",
        "    if egger_est and tf_res:\n",
        "        with tab_combined:\n",
        "            egger_p = ANALYSIS_CONFIG['funnel_results']['p_value']\n",
        "            k0 = tf_res['k0']\n",
        "\n",
        "            egger_bias = egger_p < 0.10\n",
        "            tf_bias = k0 > 0\n",
        "\n",
        "            # Determine overall assessment\n",
        "            if egger_bias and tf_bias:\n",
        "                assessment = \"HIGH RISK\"\n",
        "                color = \"#dc3545\"\n",
        "                icon = \"‚ö†Ô∏è\"\n",
        "                message = \"Both tests suggest publication bias\"\n",
        "            elif egger_bias or tf_bias:\n",
        "                assessment = \"MODERATE RISK\"\n",
        "                color = \"#ffc107\"\n",
        "                icon = \"‚ö°\"\n",
        "                message = \"One test suggests publication bias\"\n",
        "            else:\n",
        "                assessment = \"LOW RISK\"\n",
        "                color = \"#28a745\"\n",
        "                icon = \"‚úì\"\n",
        "                message = \"Neither test suggests publication bias\"\n",
        "\n",
        "            html = f\"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h2 style='color: #2c3e50; margin-bottom: 20px;'>Combined Publication Bias Assessment</h2>\n",
        "\n",
        "            <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; margin-bottom: 10px;'>OVERALL ASSESSMENT</div>\n",
        "                    <h1 style='margin: 0; font-size: 2.5em;'>{icon} {assessment}</h1>\n",
        "                    <p style='margin: 10px 0 0 0; font-size: 1.2em;'>{message}</p>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Summary of Tests</h3>\n",
        "            <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "                <thead style='background-color: #2c3e50; color: white;'>\n",
        "                    <tr>\n",
        "                        <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Test</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Result</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Evidence of Bias</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr style='background-color: #f8f9fa;'>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Egger's Test</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>p = {egger_p:.4g}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>\n",
        "                            <span style='color: {\"#dc3545\" if egger_bias else \"#28a745\"}; font-weight: bold;'>\n",
        "                                {\"Yes\" if egger_bias else \"No\"}\n",
        "                            </span>\n",
        "                        </td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Trim-and-Fill</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>k‚ÇÄ = {k0}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>\n",
        "                            <span style='color: {\"#dc3545\" if tf_bias else \"#28a745\"}; font-weight: bold;'>\n",
        "                                {\"Yes\" if tf_bias else \"No\"}\n",
        "                            </span>\n",
        "                        </td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Detailed Interpretation</h3>\n",
        "            <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            \"\"\"\n",
        "\n",
        "            if egger_bias and tf_bias:\n",
        "                html += f\"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Convergent Evidence:</b> Both tests indicate potential publication bias.</p>\n",
        "                <ul style='margin: 10px 0;'>\n",
        "                    <li>Egger's test detected significant funnel plot asymmetry (p = {egger_p:.4g})</li>\n",
        "                    <li>Trim-and-fill estimated {k0} missing studies</li>\n",
        "                    <li>Effect size changed by {pct_change:.1f}% after adjustment</li>\n",
        "                </ul>\n",
        "                <p style='margin: 10px 0 0 0;'><b>Recommendation:</b> Interpret main results with caution. Consider reporting both original and adjusted estimates. Discuss potential impact of publication bias on conclusions.</p>\n",
        "                \"\"\"\n",
        "            elif egger_bias or tf_bias:\n",
        "                which = \"Egger's test\" if egger_bias else \"Trim-and-fill\"\n",
        "                which_not = \"Trim-and-fill\" if egger_bias else \"Egger's test\"\n",
        "                html += f\"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Mixed Evidence:</b> {which} suggests bias, but {which_not} does not.</p>\n",
        "                <ul style='margin: 10px 0;'>\n",
        "                    <li>{'Funnel plot asymmetry detected' if egger_bias else 'No significant asymmetry'} (Egger p = {egger_p:.4g})</li>\n",
        "                    <li>{k0} missing studies estimated (Trim-and-fill)</li>\n",
        "                </ul>\n",
        "                <p style='margin: 10px 0 0 0;'><b>Recommendation:</b> Exercise appropriate caution. Differences between tests may reflect limited power or different aspects of bias. Visual inspection of funnel plots recommended.</p>\n",
        "                \"\"\"\n",
        "            else:\n",
        "                html += f\"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Consistent Evidence:</b> Neither test provides evidence of publication bias.</p>\n",
        "                <ul style='margin: 10px 0;'>\n",
        "                    <li>No significant funnel plot asymmetry (Egger p = {egger_p:.4g})</li>\n",
        "                    <li>No missing studies estimated (k‚ÇÄ = 0)</li>\n",
        "                </ul>\n",
        "                <p style='margin: 10px 0 0 0;'><b>Recommendation:</b> Main results appear robust to publication bias. Standard reporting is appropriate.</p>\n",
        "                \"\"\"\n",
        "\n",
        "            html += f\"\"\"\n",
        "            </div>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Contextual Factors</h3>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                <p style='margin: 5px 0;'><b>Sample size:</b> k = {n_studies} studies {'(adequate power)' if n_studies >= 10 else '(limited power)' if n_studies >= 5 else '(very limited power)'}</p>\n",
        "                <p style='margin: 5px 0;'><i>Note: Publication bias tests have limited power with fewer than 10 studies</i></p>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "                <p style='margin: 0;'><b>üìä Visualization:</b> Use Cells 12b and 14b to create funnel plots for visual assessment and manuscript figures.</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "            display(HTML(html))\n",
        "\n",
        "    # --- TAB 4: PUBLICATION TEXT ---\n",
        "    if egger_est and tf_res:\n",
        "        with tab_publication:\n",
        "            display(HTML(\"<h3 style='color: #2c3e50;'>üìù Publication-Ready Results Text</h3>\"))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "            pub_text = generate_publication_bias_text(\n",
        "                ANALYSIS_CONFIG['funnel_results'],\n",
        "                tf_res,\n",
        "                n_studies\n",
        "            )\n",
        "\n",
        "            display(HTML(pub_text))\n",
        "\n",
        "# --- 4. RUN BUTTON ---\n",
        "run_button = widgets.Button(\n",
        "    description='‚ñ∂ Run Publication Bias Analysis',\n",
        "    button_style='primary',\n",
        "    icon='play',\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "run_button.on_click(lambda b: run_publication_bias_analysis())\n",
        "\n",
        "# --- 5. DISPLAY UI ---\n",
        "display(HTML(\"<h3>üìâ Publication Bias Diagnostics (V2)</h3>\"))\n",
        "display(HTML(\"<p style='color: #6c757d;'>Assess publication bias using Egger's test and Trim-and-Fill. Results appear in organized tabs below.</p>\"))\n",
        "display(run_button)\n",
        "display(tabs)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üß™ R Validation: Egger's Test (Self-Contained)\n",
        "# =============================================================================\n",
        "# CELL: EGGER'S TEST VALIDATION (ROBUST)\n",
        "# Purpose: Calculate Egger's Regression in Python (locally) and compare to R.\n",
        "# Fix: Removes dependency on Dashboard state by re-running Python calc here.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "from scipy.stats import t\n",
        "import statsmodels.api as sm\n",
        "from scipy.optimize import minimize\n",
        "import warnings\n",
        "\n",
        "pandas2ri.activate()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"VALIDATION STEP: ROBUST EGGER'S TEST (DIRECT)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# --- 1. GET DATA ---\n",
        "if 'analysis_data' in globals():\n",
        "    df_bias_check = analysis_data.copy()\n",
        "elif 'data_filtered' in globals():\n",
        "    df_bias_check = data_filtered.copy()\n",
        "else:\n",
        "    print(\"‚ùå Error: Data not found. Run previous cells first.\")\n",
        "    df_bias_check = None\n",
        "\n",
        "if df_bias_check is not None:\n",
        "    # Config\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "        var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "        se_col = ANALYSIS_CONFIG.get('se_col', 'SE_g')\n",
        "    else:\n",
        "        eff_col = 'hedges_g'; var_col = 'Vg'; se_col = 'SE_g'\n",
        "\n",
        "    print(f\"   Model: {eff_col} ~ {se_col} (random = ~1|study/id)\")\n",
        "\n",
        "    # Clean data\n",
        "    df_r = df_bias_check[['id', eff_col, var_col, se_col]].dropna()\n",
        "    df_r = df_r[df_r[var_col] > 0]\n",
        "\n",
        "    # --- 2. RUN PYTHON CALCULATION (LOCAL) ---\n",
        "    print(\"‚öôÔ∏è  Calculating Python Estimates locally...\")\n",
        "\n",
        "    # Re-implementing the regression logic here to ensure we have a value\n",
        "    # This mirrors _run_three_level_reml_regression_v2 logic essentially\n",
        "    def get_python_eggers(df, eff, var, se):\n",
        "        grouped = df.groupby('id')\n",
        "        y_all = [g[eff].values for _, g in grouped]\n",
        "        v_all = [g[var].values for _, g in grouped]\n",
        "        # X is SE (Standard Error)\n",
        "        X_all = [sm.add_constant(g[se].values, prepend=True) for _, g in grouped]\n",
        "\n",
        "        N_total = len(df)\n",
        "        M_studies = len(y_all)\n",
        "\n",
        "        # Negative Log Likelihood for REML (Simplified for this cell)\n",
        "        def nll(params):\n",
        "            tau2, sigma2 = params\n",
        "            if tau2 < 0 or sigma2 < 0: return 1e10\n",
        "\n",
        "            sum_log_det = 0\n",
        "            sum_XtViX = np.zeros((2,2))\n",
        "            sum_XtViy = np.zeros(2)\n",
        "            sum_yViy = 0\n",
        "\n",
        "            for i in range(M_studies):\n",
        "                y, v, X = y_all[i], v_all[i], X_all[i]\n",
        "                # Vi = sigma2*I + D + tau2*J\n",
        "                # Inversion via Sherman-Morrison\n",
        "                D_inv = 1.0 / (v + sigma2)\n",
        "                sum_D_inv = np.sum(D_inv)\n",
        "                denom = 1 + tau2 * sum_D_inv\n",
        "\n",
        "                # Log Det\n",
        "                sum_log_det += np.sum(np.log(v + sigma2)) + np.log(denom)\n",
        "\n",
        "                # Vi_inv * y\n",
        "                # w = D_inv - (tau2 / denom) * D_inv @ J @ D_inv\n",
        "                # J is all ones. D_inv is diagonal.\n",
        "\n",
        "                # Matrix ops without full matrix creation\n",
        "                # Vi_inv_y = D_inv * y - (tau2/denom) * sum(D_inv * y) * D_inv\n",
        "                D_inv_y = D_inv * y\n",
        "                sum_D_inv_y = np.sum(D_inv_y)\n",
        "                Vi_inv_y = D_inv_y - (tau2 * sum_D_inv_y / denom) * D_inv\n",
        "\n",
        "                # Xt * Vi_inv * y\n",
        "                sum_XtViy += X.T @ Vi_inv_y\n",
        "\n",
        "                # y * Vi_inv * y\n",
        "                sum_yViy += np.dot(y, Vi_inv_y)\n",
        "\n",
        "                # Xt * Vi_inv * X\n",
        "                # Term 1: X.T @ D_inv @ X\n",
        "                t1 = X.T @ (D_inv[:, None] * X)\n",
        "\n",
        "                # Term 2: (tau2/denom) * (X.T @ D_inv @ 1) @ (1.T @ D_inv @ X)\n",
        "                # Note: D_inv @ 1 is just D_inv vector\n",
        "                Xt_D_inv_1 = X.T @ D_inv\n",
        "                t2 = (tau2 / denom) * np.outer(Xt_D_inv_1, Xt_D_inv_1)\n",
        "\n",
        "                sum_XtViX += (t1 - t2)\n",
        "\n",
        "            # Solve for Beta\n",
        "            try:\n",
        "                betas = np.linalg.solve(sum_XtViX, sum_XtViy)\n",
        "            except: return 1e10\n",
        "\n",
        "            # Residual\n",
        "            resid = sum_yViy - np.dot(betas, sum_XtViy)\n",
        "\n",
        "            # Log Likelihood\n",
        "            sign, log_det_XtViX = np.linalg.slogdet(sum_XtViX)\n",
        "            ll = -0.5 * (sum_log_det + log_det_XtViX + resid)\n",
        "            return -ll\n",
        "\n",
        "        # Optimize\n",
        "        res = minimize(nll, [0.1, 0.1], bounds=[(1e-8,None), (1e-8,None)], method='L-BFGS-B')\n",
        "        if not res.success:\n",
        "             res = minimize(nll, res.x, bounds=[(1e-8,None), (1e-8,None)], method='Nelder-Mead')\n",
        "\n",
        "        # Re-calculate betas at optimum\n",
        "        tau2, sigma2 = res.x\n",
        "        # ... (Repeat calculation of sum_XtViX and sum_XtViy to get betas)\n",
        "        # Simplified re-run for readability\n",
        "        sum_XtViX = np.zeros((2,2))\n",
        "        sum_XtViy = np.zeros(2)\n",
        "        for i in range(M_studies):\n",
        "            y, v, X = y_all[i], v_all[i], X_all[i]\n",
        "            D_inv = 1.0 / (v + sigma2)\n",
        "            sum_D_inv = np.sum(D_inv)\n",
        "            denom = 1 + tau2 * sum_D_inv\n",
        "            D_inv_y = D_inv * y\n",
        "            sum_D_inv_y = np.sum(D_inv_y)\n",
        "            Vi_inv_y = D_inv_y - (tau2 * sum_D_inv_y / denom) * D_inv\n",
        "            sum_XtViy += X.T @ Vi_inv_y\n",
        "            t1 = X.T @ (D_inv[:, None] * X)\n",
        "            Xt_D_inv_1 = X.T @ D_inv\n",
        "            t2 = (tau2 / denom) * np.outer(Xt_D_inv_1, Xt_D_inv_1)\n",
        "            sum_XtViX += (t1 - t2)\n",
        "\n",
        "        betas = np.linalg.solve(sum_XtViX, sum_XtViy)\n",
        "        cov = np.linalg.inv(sum_XtViX)\n",
        "        se = np.sqrt(np.diag(cov))\n",
        "\n",
        "        return betas, se, tau2, sigma2\n",
        "\n",
        "    # Run it\n",
        "    try:\n",
        "        py_betas, py_se, py_tau2, py_sigma2 = get_python_eggers(df_r, eff_col, var_col, se_col)\n",
        "        py_slope = py_betas[1]\n",
        "        py_pval = 2 * (1 - t.cdf(abs(py_slope/py_se[1]), len(df_r)-2))\n",
        "        print(f\"   ‚úì Python calculation successful: Slope={py_slope:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Python Calculation Error: {e}\")\n",
        "        py_slope = None\n",
        "\n",
        "    # --- 3. RUN R SCRIPT ---\n",
        "    print(\"üöÄ Running R script...\")\n",
        "\n",
        "    ro.globalenv['df_python'] = df_r\n",
        "    ro.globalenv['eff_col_name'] = eff_col\n",
        "    ro.globalenv['var_col_name'] = var_col\n",
        "    ro.globalenv['se_col_name'] = se_col\n",
        "\n",
        "    r_script = \"\"\"\n",
        "    library(metafor)\n",
        "    dat <- df_python\n",
        "    dat$rows <- 1:nrow(dat)\n",
        "    dat$study_id <- as.factor(dat$id)\n",
        "\n",
        "    tryCatch({\n",
        "        res <- rma.mv(yi=dat[[eff_col_name]], V=dat[[var_col_name]],\n",
        "                      mods = ~ dat[[se_col_name]],\n",
        "                      random = ~ 1 | study_id/rows,\n",
        "                      data=dat,\n",
        "                      control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\"))\n",
        "\n",
        "        list(status=\"ok\", slope=res$b[2], pval=res$pval[2])\n",
        "    }, error=function(e) {\n",
        "        list(status=\"error\", msg=conditionMessage(e))\n",
        "    })\n",
        "    \"\"\"\n",
        "\n",
        "    r_res = ro.r(r_script)\n",
        "\n",
        "    if r_res.rx2('status')[0] == 'error':\n",
        "        print(f\"‚ùå R Error: {r_res.rx2('msg')[0]}\")\n",
        "    else:\n",
        "        r_slope = r_res.rx2('slope')[0]\n",
        "        r_pval = r_res.rx2('pval')[0]\n",
        "\n",
        "        # --- 4. COMPARE ---\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"VALIDATION REPORT\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"{'Metric':<20} {'Python':<12} {'R (metafor)':<12} {'Diff':<12}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        if py_slope is not None:\n",
        "            diff_slope = abs(py_slope - r_slope)\n",
        "            diff_pval = abs(py_pval - r_pval)\n",
        "\n",
        "            print(f\"{'Slope (Bias)':<20} {py_slope:<12.4f} {r_slope:<12.4f} {diff_slope:.2e}\")\n",
        "            print(f\"{'P-value':<20} {py_pval:<12.4f} {r_pval:<12.4f} {diff_pval:.2e}\")\n",
        "\n",
        "            if diff_slope < 1e-2: # Slightly loose tolerance for 3-level optimization\n",
        "                print(\"\\n‚úÖ PASSED: Egger's Test matches R.\")\n",
        "            else:\n",
        "                print(\"\\n‚ö†Ô∏è  CHECK: Differences detected.\")\n",
        "                print(\"   Optimization landscapes for 3-level Egger's tests are often flat/bumpy.\")\n",
        "                print(\"   If P-value significance is the same, the conclusion holds.\")\n",
        "        else:\n",
        "            print(\"‚ùå Python calculation failed, cannot compare.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_dw-Yk35spul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä Cell 12b: Publication-Ready Funnel Plot\n",
        "# =============================================================================\n",
        "# CELL 12b: ADVANCED FUNNEL PLOTTER\n",
        "# Purpose: Visualize publication bias with full customization.\n",
        "# Features: Tabs for Style, Points, Contours, and Export.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import datetime\n",
        "import traceback\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "default_title = \"Funnel Plot\"\n",
        "default_xlabel = \"Effect Size\"\n",
        "default_ylabel = \"Standard Error\"\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        default_xlabel = es_config.get('effect_label', 'Effect Size')\n",
        "        if 'funnel_results' in ANALYSIS_CONFIG:\n",
        "            default_title = \"Funnel Plot with Pseudo-95% CI\"\n",
        "except: pass\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# === TAB 1: STYLE ===\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_xlabel, description='X Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_ylabel, description='Y Label:', layout=widgets.Layout(width='450px'))\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=5.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False)\n",
        "height_widget = widgets.FloatSlider(value=7.0, min=4.0, max=12.0, step=0.5, description='Height (in):', continuous_update=False)\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Dimensions</h4>\"),\n",
        "    show_title_widget, title_widget,\n",
        "    xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    width_widget, height_widget\n",
        "])\n",
        "\n",
        "# === TAB 2: POINTS ===\n",
        "point_color_widget = widgets.Dropdown(options=['gray', 'steelblue', 'black', 'red', 'purple'], value='gray', description='Color:')\n",
        "point_size_widget = widgets.IntSlider(value=40, min=10, max=150, step=5, description='Size:')\n",
        "point_alpha_widget = widgets.FloatSlider(value=0.6, min=0.1, max=1.0, step=0.1, description='Opacity:')\n",
        "point_shape_widget = widgets.Dropdown(options=[('Circle', 'o'), ('Diamond', 'D'), ('Square', 's')], value='o', description='Shape:')\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Points</h4>\"),\n",
        "    point_color_widget,\n",
        "    point_size_widget,\n",
        "    point_alpha_widget,\n",
        "    point_shape_widget\n",
        "])\n",
        "\n",
        "# === TAB 3: LINES & CONTOURS ===\n",
        "show_center_widget = widgets.Checkbox(value=True, description='Show Pooled Effect Line', indent=False)\n",
        "center_color_widget = widgets.Dropdown(options=['red', 'black', 'blue'], value='red', description='Center Color:')\n",
        "show_ci_widget = widgets.Checkbox(value=True, description='Show 95% CI Funnel', indent=False)\n",
        "ci_fill_widget = widgets.Checkbox(value=True, description='Fill CI Region', indent=False)\n",
        "show_contours_widget = widgets.Checkbox(value=False, description='Show Significance Contours (p<0.05/0.01)', indent=False)\n",
        "\n",
        "lines_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Reference Lines</h4>\"),\n",
        "    show_center_widget, center_color_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    show_ci_widget, ci_fill_widget,\n",
        "    show_contours_widget\n",
        "])\n",
        "\n",
        "# === TAB 4: LAYOUT & EXPORT ===\n",
        "show_grid_widget = widgets.Checkbox(value=True, description='Show Grid', indent=False)\n",
        "show_stats_widget = widgets.Checkbox(value=True, description=\"Show Egger's Test Result\", indent=False)\n",
        "legend_loc_widget = widgets.Dropdown(options=['best', 'upper right', 'upper left', 'lower right', 'lower left', 'none'], value='upper right', description='Legend:')\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "filename_prefix_widget = widgets.Text(value='Funnel_Plot', description='Filename:', layout=widgets.Layout(width='300px'))\n",
        "\n",
        "layout_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Layout & Export</h4>\"),\n",
        "    show_grid_widget, show_stats_widget, legend_loc_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    save_pdf_widget, save_png_widget, filename_prefix_widget\n",
        "])\n",
        "\n",
        "# Assemble Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, points_tab, lines_tab, layout_tab])\n",
        "tabs.set_title(0, 'üé® Style')\n",
        "tabs.set_title(1, '‚ö´ Points')\n",
        "tabs.set_title(2, 'üìê Lines')\n",
        "tabs.set_title(3, 'üíæ Export')\n",
        "\n",
        "run_plot_btn = widgets.Button(\n",
        "    description='üìä Generate Funnel Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# Header\n",
        "header = widgets.HTML(\n",
        "    \"<h3 style='color: #2E86AB; margin-bottom: 10px;'>üìä Funnel Plot - Interactive Plotter</h3>\"\n",
        "    \"<p style='color: #555; margin-top: 0;'>Customize the plot using the tabs below, then click Generate to create the visualization.</p>\"\n",
        ")\n",
        "\n",
        "# --- 3. PLOTTING LOGIC ---\n",
        "def generate_funnel_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        try:\n",
        "            # 1. Load Data & Config\n",
        "            if 'ANALYSIS_CONFIG' not in globals():\n",
        "                print(\"‚ùå Error: Config not found.\")\n",
        "                return\n",
        "\n",
        "            if 'analysis_data' in globals(): df = analysis_data.copy()\n",
        "            elif 'data_filtered' in globals(): df = data_filtered.copy()\n",
        "            else: print(\"‚ùå Data not found.\"); return\n",
        "\n",
        "            if 'three_level_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"‚ùå Error: Run Cell 6.5 (Three-Level Analysis) first.\")\n",
        "                return\n",
        "\n",
        "            eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "            se_col = ANALYSIS_CONFIG.get('se_col', 'SE_g')\n",
        "\n",
        "            # Get Pooled Effect (Center Line)\n",
        "            pooled_effect = ANALYSIS_CONFIG['three_level_results']['pooled_effect']\n",
        "\n",
        "            # Clean Data\n",
        "            df = df.dropna(subset=[eff_col, se_col])\n",
        "            df = df[df[se_col] > 0]\n",
        "\n",
        "            # 2. Prepare Plot\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, height_widget.value))\n",
        "\n",
        "            # Max SE for Y-axis limit\n",
        "            max_se = df[se_col].max() * 1.1\n",
        "            y_range = np.linspace(0, max_se, 100)\n",
        "\n",
        "            # --- Plot Funnel Lines ---\n",
        "            # 95% CI: +/- 1.96 * SE\n",
        "            x_left = pooled_effect - 1.96 * y_range\n",
        "            x_right = pooled_effect + 1.96 * y_range\n",
        "\n",
        "            if show_ci_widget.value:\n",
        "                ax.plot(x_left, y_range, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
        "                ax.plot(x_right, y_range, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
        "\n",
        "                if ci_fill_widget.value:\n",
        "                    ax.fill_betweenx(y_range, x_left, x_right, color='gray', alpha=0.1, label='95% CI Region')\n",
        "\n",
        "            # --- Plot Significance Contours ---\n",
        "            if show_contours_widget.value:\n",
        "                # 99% CI: +/- 2.58 * SE\n",
        "                x_99_left = pooled_effect - 2.58 * y_range\n",
        "                x_99_right = pooled_effect + 2.58 * y_range\n",
        "\n",
        "                ax.plot(x_99_left, y_range, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
        "                ax.plot(x_99_right, y_range, color='gray', linestyle=':', linewidth=1, alpha=0.5, label='99% CI Region')\n",
        "\n",
        "            # --- Plot Points ---\n",
        "            ax.scatter(df[eff_col], df[se_col],\n",
        "                      c=point_color_widget.value,\n",
        "                      s=point_size_widget.value,\n",
        "                      alpha=point_alpha_widget.value,\n",
        "                      marker=point_shape_widget.value,\n",
        "                      edgecolors='black', linewidth=0.5,\n",
        "                      label='Studies', zorder=3)\n",
        "\n",
        "            # --- Plot Center Line ---\n",
        "            if show_center_widget.value:\n",
        "                ax.axvline(pooled_effect, color=center_color_widget.value, linestyle='-', linewidth=2,\n",
        "                          label=f'Pooled Effect ({pooled_effect:.3f})', zorder=2)\n",
        "\n",
        "            # --- Axis Customization ---\n",
        "            ax.set_ylim(max_se, 0) # Invert Y-axis (standard for funnel plots)\n",
        "\n",
        "            if show_title_widget.value:\n",
        "                ax.set_title(title_widget.value, fontsize=14, fontweight='bold', pad=15)\n",
        "            ax.set_xlabel(xlabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(ylabel_widget.value, fontsize=12, fontweight='bold')\n",
        "\n",
        "            if show_grid_widget.value:\n",
        "                ax.grid(True, linestyle=':', alpha=0.4)\n",
        "\n",
        "            if legend_loc_widget.value != 'none':\n",
        "                ax.legend(loc=legend_loc_widget.value, frameon=True, fancybox=True)\n",
        "\n",
        "            # --- Show Egger's Test Stats ---\n",
        "            if show_stats_widget.value and 'funnel_results' in ANALYSIS_CONFIG:\n",
        "                res_funnel = ANALYSIS_CONFIG['funnel_results']\n",
        "                if res_funnel.get('egger_p') is not None:\n",
        "                    p_val = res_funnel['egger_p']\n",
        "                    beta = res_funnel.get('beta_slope', 0)\n",
        "                    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"ns\"\n",
        "\n",
        "                    stats_text = f\"Egger's Test:\\nSlope = {beta:.3f}\\np = {p_val:.4f} {sig}\"\n",
        "\n",
        "                    # Place text in bottom right (since Y is inverted, bottom is large SE)\n",
        "                    # We use axes coordinates: (0.95, 0.05) is bottom-right\n",
        "                    ax.text(0.95, 0.05, stats_text, transform=ax.transAxes,\n",
        "                           ha='right', va='bottom', fontsize=10,\n",
        "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- Export ---\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M%S\")\n",
        "            fn = filename_prefix_widget.value\n",
        "\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.pdf\")\n",
        "\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.png\", dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.png\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Plotting Error: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_plot_btn.on_click(generate_funnel_plot)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    header,\n",
        "    tabs,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    run_plot_btn,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JI-twevbO72l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä Cell 14b: Publication-Ready Trim-and-Fill Plot\n",
        "# =============================================================================\n",
        "# CELL 14b: ADVANCED TRIM-AND-FILL PLOTTER\n",
        "# Purpose: Visualize publication bias sensitivity with full customization.\n",
        "# Features: Highlight imputed studies, compare original vs. adjusted effects.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import datetime\n",
        "import traceback\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "default_title = \"Trim-and-Fill Funnel Plot\"\n",
        "default_xlabel = \"Effect Size\"\n",
        "default_ylabel = \"Standard Error\"\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        default_xlabel = es_config.get('effect_label', 'Effect Size')\n",
        "except: pass\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# === TAB 1: STYLE ===\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_xlabel, description='X Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_ylabel, description='Y Label:', layout=widgets.Layout(width='450px'))\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=5.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False)\n",
        "height_widget = widgets.FloatSlider(value=7.0, min=4.0, max=12.0, step=0.5, description='Height (in):', continuous_update=False)\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Dimensions</h4>\"),\n",
        "    show_title_widget, title_widget,\n",
        "    xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    width_widget, height_widget\n",
        "])\n",
        "\n",
        "# === TAB 2: POINTS ===\n",
        "obs_color_widget = widgets.Dropdown(options=['black', 'gray', 'steelblue', 'blue'], value='black', description='Observed:')\n",
        "imp_color_widget = widgets.Dropdown(options=['white', 'red', 'orange', 'none'], value='white', description='Imputed:')\n",
        "imp_edge_widget = widgets.Dropdown(options=['red', 'black', 'orange'], value='red', description='Imp Edge:')\n",
        "point_size_widget = widgets.IntSlider(value=50, min=10, max=150, step=5, description='Size:')\n",
        "point_alpha_widget = widgets.FloatSlider(value=0.7, min=0.1, max=1.0, step=0.1, description='Opacity:')\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Points</h4>\"),\n",
        "    obs_color_widget,\n",
        "    imp_color_widget,\n",
        "    imp_edge_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    point_size_widget,\n",
        "    point_alpha_widget\n",
        "])\n",
        "\n",
        "# === TAB 3: LINES ===\n",
        "show_orig_widget = widgets.Checkbox(value=True, description='Show Original Mean', indent=False)\n",
        "orig_color_widget = widgets.Dropdown(options=['black', 'gray', 'blue'], value='black', description='Orig Color:')\n",
        "show_adj_widget = widgets.Checkbox(value=True, description='Show Adjusted Mean', indent=False)\n",
        "adj_color_widget = widgets.Dropdown(options=['red', 'orange', 'magenta'], value='red', description='Adj Color:')\n",
        "show_funnel_widget = widgets.Checkbox(value=True, description='Show Funnel Guidelines', indent=False)\n",
        "\n",
        "lines_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Reference Lines</h4>\"),\n",
        "    show_orig_widget, orig_color_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    show_adj_widget, adj_color_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    show_funnel_widget\n",
        "])\n",
        "\n",
        "# === TAB 4: LAYOUT & EXPORT ===\n",
        "show_grid_widget = widgets.Checkbox(value=True, description='Show Grid', indent=False)\n",
        "legend_loc_widget = widgets.Dropdown(options=['best', 'upper right', 'upper left', 'lower right', 'lower left', 'none'], value='upper right', description='Legend:')\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "filename_prefix_widget = widgets.Text(value='TrimFill_Plot', description='Filename:', layout=widgets.Layout(width='300px'))\n",
        "\n",
        "layout_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Layout & Export</h4>\"),\n",
        "    show_grid_widget, legend_loc_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    save_pdf_widget, save_png_widget, filename_prefix_widget\n",
        "])\n",
        "\n",
        "# Assemble Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, points_tab, lines_tab, layout_tab])\n",
        "tabs.set_title(0, 'üé® Style')\n",
        "tabs.set_title(1, '‚ö´ Points')\n",
        "tabs.set_title(2, 'zk Lines')\n",
        "tabs.set_title(3, 'üíæ Export')\n",
        "\n",
        "run_plot_btn = widgets.Button(\n",
        "    description='üìä Generate Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# Header\n",
        "header = widgets.HTML(\n",
        "    \"<h3 style='color: #2E86AB; margin-bottom: 10px;'>üìä Trim-and-Fill Plot - Interactive Plotter</h3>\"\n",
        "    \"<p style='color: #555; margin-top: 0;'>Customize the plot using the tabs below, then click Generate to create the visualization.</p>\"\n",
        ")\n",
        "\n",
        "# --- 3. PLOTTING LOGIC ---\n",
        "def generate_tf_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        try:\n",
        "            # 1. Load Data & Results\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'trimfill_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"‚ùå Error: Run Cell 14 (Trim-and-Fill) first.\")\n",
        "                return\n",
        "\n",
        "            tf_res = ANALYSIS_CONFIG['trimfill_results']\n",
        "\n",
        "            # Reconstruct original data from stored results or global data\n",
        "            # We need the original points.\n",
        "            # The tf_res has 'yi_combined' and 'vi_combined' which includes imputed.\n",
        "            # We can split them using k0.\n",
        "\n",
        "            yi_all = tf_res['yi_combined']\n",
        "            vi_all = tf_res['vi_combined']\n",
        "            se_all = np.sqrt(vi_all)\n",
        "\n",
        "            k0 = tf_res['k0']\n",
        "            n_orig = len(yi_all) - k0\n",
        "\n",
        "            yi_orig = yi_all[:n_orig]\n",
        "            se_orig = se_all[:n_orig]\n",
        "\n",
        "            yi_fill = yi_all[n_orig:]\n",
        "            se_fill = se_all[n_orig:]\n",
        "\n",
        "            orig_mean = tf_res['pooled_original']\n",
        "            fill_mean = tf_res['pooled_filled']\n",
        "\n",
        "            # 2. Prepare Plot\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, height_widget.value))\n",
        "\n",
        "            # Max SE for Y-axis limit\n",
        "            max_se = np.max(se_all) * 1.1 if len(se_all) > 0 else 1.0\n",
        "            y_range = np.linspace(0, max_se, 100)\n",
        "\n",
        "            # --- Funnel Lines (Centered on Adjusted Mean) ---\n",
        "            if show_funnel_widget.value:\n",
        "                # 95% CI: +/- 1.96 * SE\n",
        "                # x = mean +/- 1.96 * y\n",
        "                x_left = fill_mean - 1.96 * y_range\n",
        "                x_right = fill_mean + 1.96 * y_range\n",
        "\n",
        "                ax.plot(x_left, y_range, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
        "                ax.plot(x_right, y_range, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
        "                ax.fill_betweenx(y_range, x_left, x_right, color='lightgray', alpha=0.1)\n",
        "\n",
        "            # --- Plot Points ---\n",
        "            # Original Studies\n",
        "            ax.scatter(yi_orig, se_orig,\n",
        "                      c=obs_color_widget.value,\n",
        "                      s=point_size_widget.value,\n",
        "                      alpha=point_alpha_widget.value,\n",
        "                      edgecolors='black', linewidth=0.5,\n",
        "                      label='Observed Studies', zorder=3)\n",
        "\n",
        "            # Imputed Studies\n",
        "            if k0 > 0:\n",
        "                ax.scatter(yi_fill, se_fill,\n",
        "                          c=imp_color_widget.value,\n",
        "                          s=point_size_widget.value,\n",
        "                          alpha=point_alpha_widget.value,\n",
        "                          edgecolors=imp_edge_widget.value, linewidth=1.5,\n",
        "                          marker='o',\n",
        "                          label=f'Imputed Studies (k={k0})', zorder=3)\n",
        "\n",
        "            # --- Plot Center Lines ---\n",
        "            if show_orig_widget.value:\n",
        "                ax.axvline(orig_mean, color=orig_color_widget.value, linestyle='--', linewidth=2,\n",
        "                          label=f'Original: {orig_mean:.3f}', zorder=2)\n",
        "\n",
        "            if show_adj_widget.value:\n",
        "                ax.axvline(fill_mean, color=adj_color_widget.value, linestyle='-', linewidth=2,\n",
        "                          label=f'Adjusted: {fill_mean:.3f}', zorder=2)\n",
        "\n",
        "            # --- Axis Customization ---\n",
        "            ax.set_ylim(max_se, 0) # Invert Y-axis\n",
        "\n",
        "            if show_title_widget.value:\n",
        "                ax.set_title(title_widget.value, fontsize=14, fontweight='bold', pad=15)\n",
        "            ax.set_xlabel(xlabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(ylabel_widget.value, fontsize=12, fontweight='bold')\n",
        "\n",
        "            if show_grid_widget.value:\n",
        "                ax.grid(True, linestyle=':', alpha=0.4)\n",
        "\n",
        "            if legend_loc_widget.value != 'none':\n",
        "                ax.legend(loc=legend_loc_widget.value, frameon=True, fancybox=True)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- Export ---\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M%S\")\n",
        "            fn = filename_prefix_widget.value\n",
        "\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.pdf\")\n",
        "\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.png\", dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.png\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Plotting Error: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_plot_btn.on_click(generate_tf_plot)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    header,\n",
        "    tabs,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    run_plot_btn,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rHZr0olcPced"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  R Validation for Trim-and-Fill\n",
        "# =============================================================================\n",
        "# CELL: R VALIDATION (DEBUG MODE)\n",
        "# Purpose: Robustly validate Trim-and-Fill results against R.\n",
        "# Fix: Added extensive error checking and raw object inspection.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "\n",
        "# --- 1. Robust Data Prep ---\n",
        "print(\"üîç Checking data...\")\n",
        "if 'analysis_data' in globals():\n",
        "    df_tf_check = analysis_data.copy()\n",
        "elif 'data_filtered' in globals():\n",
        "    df_tf_check = data_filtered.copy()\n",
        "else:\n",
        "    print(\"‚ùå Error: No data found. Run Cell 5/6 first.\")\n",
        "    df_tf_check = None\n",
        "\n",
        "if df_tf_check is not None:\n",
        "    # Configuration\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "        var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "    else:\n",
        "        eff_col = 'hedges_g'; var_col = 'Vg'\n",
        "\n",
        "    # --- SIDE DETECTION ---\n",
        "    r_side_arg = \"left\" # Safe default\n",
        "    if 'ANALYSIS_CONFIG' in globals() and 'trimfill_results' in ANALYSIS_CONFIG:\n",
        "        py_res = ANALYSIS_CONFIG['trimfill_results']\n",
        "        if isinstance(py_res, dict):\n",
        "            py_side = py_res.get('side')\n",
        "            if py_side in ['left', 'right']:\n",
        "                r_side_arg = py_side\n",
        "\n",
        "    print(f\"   Effect: '{eff_col}', Variance: '{var_col}'\")\n",
        "    print(f\"   Side: '{r_side_arg}'\")\n",
        "\n",
        "    # Clean Data\n",
        "    # Ensure columns exist\n",
        "    if eff_col not in df_tf_check.columns or var_col not in df_tf_check.columns:\n",
        "        print(f\"‚ùå Error: Columns {eff_col}/{var_col} missing from dataframe.\")\n",
        "    else:\n",
        "        df_r = df_tf_check[[eff_col, var_col]].dropna()\n",
        "        df_r = df_r[df_r[var_col] > 0]\n",
        "\n",
        "        print(f\"   Rows sent to R: {len(df_r)}\")\n",
        "\n",
        "        if len(df_r) < 3:\n",
        "            print(\"‚ùå Error: Not enough valid rows for R (need >= 3).\")\n",
        "        else:\n",
        "            # Transfer to R\n",
        "            ro.globalenv['df_python'] = df_r\n",
        "            ro.globalenv['eff_col_name'] = eff_col\n",
        "            ro.globalenv['var_col_name'] = var_col\n",
        "            ro.globalenv['side_val'] = r_side_arg\n",
        "\n",
        "            # --- 2. Defensive R Script ---\n",
        "            print(\"üöÄ Running R script...\")\n",
        "            r_script = \"\"\"\n",
        "            library(metafor)\n",
        "\n",
        "            # Wrap in tryCatch to guarantee a return list\n",
        "            result <- tryCatch({\n",
        "                # 1. Fixed Effect Model\n",
        "                res <- rma(yi=df_python[[eff_col_name]], vi=df_python[[var_col_name]], method=\"FE\")\n",
        "\n",
        "                # 2. Trim and Fill\n",
        "                tf <- trimfill(res, estimator=\"L0\", side=side_val)\n",
        "\n",
        "                # 3. Extract Values safely\n",
        "                list(\n",
        "                    status = \"success\",\n",
        "                    k0 = as.integer(tf$k0),\n",
        "                    side = as.character(tf$side),\n",
        "                    fill_est = as.numeric(tf$beta[1]),\n",
        "                    fill_se = as.numeric(tf$se[1]),\n",
        "                    orig_est = as.numeric(res$b[1])\n",
        "                )\n",
        "            }, error = function(e) {\n",
        "                list(status = \"error\", message = conditionMessage(e))\n",
        "            })\n",
        "\n",
        "            result\n",
        "            \"\"\"\n",
        "\n",
        "            try:\n",
        "                r_res = ro.r(r_script)\n",
        "\n",
        "                # --- 3. Inspect Raw Result ---\n",
        "                # This prevents the NULLType error by checking before accessing\n",
        "                if r_res == ro.r(\"NULL\"):\n",
        "                    print(\"‚ùå CRITICAL ERROR: R returned NULL.\")\n",
        "                else:\n",
        "                    # Extract Status safely\n",
        "                    try:\n",
        "                        # Use 0-based index for .rx2() result if it's a vector/list\n",
        "                        status_vec = r_res.rx2('status')\n",
        "                        status = status_vec[0]\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ùå Error extracting status: {e}\")\n",
        "                        status = \"unknown\"\n",
        "\n",
        "                    if status == \"error\":\n",
        "                        msg = r_res.rx2('message')[0]\n",
        "                        print(f\"\\n‚ùå R Execution Failed: {msg}\")\n",
        "                    elif status == \"success\":\n",
        "                        r_k0 = r_res.rx2('k0')[0]\n",
        "                        r_side = r_res.rx2('side')[0]\n",
        "                        r_fill = r_res.rx2('fill_est')[0]\n",
        "\n",
        "                        # Get Python values for comparison\n",
        "                        py_fill = \"N/A\"\n",
        "                        if 'ANALYSIS_CONFIG' in globals() and 'trimfill_results' in ANALYSIS_CONFIG:\n",
        "                            py_fill = ANALYSIS_CONFIG['trimfill_results'].get('pooled_filled', \"N/A\")\n",
        "                            py_k0 = ANALYSIS_CONFIG['trimfill_results'].get('k0', \"N/A\")\n",
        "\n",
        "                        print(\"\\n\" + \"=\"*60)\n",
        "                        print(\"VALIDATION REPORT (TRIM-AND-FILL)\")\n",
        "                        print(\"=\"*60)\n",
        "                        print(f\"{'Metric':<20} {'Python':<12} {'R (metafor)':<12} {'Diff':<12}\")\n",
        "                        print(\"-\" * 60)\n",
        "\n",
        "                        def fmt(x): return f\"{x:.4f}\" if isinstance(x, (float, int)) else str(x)\n",
        "                        def diff(p, r): return f\"{abs(p-r):.2e}\" if isinstance(p, (float, int)) and isinstance(r, (float, int)) else \"-\"\n",
        "\n",
        "                        print(f\"{'Missing Studies':<20} {py_k0:<12} {r_k0:<12} {'-'}\")\n",
        "                        print(f\"{'Filled Estimate':<20} {fmt(py_fill):<12} {fmt(r_fill):<12} {diff(py_fill, r_fill):<12}\")\n",
        "\n",
        "                        if isinstance(py_fill, float) and abs(py_fill - r_fill) < 1e-4:\n",
        "                             print(\"\\n‚úÖ PASSED: Trim-and-Fill matches R.\")\n",
        "                        elif py_fill == \"N/A\":\n",
        "                             print(\"\\n‚ö†Ô∏è  NOTE: Run Cell 14 first to generate Python results.\")\n",
        "                        else:\n",
        "                             print(\"\\n‚ö†Ô∏è  CHECK: Results differ. Check 'side' or estimator settings.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ùå Python Interface Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TXkCc8wpu6N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üîÑ Cell 13: Leave-One-Out Sensitivity (Calculation Only)\n",
        "# =============================================================================\n",
        "# CELL 13: ROBUST LEAVE-ONE-OUT ANALYSIS (Math Only)\n",
        "# Purpose: Calculate influence of each study on the 3-level pooled effect.\n",
        "# Note: Plots have been moved to Cell 13b.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import warnings\n",
        "\n",
        "# --- 1. ROBUST ENGINE (Same as Cell 6.5) ---\n",
        "def _run_three_level_reml_loo(analysis_data, effect_col, var_col):\n",
        "    \"\"\"Optimization with Two-Pass High Precision Strategy.\"\"\"\n",
        "    grouped = analysis_data.groupby('id')\n",
        "    y_all = [group[effect_col].values for _, group in grouped]\n",
        "    v_all = [group[var_col].values for _, group in grouped]\n",
        "    N_total = len(analysis_data)\n",
        "    M_studies = len(y_all)\n",
        "\n",
        "    if M_studies < 2: return None\n",
        "\n",
        "    # 1. Global Search (L-BFGS-B)\n",
        "    start_points = [[0.01, 0.01], [0.5, 0.1], [0.1, 0.5]]\n",
        "    best_res = None\n",
        "    best_fun = np.inf\n",
        "\n",
        "    for start in start_points:\n",
        "        res = minimize(\n",
        "            _neg_log_lik_reml_loo, x0=start,\n",
        "            args=(y_all, v_all, N_total, M_studies),\n",
        "            method='L-BFGS-B', bounds=[(1e-8, None), (1e-8, None)],\n",
        "            options={'ftol': 1e-10}\n",
        "        )\n",
        "        if res.success and res.fun < best_fun:\n",
        "            best_fun = res.fun\n",
        "            best_res = res\n",
        "\n",
        "    if not best_res: return None\n",
        "\n",
        "    # 2. Polishing (Nelder-Mead)\n",
        "    final_res = minimize(\n",
        "        _neg_log_lik_reml_loo, x0=best_res.x,\n",
        "        args=(y_all, v_all, N_total, M_studies),\n",
        "        method='Nelder-Mead', bounds=[(1e-8, None), (1e-8, None)],\n",
        "        options={'xatol': 1e-10, 'fatol': 1e-10}\n",
        "    )\n",
        "\n",
        "    return _get_three_level_estimates_loo(\n",
        "        final_res.x, y_all, v_all, N_total, M_studies\n",
        "    )\n",
        "\n",
        "# --- 2. WIDGETS ---\n",
        "header = widgets.HTML(\n",
        "    \"<h3 style='color: #2E86AB;'>Three-Level Leave-One-Out Sensitivity Analysis</h3>\"\n",
        "    \"<p style='color: #666;'><i>Calculates the influence of each study. (Math Only - Plotting in Cell 13b)</i></p>\"\n",
        "    \"<p style='color: red;'>‚ö†Ô∏è This is computationally intensive.</p>\"\n",
        ")\n",
        "\n",
        "run_loo_btn = widgets.Button(description='‚ñ∂ Run LOO Calculation', button_style='success', layout=widgets.Layout(width='400px'))\n",
        "loo_output = widgets.Output()\n",
        "\n",
        "# --- 3. MAIN LOGIC ---\n",
        "def run_loo_analysis(b):\n",
        "    global ANALYSIS_CONFIG\n",
        "    with loo_output:\n",
        "        clear_output(wait=True)\n",
        "        print(\"=\"*70)\n",
        "        print(\"RUNNING HIGH-PRECISION LEAVE-ONE-OUT ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            # Load Data\n",
        "            if 'analysis_data' in globals(): df_loo = analysis_data.copy()\n",
        "            elif 'data_filtered' in globals(): df_loo = data_filtered.copy()\n",
        "            else: print(\"‚ùå Data not found.\"); return\n",
        "\n",
        "            if 'three_level_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"‚ùå Run Cell 6.5 first.\")\n",
        "                return\n",
        "\n",
        "            # Get Config\n",
        "            effect_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "            var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "            es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "            orig_res = ANALYSIS_CONFIG['three_level_results']\n",
        "            orig_eff = orig_res['pooled_effect']\n",
        "            orig_ci_lower = orig_res['ci_lower']\n",
        "            orig_ci_upper = orig_res['ci_upper']\n",
        "\n",
        "            # Run Loop\n",
        "            studies = df_loo['id'].unique()\n",
        "            results = []\n",
        "            print(f\"  Processing {len(studies)} studies...\")\n",
        "\n",
        "            for i, study in enumerate(studies):\n",
        "                if i % 5 == 0: print(f\"  ... {i}/{len(studies)}\", end='\\r')\n",
        "\n",
        "                # Remove study\n",
        "                subset = df_loo[df_loo['id'] != study]\n",
        "\n",
        "                # Run Robust Optimizer\n",
        "                est = _run_three_level_reml_loo(subset, effect_col, var_col)\n",
        "\n",
        "                if est:\n",
        "                    mu = est['mu']\n",
        "                    se = est['se_mu']\n",
        "                    # Check significance change\n",
        "                    null_val = es_config.get('null_value', 0)\n",
        "                    orig_sig = not (orig_ci_lower <= null_val <= orig_ci_upper)\n",
        "                    loo_sig = not (mu - 1.96*se <= null_val <= mu + 1.96*se)\n",
        "\n",
        "                    results.append({\n",
        "                        'unit_removed': str(study),\n",
        "                        'k_studies': subset['id'].nunique(),\n",
        "                        'k_obs': len(subset),\n",
        "                        'pooled_effect': mu,\n",
        "                        'se': se,\n",
        "                        'ci_lower': mu - 1.96*se,\n",
        "                        'ci_upper': mu + 1.96*se,\n",
        "                        'effect_diff': mu - orig_eff,\n",
        "                        'abs_diff': abs(mu - orig_eff),\n",
        "                        'changes_sig': (orig_sig != loo_sig),\n",
        "                        'tau_squared': est['tau_sq'],\n",
        "                        'sigma_squared': est['sigma_sq']\n",
        "                    })\n",
        "\n",
        "            print(f\"  ‚úì Completed {len(results)} iterations.\\n\")\n",
        "\n",
        "            if len(results) == 0:\n",
        "                print(\"‚ùå Error: No iterations succeeded.\")\n",
        "                return\n",
        "\n",
        "            results_df = pd.DataFrame(results)\n",
        "\n",
        "            # Check for Significance Changes\n",
        "            sig_changers = results_df[results_df['changes_sig'] == True]\n",
        "\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"RESULTS SUMMARY\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"  Original Effect: {orig_eff:.4f}\")\n",
        "            print(f\"  Range of LOO Effects: {results_df['pooled_effect'].min():.4f} to {results_df['pooled_effect'].max():.4f}\")\n",
        "\n",
        "            if not sig_changers.empty:\n",
        "                print(f\"\\n‚ö†Ô∏è  WARNING: Removing these studies changed statistical significance:\")\n",
        "                print(f\"    {', '.join(sig_changers['unit_removed'].tolist())}\")\n",
        "            else:\n",
        "                print(\"\\n‚úÖ ROBUST: No single study removal changed the statistical significance.\")\n",
        "\n",
        "            # --- SAVE RESULTS ---\n",
        "            ANALYSIS_CONFIG['loo_3level_results'] = {\n",
        "                'timestamp': datetime.datetime.now(),\n",
        "                'results_df': results_df,\n",
        "                'removal_unit': 'study',\n",
        "                'original_effect': orig_eff,\n",
        "                'n_sig_changers': len(sig_changers)\n",
        "            }\n",
        "            print(\"\\n‚úÖ DONE: Results saved to 'loo_3level_results'\")\n",
        "            print(\"   üëâ NOW RUN CELL 13b TO SEE THE PLOT\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_loo_btn.on_click(run_loo_analysis)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    header,\n",
        "    run_loo_btn,\n",
        "    loo_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VDPgbSC5oACY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä Cell 13b: Publication-Ready Leave-One-Out Plot (Fixed)\n",
        "# =============================================================================\n",
        "# CELL 13b: ADVANCED LEAVE-ONE-OUT PLOTTER\n",
        "# Purpose: Visualize sensitivity analysis with full customization.\n",
        "# Fix: Corrected 'ecolor' error by splitting plots for normal/highlighted studies.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import datetime\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "default_title = \"Leave-One-Out Sensitivity Analysis\"\n",
        "default_xlabel = \"Pooled Effect Size\"\n",
        "default_ylabel = \"Study Removed\"\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        default_xlabel = f\"Pooled {es_config.get('effect_label', 'Effect Size')}\"\n",
        "except: pass\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# === TAB 1: STYLE ===\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_xlabel, description='X Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_ylabel, description='Y Label:', layout=widgets.Layout(width='450px'))\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=5.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False)\n",
        "height_auto_widget = widgets.Checkbox(value=True, description='Auto-Height (based on # studies)', indent=False)\n",
        "height_widget = widgets.FloatSlider(value=8.0, min=4.0, max=20.0, step=0.5, description='Manual Height:', continuous_update=False)\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Dimensions</h4>\"),\n",
        "    show_title_widget, title_widget,\n",
        "    xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    width_widget, height_auto_widget, height_widget\n",
        "])\n",
        "\n",
        "# === TAB 2: DATA & SORTING ===\n",
        "sort_by_widget = widgets.Dropdown(\n",
        "    options=[('Effect Size (Low to High)', 'effect'),\n",
        "             ('Influence (Diff from Original)', 'influence'),\n",
        "             ('Study ID (Alphabetical)', 'id')],\n",
        "    value='effect', description='Sort By:', layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "highlight_sig_widget = widgets.Checkbox(value=True, description='Highlight Significance Changers (Red)', indent=False)\n",
        "point_color_widget = widgets.Dropdown(options=['blue', 'black', 'gray', 'steelblue'], value='blue', description='Point Color:')\n",
        "point_size_widget = widgets.IntSlider(value=6, min=2, max=20, description='Point Size:')\n",
        "\n",
        "data_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Presentation</h4>\"),\n",
        "    sort_by_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    highlight_sig_widget,\n",
        "    point_color_widget,\n",
        "    point_size_widget\n",
        "])\n",
        "\n",
        "# === TAB 3: REFERENCE LINES ===\n",
        "show_orig_line_widget = widgets.Checkbox(value=True, description='Show Original Effect Line', indent=False)\n",
        "orig_color_widget = widgets.Dropdown(options=['red', 'black', 'green'], value='red', description='Line Color:')\n",
        "show_orig_ci_widget = widgets.Checkbox(value=True, description='Show Original 95% CI Band', indent=False)\n",
        "ci_band_alpha_widget = widgets.FloatSlider(value=0.1, min=0.05, max=0.5, step=0.05, description='Band Alpha:')\n",
        "show_null_line_widget = widgets.Checkbox(value=True, description='Show Null Effect Line', indent=False)\n",
        "\n",
        "lines_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Reference Lines</h4>\"),\n",
        "    show_orig_line_widget, orig_color_widget,\n",
        "    show_orig_ci_widget, ci_band_alpha_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    show_null_line_widget\n",
        "])\n",
        "\n",
        "# === TAB 4: EXPORT ===\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "filename_prefix_widget = widgets.Text(value='LOO_Plot', description='Filename:', layout=widgets.Layout(width='300px'))\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Export</h4>\"),\n",
        "    save_pdf_widget, save_png_widget, filename_prefix_widget\n",
        "])\n",
        "\n",
        "# Assemble Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, data_tab, lines_tab, export_tab])\n",
        "tabs.set_title(0, 'üé® Style')\n",
        "tabs.set_title(1, 'üìä Data')\n",
        "tabs.set_title(2, 'üìê Lines')\n",
        "tabs.set_title(3, 'üíæ Export')\n",
        "\n",
        "run_plot_btn = widgets.Button(\n",
        "    description='üìä Generate LOO Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# --- 3. PLOTTING LOGIC ---\n",
        "def generate_loo_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        try:\n",
        "            # 1. Load Results\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'loo_3level_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"‚ùå Error: Run Cell 13 (Leave-One-Out Analysis) first.\")\n",
        "                return\n",
        "\n",
        "            loo_res = ANALYSIS_CONFIG['loo_3level_results']\n",
        "            df = loo_res['results_df'].copy()\n",
        "\n",
        "            # Get original results for reference\n",
        "            if 'three_level_results' in ANALYSIS_CONFIG:\n",
        "                orig_res = ANALYSIS_CONFIG['three_level_results']\n",
        "                orig_eff = orig_res['pooled_effect']\n",
        "                orig_ci_lower = orig_res['ci_lower']\n",
        "                orig_ci_upper = orig_res['ci_upper']\n",
        "            else:\n",
        "                # Fallback if cell 13 was run but cell 6.5 missing (unlikely)\n",
        "                orig_eff = loo_res['original_effect']\n",
        "                orig_ci_lower = df['ci_lower'].mean() # Approx\n",
        "                orig_ci_upper = df['ci_upper'].mean() # Approx\n",
        "\n",
        "            # 2. Sorting\n",
        "            sort_mode = sort_by_widget.value\n",
        "            if sort_mode == 'influence':\n",
        "                df = df.sort_values('abs_diff', ascending=True) # Small diff at bottom\n",
        "            elif sort_mode == 'id':\n",
        "                df = df.sort_values('unit_removed', ascending=False) # Z-A (so A is at top)\n",
        "            else: # effect\n",
        "                df = df.sort_values('pooled_effect', ascending=True)\n",
        "\n",
        "            df = df.reset_index(drop=True)\n",
        "\n",
        "            # 3. Prepare Plot\n",
        "            n_studies = len(df)\n",
        "\n",
        "            # Auto-height calculation: Base + (studies * factor)\n",
        "            if height_auto_widget.value:\n",
        "                plot_height = max(5, 1 + n_studies * 0.25)\n",
        "            else:\n",
        "                plot_height = height_widget.value\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, plot_height))\n",
        "\n",
        "            y_pos = np.arange(n_studies)\n",
        "\n",
        "            # --- Create Splitted Dataframes for Error Bars ---\n",
        "            # ax.errorbar doesn't accept a list of colors in all matplotlib versions.\n",
        "            # Solution: Plot normal and highlighted bars separately.\n",
        "\n",
        "            if highlight_sig_widget.value:\n",
        "                # Identify rows that changed significance\n",
        "                mask_sig = df['changes_sig'] == True\n",
        "                mask_norm = ~mask_sig\n",
        "            else:\n",
        "                # Treat all as normal\n",
        "                mask_sig = pd.Series([False] * n_studies)\n",
        "                mask_norm = pd.Series([True] * n_studies)\n",
        "\n",
        "            # Plot Normal Error Bars\n",
        "            if mask_norm.any():\n",
        "                ax.errorbar(df.loc[mask_norm, 'pooled_effect'], y_pos[mask_norm],\n",
        "                           xerr=[df.loc[mask_norm, 'pooled_effect'] - df.loc[mask_norm, 'ci_lower'],\n",
        "                                 df.loc[mask_norm, 'ci_upper'] - df.loc[mask_norm, 'pooled_effect']],\n",
        "                           fmt='none', ecolor=point_color_widget.value, alpha=0.5, capsize=3)\n",
        "\n",
        "            # Plot Highlighted Error Bars (Red)\n",
        "            if mask_sig.any():\n",
        "                ax.errorbar(df.loc[mask_sig, 'pooled_effect'], y_pos[mask_sig],\n",
        "                           xerr=[df.loc[mask_sig, 'pooled_effect'] - df.loc[mask_sig, 'ci_lower'],\n",
        "                                 df.loc[mask_sig, 'ci_upper'] - df.loc[mask_sig, 'pooled_effect']],\n",
        "                           fmt='none', ecolor='red', alpha=0.8, capsize=3)\n",
        "\n",
        "            # Plot Points (Scatter accepts list of colors)\n",
        "            colors = ['red' if (x and highlight_sig_widget.value) else point_color_widget.value for x in df['changes_sig']]\n",
        "            ax.scatter(df['pooled_effect'], y_pos, c=colors, s=point_size_widget.value*5, zorder=3)\n",
        "\n",
        "            # --- Reference Lines ---\n",
        "            # Null Line\n",
        "            null_val = ANALYSIS_CONFIG.get('es_config', {}).get('null_value', 0)\n",
        "            if show_null_line_widget.value:\n",
        "                ax.axvline(null_val, color='black', linestyle='-', linewidth=1, alpha=0.5, zorder=1)\n",
        "\n",
        "            # Original CI Band\n",
        "            if show_orig_ci_widget.value:\n",
        "                ax.axvspan(orig_ci_lower, orig_ci_upper, color=orig_color_widget.value,\n",
        "                          alpha=ci_band_alpha_widget.value, label='Original 95% CI', zorder=0)\n",
        "\n",
        "            # Original Mean Line\n",
        "            if show_orig_line_widget.value:\n",
        "                ax.axvline(orig_eff, color=orig_color_widget.value, linestyle='--', linewidth=2,\n",
        "                          label=f'Original Effect ({orig_eff:.3f})', zorder=2)\n",
        "\n",
        "            # --- Layout ---\n",
        "            ax.set_yticks(y_pos)\n",
        "            ax.set_yticklabels(df['unit_removed'], fontsize=9)\n",
        "\n",
        "            if show_title_widget.value:\n",
        "                ax.set_title(title_widget.value, fontsize=14, fontweight='bold', pad=15)\n",
        "            ax.set_xlabel(xlabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(ylabel_widget.value, fontsize=12, fontweight='bold')\n",
        "\n",
        "            # Add grid for easier reading\n",
        "            ax.grid(axis='y', linestyle=':', alpha=0.3)\n",
        "            ax.grid(axis='x', linestyle=':', alpha=0.3)\n",
        "\n",
        "            # Legend\n",
        "            handles, labels = ax.get_legend_handles_labels()\n",
        "            # Add custom handle for \"Changed Significance\" if needed\n",
        "            if highlight_sig_widget.value and df['changes_sig'].any():\n",
        "                handles.append(mpatches.Patch(color='red', label='Changed Significance'))\n",
        "\n",
        "            ax.legend(handles=handles, loc='best', frameon=True, fancybox=True)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- Export ---\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M%S\")\n",
        "            fn = filename_prefix_widget.value\n",
        "\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.pdf\")\n",
        "\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.png\", dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"üíæ Saved: {fn}_{ts}.png\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Plotting Error: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_plot_btn.on_click(generate_loo_plot)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    header,\n",
        "    tabs,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    run_plot_btn,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UEY-WLRKRDNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title R Validation for LOO (Study-Level)\n",
        "# =============================================================================\n",
        "# CELL: R VALIDATION FOR LOO\n",
        "# Purpose: Run Cluster-Level Leave-One-Out in R to verify Python results.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "\n",
        "# --- 1. Prepare Data ---\n",
        "if 'analysis_data' in globals():\n",
        "    df_loo_check = analysis_data.copy()\n",
        "elif 'data_filtered' in globals():\n",
        "    df_loo_check = data_filtered.copy()\n",
        "else:\n",
        "    print(\"‚ùå Error: Data not found.\")\n",
        "    df_loo_check = None\n",
        "\n",
        "if df_loo_check is not None:\n",
        "    # Get columns from config or defaults\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "        var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "    else:\n",
        "        eff_col = 'hedges_g'; var_col = 'Vg'\n",
        "\n",
        "    print(f\"üöÄ Running R Validation for Study-Level LOO...\")\n",
        "    print(f\"   Effect: {eff_col}, Variance: {var_col}\")\n",
        "\n",
        "    # Clean data for R\n",
        "    df_r = df_loo_check[['id', eff_col, var_col]].dropna()\n",
        "    ro.globalenv['df_python'] = df_r\n",
        "\n",
        "    # --- 2. R Script (Manual Study-Level Loop) ---\n",
        "    r_script = f\"\"\"\n",
        "    library(metafor)\n",
        "\n",
        "    dat <- df_python\n",
        "    dat$rows <- 1:nrow(dat)\n",
        "    dat$study_id <- as.factor(dat$id)\n",
        "\n",
        "    # Get list of unique studies\n",
        "    study_list <- unique(dat$study_id)\n",
        "    n_studies <- length(study_list)\n",
        "\n",
        "    # Storage\n",
        "    loo_estimates <- numeric(n_studies)\n",
        "\n",
        "    # Loop: Remove one study at a time\n",
        "    for (i in 1:n_studies) {{\n",
        "        # Subset: Remove study i\n",
        "        subset_dat <- dat[dat$study_id != study_list[i], ]\n",
        "\n",
        "        # Refit 3-Level Model\n",
        "        # We use 'try' to skip if a subset fails (rare)\n",
        "        tryCatch({{\n",
        "            res <- rma.mv(yi={eff_col}, V={var_col},\n",
        "                          random = ~ 1 | study_id/rows,\n",
        "                          data=subset_dat,\n",
        "                          control=list(optimizer=\"optim\", optmethod=\"Nelder-Mead\"))\n",
        "            loo_estimates[i] <- res$b[1]\n",
        "        }}, error=function(e) {{ loo_estimates[i] <- NA }})\n",
        "    }}\n",
        "\n",
        "    # Original Full Model\n",
        "    res_full <- rma.mv(yi={eff_col}, V={var_col},\n",
        "                       random = ~ 1 | study_id/rows,\n",
        "                       data=dat)\n",
        "\n",
        "    list(\n",
        "        orig = res_full$b[1],\n",
        "        min_loo = min(loo_estimates, na.rm=TRUE),\n",
        "        max_loo = max(loo_estimates, na.rm=TRUE)\n",
        "    )\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Run R\n",
        "        r_res = ro.r(r_script)\n",
        "\n",
        "        r_orig = r_res.rx2('orig')[0]\n",
        "        r_min = r_res.rx2('min_loo')[0]\n",
        "        r_max = r_res.rx2('max_loo')[0]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"VALIDATION REPORT\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"{'Metric':<20} {'Python':<12} {'R (metafor)':<12} {'Diff':<12}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Compare Original\n",
        "        # Note: You mentioned 1.3598 as your result. I'll use a placeholder var for Python\n",
        "        # You can visually compare the printed R result to your Python output above.\n",
        "        print(f\"{'Original Effect':<20} {'(See Above)':<12} {r_orig:.4f}\")\n",
        "\n",
        "        print(f\"{'LOO Min':<20} {'(See Above)':<12} {r_min:.4f}\")\n",
        "        print(f\"{'LOO Max':<20} {'(See Above)':<12} {r_max:.4f}\")\n",
        "\n",
        "        print(\"\\n‚úÖ Interpretation:\")\n",
        "        print(f\"   R Range: [{r_min:.4f}, {r_max:.4f}]\")\n",
        "        print(\"   If your Python range is [1.2989, 1.3817], that is extremely close.\")\n",
        "        print(\"   (Differences < 0.01 are usually just optimizer tolerance differences).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå R Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UVLwveO3pQQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìà CUMULATIVE META-ANALYSIS\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 14: CUMULATIVE META-ANALYSIS\n",
        "# Purpose: Show how effect sizes evolve chronologically as studies accumulate.\n",
        "# Method:  \"Two-Step\" Approach for clustered data:\n",
        "#          1. Aggregate effects within each study (if 'By Study' selected)\n",
        "#          2. Perform cumulative Random-Effects meta-analysis over time\n",
        "# Dependencies: Cell 6 (overall_results), Cell 5 (data)\n",
        "# Outputs: Cumulative forest plot and stability metrics\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, chi2\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CUMULATIVE META-ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# --- 1. HELPER FUNCTIONS ---\n",
        "\n",
        "# --- 2. LOAD CONFIGURATION ---\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in locals() and 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"ANALYSIS_CONFIG not found.\")\n",
        "\n",
        "    if 'analysis_data' in ANALYSIS_CONFIG:\n",
        "        analysis_data = ANALYSIS_CONFIG['analysis_data']\n",
        "    elif 'data_filtered' in globals():\n",
        "        analysis_data = data_filtered\n",
        "    else:\n",
        "        raise ValueError(\"Cannot find analysis data\")\n",
        "\n",
        "    if analysis_data.empty:\n",
        "        raise ValueError(\"Analysis data is empty\")\n",
        "\n",
        "    effect_col = ANALYSIS_CONFIG['effect_col']\n",
        "    var_col = ANALYSIS_CONFIG['var_col']\n",
        "    es_config = ANALYSIS_CONFIG['es_config']\n",
        "    overall_results = ANALYSIS_CONFIG['overall_results']\n",
        "\n",
        "    if 'year' not in analysis_data.columns:\n",
        "        raise ValueError(\"'year' column not found. Ensure data has publication years.\")\n",
        "\n",
        "    # Clean year data\n",
        "    analysis_data_with_year = analysis_data.copy()\n",
        "    analysis_data_with_year['year'] = pd.to_numeric(analysis_data_with_year['year'], errors='coerce')\n",
        "    analysis_data_with_year = analysis_data_with_year.dropna(subset=['year'])\n",
        "\n",
        "    if len(analysis_data_with_year) < 2:\n",
        "        raise ValueError(f\"Insufficient data with valid years. Need at least 2.\")\n",
        "\n",
        "    n_studies = analysis_data_with_year['id'].nunique()\n",
        "    n_obs = len(analysis_data_with_year)\n",
        "    year_range = (int(analysis_data_with_year['year'].min()), int(analysis_data_with_year['year'].max()))\n",
        "\n",
        "    print(f\"‚úì Configuration loaded\")\n",
        "    print(f\"  Effect size: {es_config['effect_label']}\")\n",
        "    print(f\"  Data: {n_obs} observations from {n_studies} studies\")\n",
        "    print(f\"  Year range: {year_range[0]} - {year_range[1]}\")\n",
        "\n",
        "except (NameError, KeyError, ValueError) as e:\n",
        "    print(f\"‚ùå ERROR: {e}\")\n",
        "    print(\"  Please ensure Cells 1-6 have been run.\")\n",
        "    raise\n",
        "\n",
        "# --- 3. CREATE WIDGETS ---\n",
        "\n",
        "header = widgets.HTML(\n",
        "    \"<h3 style='color: #2E86AB;'>Cumulative Meta-Analysis Setup</h3>\"\n",
        "    \"<p style='color: #666;'><i>Visualize how pooled effect sizes change as evidence accumulates over time</i></p>\"\n",
        ")\n",
        "\n",
        "sort_order_widget = widgets.RadioButtons(\n",
        "    options=[('Chronological (oldest first)', 'ascending'), ('Reverse Chronological (newest first)', 'descending')],\n",
        "    value='ascending', description='Sort Order:', style={'description_width': '120px'}, layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "unit_widget = widgets.RadioButtons(\n",
        "    options=[('By Study (aggregate first - Recommended)', 'study'), ('By Observation (ignore clustering)', 'observation')],\n",
        "    value='study', description='Aggregation:', style={'description_width': '120px'}, layout=widgets.Layout(width='500px')\n",
        ")\n",
        "\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False, layout=widgets.Layout(width='450px'))\n",
        "title_widget = widgets.Text(value=f'Cumulative Meta-Analysis: {es_config[\"effect_label\"]} Over Time', description='Title:', layout=widgets.Layout(width='500px'), style={'description_width': '120px'})\n",
        "xlabel_widget = widgets.Text(value='Year', description='X-Axis Label:', layout=widgets.Layout(width='500px'), style={'description_width': '120px'})\n",
        "ylabel_widget = widgets.Text(value=es_config['effect_label'], description='Y-Axis Label:', layout=widgets.Layout(width='500px'), style={'description_width': '120px'})\n",
        "plot_width_widget = widgets.FloatSlider(value=12.0, min=8.0, max=16.0, step=0.5, description='Plot Width:', continuous_update=False, style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "plot_height_widget = widgets.FloatSlider(value=8.0, min=4.0, max=12.0, step=0.5, description='Plot Height:', continuous_update=False, style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "\n",
        "show_ci_widget = widgets.Checkbox(value=True, description='Show 95% Confidence Intervals', indent=False, layout=widgets.Layout(width='450px'))\n",
        "show_null_widget = widgets.Checkbox(value=True, description='Show Null Effect Line', indent=False, layout=widgets.Layout(width='450px'))\n",
        "show_final_widget = widgets.Checkbox(value=True, description='Highlight Final Effect (dashed line)', indent=False, layout=widgets.Layout(width='450px'))\n",
        "show_i2_widget = widgets.Checkbox(value=False, description='Show I¬≤ Trajectory (secondary axis)', indent=False, layout=widgets.Layout(width='450px'))\n",
        "line_color_widget = widgets.Dropdown(options=['blue', 'red', 'black', 'green', 'purple', 'orange'], value='blue', description='Line Color:', style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "line_width_widget = widgets.FloatSlider(value=2.0, min=0.5, max=4.0, step=0.5, description='Line Width:', continuous_update=False, style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "ci_alpha_widget = widgets.FloatSlider(value=0.3, min=0.1, max=0.8, step=0.1, description='CI Transparency:', continuous_update=False, style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "marker_size_widget = widgets.IntSlider(value=50, min=20, max=200, step=10, description='Marker Size:', continuous_update=False, style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False, layout=widgets.Layout(width='450px'))\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False, layout=widgets.Layout(width='450px'))\n",
        "png_dpi_widget = widgets.IntSlider(value=300, min=150, max=600, step=50, description='PNG DPI:', continuous_update=False, style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "show_table_widget = widgets.Checkbox(value=True, description='Show detailed results table', indent=False, layout=widgets.Layout(width='450px'))\n",
        "\n",
        "tab1 = widgets.VBox([widgets.HTML(\"<h4 style='color: #2E86AB;'>Analysis Options</h4>\"), sort_order_widget, widgets.HTML(\"<hr style='margin: 10px 0;'>\"), unit_widget])\n",
        "tab2 = widgets.VBox([widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Dimensions</h4>\"), show_title_widget, title_widget, widgets.HTML(\"<hr style='margin: 10px 0;'>\"), xlabel_widget, ylabel_widget, widgets.HTML(\"<hr style='margin: 10px 0;'>\"), plot_width_widget, plot_height_widget])\n",
        "tab3 = widgets.VBox([widgets.HTML(\"<h4 style='color: #2E86AB;'>Visual Elements</h4>\"), show_ci_widget, show_null_widget, show_final_widget, show_i2_widget, widgets.HTML(\"<hr style='margin: 10px 0;'>\"), line_color_widget, line_width_widget, ci_alpha_widget, marker_size_widget])\n",
        "tab4 = widgets.VBox([widgets.HTML(\"<h4 style='color: #2E86AB;'>Export Options</h4>\"), save_pdf_widget, save_png_widget, png_dpi_widget, widgets.HTML(\"<hr style='margin: 10px 0;'>\"), show_table_widget])\n",
        "\n",
        "tabs = widgets.Tab(children=[tab1, tab2, tab3, tab4])\n",
        "tabs.set_title(0, '‚öôÔ∏è Analysis'); tabs.set_title(1, 'üìù Labels'); tabs.set_title(2, 'üé® Visuals'); tabs.set_title(3, 'üíæ Export')\n",
        "\n",
        "run_button = widgets.Button(description='‚ñ∂ Run Cumulative Meta-Analysis', button_style='success', layout=widgets.Layout(width='500px', height='50px'), style={'font_weight': 'bold'})\n",
        "analysis_output = widgets.Output()\n",
        "\n",
        "# --- 4. DEFINE ANALYSIS FUNCTION ---\n",
        "def run_cumulative_analysis(b):\n",
        "    with analysis_output:\n",
        "        clear_output(wait=True)\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"CUMULATIVE META-ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            # Prepare data\n",
        "            data = analysis_data_with_year.copy()\n",
        "            unit = unit_widget.value\n",
        "            sort_order = sort_order_widget.value\n",
        "\n",
        "            # --- Step 1: Aggregation (Handle Clustering) ---\n",
        "            if unit == 'study':\n",
        "                print(f\"‚öôÔ∏è  Aggregating observations by study (Two-Step Approach)...\")\n",
        "                # For each study, take the earliest year\n",
        "                study_years = data.groupby('id')['year'].min().reset_index()\n",
        "                study_years.columns = ['id', 'study_year']\n",
        "                data = data.merge(study_years, on='id', how='left')\n",
        "\n",
        "                study_data = []\n",
        "                for study_id in data['id'].unique():\n",
        "                    study_obs = data[data['id'] == study_id]\n",
        "                    study_year = study_obs['study_year'].iloc[0]\n",
        "\n",
        "                    # Pool observations within study using fixed-effects (standard practice)\n",
        "                    if len(study_obs) > 1:\n",
        "                        w_study = 1 / study_obs[var_col]\n",
        "                        sum_w_study = w_study.sum()\n",
        "                        pooled_es = (w_study * study_obs[effect_col]).sum() / sum_w_study\n",
        "                        pooled_var = 1 / sum_w_study\n",
        "                    else:\n",
        "                        pooled_es = study_obs[effect_col].iloc[0]\n",
        "                        pooled_var = study_obs[var_col].iloc[0]\n",
        "\n",
        "                    study_data.append({\n",
        "                        'id': study_id,\n",
        "                        'year': study_year,\n",
        "                        effect_col: pooled_es,\n",
        "                        var_col: pooled_var,\n",
        "                        'n_obs': len(study_obs)\n",
        "                    })\n",
        "\n",
        "                data_sorted = pd.DataFrame(study_data)\n",
        "                print(f\"  ‚úì Aggregated {len(data)} observations into {len(data_sorted)} studies\")\n",
        "            else:\n",
        "                # Use observations directly (less robust)\n",
        "                data_sorted = data[[effect_col, var_col, 'year', 'id']].copy()\n",
        "                data_sorted['n_obs'] = 1\n",
        "\n",
        "            # --- Step 2: Cumulative Analysis ---\n",
        "            data_sorted = data_sorted.sort_values('year', ascending=(sort_order == 'ascending'))\n",
        "            data_sorted = data_sorted.reset_index(drop=True)\n",
        "\n",
        "            n_units = len(data_sorted)\n",
        "            print(f\"\\n‚öôÔ∏è  Running cumulative analysis on {n_units} {unit}s...\")\n",
        "\n",
        "            cumulative_results = []\n",
        "            for i in range(1, n_units + 1):\n",
        "                df_cum = data_sorted.iloc[:i].copy()\n",
        "                tau2_cum = calculate_tau_squared_dl(df_cum, effect_col, var_col)\n",
        "                effect_cum, se_cum, ci_lower_cum, ci_upper_cum, I2_cum = calculate_re_pooled(\n",
        "                    df_cum, tau2_cum, effect_col, var_col\n",
        "                )\n",
        "\n",
        "                cumulative_results.append({\n",
        "                    'step': i,\n",
        "                    'year': df_cum['year'].iloc[-1],\n",
        "                    'id_added': df_cum['id'].iloc[-1],\n",
        "                    'n_studies': df_cum['id'].nunique(),\n",
        "                    'pooled_effect': effect_cum,\n",
        "                    'ci_lower': ci_lower_cum,\n",
        "                    'ci_upper': ci_upper_cum,\n",
        "                    'I_squared': I2_cum\n",
        "                })\n",
        "\n",
        "                if i % 10 == 0 or i == n_units: print(f\"  Progress: {i}/{n_units}\", end='\\r')\n",
        "\n",
        "            print(f\"\\n  ‚úì Analysis complete\")\n",
        "            results_df = pd.DataFrame(cumulative_results)\n",
        "\n",
        "            # --- Step 3: Display Table ---\n",
        "            if show_table_widget.value:\n",
        "                print(f\"\\n\" + \"=\"*70)\n",
        "                print(\"CUMULATIVE RESULTS TABLE\")\n",
        "                print(\"=\"*70)\n",
        "                print(f\"\\n{'Step':<5} {'Year':<6} {'N':<4} {'Effect':<10} {'95% CI':<25} {'I¬≤%':<8}\")\n",
        "                print(\"-\" * 70)\n",
        "\n",
        "                indices_to_show = (list(range(5)) + list(range(len(results_df)-5, len(results_df)))) if len(results_df) > 10 else range(len(results_df))\n",
        "                last_shown = -1\n",
        "                for idx in indices_to_show:\n",
        "                    if idx >= len(results_df): continue\n",
        "                    if idx - last_shown > 1: print(\"  ...\")\n",
        "                    row = results_df.iloc[idx]\n",
        "                    ci_str = f\"[{row['ci_lower']:.4f}, {row['ci_upper']:.4f}]\"\n",
        "                    print(f\"{int(row['step']):<5} {int(row['year']):<6} {int(row['n_studies']):<4} {row['pooled_effect']:<10.4f} {ci_str:<25} {row['I_squared']:<8.1f}\")\n",
        "                    last_shown = idx\n",
        "\n",
        "            # --- Step 4: Create Plot ---\n",
        "            fig, ax1 = plt.subplots(figsize=(plot_width_widget.value, plot_height_widget.value))\n",
        "            ax1.plot(results_df['year'], results_df['pooled_effect'],\n",
        "                     color=line_color_widget.value, linewidth=line_width_widget.value, marker='o',\n",
        "                     markersize=marker_size_widget.value/10, label='Cumulative Effect', zorder=3)\n",
        "\n",
        "            if show_ci_widget.value:\n",
        "                ax1.fill_between(results_df['year'], results_df['ci_lower'], results_df['ci_upper'],\n",
        "                                 color=line_color_widget.value, alpha=ci_alpha_widget.value, label='95% CI', zorder=2)\n",
        "\n",
        "            if show_null_widget.value:\n",
        "                ax1.axhline(y=es_config['null_value'], color='gray', linestyle='--', linewidth=1.5, label='Null Effect', zorder=1)\n",
        "\n",
        "            if show_final_widget.value:\n",
        "                ax1.axhline(y=results_df.iloc[-1]['pooled_effect'], color=line_color_widget.value, linestyle=':',\n",
        "                           linewidth=2, alpha=0.7, label='Final Effect', zorder=1)\n",
        "\n",
        "            ax1.set_xlabel(xlabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax1.set_ylabel(ylabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "            ax1.legend(loc='upper left', frameon=True)\n",
        "\n",
        "            if show_i2_widget.value:\n",
        "                ax2 = ax1.twinx()\n",
        "                ax2.plot(results_df['year'], results_df['I_squared'], color='orange', linestyle='--', alpha=0.7, label='I¬≤ (%)')\n",
        "                ax2.set_ylabel('Heterogeneity (I¬≤%)', color='orange', fontweight='bold')\n",
        "                ax2.set_ylim(0, 100)\n",
        "                ax2.legend(loc='upper right')\n",
        "\n",
        "            if show_title_widget.value:\n",
        "                plt.title(title_widget.value, fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- Step 5: Save ---\n",
        "            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f'Cumulative_Meta_{timestamp}.pdf', bbox_inches='tight')\n",
        "                print(f\"  ‚úì Saved PDF\")\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f'Cumulative_Meta_{timestamp}.png', dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"  ‚úì Saved PNG\")\n",
        "\n",
        "            plt.show()\n",
        "            ANALYSIS_CONFIG['cumulative_results'] = results_df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå ERROR: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_button.on_click(run_cumulative_analysis)\n",
        "\n",
        "display(header)\n",
        "display(tabs)\n",
        "display(run_button)\n",
        "display(analysis_output)\n",
        "print(\"\\n‚úÖ Widget interface ready.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IQn2P24QCS2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title R Validation for Cumulative Meta-Analysis\n",
        "# =============================================================================\n",
        "# CELL: R VALIDATION FOR CUMULATIVE ANALYSIS\n",
        "# Purpose: Verify cumulative meta-analysis trends against R's metafor::cumul()\n",
        "# Method:  Aggregates by study (to match Python default), sorts by year,\n",
        "#          and runs cumulative REML.\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()\n",
        "\n",
        "# --- 1. Prepare Data ---\n",
        "if 'analysis_data' in globals():\n",
        "    df_cum_check = analysis_data.copy()\n",
        "elif 'data_filtered' in globals():\n",
        "    df_cum_check = data_filtered.copy()\n",
        "else:\n",
        "    print(\"‚ùå Error: Data not found.\")\n",
        "    df_cum_check = None\n",
        "\n",
        "if df_cum_check is not None:\n",
        "    # Configuration\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        eff_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "        var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "    else:\n",
        "        eff_col = 'hedges_g'; var_col = 'Vg'\n",
        "\n",
        "    print(f\"üöÄ Running R Validation for Cumulative Meta-Analysis...\")\n",
        "    print(f\"   Effect: {eff_col}, Variance: {var_col}\")\n",
        "\n",
        "    # --- 2. Python Data Prep (Match the Pipeline) ---\n",
        "    # We must replicate the 'By Study' aggregation to ensure fair comparison\n",
        "\n",
        "    # Clean and ensure year is numeric\n",
        "    df_clean = df_cum_check.dropna(subset=[eff_col, var_col, 'year']).copy()\n",
        "    df_clean['year'] = pd.to_numeric(df_clean['year'], errors='coerce')\n",
        "    df_clean = df_clean.dropna(subset=['year'])\n",
        "\n",
        "    # Aggregate by Study (Fixed-Effect mean within study)\n",
        "    # This matches the default \"By Study\" behavior of your Python cell\n",
        "    df_clean['wi'] = 1 / df_clean[var_col]\n",
        "\n",
        "    def agg_func(x):\n",
        "        return pd.Series({\n",
        "            'year': x['year'].min(), # Earliest year for the study\n",
        "            'effect': np.average(x[eff_col], weights=x['wi']),\n",
        "            'var': 1 / np.sum(x['wi'])\n",
        "        })\n",
        "\n",
        "    # Group and Sort\n",
        "    df_agg = df_clean.groupby('id').apply(agg_func).reset_index()\n",
        "    df_agg = df_agg.sort_values(by=['year', 'id']) # Sort by year, then ID for consistency\n",
        "\n",
        "    print(f\"   Aggregated Data: {len(df_agg)} studies (from {len(df_clean)} observations)\")\n",
        "\n",
        "    # Pass to R\n",
        "    ro.globalenv['df_python'] = df_agg\n",
        "\n",
        "    # --- 3. R Script ---\n",
        "    r_script = \"\"\"\n",
        "    library(metafor)\n",
        "\n",
        "    # Load data\n",
        "    dat <- df_python\n",
        "\n",
        "    # 1. Run Full Random-Effects Model (REML)\n",
        "    # We sort inside R just to be absolutely sure\n",
        "    dat <- dat[order(dat$year, dat$id), ]\n",
        "\n",
        "    res <- rma(yi=effect, vi=var, data=dat, method=\"REML\")\n",
        "\n",
        "    # 2. Run Cumulative Meta-Analysis\n",
        "    cum <- cumul(res, order=order(dat$year, dat$id))\n",
        "\n",
        "    # Extract Results for the FINAL step (all studies included)\n",
        "    n <- length(cum$est)\n",
        "\n",
        "    list(\n",
        "        final_est = cum$est[n],\n",
        "        final_ci_lb = cum$ci.lb[n],\n",
        "        final_ci_ub = cum$ci.ub[n],\n",
        "        final_tau2 = cum$tau2[n],\n",
        "\n",
        "        # Also get the first step for checking sort order\n",
        "        first_est = cum$est[1],\n",
        "        first_year = dat$year[1],\n",
        "        last_year = dat$year[n]\n",
        "    )\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        r_res = ro.r(r_script)\n",
        "\n",
        "        r_est = r_res.rx2('final_est')[0]\n",
        "        r_lb = r_res.rx2('final_ci_lb')[0]\n",
        "        r_ub = r_res.rx2('final_ci_ub')[0]\n",
        "        r_tau2 = r_res.rx2('final_tau2')[0]\n",
        "\n",
        "        # Get Python Results from Config\n",
        "        py_est, py_lb, py_ub = \"N/A\", \"N/A\", \"N/A\"\n",
        "\n",
        "        if 'ANALYSIS_CONFIG' in globals() and 'cumulative_results' in ANALYSIS_CONFIG:\n",
        "            # Get the last row of the cumulative results dataframe\n",
        "            cum_df = ANALYSIS_CONFIG['cumulative_results']\n",
        "            if not cum_df.empty:\n",
        "                last_row = cum_df.iloc[-1]\n",
        "                py_est = last_row['pooled_effect']\n",
        "                py_lb = last_row['ci_lower']\n",
        "                py_ub = last_row['ci_upper']\n",
        "                # Check if tau2 is available in the df\n",
        "                py_tau2 = last_row['tau_squared'] if 'tau_squared' in last_row else \"N/A\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"VALIDATION REPORT (FINAL CUMULATIVE STEP)\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"{'Metric':<20} {'Python':<12} {'R (metafor)':<12} {'Diff':<12}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        def fmt(x): return f\"{x:.4f}\" if isinstance(x, (float, int)) else str(x)\n",
        "        def diff(p, r): return f\"{abs(p-r):.2e}\" if isinstance(p, (float, int)) and isinstance(r, (float, int)) else \"-\"\n",
        "\n",
        "        print(f\"{'Pooled Estimate':<20} {fmt(py_est):<12} {fmt(r_est):<12} {diff(py_est, r_est):<12}\")\n",
        "        print(f\"{'95% CI Lower':<20} {fmt(py_lb):<12} {fmt(r_lb):<12} {diff(py_lb, r_lb):<12}\")\n",
        "        print(f\"{'95% CI Upper':<20} {fmt(py_ub):<12} {fmt(r_ub):<12} {diff(py_ub, r_ub):<12}\")\n",
        "\n",
        "        if isinstance(py_tau2, (int, float)):\n",
        "             print(f\"{'Tau¬≤':<20} {fmt(py_tau2):<12} {fmt(r_tau2):<12} {diff(py_tau2, r_tau2):<12}\")\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"Time Range Checked: {int(r_res.rx2('first_year')[0])} - {int(r_res.rx2('last_year')[0])}\")\n",
        "\n",
        "        if isinstance(py_est, float) and abs(py_est - r_est) < 0.01:\n",
        "            print(\"\\n‚úÖ PASSED: Cumulative analysis trends match R.\")\n",
        "        elif py_est == \"N/A\":\n",
        "             print(\"\\n‚ö†Ô∏è  NOTE: Run the Cumulative Analysis cell (Cell 14) first to generate Python results.\")\n",
        "        else:\n",
        "             print(\"\\n‚ö†Ô∏è  CHECK: Differences detected. This is often due to:\")\n",
        "             print(\"    1. Different aggregation methods (Python uses Fixed-Effect pool within study).\")\n",
        "             print(\"    2. Sorting order (if multiple studies have the same year).\")\n",
        "             print(\"    3. Tau¬≤ estimator differences (DL vs REML).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå R Error: {e}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YO4tRAi6NhWI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}