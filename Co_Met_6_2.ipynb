{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErickJLA/Co-Met/blob/main/Co_Met_6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TKxhknlidcLn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title \u2699\ufe0f 1. Environment Setup & Core Functions\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 1: ENVIRONMENT SETUP\n",
        "# Purpose: Import required libraries and authenticate Google Sheets access\n",
        "# Dependencies: None\n",
        "# Outputs: Authentication status, library versions, system info\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import ipywidgets as widgets\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import display, HTML, clear_output, Javascript\n",
        "from scipy.stats import norm, t, chi2\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import sys\n",
        "import warnings\n",
        "from scipy.special import gamma\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "\n",
        "# Suppress unnecessary warnings for cleaner output\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "# --- Configuration Constants ---\n",
        "REQUIRED_COLUMNS = {\n",
        "    'effect_data': ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc'],\n",
        "    'metadata': ['id']\n",
        "}\n",
        "\n",
        "SUPPORTED_EFFECT_SIZES = {\n",
        "    'lnRR': 'Log Response Ratio',\n",
        "    'hedges_g': \"Hedges' g (corrected SMD)\",\n",
        "    'cohen_d': \"Cohen's d (uncorrected SMD)\",\n",
        "    'log_OR': 'Log Odds Ratio'\n",
        "}\n",
        "\n",
        "# --- Authentication ---\n",
        "print(\"=\" * 70)\n",
        "print(\"CO-META - INITIALIZATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# UTILITY FUNCTIONS - Extracted from original cells for reusability\n",
        "# =============================================================================\n",
        "\n",
        "# --- STATISTICAL FUNCTIONS ---\n",
        "\n",
        "def calculate_tau_squared_DL(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    DerSimonian-Laird estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Simple, fast\n",
        "    - Non-iterative\n",
        "    - Always converges\n",
        "\n",
        "    Disadvantages:\n",
        "    - Can underestimate tau\u00b2 in small samples\n",
        "    - Negative values truncated to 0\n",
        "    - Less efficient than ML methods\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Fixed-effects weights\n",
        "        w = 1 / df[var_col]\n",
        "        sum_w = w.sum()\n",
        "\n",
        "        if sum_w <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        # Fixed-effects pooled estimate\n",
        "        pooled_effect = (w * df[effect_col]).sum() / sum_w\n",
        "\n",
        "        # Q statistic\n",
        "        Q = (w * (df[effect_col] - pooled_effect)**2).sum()\n",
        "        df_Q = k - 1\n",
        "\n",
        "        # C constant\n",
        "        sum_w_sq = (w**2).sum()\n",
        "        C = sum_w - (sum_w_sq / sum_w)\n",
        "\n",
        "        # Tau-squared\n",
        "        if C > 0 and Q > df_Q:\n",
        "            tau_sq = (Q - df_Q) / C\n",
        "        else:\n",
        "            tau_sq = 0.0\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in DL estimator: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "\n",
        "def calculate_tau_squared(df, effect_col, var_col, method='REML', **kwargs):\n",
        "    \"\"\"\n",
        "    Unified function to calculate tau-squared using specified method\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    method : str\n",
        "        Estimation method: 'DL', 'REML', 'ML', 'PM', 'SJ'\n",
        "        Default: 'REML' (recommended)\n",
        "    **kwargs : dict\n",
        "        Additional arguments passed to estimator\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    dict : additional information (method used, convergence, etc.)\n",
        "    \"\"\"\n",
        "    method = method.upper()\n",
        "\n",
        "    estimators = {\n",
        "        'DL': calculate_tau_squared_DL,\n",
        "        'REML': calculate_tau_squared_REML,\n",
        "        'ML': calculate_tau_squared_ML,\n",
        "        'PM': calculate_tau_squared_PM,\n",
        "        'SJ': calculate_tau_squared_SJ\n",
        "    }\n",
        "\n",
        "    if method not in estimators:\n",
        "        warnings.warn(f\"Unknown method '{method}', using REML\")\n",
        "        method = 'REML'\n",
        "\n",
        "    try:\n",
        "        tau_sq = estimators[method](df, effect_col, var_col, **kwargs)\n",
        "\n",
        "        info = {\n",
        "            'method': method,\n",
        "            'tau_squared': tau_sq,\n",
        "            'tau': np.sqrt(tau_sq),\n",
        "            'success': True\n",
        "        }\n",
        "\n",
        "        return tau_sq, info\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error with {method}, falling back to DL: {e}\")\n",
        "        tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        info = {\n",
        "            'method': 'DL',\n",
        "            'tau_squared': tau_sq,\n",
        "            'tau': np.sqrt(tau_sq),\n",
        "            'success': False,\n",
        "            'fallback': True,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "        return tau_sq, info\n",
        "\n",
        "\n",
        "\n",
        "def calculate_tau_squared_dl(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Calculate Tau-squared. Uses Global Advanced Estimator (Cell 4.5) if available,\n",
        "    otherwise falls back to DerSimonian-Laird (DL).\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2: return 0.0\n",
        "\n",
        "    # Try using the advanced REML estimator from Cell 4.5 first\n",
        "    if 'calculate_tau_squared' in globals():\n",
        "        tau_method = 'REML' # Prefer REML for consistency\n",
        "        try:\n",
        "            tau_sq, info = calculate_tau_squared(df, effect_col, var_col, method=tau_method)\n",
        "            if info.get('success', True):\n",
        "                return tau_sq\n",
        "        except Exception:\n",
        "            pass # Fall back to DL if REML fails (common in small cumulative steps)\n",
        "\n",
        "    # Classic DL Method (Fallback)\n",
        "    try:\n",
        "        w_fixed = 1 / df[var_col]\n",
        "        sum_w = w_fixed.sum()\n",
        "        if sum_w <= 0: return 0.0\n",
        "        pooled_effect = (w_fixed * df[effect_col]).sum() / sum_w\n",
        "        Qt = (w_fixed * (df[effect_col] - pooled_effect)**2).sum()\n",
        "        df_Q = k - 1\n",
        "        sum_w_sq = (w_fixed**2).sum()\n",
        "        C = sum_w - (sum_w_sq / sum_w)\n",
        "        if C > 0 and Qt > df_Q:\n",
        "            tau_squared = (Qt - df_Q) / C\n",
        "        else:\n",
        "            tau_squared = 0.0\n",
        "        return max(0.0, tau_squared)\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "def calculate_re_pooled(df, tau_squared, effect_col, var_col, alpha=0.05):\n",
        "    \"\"\"Calculate Random-Effects pooled estimate with CI\"\"\"\n",
        "    k = len(df)\n",
        "    if k < 1: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "    try:\n",
        "        w_re = 1 / (df[var_col] + tau_squared)\n",
        "        sum_w_re = w_re.sum()\n",
        "        if sum_w_re <= 0: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "        pooled_effect = (w_re * df[effect_col]).sum() / sum_w_re\n",
        "        pooled_var = 1 / sum_w_re\n",
        "        pooled_se = np.sqrt(pooled_var)\n",
        "\n",
        "        z_crit = norm.ppf(1 - alpha / 2)\n",
        "        ci_lower = pooled_effect - z_crit * pooled_se\n",
        "        ci_upper = pooled_effect + z_crit * pooled_se\n",
        "\n",
        "        # Calculate I-squared\n",
        "        w_fixed = 1 / df[var_col]\n",
        "        sum_w_fixed = w_fixed.sum()\n",
        "        pooled_effect_fe = (w_fixed * df[effect_col]).sum() / sum_w_fixed\n",
        "        Q = (w_fixed * (df[effect_col] - pooled_effect_fe)**2).sum()\n",
        "        df_Q = k - 1\n",
        "        I_sq = max(0, ((Q - df_Q) / Q) * 100) if Q > 0 else 0\n",
        "\n",
        "        return pooled_effect, pooled_se, ci_lower, ci_upper, I_sq\n",
        "    except Exception:\n",
        "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "\n",
        "def calculate_knapp_hartung_ci(yi, vi, tau_sq, pooled_effect, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Calculate Knapp-Hartung adjusted confidence interval\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    yi = np.array(yi)\n",
        "    vi = np.array(vi)\n",
        "\n",
        "    # Random-effects weights\n",
        "    wi_star = 1 / (vi + tau_sq)\n",
        "    sum_wi_star = np.sum(wi_star)\n",
        "\n",
        "    # Degrees of freedom\n",
        "    k = len(yi)\n",
        "    df = k - 1\n",
        "\n",
        "    if df <= 0:\n",
        "        # Can't use K-H with k=1\n",
        "        return None\n",
        "\n",
        "    # Calculate Q statistic (residual heterogeneity)\n",
        "    Q = np.sum(wi_star * (yi - pooled_effect)**2)\n",
        "\n",
        "    # Standard random-effects variance\n",
        "    var_standard = 1 / sum_wi_star\n",
        "\n",
        "    # Knapp-Hartung adjusted variance\n",
        "    # SE_KH\u00b2 = (Q / (k-1)) \u00d7 (1 / \u03a3w*)\n",
        "    var_KH = (Q / df) * var_standard\n",
        "    se_KH = np.sqrt(var_KH)\n",
        "\n",
        "    # t-distribution critical value\n",
        "    t_crit = t.ppf(1 - alpha/2, df)\n",
        "\n",
        "    # Confidence interval\n",
        "    ci_lower = pooled_effect - t_crit * se_KH\n",
        "    ci_upper = pooled_effect + t_crit * se_KH\n",
        "\n",
        "    # Test statistic and p-value\n",
        "    t_stat = pooled_effect / se_KH\n",
        "    p_value = 2 * (1 - t.cdf(abs(t_stat), df))\n",
        "\n",
        "    return {\n",
        "        'se_KH': se_KH,\n",
        "        'var_KH': var_KH,\n",
        "        'ci_lower': ci_lower,\n",
        "        'ci_upper': ci_upper,\n",
        "        't_stat': t_stat,\n",
        "        't_crit': t_crit,\n",
        "        'df': df,\n",
        "        'p_value': p_value,\n",
        "        'Q': Q\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def compare_tau_estimators(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Compare all tau-squared estimators on the same dataset\n",
        "\n",
        "    Useful for sensitivity analysis and understanding which method\n",
        "    is most appropriate for your data.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame : Comparison of all methods\n",
        "    \"\"\"\n",
        "    methods = ['DL', 'REML', 'ML', 'PM', 'SJ']\n",
        "    results = []\n",
        "\n",
        "    for method in methods:\n",
        "        try:\n",
        "            tau_sq, info = calculate_tau_squared(df, effect_col, var_col, method=method)\n",
        "\n",
        "            results.append({\n",
        "                'Method': method,\n",
        "                '\u03c4\u00b2': tau_sq,\n",
        "                '\u03c4': np.sqrt(tau_sq),\n",
        "                'Success': info['success']\n",
        "            })\n",
        "        except Exception as e:\n",
        "            results.append({\n",
        "                'Method': method,\n",
        "                '\u03c4\u00b2': np.nan,\n",
        "                '\u03c4': np.nan,\n",
        "                'Success': False\n",
        "            })\n",
        "\n",
        "    comparison_df = pd.DataFrame(results)\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "\n",
        "\n",
        "def calculate_hedges_g_python(df):\n",
        "    \"\"\"Calculate Hedges' g using EXACT Gamma correction.\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Pooled SD\n",
        "    n_e, n_c = df['ne'], df['nc']\n",
        "    sd_e, sd_c = df['sde'], df['sdc']\n",
        "    mean_e, mean_c = df['xe'], df['xc']\n",
        "\n",
        "    df_d = n_e + n_c - 2\n",
        "    sd_pooled = np.sqrt(((n_e - 1)*sd_e**2 + (n_c - 1)*sd_c**2) / df_d)\n",
        "\n",
        "    # Cohen's d\n",
        "    d = (mean_e - mean_c) / sd_pooled\n",
        "\n",
        "    # Hedges' correction (J) - EXACT FORMULA to match metafor\n",
        "    # J = exp(lgamma(m/2) - log(sqrt(m/2)) - lgamma((m-1)/2))\n",
        "    m = df_d\n",
        "    J = gamma(m / 2) / (np.sqrt(m / 2) * gamma((m - 1) / 2))\n",
        "\n",
        "    g = d * J\n",
        "\n",
        "    # Variance of g (Exact)\n",
        "    vg = ((n_e + n_c) / (n_e * n_c) + (g**2 / (2 * (n_e + n_c)))) * J**2\n",
        "\n",
        "    return g, vg\n",
        "\n",
        "\n",
        "# --- THREE-LEVEL MODEL FUNCTIONS ---\n",
        "\n",
        "def _get_three_level_estimates(params, y_all, vcv_all, N_total, M_studies):\n",
        "    \"\"\"\n",
        "    Core function to calculate 3-level estimates using VCV matrices.\n",
        "    FIXED: Proper REML log-likelihood formula to match metafor.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tau_sq, sigma_sq = params\n",
        "        # Safety check for negatives\n",
        "        if tau_sq < 0: tau_sq = 1e-10\n",
        "        if sigma_sq < 0: sigma_sq = 1e-10\n",
        "\n",
        "        sum_log_det_Vi = 0.0\n",
        "        sum_S = 0.0       # 1' * V_i\u207b\u00b9 * 1\n",
        "        sum_Sy = 0.0      # 1' * V_i\u207b\u00b9 * y_i\n",
        "        sum_ySy = 0.0     # y_i' * V_i\u207b\u00b9 * y_i\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = np.asarray(y_all[i], dtype=np.float64)\n",
        "            V_i = np.asarray(vcv_all[i], dtype=np.float64)\n",
        "            k = len(y_i)\n",
        "\n",
        "            # Ensure V_i is 2D\n",
        "            if V_i.ndim == 1:\n",
        "                V_i = np.diag(V_i)\n",
        "\n",
        "            # --- CONSTRUCT TOTAL VARIANCE MATRIX (Sigma_i) ---\n",
        "            # Sigma_i = V_i (Sampling Error) + sigma\u00b2*I (Level 2) + tau\u00b2*J (Level 3)\n",
        "\n",
        "            # Check if V_i is diagonal (no shared controls) - use fast path\n",
        "            is_diagonal = (k == 1) or np.allclose(V_i, np.diag(np.diag(V_i)))\n",
        "\n",
        "            if is_diagonal:\n",
        "                # --- FAST PATH: Sherman-Morrison Formula ---\n",
        "                v_i = np.diag(V_i) if k > 1 else np.array([V_i[0, 0]])\n",
        "\n",
        "                # A = diag(v_ij + \u03c3\u00b2)\n",
        "                A_diag = v_i + sigma_sq\n",
        "                inv_A_diag = 1.0 / A_diag\n",
        "\n",
        "                # Sherman-Morrison components\n",
        "                sum_inv_A = np.sum(inv_A_diag)\n",
        "                denom = 1.0 + tau_sq * sum_inv_A\n",
        "\n",
        "                # Log Determinant: |A + tau\u00b2*J| = |A| * (1 + tau\u00b2 * 1'A\u207b\u00b91)\n",
        "                log_det_A = np.sum(np.log(A_diag))\n",
        "                log_det_Vi = log_det_A + np.log(denom)\n",
        "\n",
        "                # Sherman-Morrison inverse: (A + tau\u00b2*J)\u207b\u00b9 = A\u207b\u00b9 - (tau\u00b2 * A\u207b\u00b9 * J * A\u207b\u00b9) / (1 + tau\u00b2 * trace(A\u207b\u00b9))\n",
        "                # V\u207b\u00b9y\n",
        "                inv_A_y = inv_A_diag * y_i\n",
        "                sum_inv_A_y = np.sum(inv_A_y)\n",
        "                w_y = inv_A_y - (tau_sq * inv_A_diag * sum_inv_A_y) / denom\n",
        "\n",
        "                # V\u207b\u00b91\n",
        "                w_1 = inv_A_diag - (tau_sq * inv_A_diag * sum_inv_A) / denom\n",
        "\n",
        "\n",
        "            else:\n",
        "                # --- FULL PATH: Matrix Inversion for Shared Controls ---\n",
        "                Sigma_i = V_i.copy()\n",
        "\n",
        "                # Add Level 2 (within-study): \u03c3\u00b2 on diagonal\n",
        "                # Use faster fill_diagonal logic\n",
        "                np.fill_diagonal(Sigma_i, np.diag(Sigma_i) + sigma_sq)\n",
        "\n",
        "                # Add Level 3 (between-study): \u03c4\u00b2 for all elements\n",
        "                Sigma_i += tau_sq\n",
        "\n",
        "                # --- INVERSION & DETERMINANT ---\n",
        "                try:\n",
        "                    # Try Cholesky first (Fastest & Most Stable)\n",
        "                    L = np.linalg.cholesky(Sigma_i)\n",
        "                    # Solve Ax = I is faster/stable than explicit inv(A)\n",
        "                    inv_Sigma_i = np.linalg.solve(Sigma_i, np.eye(k))\n",
        "                    log_det_Vi = 2.0 * np.sum(np.log(np.diag(L)))\n",
        "                except np.linalg.LinAlgError:\n",
        "                    # Fallback 1: Add Jitter (Ridge) and retry Cholesky\n",
        "                    try:\n",
        "                        Sigma_ridged = Sigma_i + 1e-6 * np.eye(k)\n",
        "                        L = np.linalg.cholesky(Sigma_ridged)\n",
        "                        inv_Sigma_i = np.linalg.solve(Sigma_ridged, np.eye(k))\n",
        "                        log_det_Vi = 2.0 * np.sum(np.log(np.diag(L)))\n",
        "                    except np.linalg.LinAlgError:\n",
        "                        # Fallback 2: Pseudo-Inverse (Slowest, but guarantees result)\n",
        "                        inv_Sigma_i = np.linalg.pinv(Sigma_i)\n",
        "                        sign, log_det_Vi = np.linalg.slogdet(Sigma_i)\n",
        "                        if sign <= 0:\n",
        "                            return {'log_lik_reml': np.inf}\n",
        "\n",
        "                ones = np.ones(k)\n",
        "                w_y = np.dot(inv_Sigma_i, y_i)\n",
        "                w_1 = np.dot(inv_Sigma_i, ones)\n",
        "\n",
        "            # Accumulate across studies\n",
        "            sum_log_det_Vi += log_det_Vi\n",
        "            sum_S += np.sum(w_1)\n",
        "            sum_Sy += np.sum(w_y)\n",
        "            sum_ySy += np.dot(y_i, w_y)\n",
        "\n",
        "        if sum_S <= 1e-10:\n",
        "            return {'log_lik_reml': np.inf}\n",
        "\n",
        "        # --- FINAL ESTIMATES ---\n",
        "        mu_hat = sum_Sy / sum_S\n",
        "        var_mu = 1.0 / sum_S\n",
        "        se_mu = np.sqrt(var_mu)\n",
        "\n",
        "        # Residual Sum of Squares (quadratic form)\n",
        "        residual_ss = sum_ySy - (sum_Sy ** 2) / sum_S  # Equivalent but more stable\n",
        "\n",
        "        # REML Log-Likelihood (matches metafor::rma.mv)\n",
        "        # -2 * logLik = log|V| + log|X'V\u207b\u00b9X| + (y-X\u03bc)'V\u207b\u00b9(y-X\u03bc) + (n-p)*log(2\u03c0)\n",
        "        # For intercept-only: X'V\u207b\u00b9X = sum_S, so log|X'V\u207b\u00b9X| = log(sum_S)\n",
        "        p = 1  # Number of fixed effects (intercept only)\n",
        "\n",
        "        log_lik_reml = -0.5 * (\n",
        "            (N_total - p) * np.log(2.0 * np.pi) +  # Constant term\n",
        "            sum_log_det_Vi +                        # log|V|\n",
        "            np.log(sum_S) +                         # log|X'V\u207b\u00b9X|\n",
        "            residual_ss                             # Residual quadratic form\n",
        "        )\n",
        "\n",
        "        # ML Log-Likelihood\n",
        "        log_lik_ml = -0.5 * (\n",
        "            N_total * np.log(2.0 * np.pi) +\n",
        "            sum_log_det_Vi +\n",
        "            residual_ss\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'mu': mu_hat, 'se_mu': se_mu, 'var_mu': var_mu,\n",
        "            'log_lik_reml': log_lik_reml, 'log_lik_ml': log_lik_ml,\n",
        "            'tau_sq': tau_sq, 'sigma_sq': sigma_sq\n",
        "        }\n",
        "\n",
        "    except (FloatingPointError, ValueError, np.linalg.LinAlgError) as e:\n",
        "        return {'log_lik_reml': np.inf}\n",
        "\n",
        "\n",
        "def _negative_log_likelihood_reml(params, y_all, vcv_all, N_total, M_studies):\n",
        "    \"\"\"Wrapper for optimizer.\"\"\"\n",
        "    estimates = _get_three_level_estimates(params, y_all, vcv_all, N_total, M_studies)\n",
        "    return -estimates['log_lik_reml']\n",
        "\n",
        "\n",
        "def _get_three_level_estimates_loo(params, y_all, vcv_all, N_total, M_studies):\n",
        "    \"\"\"\n",
        "    Core calculation for 3-level estimates with VCV matrix support (LOO Version).\n",
        "    Silent version without ML likelihood calculation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tau_sq, sigma_sq = params\n",
        "        if tau_sq < 0: tau_sq = 1e-10\n",
        "        if sigma_sq < 0: sigma_sq = 1e-10\n",
        "\n",
        "        sum_log_det_Vi = 0.0\n",
        "        sum_S = 0.0\n",
        "        sum_Sy = 0.0\n",
        "        sum_ySy = 0.0\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = y_all[i]\n",
        "            V_i = vcv_all[i]  # Now using VCV matrix\n",
        "            k = len(y_i)\n",
        "\n",
        "            # Check if diagonal (no shared controls) - use fast path\n",
        "            is_diagonal = (k == 1) or np.allclose(V_i, np.diag(np.diag(V_i)))\n",
        "\n",
        "            if is_diagonal:\n",
        "                # Fast path: Sherman-Morrison\n",
        "                v_i = np.diag(V_i) if k > 1 else np.array([V_i[0, 0]])\n",
        "\n",
        "                A_diag = v_i + sigma_sq\n",
        "                inv_A_diag = 1.0 / A_diag\n",
        "                sum_inv_A = np.sum(inv_A_diag)\n",
        "                denom = 1 + tau_sq * sum_inv_A\n",
        "\n",
        "                log_det_A = np.sum(np.log(A_diag))\n",
        "                sum_log_det_Vi += log_det_A + np.log(denom)\n",
        "\n",
        "                inv_A_y = inv_A_diag * y_i\n",
        "                sum_inv_A_y = np.sum(inv_A_y)\n",
        "\n",
        "                w_y = inv_A_y - (tau_sq * inv_A_diag * sum_inv_A_y) / denom\n",
        "                w_1 = inv_A_diag - (tau_sq * inv_A_diag * sum_inv_A) / denom\n",
        "            else:\n",
        "                # Full path: Matrix inversion for shared controls\n",
        "                Sigma_i = V_i.copy()\n",
        "                np.fill_diagonal(Sigma_i, np.diag(Sigma_i) + sigma_sq)\n",
        "                Sigma_i += tau_sq\n",
        "\n",
        "                try:\n",
        "                    L = np.linalg.cholesky(Sigma_i)\n",
        "                    inv_Sigma_i = np.linalg.inv(Sigma_i)\n",
        "                    log_det_Vi = 2 * np.sum(np.log(np.diag(L)))\n",
        "                except np.linalg.LinAlgError:\n",
        "                    inv_Sigma_i = np.linalg.pinv(Sigma_i)\n",
        "                    sign, log_det_Vi = np.linalg.slogdet(Sigma_i)\n",
        "                    if sign <= 0:\n",
        "                        log_det_Vi = 1e10\n",
        "\n",
        "                sum_log_det_Vi += log_det_Vi\n",
        "\n",
        "                ones = np.ones(k)\n",
        "                w_y = np.dot(inv_Sigma_i, y_i)\n",
        "                w_1 = np.dot(inv_Sigma_i, ones)\n",
        "\n",
        "            sum_S += np.sum(w_1)\n",
        "            sum_Sy += np.sum(w_y)\n",
        "            sum_ySy += np.dot(y_i, w_y)\n",
        "\n",
        "        if sum_S <= 1e-10: return {'log_lik_reml': np.inf}\n",
        "\n",
        "        mu_hat = sum_Sy / sum_S\n",
        "        var_mu = 1.0 / sum_S\n",
        "        se_mu = np.sqrt(var_mu)\n",
        "        residual_ss = sum_ySy - 2.0 * mu_hat * sum_Sy + mu_hat**2 * sum_S\n",
        "\n",
        "        log_lik_reml = -0.5 * (sum_log_det_Vi + np.log(sum_S) + residual_ss)\n",
        "        if np.isnan(log_lik_reml): return {'log_lik_reml': np.inf}\n",
        "\n",
        "        return {'mu': mu_hat, 'se_mu': se_mu, 'log_lik_reml': log_lik_reml,\n",
        "                'tau_sq': tau_sq, 'sigma_sq': sigma_sq}\n",
        "\n",
        "    except (FloatingPointError, ValueError, np.linalg.LinAlgError):\n",
        "        return {'log_lik_reml': np.inf}\n",
        "\n",
        "def _neg_log_lik_reml(params, y, v, groups):\n",
        "    tau2, sigma2 = params\n",
        "    # Bounds are handled by optimizer, but safe-guard here for math domain errors\n",
        "    if tau2 < 0: tau2 = 1e-10\n",
        "    if sigma2 < 0: sigma2 = 1e-10\n",
        "\n",
        "    unique_groups = np.unique(groups)\n",
        "\n",
        "    log_lik = 0\n",
        "    sum_S = 0\n",
        "    sum_Sy = 0\n",
        "    sum_ySy = 0\n",
        "\n",
        "    for grp in unique_groups:\n",
        "        mask = (groups == grp)\n",
        "        y_i = y[mask]\n",
        "        v_i = v[mask]\n",
        "\n",
        "        # V_i = D + sigma2*I + tau2*J\n",
        "        # A = D + sigma2*I (Diagonal matrix)\n",
        "        A_diag = v_i + sigma2\n",
        "        inv_A_diag = 1.0 / A_diag\n",
        "\n",
        "        # Woodbury/Sherman-Morrison components\n",
        "        # (A + uv^T)^-1 = A^-1 - (A^-1 u v^T A^-1) / (1 + v^T A^-1 u)\n",
        "        # Here u = v = tau * 1\n",
        "\n",
        "        sum_inv_A = np.sum(inv_A_diag)\n",
        "        denom = 1 + tau2 * sum_inv_A\n",
        "\n",
        "        # Log Determinant of V_i\n",
        "        # det(A + uv^T) = det(A) * (1 + v^T A^-1 u)\n",
        "        log_det_A = np.sum(np.log(A_diag))\n",
        "        log_det_Vi = log_det_A + np.log(denom)\n",
        "        log_lik += log_det_Vi\n",
        "\n",
        "        # Inversion Operations\n",
        "        inv_A_y = inv_A_diag * y_i\n",
        "        # w_y = V_i^-1 * y_i\n",
        "        w_y = inv_A_y - (tau2 * inv_A_diag * np.sum(inv_A_y)) / denom\n",
        "\n",
        "        # w_1 = V_i^-1 * 1\n",
        "        w_1 = inv_A_diag - (tau2 * inv_A_diag * sum_inv_A) / denom\n",
        "\n",
        "        sum_S += np.sum(w_1)      # 1^T V^-1 1\n",
        "        sum_Sy += np.sum(w_y)     # 1^T V^-1 y\n",
        "        sum_ySy += np.dot(y_i, w_y) # y^T V^-1 y\n",
        "\n",
        "    # REML Profile Likelihood Calculation\n",
        "    mu = sum_Sy / sum_S\n",
        "    resid = sum_ySy - 2*mu*sum_Sy + mu**2 * sum_S\n",
        "\n",
        "    # Full REML Log Likelihood\n",
        "    total_log_lik = -0.5 * (log_lik + np.log(sum_S) + resid)\n",
        "\n",
        "    return -total_log_lik\n",
        "\n",
        "\n",
        "def run_python_3level(yi, vi, study_ids):\n",
        "    # 1. First Pass: L-BFGS-B (Global search)\n",
        "    best_res = None\n",
        "    best_fun = np.inf\n",
        "\n",
        "    # Multiple start points to avoid local minima\n",
        "    start_points = [[0.01, 0.01], [0.5, 0.1], [0.1, 0.5], [0.001, 0.001]]\n",
        "\n",
        "    for start in start_points:\n",
        "        res = minimize(_neg_log_lik_reml, x0=start, args=(yi, vi, study_ids),\n",
        "                       bounds=[(1e-8, None), (1e-8, None)],\n",
        "                       method='L-BFGS-B',\n",
        "                       options={'ftol': 1e-12, 'gtol': 1e-12}) # High precision\n",
        "        if res.success and res.fun < best_fun:\n",
        "            best_fun = res.fun\n",
        "            best_res = res\n",
        "\n",
        "    if not best_res: return None\n",
        "\n",
        "    # 2. Second Pass: Nelder-Mead (Polishing)\n",
        "    # Sometimes gradient methods get stuck slightly off in flat valleys\n",
        "    final_res = minimize(_neg_log_lik_reml, x0=best_res.x, args=(yi, vi, study_ids),\n",
        "                         method='Nelder-Mead',\n",
        "                         bounds=[(1e-8, None), (1e-8, None)],\n",
        "                         options={'xatol': 1e-12, 'fatol': 1e-12})\n",
        "\n",
        "    tau2, sigma2 = final_res.x\n",
        "    return tau2, sigma2\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CORE: _get_three_level_regression_estimates_v2 (BACKWARD COMPATIBLE)\n",
        "# =============================================================================\n",
        "\n",
        "def _get_three_level_regression_estimates_v2(params, y_all, v_all, X_all,\n",
        "                                              N_total, M_studies, p_params):\n",
        "    \"\"\"\n",
        "    Calculates betas, standard errors, p-values, and likelihood.\n",
        "\n",
        "    BACKWARD COMPATIBLE: Returns all original keys plus new ones.\n",
        "    \"\"\"\n",
        "    JITTER = 1e-8\n",
        "\n",
        "    try:\n",
        "        tau_sq = max(params[0], 1e-10)\n",
        "        sigma_sq = max(params[1], 1e-10)\n",
        "\n",
        "        sum_log_det_Vi = 0.0\n",
        "        sum_XWX = np.zeros((p_params, p_params))\n",
        "        sum_XWy = np.zeros(p_params)\n",
        "        sum_yWy = 0.0\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = y_all[i]\n",
        "            v_i = v_all[i]\n",
        "            X_i = X_all[i]\n",
        "\n",
        "            # V_i = diag(v_i) + sigma\u00b2*I + tau\u00b2*J, inverted via Sherman-Morrison\n",
        "            A_diag = v_i + sigma_sq + JITTER\n",
        "            inv_A_diag = 1.0 / A_diag\n",
        "            sum_inv_A = np.sum(inv_A_diag)\n",
        "            denom = max(1.0 + tau_sq * sum_inv_A, JITTER)\n",
        "\n",
        "            # Log determinant\n",
        "            log_det_A = np.sum(np.log(A_diag))\n",
        "            sum_log_det_Vi += log_det_A + np.log(denom)\n",
        "\n",
        "            # Efficient X'V\u207b\u00b9X and X'V\u207b\u00b9y computation\n",
        "            inv_A_X = inv_A_diag[:, None] * X_i\n",
        "            inv_A_y = inv_A_diag * y_i\n",
        "            sum_inv_A_X = np.sum(inv_A_X, axis=0)\n",
        "            sum_inv_A_y = np.sum(inv_A_y)\n",
        "\n",
        "            xt_invA_x = X_i.T @ inv_A_X\n",
        "            correction_term = (tau_sq / denom) * np.outer(sum_inv_A_X, sum_inv_A_X)\n",
        "            sum_XWX += xt_invA_x - correction_term\n",
        "\n",
        "            xt_invA_y = X_i.T @ inv_A_y\n",
        "            correction_y = (tau_sq / denom) * sum_inv_A_X * sum_inv_A_y\n",
        "            sum_XWy += xt_invA_y - correction_y\n",
        "\n",
        "            yt_invA_y = np.dot(y_i, inv_A_y)\n",
        "            correction_yy = (tau_sq / denom) * (sum_inv_A_y ** 2)\n",
        "            sum_yWy += yt_invA_y - correction_yy\n",
        "\n",
        "        # Add jitter for numerical stability\n",
        "        sum_XWX += JITTER * np.eye(p_params)\n",
        "\n",
        "        try:\n",
        "            betas = np.linalg.solve(sum_XWX, sum_XWy)\n",
        "            var_betas = np.linalg.inv(sum_XWX)\n",
        "        except np.linalg.LinAlgError:\n",
        "            return {'log_lik_reml': np.inf}\n",
        "\n",
        "        se_betas = np.sqrt(np.diag(var_betas))\n",
        "\n",
        "        # === CORRECT DF CALCULATION ===\n",
        "        # For 3-level models, metafor uses different df depending on the moderator:\n",
        "        # - If moderator varies within studies: df = k_studies - p (conservative)\n",
        "        # - If moderator is constant within studies (study-level): df = n_obs - p\n",
        "        #\n",
        "        # We detect this by checking if sigma_sq \u2248 0 (within-study variance negligible)\n",
        "        # When sigma_sq \u2192 0, the model effectively treats each observation as independent\n",
        "\n",
        "        if sigma_sq < 1e-4:\n",
        "            # Study-level moderator: use observation-based df (matches metafor)\n",
        "            df = max(N_total - p_params, 1)\n",
        "        else:\n",
        "            # Effect-level moderator: use study-based df (conservative)\n",
        "            df = max(M_studies - p_params, 1)\n",
        "\n",
        "        t_values = betas / se_betas\n",
        "        p_values = 2.0 * t_dist.sf(np.abs(t_values), df=df)\n",
        "\n",
        "        t_crit = t_dist.ppf(0.975, df=df)\n",
        "        ci_lower = betas - t_crit * se_betas\n",
        "        ci_upper = betas + t_crit * se_betas\n",
        "\n",
        "        # REML likelihood\n",
        "        residual_ss = sum_yWy - np.dot(betas, sum_XWy)\n",
        "        sign, log_det_XWX = np.linalg.slogdet(sum_XWX)\n",
        "        if sign <= 0:\n",
        "            return {'log_lik_reml': np.inf}\n",
        "        log_lik_reml = -0.5 * (sum_log_det_Vi + log_det_XWX + residual_ss)\n",
        "\n",
        "        # === RETURN: All original keys + new ones ===\n",
        "        return {\n",
        "            # Original keys (backward compatible)\n",
        "            'betas': betas,\n",
        "            'se_betas': se_betas,\n",
        "            'var_betas_robust': var_betas,  # Original key name preserved\n",
        "            'log_lik_reml': log_lik_reml,\n",
        "            'tau_sq': tau_sq,\n",
        "            'sigma_sq': sigma_sq,\n",
        "            # New keys (additions)\n",
        "            'var_betas': var_betas,         # Alias\n",
        "            't_values': t_values,\n",
        "            'p_values': p_values,\n",
        "            'df': df,                        # df depends on moderator type\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'n_obs': N_total,               # For reference\n",
        "            'k_studies': M_studies,         # For reference\n",
        "        }\n",
        "\n",
        "    except (FloatingPointError, ValueError, np.linalg.LinAlgError):\n",
        "        return {'log_lik_reml': np.inf}\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# NEGATIVE LOG-LIKELIHOOD (unchanged interface)\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# COMPONENT 1: _get_gls_estimates (FULL REWRITE with VCV support)\n",
        "# =============================================================================\n",
        "\n",
        "def _get_gls_estimates(params, y_all, vcv_all, X_all, N_total, M_studies, p_params):\n",
        "    \"\"\"\n",
        "    Calculates Fixed Effects (Betas) using Generalized Least Squares (GLS).\n",
        "\n",
        "    Supports:\n",
        "      - Full VCV matrices for shared controls\n",
        "      - Diagonal matrices (independence assumption)\n",
        "      - Sherman-Morrison optimization for diagonal case\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    params : array-like\n",
        "        [tau_sq, sigma_sq] - variance components\n",
        "    y_all : list of arrays\n",
        "        Effect sizes for each study\n",
        "    vcv_all : list of 2D arrays\n",
        "        Sampling covariance matrices for each study (k_i \u00d7 k_i)\n",
        "    X_all : list of 2D arrays\n",
        "        Design matrices for each study (k_i \u00d7 p)\n",
        "    N_total : int\n",
        "        Total number of observations\n",
        "    M_studies : int\n",
        "        Number of studies\n",
        "    p_params : int\n",
        "        Number of fixed effect parameters (including intercept)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict with keys:\n",
        "        'betas', 'cov_beta', 'se_betas', 'log_lik_reml', 'tau_sq', 'sigma_sq'\n",
        "        Returns {'log_lik_reml': -np.inf} on failure\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tau_sq, sigma_sq = params\n",
        "\n",
        "        # Safety constraints\n",
        "        tau_sq = max(tau_sq, 1e-10)\n",
        "        sigma_sq = max(sigma_sq, 1e-10)\n",
        "\n",
        "        # Accumulators for GLS normal equations\n",
        "        # \u03b2 = (X'\u03a3\u207b\u00b9X)\u207b\u00b9 X'\u03a3\u207b\u00b9y\n",
        "        sum_Xt_invS_X = np.zeros((p_params, p_params))\n",
        "        sum_Xt_invS_y = np.zeros(p_params)\n",
        "\n",
        "        # Accumulators for likelihood\n",
        "        sum_log_det = 0.0\n",
        "        sum_y_invS_y = 0.0\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = np.asarray(y_all[i], dtype=np.float64)\n",
        "            X_i = np.asarray(X_all[i], dtype=np.float64)\n",
        "            V_i = np.asarray(vcv_all[i], dtype=np.float64)\n",
        "            k = len(y_i)\n",
        "\n",
        "            # Ensure V_i is 2D\n",
        "            if V_i.ndim == 1:\n",
        "                V_i = np.diag(V_i)\n",
        "\n",
        "            # Check if V_i is diagonal (use fast path)\n",
        "            is_diagonal = (k == 1) or np.allclose(V_i, np.diag(np.diag(V_i)))\n",
        "\n",
        "            if is_diagonal:\n",
        "                # =============================================================\n",
        "                # FAST PATH: Sherman-Morrison Formula\n",
        "                # \u03a3_i = diag(v_i + \u03c3\u00b2) + \u03c4\u00b2J  where J is all-ones matrix\n",
        "                # =============================================================\n",
        "                v_i = np.diag(V_i) if k > 1 else np.array([V_i[0, 0]])\n",
        "\n",
        "                # A = diag(v_i + \u03c3\u00b2)\n",
        "                A_diag = v_i + sigma_sq\n",
        "                inv_A_diag = 1.0 / A_diag\n",
        "\n",
        "                # Sherman-Morrison: (A + \u03c4\u00b2J)\u207b\u00b9 = A\u207b\u00b9 - (\u03c4\u00b2 A\u207b\u00b9 J A\u207b\u00b9)/(1 + \u03c4\u00b2 tr(A\u207b\u00b9))\n",
        "                sum_inv_A = np.sum(inv_A_diag)\n",
        "                denom = 1.0 + tau_sq * sum_inv_A\n",
        "\n",
        "                if denom <= 0:\n",
        "                    return {'log_lik_reml': -np.inf}\n",
        "\n",
        "                # Log determinant: log|A + \u03c4\u00b2J| = log|A| + log(1 + \u03c4\u00b2 1'A\u207b\u00b91)\n",
        "                log_det = np.sum(np.log(A_diag)) + np.log(denom)\n",
        "\n",
        "                # \u03a3\u207b\u00b9X using Sherman-Morrison\n",
        "                # invS_X[j,:] = inv_A_diag[j] * X_i[j,:] - (\u03c4\u00b2/denom) * inv_A_diag[j] * (sum over l of inv_A_diag[l] * X_i[l,:])\n",
        "                invA_X = X_i * inv_A_diag[:, np.newaxis]  # Element-wise: each row scaled\n",
        "                sum_invA_X = np.sum(invA_X, axis=0)  # Column sums\n",
        "                invS_X = invA_X - (tau_sq / denom) * np.outer(inv_A_diag, sum_invA_X)\n",
        "\n",
        "                # \u03a3\u207b\u00b9y using Sherman-Morrison\n",
        "                invA_y = y_i * inv_A_diag\n",
        "                sum_invA_y = np.sum(invA_y)\n",
        "                invS_y = invA_y - (tau_sq / denom) * inv_A_diag * sum_invA_y\n",
        "\n",
        "            else:\n",
        "                # =============================================================\n",
        "                # FULL PATH: Direct Matrix Inversion for Shared Controls\n",
        "                # \u03a3_i = V_i + \u03c3\u00b2I + \u03c4\u00b2J\n",
        "                # =============================================================\n",
        "                Sigma_i = V_i.copy()\n",
        "\n",
        "                # Add Level 2: \u03c3\u00b2 on diagonal\n",
        "                Sigma_i = Sigma_i + sigma_sq * np.eye(k)\n",
        "\n",
        "                # Add Level 3: \u03c4\u00b2 to all elements (compound symmetry)\n",
        "                Sigma_i = Sigma_i + tau_sq * np.ones((k, k))\n",
        "\n",
        "                # Inversion with numerical stability\n",
        "                try:\n",
        "                    # Check for positive definiteness\n",
        "                    eigvals = np.linalg.eigvalsh(Sigma_i)\n",
        "                    if np.min(eigvals) < 1e-10:\n",
        "                        # Add ridge for stability\n",
        "                        Sigma_i = Sigma_i + 1e-8 * np.eye(k)\n",
        "\n",
        "                    L = np.linalg.cholesky(Sigma_i)\n",
        "                    # Solve via Cholesky (more stable than explicit inverse)\n",
        "                    #inv_Sigma_i = scipy.linalg.cho_solve((L, True), np.eye(k)) // old\n",
        "                    inv_Sigma_i = np.linalg.solve(Sigma_i, np.eye(k))\n",
        "                    log_det = 2.0 * np.sum(np.log(np.diag(L)))\n",
        "\n",
        "                except np.linalg.LinAlgError:\n",
        "                    # Fallback: pseudo-inverse\n",
        "                    try:\n",
        "                        inv_Sigma_i = np.linalg.pinv(Sigma_i)\n",
        "                        sign, log_det = np.linalg.slogdet(Sigma_i)\n",
        "                        if sign <= 0:\n",
        "                            return {'log_lik_reml': -np.inf}\n",
        "                    except:\n",
        "                        return {'log_lik_reml': -np.inf}\n",
        "\n",
        "                # Compute weighted quantities\n",
        "                invS_X = inv_Sigma_i @ X_i\n",
        "                invS_y = inv_Sigma_i @ y_i\n",
        "\n",
        "            # =============================================================\n",
        "            # Accumulate across studies\n",
        "            # =============================================================\n",
        "            sum_Xt_invS_X += X_i.T @ invS_X      # X'\u03a3\u207b\u00b9X\n",
        "            sum_Xt_invS_y += X_i.T @ invS_y      # X'\u03a3\u207b\u00b9y\n",
        "            sum_y_invS_y += np.dot(y_i, invS_y)  # y'\u03a3\u207b\u00b9y\n",
        "            sum_log_det += log_det\n",
        "\n",
        "        # =============================================================\n",
        "        # Solve GLS Normal Equations: \u03b2 = (X'\u03a3\u207b\u00b9X)\u207b\u00b9 X'\u03a3\u207b\u00b9y\n",
        "        # =============================================================\n",
        "        try:\n",
        "            # Add small ridge for numerical stability\n",
        "            ridge = 1e-10 * np.eye(p_params)\n",
        "            cov_beta = np.linalg.inv(sum_Xt_invS_X + ridge)\n",
        "            betas = cov_beta @ sum_Xt_invS_y\n",
        "        except np.linalg.LinAlgError:\n",
        "            # Heavier ridge if needed\n",
        "            try:\n",
        "                cov_beta = np.linalg.inv(sum_Xt_invS_X + 1e-6 * np.eye(p_params))\n",
        "                betas = cov_beta @ sum_Xt_invS_y\n",
        "            except:\n",
        "                return {'log_lik_reml': -np.inf}\n",
        "\n",
        "        # =============================================================\n",
        "        # REML Log-Likelihood\n",
        "        # =============================================================\n",
        "        # RSS = y'\u03a3\u207b\u00b9y - 2\u03b2'X'\u03a3\u207b\u00b9y + \u03b2'X'\u03a3\u207b\u00b9X\u03b2\n",
        "        #     = sum_y_invS_y - \u03b2'X'\u03a3\u207b\u00b9y  (simplified using normal equations)\n",
        "        rss = sum_y_invS_y - np.dot(betas, sum_Xt_invS_y)\n",
        "\n",
        "        # Ensure RSS is non-negative (numerical precision)\n",
        "        rss = max(rss, 0.0)\n",
        "\n",
        "        # log|X'\u03a3\u207b\u00b9X|\n",
        "        sign, log_det_XtSX = np.linalg.slogdet(sum_Xt_invS_X)\n",
        "        if sign <= 0:\n",
        "            log_det_XtSX = -50  # Penalize but don't crash\n",
        "\n",
        "        # REML log-likelihood (matches metafor::rma.mv)\n",
        "        # -2 * logLik_REML = (N-p)*log(2\u03c0) + log|\u03a3| + log|X'\u03a3\u207b\u00b9X| + RSS\n",
        "        log_lik_reml = -0.5 * (\n",
        "            (N_total - p_params) * np.log(2.0 * np.pi) +\n",
        "            sum_log_det +\n",
        "            log_det_XtSX +\n",
        "            rss\n",
        "        )\n",
        "\n",
        "        # =============================================================\n",
        "        # Standard Errors for Betas\n",
        "        # =============================================================\n",
        "        se_betas = np.sqrt(np.diag(cov_beta))\n",
        "\n",
        "        # Check for valid SEs\n",
        "        if np.any(np.isnan(se_betas)) or np.any(se_betas <= 0):\n",
        "            se_betas = np.full(p_params, np.nan)\n",
        "\n",
        "        return {\n",
        "            'betas': betas,\n",
        "            'cov_beta': cov_beta,\n",
        "            'se_betas': se_betas,\n",
        "            'log_lik_reml': log_lik_reml,\n",
        "            'tau_sq': tau_sq,\n",
        "            'sigma_sq': sigma_sq,\n",
        "            'rss': rss,\n",
        "            'sum_log_det': sum_log_det\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {'log_lik_reml': -np.inf}\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# COMPONENT 2: _neg_log_lik_reml_reg (Updated wrapper)\n",
        "# =============================================================================\n",
        "\n",
        "def _neg_log_lik_reml_reg(params, y_all, vcv_all, X_all, N_total, M_studies, p_params):\n",
        "    \"\"\"\n",
        "    Negative REML log-likelihood for optimization.\n",
        "\n",
        "    Now accepts vcv_all (list of matrices) instead of v_all (list of vectors).\n",
        "    \"\"\"\n",
        "    tau_sq = max(params[0], 1e-10)\n",
        "    sigma_sq = max(params[1], 1e-10)\n",
        "\n",
        "    est = _get_gls_estimates(\n",
        "        [tau_sq, sigma_sq], y_all, vcv_all, X_all, N_total, M_studies, p_params\n",
        "    )\n",
        "\n",
        "    ll = est.get('log_lik_reml', -np.inf)\n",
        "\n",
        "    if not np.isfinite(ll):\n",
        "        return 1e10\n",
        "\n",
        "    return -ll\n",
        "\n",
        "\n",
        "def _neg_log_lik_reml_reg_constrained(params, y_all, vcv_all, X_all, N_total, M_studies,\n",
        "                                       p_params, tau_sq_prior, penalty_weight):\n",
        "    \"\"\"\n",
        "    Constrained REML for constant-within-study moderators.\n",
        "    Adds penalty to prevent tau\u00b2 from collapsing to zero.\n",
        "    \"\"\"\n",
        "    base_nll = _neg_log_lik_reml_reg(params, y_all, vcv_all, X_all, N_total, M_studies, p_params)\n",
        "\n",
        "    # Penalty: discourage tau\u00b2 from going too far from the intercept-only estimate\n",
        "    tau_sq = max(params[0], 1e-10)\n",
        "    penalty = penalty_weight * (np.log(tau_sq) - np.log(tau_sq_prior)) ** 2\n",
        "\n",
        "    return base_nll + penalty\n",
        "\n",
        "#==============================================================================\n",
        "# Meta regression function\n",
        "#==============================================================================\n",
        "import scipy.linalg\n",
        "from scipy.optimize import minimize, minimize_scalar\n",
        "\n",
        "def _run_three_level_reml_regression_v2(analysis_data, moderator_col, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Robust 3-level REML meta-regression with Fallback Strategy.\n",
        "\n",
        "    Strategies:\n",
        "      - Plan A: Full 3-Level GLS with VCV Matrices\n",
        "      - Plan B: 3-Level GLS with Diagonal (Independence)\n",
        "      - Plan C: Aggregated 2-Level Regression (Fallback for Study-Level Moderators)\n",
        "    \"\"\"\n",
        "\n",
        "    # =================================================================\n",
        "    # 1. DATA PREPARATION\n",
        "    # =================================================================\n",
        "    analysis_data = analysis_data.sort_values(['id']).reset_index(drop=True)\n",
        "    vcv_dict = ANALYSIS_CONFIG.get('vcv_matrices', {})\n",
        "\n",
        "    grouped = analysis_data.groupby('id', sort=False)\n",
        "\n",
        "    y_all = []\n",
        "    vcv_all_matrix = []\n",
        "    vcv_all_diag = []\n",
        "    X_all = []\n",
        "    study_ids = []\n",
        "\n",
        "    for study_id, group in grouped:\n",
        "        k = len(group)\n",
        "        study_ids.append(study_id)\n",
        "\n",
        "        y_i = group[effect_col].values.astype(np.float64)\n",
        "        y_all.append(y_i)\n",
        "\n",
        "        vi = group[var_col].values.astype(np.float64)\n",
        "        vcv_all_diag.append(np.diag(vi))\n",
        "\n",
        "        sid_str = str(study_id)\n",
        "        if sid_str in vcv_dict:\n",
        "            V_i = np.asarray(vcv_dict[sid_str], dtype=np.float64)\n",
        "            if V_i.shape[0] != k: V_i = np.diag(vi)\n",
        "        elif study_id in vcv_dict:\n",
        "            V_i = np.asarray(vcv_dict[study_id], dtype=np.float64)\n",
        "            if V_i.shape[0] != k: V_i = np.diag(vi)\n",
        "        else:\n",
        "            V_i = np.diag(vi)\n",
        "        vcv_all_matrix.append(V_i)\n",
        "\n",
        "        mod_values = group[moderator_col].values.astype(np.float64)\n",
        "        X_i = np.column_stack([np.ones(k), mod_values])\n",
        "        X_all.append(X_i)\n",
        "\n",
        "    N_total = len(analysis_data)\n",
        "    M_studies = len(y_all)\n",
        "    p_params = 2\n",
        "\n",
        "    if M_studies < 2 or N_total < 3:\n",
        "        return None, None, None\n",
        "\n",
        "    is_constant_within = analysis_data.groupby('id')[moderator_col].nunique().max() == 1\n",
        "\n",
        "    mod_range = analysis_data[moderator_col].max() - analysis_data[moderator_col].min()\n",
        "    if mod_range < 1e-10:\n",
        "        return None, None, None\n",
        "\n",
        "    tau_sq_prior, sigma_sq_prior = _estimate_variance_from_intercept_model_vcv(\n",
        "        y_all, vcv_all_matrix, M_studies\n",
        "    )\n",
        "\n",
        "    # =================================================================\n",
        "    # 2. OPTIMIZER DEFINITION\n",
        "    # =================================================================\n",
        "\n",
        "    def run_optimizer(vcv_input, constrained=False):\n",
        "        best_res = None\n",
        "        best_fun = np.inf\n",
        "\n",
        "        if constrained:\n",
        "            starts = [\n",
        "                [tau_sq_prior, sigma_sq_prior],\n",
        "                [tau_sq_prior * 0.5, sigma_sq_prior],\n",
        "                [tau_sq_prior * 2.0, sigma_sq_prior],\n",
        "                [0.1, 0.1],\n",
        "                [0.5, 0.01],\n",
        "            ]\n",
        "            penalty = 5.0\n",
        "\n",
        "            for start in starts:\n",
        "                try:\n",
        "                    with warnings.catch_warnings():\n",
        "                        warnings.simplefilter(\"ignore\")\n",
        "                        res = minimize(\n",
        "                            _neg_log_lik_reml_reg_constrained,\n",
        "                            x0=start,\n",
        "                            args=(y_all, vcv_input, X_all, N_total, M_studies, p_params,\n",
        "                                  tau_sq_prior, penalty),\n",
        "                            method='L-BFGS-B',\n",
        "                            bounds=[(1e-8, 50.0), (1e-8, 50.0)],\n",
        "                            options={'ftol': 1e-11, 'maxiter': 2000}\n",
        "                        )\n",
        "                    if res.fun < best_fun and np.isfinite(res.fun):\n",
        "                        best_fun = res.fun\n",
        "                        best_res = res\n",
        "                except:\n",
        "                    continue\n",
        "        else:\n",
        "            starts = [\n",
        "                [tau_sq_prior, sigma_sq_prior],\n",
        "                [0.01, 0.01], [0.1, 0.1], [1.0, 0.1], [0.1, 1.0], [0.5, 0.5]\n",
        "            ]\n",
        "            for start in starts:\n",
        "                try:\n",
        "                    with warnings.catch_warnings():\n",
        "                        warnings.simplefilter(\"ignore\")\n",
        "                        res = minimize(\n",
        "                            _neg_log_lik_reml_reg,\n",
        "                            x0=start,\n",
        "                            args=(y_all, vcv_input, X_all, N_total, M_studies, p_params),\n",
        "                            method='L-BFGS-B',\n",
        "                            bounds=[(1e-8, 50.0), (1e-8, 50.0)],\n",
        "                            options={'ftol': 1e-11, 'maxiter': 2000}\n",
        "                        )\n",
        "                    if res.fun < best_fun and np.isfinite(res.fun):\n",
        "                        best_fun = res.fun\n",
        "                        best_res = res\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        return best_res\n",
        "\n",
        "    # =================================================================\n",
        "    # 3. EXECUTION: PLAN A -> B -> C\n",
        "    # =================================================================\n",
        "\n",
        "    best_res = None\n",
        "    final_vcv = None\n",
        "    model_type = \"Unknown\"\n",
        "    plan_c_result = None  # NEW: Store Plan C result separately\n",
        "\n",
        "    # --- Plan A: Full Matrix ---\n",
        "    has_off_diag = any(not np.allclose(m, np.diag(np.diag(m))) for m in vcv_all_matrix)\n",
        "\n",
        "    if has_off_diag:\n",
        "        best_res = run_optimizer(vcv_all_matrix, constrained=is_constant_within)\n",
        "        if best_res is not None:\n",
        "            final_vcv = vcv_all_matrix\n",
        "            model_type = \"3-Level VCV\" if not is_constant_within else \"3-Level VCV (Constrained)\"\n",
        "\n",
        "    # --- Plan B: Diagonal ---\n",
        "    if best_res is None:\n",
        "        best_res = run_optimizer(vcv_all_diag, constrained=is_constant_within)\n",
        "        if best_res is not None:\n",
        "            final_vcv = vcv_all_diag\n",
        "            model_type = \"3-Level Diagonal\" if not is_constant_within else \"3-Level Diagonal (Constrained)\"\n",
        "\n",
        "    # --- Plan C: Aggregated 2-Level ---\n",
        "    # CRITICAL: This returns DIRECTLY, not through _get_gls_estimates\n",
        "    if best_res is None and is_constant_within:\n",
        "        plan_c_result = _run_aggregated_2level_regression(\n",
        "            y_all, vcv_all_diag, X_all, M_studies, tau_sq_prior\n",
        "        )\n",
        "\n",
        "        if plan_c_result is not None:\n",
        "            # Add model type and return immediately\n",
        "            plan_c_result['model_type'] = \"2-Level Aggregated (Fallback)\"\n",
        "            plan_c_result['is_constant_within'] = True\n",
        "            plan_c_result['n_studies'] = M_studies\n",
        "            plan_c_result['n_obs'] = N_total\n",
        "\n",
        "            info = (N_total, M_studies, p_params)\n",
        "            fake_opt_result = type('obj', (object,), {\n",
        "                'x': np.array([plan_c_result['tau_sq'], plan_c_result['sigma_sq']]),\n",
        "                'success': True,\n",
        "                'fun': 0.0\n",
        "            })()\n",
        "\n",
        "            return plan_c_result, info, fake_opt_result\n",
        "\n",
        "    # All plans failed\n",
        "    if best_res is None:\n",
        "        return None, None, None\n",
        "\n",
        "    # =================================================================\n",
        "    # 4. FINAL CALCULATION (Plans A & B only)\n",
        "    # =================================================================\n",
        "\n",
        "    try:\n",
        "        # Polish with Nelder-Mead\n",
        "        try:\n",
        "            final_res = minimize(\n",
        "                _neg_log_lik_reml_reg,\n",
        "                x0=best_res.x,\n",
        "                args=(y_all, final_vcv, X_all, N_total, M_studies, p_params),\n",
        "                method='Nelder-Mead',\n",
        "                options={'xatol': 1e-10, 'fatol': 1e-10, 'maxiter': 1000}\n",
        "            )\n",
        "            if np.isfinite(final_res.fun) and final_res.fun < best_res.fun:\n",
        "                best_res = final_res\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Calculate final estimates\n",
        "        final_est = _get_gls_estimates(\n",
        "            best_res.x, y_all, final_vcv, X_all, N_total, M_studies, p_params\n",
        "        )\n",
        "\n",
        "        if final_est.get('log_lik_reml', -np.inf) == -np.inf:\n",
        "            return None, None, None\n",
        "\n",
        "        betas = final_est['betas']\n",
        "        se_betas = final_est['se_betas']\n",
        "\n",
        "        # Robust SEs\n",
        "        try:\n",
        "            var_betas_robust = _compute_robust_var_betas(\n",
        "                betas, y_all, final_vcv, X_all, final_est['tau_sq'], final_est['sigma_sq']\n",
        "            )\n",
        "            se_betas_robust = np.sqrt(np.diag(var_betas_robust))\n",
        "            # Use robust SEs if they're valid\n",
        "            if np.all(np.isfinite(se_betas_robust)) and np.all(se_betas_robust > 0):\n",
        "                se_betas = se_betas_robust\n",
        "            else:\n",
        "                var_betas_robust = final_est['cov_beta']\n",
        "        except:\n",
        "            var_betas_robust = final_est['cov_beta']\n",
        "\n",
        "        # Degrees of freedom\n",
        "        if is_constant_within:\n",
        "            df = max(1, M_studies - p_params)\n",
        "        else:\n",
        "            df = max(1, N_total - M_studies - p_params + 1)\n",
        "\n",
        "        # Inference\n",
        "        t_stats = betas / se_betas\n",
        "        p_values = 2 * (1 - t.cdf(np.abs(t_stats), df))\n",
        "\n",
        "        # Confidence intervals\n",
        "        alpha = ANALYSIS_CONFIG.get('global_settings', {}).get('alpha', 0.05)\n",
        "        crit_val = t.ppf(1 - alpha/2, df)\n",
        "        ci_lower = betas - crit_val * se_betas\n",
        "        ci_upper = betas + crit_val * se_betas\n",
        "\n",
        "        final_est.update({\n",
        "            'df': df,\n",
        "            't_stats': t_stats,\n",
        "            'p_values': p_values,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'var_betas_robust': var_betas_robust,\n",
        "            'se_betas': se_betas,\n",
        "            'model_type': model_type,\n",
        "            'is_constant_within': is_constant_within,\n",
        "            'n_studies': M_studies,\n",
        "            'n_obs': N_total,\n",
        "            'optimizer_converged': getattr(best_res, 'success', False)\n",
        "        })\n",
        "\n",
        "        return final_est, (N_total, M_studies, p_params), best_res\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# NEW HELPER: Plan C - Aggregated 2-Level Regression\n",
        "# =============================================================================\n",
        "\n",
        "def _run_aggregated_2level_regression(y_all, vcv_all, X_all, M_studies, tau_sq_prior):\n",
        "    \"\"\"\n",
        "    Runs a 2-level (study-level) meta-regression when 3-level fails.\n",
        "\n",
        "    This aggregates multiple effects per study into a single weighted mean,\n",
        "    then performs standard random-effects meta-regression.\n",
        "\n",
        "    Returns a complete estimates dictionary matching _get_gls_estimates output.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # =============================================================\n",
        "        # 1. AGGREGATE TO STUDY LEVEL\n",
        "        # =============================================================\n",
        "\n",
        "        agg_y = []      # Aggregated effect sizes\n",
        "        agg_v = []      # Aggregated variances\n",
        "        agg_mod = []    # Moderator values (constant within study)\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = y_all[i]\n",
        "            V_i = vcv_all[i]\n",
        "            X_i = X_all[i]\n",
        "\n",
        "            # Get variances (diagonal of VCV)\n",
        "            if V_i.ndim == 1:\n",
        "                v_i = V_i\n",
        "            else:\n",
        "                v_i = np.diag(V_i)\n",
        "\n",
        "            # Weights = inverse variance\n",
        "            w_i = 1.0 / v_i\n",
        "            sum_w = np.sum(w_i)\n",
        "\n",
        "            # Weighted mean effect size\n",
        "            mu_agg = np.sum(y_i * w_i) / sum_w\n",
        "\n",
        "            # Variance of the weighted mean\n",
        "            # For independent effects: Var(weighted mean) = 1 / sum(weights)\n",
        "            # For correlated effects, this is an approximation\n",
        "            v_agg = 1.0 / sum_w\n",
        "\n",
        "            # Moderator (take first value - it's constant within study)\n",
        "            mod_val = X_i[0, 1]\n",
        "\n",
        "            agg_y.append(mu_agg)\n",
        "            agg_v.append(v_agg)\n",
        "            agg_mod.append(mod_val)\n",
        "\n",
        "        agg_y = np.array(agg_y)\n",
        "        agg_v = np.array(agg_v)\n",
        "        agg_mod = np.array(agg_mod)\n",
        "\n",
        "        # =============================================================\n",
        "        # 2. OPTIMIZE TAU\u00b2 (Between-Study Variance)\n",
        "        # =============================================================\n",
        "\n",
        "        def neg_reml_2level(tau_sq):\n",
        "            \"\"\"Negative REML log-likelihood for 2-level model.\"\"\"\n",
        "            tau_sq = max(tau_sq, 1e-10)\n",
        "\n",
        "            # Total variance = sampling variance + tau\u00b2\n",
        "            total_v = agg_v + tau_sq\n",
        "            weights = 1.0 / total_v\n",
        "\n",
        "            # Weighted least squares\n",
        "            X = np.column_stack([np.ones(M_studies), agg_mod])\n",
        "            W = np.diag(weights)\n",
        "\n",
        "            try:\n",
        "                XtWX = X.T @ W @ X\n",
        "                XtWy = X.T @ W @ agg_y\n",
        "\n",
        "                # Check for singularity\n",
        "                if np.linalg.cond(XtWX) > 1e10:\n",
        "                    return 1e10\n",
        "\n",
        "                betas = np.linalg.solve(XtWX, XtWy)\n",
        "\n",
        "                # Residuals\n",
        "                resid = agg_y - X @ betas\n",
        "\n",
        "                # REML log-likelihood components\n",
        "                log_det_V = np.sum(np.log(total_v))\n",
        "                sign, log_det_XtWX = np.linalg.slogdet(XtWX)\n",
        "                rss = resid.T @ W @ resid\n",
        "\n",
        "                # REML: -2 * logLik = log|V| + log|X'V\u207b\u00b9X| + RSS\n",
        "                neg_2_loglik = log_det_V + log_det_XtWX + rss\n",
        "\n",
        "                return 0.5 * neg_2_loglik\n",
        "\n",
        "            except:\n",
        "                return 1e10\n",
        "\n",
        "        # Multi-start optimization\n",
        "        starts = [tau_sq_prior, 0.01, 0.1, 0.5, 1.0, 2.0]\n",
        "        best_tau_sq = tau_sq_prior\n",
        "        best_nll = np.inf\n",
        "\n",
        "        for start in starts:\n",
        "            try:\n",
        "                res = minimize_scalar(\n",
        "                    neg_reml_2level,\n",
        "                    bounds=(1e-10, 50.0),\n",
        "                    method='bounded',\n",
        "                    options={'xatol': 1e-10}\n",
        "                )\n",
        "                if res.fun < best_nll:\n",
        "                    best_nll = res.fun\n",
        "                    best_tau_sq = res.x\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        tau_sq = max(best_tau_sq, 1e-10)\n",
        "\n",
        "        # =============================================================\n",
        "        # 3. COMPUTE FINAL ESTIMATES\n",
        "        # =============================================================\n",
        "\n",
        "        total_v = agg_v + tau_sq\n",
        "        weights = 1.0 / total_v\n",
        "\n",
        "        X = np.column_stack([np.ones(M_studies), agg_mod])\n",
        "        W = np.diag(weights)\n",
        "\n",
        "        XtWX = X.T @ W @ X\n",
        "        XtWy = X.T @ W @ agg_y\n",
        "\n",
        "        # Coefficients\n",
        "        cov_beta = np.linalg.inv(XtWX)\n",
        "        betas = cov_beta @ XtWy\n",
        "        se_betas = np.sqrt(np.diag(cov_beta))\n",
        "\n",
        "        # Residuals and RSS\n",
        "        resid = agg_y - X @ betas\n",
        "        rss = resid.T @ W @ resid\n",
        "\n",
        "        # Log-likelihood (for reporting)\n",
        "        log_det_V = np.sum(np.log(total_v))\n",
        "        sign, log_det_XtWX = np.linalg.slogdet(XtWX)\n",
        "        log_lik_reml = -0.5 * (\n",
        "            (M_studies - 2) * np.log(2 * np.pi) +\n",
        "            log_det_V +\n",
        "            log_det_XtWX +\n",
        "            rss\n",
        "        )\n",
        "\n",
        "        # Degrees of freedom\n",
        "        df = max(1, M_studies - 2)\n",
        "\n",
        "        # Inference\n",
        "        t_stats = betas / se_betas\n",
        "        p_values = 2 * (1 - t.cdf(np.abs(t_stats), df))\n",
        "\n",
        "        # Confidence intervals\n",
        "        alpha = ANALYSIS_CONFIG.get('global_settings', {}).get('alpha', 0.05)\n",
        "        crit_val = t.ppf(1 - alpha/2, df)\n",
        "        ci_lower = betas - crit_val * se_betas\n",
        "        ci_upper = betas + crit_val * se_betas\n",
        "\n",
        "        return {\n",
        "            'betas': betas,\n",
        "            'cov_beta': cov_beta,\n",
        "            'se_betas': se_betas,\n",
        "            'var_betas_robust': cov_beta,  # No robust SEs for 2-level\n",
        "            'tau_sq': tau_sq,\n",
        "            'sigma_sq': 0.0,  # No within-study variance in 2-level\n",
        "            'log_lik_reml': log_lik_reml,\n",
        "            'rss': rss,\n",
        "            'df': df,\n",
        "            't_stats': t_stats,\n",
        "            'p_values': p_values,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'optimizer_converged': True\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "# =============================================================================\n",
        "# COMPONENT 4: Helper Functions\n",
        "# =============================================================================\n",
        "\n",
        "def _estimate_variance_from_intercept_model_vcv(y_all, vcv_all, M_studies):\n",
        "    \"\"\"\n",
        "    Get variance component starting values from intercept-only model.\n",
        "    Uses method-of-moments (similar to DerSimonian-Laird).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Simple weighted mean for starting point\n",
        "        weights = []\n",
        "        effects = []\n",
        "\n",
        "        for i in range(M_studies):\n",
        "            y_i = y_all[i]\n",
        "            V_i = vcv_all[i]\n",
        "\n",
        "            # Use inverse of total variance as weight\n",
        "            if V_i.ndim == 1:\n",
        "                w_i = 1.0 / np.mean(V_i)\n",
        "            else:\n",
        "                w_i = 1.0 / np.mean(np.diag(V_i))\n",
        "\n",
        "            weights.append(w_i * len(y_i))\n",
        "            effects.extend(y_i)\n",
        "\n",
        "        weights = np.array(weights)\n",
        "        effects = np.array(effects)\n",
        "\n",
        "        # Weighted mean\n",
        "        overall_mean = np.average([np.mean(y) for y in y_all], weights=weights)\n",
        "\n",
        "        # Between-study variance (tau\u00b2) - variance of study means\n",
        "        study_means = np.array([np.mean(y) for y in y_all])\n",
        "        tau_sq = np.var(study_means, ddof=1)\n",
        "        tau_sq = max(tau_sq, 0.01)\n",
        "\n",
        "        # Within-study variance (sigma\u00b2) - average within-study variance\n",
        "        within_vars = []\n",
        "        for y_i in y_all:\n",
        "            if len(y_i) > 1:\n",
        "                within_vars.append(np.var(y_i, ddof=1))\n",
        "\n",
        "        if within_vars:\n",
        "            sigma_sq = np.mean(within_vars)\n",
        "        else:\n",
        "            sigma_sq = 0.01\n",
        "\n",
        "        sigma_sq = max(sigma_sq, 0.01)\n",
        "\n",
        "        return tau_sq, sigma_sq\n",
        "\n",
        "    except Exception:\n",
        "        return 0.1, 0.1\n",
        "\n",
        "\n",
        "def _compute_robust_var_betas(betas, y_all, vcv_all, X_all, tau_sq, sigma_sq):\n",
        "    \"\"\"\n",
        "    Compute robust (sandwich) variance estimator for beta coefficients.\n",
        "\n",
        "    Var_robust(\u03b2) = (X'\u03a3\u207b\u00b9X)\u207b\u00b9 (X'\u03a3\u207b\u00b9 e e' \u03a3\u207b\u00b9X) (X'\u03a3\u207b\u00b9X)\u207b\u00b9\n",
        "\n",
        "    where e = y - X\u03b2 are the residuals.\n",
        "    \"\"\"\n",
        "    M_studies = len(y_all)\n",
        "    p_params = len(betas)\n",
        "\n",
        "    # Recompute (X'\u03a3\u207b\u00b9X)\u207b\u00b9\n",
        "    sum_Xt_invS_X = np.zeros((p_params, p_params))\n",
        "\n",
        "    # Middle term: sum over studies of X_i'\u03a3_i\u207b\u00b9 e_i e_i' \u03a3_i\u207b\u00b9 X_i\n",
        "    meat = np.zeros((p_params, p_params))\n",
        "\n",
        "    for i in range(M_studies):\n",
        "        y_i = np.asarray(y_all[i], dtype=np.float64)\n",
        "        X_i = np.asarray(X_all[i], dtype=np.float64)\n",
        "        V_i = np.asarray(vcv_all[i], dtype=np.float64)\n",
        "        k = len(y_i)\n",
        "\n",
        "        if V_i.ndim == 1:\n",
        "            V_i = np.diag(V_i)\n",
        "\n",
        "        # Build \u03a3_i\n",
        "        Sigma_i = V_i + sigma_sq * np.eye(k) + tau_sq * np.ones((k, k))\n",
        "\n",
        "        try:\n",
        "            inv_Sigma_i = np.linalg.inv(Sigma_i)\n",
        "        except:\n",
        "            inv_Sigma_i = np.linalg.pinv(Sigma_i)\n",
        "\n",
        "        # Residuals for this study\n",
        "        e_i = y_i - X_i @ betas\n",
        "\n",
        "        # Accumulate bread\n",
        "        invS_X = inv_Sigma_i @ X_i\n",
        "        sum_Xt_invS_X += X_i.T @ invS_X\n",
        "\n",
        "        # Accumulate meat: X_i' \u03a3\u207b\u00b9 e_i e_i' \u03a3\u207b\u00b9 X_i\n",
        "        invS_e = inv_Sigma_i @ e_i\n",
        "        meat += np.outer(X_i.T @ invS_e, X_i.T @ invS_e)\n",
        "\n",
        "    # Sandwich: bread\u207b\u00b9 \u00d7 meat \u00d7 bread\u207b\u00b9\n",
        "    try:\n",
        "        bread_inv = np.linalg.inv(sum_Xt_invS_X)\n",
        "        var_robust = bread_inv @ meat @ bread_inv\n",
        "    except:\n",
        "        var_robust = np.eye(p_params) * 0.01\n",
        "\n",
        "    return var_robust\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# --- PLOTTING FUNCTIONS ---\n",
        "# =============================================================================\n",
        "\n",
        "def plot_trim_fill(data, effect_col, se_col, results, es_label):\n",
        "    \"\"\"Simple Forest Plot for Trim/Fill (Preview)\"\"\"\n",
        "    k0 = results['k0']\n",
        "    orig_est = results['pooled_original']\n",
        "    fill_est = results['pooled_filled']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Plot Original Studies\n",
        "    ax.scatter(data[effect_col], data[se_col], c='black', alpha=0.6, label='Observed Studies')\n",
        "\n",
        "    # Plot Filled Studies\n",
        "    if k0 > 0:\n",
        "        se_filled = np.sqrt(results['vi_filled'])\n",
        "        ax.scatter(results['yi_filled'], se_filled, c='white', edgecolors='red', marker='o', label='Imputed Studies')\n",
        "\n",
        "    # Plot Center Lines\n",
        "    ax.axvline(orig_est, color='black', linestyle='--', label=f'Original: {orig_est:.3f}')\n",
        "    ax.axvline(fill_est, color='red', linestyle='-', label=f'Adjusted: {fill_est:.3f}')\n",
        "\n",
        "    y_max = data[se_col].max() * 1.1\n",
        "    ax.set_ylim(y_max, 0)\n",
        "    ax.set_xlabel(es_label)\n",
        "    ax.set_ylabel(\"Standard Error\")\n",
        "    ax.set_title(f\"Trim-and-Fill Funnel Plot (Missing: {results['side']})\")\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "# =============================================================================\n",
        "#SPLILINE\n",
        "# =============================================================================\n",
        "\n",
        "def _run_robust_spline_analysis(df, moderator_col, effect_col, var_col, df_spline=3):\n",
        "    \"\"\"\n",
        "    Robust 3-Level Spline Analysis.\n",
        "    Uses VCV Matrices and fixed variance components from linear meta-regression.\n",
        "    \"\"\"\n",
        "    # 1. Run Robust Linear Meta-Regression to get stable Tau^2 and Sigma^2\n",
        "    #print(\"   Step 1: Estimating variance components via linear meta-regression...\")\n",
        "    lin_est, lin_info, _ = _run_three_level_reml_regression_v2(\n",
        "        df, moderator_col, effect_col, var_col\n",
        "    )\n",
        "\n",
        "    if lin_est is None:\n",
        "        return None, \"Linear model failed to converge\"\n",
        "\n",
        "    fixed_tau2 = lin_est['tau_sq']\n",
        "    fixed_sigma2 = lin_est['sigma_sq']\n",
        "\n",
        "    # 2. Prepare Spline Design Matrix\n",
        "    # We need to sort df exactly like _run_three_level... does to match matrices\n",
        "    df_sorted = df.sort_values('id').reset_index(drop=True)\n",
        "\n",
        "    # Generate Basis\n",
        "    # Standardize moderator for numerical stability\n",
        "    mod_vals = df_sorted[moderator_col].values\n",
        "    mod_mean = np.mean(mod_vals)\n",
        "    mod_std = np.std(mod_vals)\n",
        "    z_vals = (mod_vals - mod_mean) / mod_std\n",
        "\n",
        "    try:\n",
        "        # Create basis matrix (Natural Cubic Spline)\n",
        "        import patsy\n",
        "        formula = f\"cr(x, df={df_spline}) - 1\" # -1 removes intercept (we add it manually)\n",
        "        basis_matrix = patsy.dmatrix(formula, {\"x\": z_vals}, return_type='matrix')\n",
        "        basis_matrix = np.asarray(basis_matrix)\n",
        "    except Exception as e:\n",
        "        return None, f\"Patsy error: {e}\"\n",
        "\n",
        "    # 3. Prepare Inputs for GLS\n",
        "    # We need to group X, y, and VCV by study, just like the regression driver\n",
        "    grouped = df_sorted.groupby('id', sort=False)\n",
        "    vcv_dict = ANALYSIS_CONFIG.get('vcv_matrices', {})\n",
        "\n",
        "    y_all = []\n",
        "    vcv_all = []\n",
        "    X_all = []\n",
        "\n",
        "    global_idx = 0\n",
        "    for study_id, group in grouped:\n",
        "        k = len(group)\n",
        "\n",
        "        # y\n",
        "        y_all.append(group[effect_col].values)\n",
        "\n",
        "        # VCV (Logic matches regression driver)\n",
        "        sid_str = str(study_id)\n",
        "        if sid_str in vcv_dict:\n",
        "            V_i = np.asarray(vcv_dict[sid_str])\n",
        "            if V_i.shape[0] != k: V_i = np.diag(group[var_col].values)\n",
        "        elif study_id in vcv_dict:\n",
        "            V_i = np.asarray(vcv_dict[study_id])\n",
        "            if V_i.shape[0] != k: V_i = np.diag(group[var_col].values)\n",
        "        else:\n",
        "            V_i = np.diag(group[var_col].values)\n",
        "        vcv_all.append(V_i)\n",
        "\n",
        "        # X (Spline Basis + Intercept)\n",
        "        # Slice the global basis matrix for this study\n",
        "        basis_i = basis_matrix[global_idx : global_idx + k, :]\n",
        "        X_i = np.column_stack([np.ones(k), basis_i])\n",
        "        X_all.append(X_i)\n",
        "\n",
        "        global_idx += k\n",
        "\n",
        "    N_total = len(df_sorted)\n",
        "    M_studies = len(y_all)\n",
        "    p_params = X_all[0].shape[1]\n",
        "\n",
        "    # 4. Run GLS (Fixed Variance)\n",
        "    # We pass the FIXED tau/sigma to the estimator\n",
        "    #print(\"   Step 2: Fitting spline coefficients using GLS...\")\n",
        "    spline_est = _get_gls_estimates(\n",
        "        [fixed_tau2, fixed_sigma2], y_all, vcv_all, X_all, N_total, M_studies, p_params\n",
        "    )\n",
        "\n",
        "    # 5. Omnibus Test (Wald Test)\n",
        "    # Test if all spline coefs (excluding intercept) are 0\n",
        "    betas = spline_est['betas']\n",
        "    cov_beta = spline_est['cov_beta']\n",
        "\n",
        "    # Parameters to test: indices 1 to end (0 is intercept)\n",
        "    b_test = betas[1:]\n",
        "    cov_test = cov_beta[1:, 1:]\n",
        "\n",
        "    try:\n",
        "        chi2_stat = b_test.T @ np.linalg.inv(cov_test) @ b_test\n",
        "        df_test = len(b_test)\n",
        "        p_val = 1 - chi2.cdf(chi2_stat, df_test)\n",
        "    except:\n",
        "        chi2_stat, df_test, p_val = 0, 0, 1.0\n",
        "\n",
        "    # Add metadata\n",
        "    spline_est.update({\n",
        "        'mod_mean': mod_mean,\n",
        "        'mod_std': mod_std,\n",
        "        'formula': formula,\n",
        "        'reg_df': df_sorted, # Important for plotting\n",
        "        'moderator_col': moderator_col,\n",
        "        'omnibus_chi2': chi2_stat,\n",
        "        'omnibus_df': df_test,\n",
        "        'omnibus_p': p_val,\n",
        "        'df_spline': df_spline,\n",
        "        'model_type': \"3-Level Spline (Robust Matrix)\"\n",
        "    })\n",
        "\n",
        "    return spline_est, None\n",
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 4.5: ADVANCED TAU-SQUARED ESTIMATORS\n",
        "# Purpose: Provides multiple methods for estimating between-study variance\n",
        "# Dependencies: None (standalone functions)\n",
        "# Used by: Cell 6 (Overall Analysis), Cell 8 (Subgroup Analysis)\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize_scalar, minimize\n",
        "from scipy.stats import chi2\n",
        "import warnings\n",
        "\n",
        "#print(\"=\"*70)\n",
        "#print(\"HETEROGENEITY ESTIMATORS MODULE\")\n",
        "#print(\"=\"*70)\n",
        "\n",
        "# --- 1. DERSIMONIAN-LAIRD (Your current method) ---\n",
        "\n",
        "# --- 2. RESTRICTED MAXIMUM LIKELIHOOD (REML) ---\n",
        "\n",
        "def calculate_tau_squared_REML(df, effect_col, var_col, max_iter=100, tol=1e-8):\n",
        "    \"\"\"\n",
        "    REML estimator for tau-squared (RECOMMENDED - Gold Standard)\n",
        "\n",
        "    Advantages:\n",
        "    - Unbiased for tau\u00b2\n",
        "    - Accounts for uncertainty in estimating mu\n",
        "    - Better performance in small samples\n",
        "    - Generally preferred in literature\n",
        "\n",
        "    Disadvantages:\n",
        "    - Iterative (slightly slower)\n",
        "    - Can fail to converge in extreme cases\n",
        "\n",
        "    Reference:\n",
        "    Viechtbauer, W. (2005). Bias and efficiency of meta-analytic variance\n",
        "    estimators in the random-effects model. Journal of Educational and\n",
        "    Behavioral Statistics, 30(3), 261-293.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    max_iter : int\n",
        "        Maximum iterations for optimization\n",
        "    tol : float\n",
        "        Convergence tolerance\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Extract data\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        # Remove any infinite or negative variances\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            warnings.warn(f\"Removed {(~valid_mask).sum()} observations with invalid variances\")\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 2:\n",
        "            return 0.0\n",
        "\n",
        "        # REML objective function (negative log-likelihood)\n",
        "        def reml_objective(tau2):\n",
        "            # Ensure tau2 is non-negative\n",
        "            tau2 = max(0, tau2)\n",
        "\n",
        "            # Weights\n",
        "            wi = 1 / (vi + tau2)\n",
        "            sum_wi = wi.sum()\n",
        "\n",
        "            if sum_wi <= 0:\n",
        "                return 1e10\n",
        "\n",
        "            # Pooled estimate\n",
        "            mu = (wi * yi).sum() / sum_wi\n",
        "\n",
        "            # Q statistic\n",
        "            Q = (wi * (yi - mu)**2).sum()\n",
        "\n",
        "            # REML log-likelihood (negative for minimization)\n",
        "            # L = -0.5 * [sum(log(vi + tau2)) + log(sum(wi)) + Q]\n",
        "            log_lik = -0.5 * (\n",
        "                np.sum(np.log(vi + tau2)) +\n",
        "                np.log(sum_wi) +\n",
        "                Q\n",
        "            )\n",
        "\n",
        "            return -log_lik  # Return negative for minimization\n",
        "\n",
        "        # Get reasonable bounds for tau2\n",
        "        # Lower bound: 0\n",
        "        # Upper bound: Use variance of effect sizes as upper limit\n",
        "        var_yi = np.var(yi, ddof=1) if k > 2 else 1.0\n",
        "        upper_bound = max(10 * var_yi, 100)\n",
        "\n",
        "        # Optimize\n",
        "        result = minimize_scalar(\n",
        "            reml_objective,\n",
        "            bounds=(0, upper_bound),\n",
        "            method='bounded',\n",
        "            options={'maxiter': max_iter, 'xatol': tol}\n",
        "        )\n",
        "\n",
        "        if result.success:\n",
        "            tau_sq = result.x\n",
        "        else:\n",
        "            warnings.warn(\"REML optimization did not converge, using DL fallback\")\n",
        "            tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in REML estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 3. MAXIMUM LIKELIHOOD (ML) ---\n",
        "\n",
        "def calculate_tau_squared_ML(df, effect_col, var_col, max_iter=100, tol=1e-8):\n",
        "    \"\"\"\n",
        "    Maximum Likelihood estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Efficient asymptotically\n",
        "    - Produces valid estimates\n",
        "\n",
        "    Disadvantages:\n",
        "    - Biased downward (underestimates tau\u00b2)\n",
        "    - Less preferred than REML\n",
        "    - REML is generally recommended instead\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    max_iter : int\n",
        "        Maximum iterations\n",
        "    tol : float\n",
        "        Convergence tolerance\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 2:\n",
        "            return 0.0\n",
        "\n",
        "        # ML objective function\n",
        "        def ml_objective(tau2):\n",
        "            tau2 = max(0, tau2)\n",
        "            wi = 1 / (vi + tau2)\n",
        "            sum_wi = wi.sum()\n",
        "\n",
        "            if sum_wi <= 0:\n",
        "                return 1e10\n",
        "\n",
        "            mu = (wi * yi).sum() / sum_wi\n",
        "            Q = (wi * (yi - mu)**2).sum()\n",
        "\n",
        "            # ML log-likelihood (without the constant term)\n",
        "            log_lik = -0.5 * (np.sum(np.log(vi + tau2)) + Q)\n",
        "\n",
        "            return -log_lik\n",
        "\n",
        "        var_yi = np.var(yi, ddof=1) if k > 2 else 1.0\n",
        "        upper_bound = max(10 * var_yi, 100)\n",
        "\n",
        "        result = minimize_scalar(\n",
        "            ml_objective,\n",
        "            bounds=(0, upper_bound),\n",
        "            method='bounded',\n",
        "            options={'maxiter': max_iter, 'xatol': tol}\n",
        "        )\n",
        "\n",
        "        if result.success:\n",
        "            tau_sq = result.x\n",
        "        else:\n",
        "            warnings.warn(\"ML optimization did not converge, using DL fallback\")\n",
        "            tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in ML estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 4. PAULE-MANDEL (PM) ---\n",
        "\n",
        "def calculate_tau_squared_PM(df, effect_col, var_col, max_iter=100, tol=1e-8):\n",
        "    \"\"\"\n",
        "    Paule-Mandel estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Exact solution to Q = k-1 equation\n",
        "    - Non-iterative in principle\n",
        "    - Good performance\n",
        "\n",
        "    Disadvantages:\n",
        "    - Can be unstable with few studies\n",
        "    - Requires iterative solution in practice\n",
        "\n",
        "    Reference:\n",
        "    Paule, R. C., & Mandel, J. (1982). Consensus values and weighting factors.\n",
        "    Journal of Research of the National Bureau of Standards, 87(5), 377-385.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "    max_iter : int\n",
        "        Maximum iterations\n",
        "    tol : float\n",
        "        Convergence tolerance\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 2:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 2:\n",
        "            return 0.0\n",
        "\n",
        "        df_Q = k - 1\n",
        "\n",
        "        # PM objective: Find tau2 such that Q(tau2) = k - 1\n",
        "        def pm_objective(tau2):\n",
        "            tau2 = max(0, tau2)\n",
        "            wi = 1 / (vi + tau2)\n",
        "            sum_wi = wi.sum()\n",
        "\n",
        "            if sum_wi <= 0:\n",
        "                return 1e10\n",
        "\n",
        "            mu = (wi * yi).sum() / sum_wi\n",
        "            Q = (wi * (yi - mu)**2).sum()\n",
        "\n",
        "            # We want Q = k - 1\n",
        "            return (Q - df_Q)**2\n",
        "\n",
        "        var_yi = np.var(yi, ddof=1) if k > 2 else 1.0\n",
        "        upper_bound = max(10 * var_yi, 100)\n",
        "\n",
        "        result = minimize_scalar(\n",
        "            pm_objective,\n",
        "            bounds=(0, upper_bound),\n",
        "            method='bounded',\n",
        "            options={'maxiter': max_iter, 'xatol': tol}\n",
        "        )\n",
        "\n",
        "        if result.success and result.fun < 1:  # Good convergence\n",
        "            tau_sq = result.x\n",
        "        else:\n",
        "            # If PM fails, use DL\n",
        "            tau_sq = calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in PM estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 5. SIDIK-JONKMAN (SJ) ---\n",
        "\n",
        "def calculate_tau_squared_SJ(df, effect_col, var_col):\n",
        "    \"\"\"\n",
        "    Sidik-Jonkman estimator for tau-squared\n",
        "\n",
        "    Advantages:\n",
        "    - Simple, non-iterative\n",
        "    - Good performance with few studies\n",
        "    - Conservative (tends to produce larger estimates)\n",
        "\n",
        "    Disadvantages:\n",
        "    - Can be overly conservative\n",
        "    - Less commonly used\n",
        "\n",
        "    Reference:\n",
        "    Sidik, K., & Jonkman, J. N. (2005). Simple heterogeneity variance\n",
        "    estimation for meta-analysis. Journal of the Royal Statistical Society,\n",
        "    Series C, 54(2), 367-384.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Data with effect sizes and variances\n",
        "    effect_col : str\n",
        "        Name of effect size column\n",
        "    var_col : str\n",
        "        Name of variance column\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    float : tau-squared estimate\n",
        "    \"\"\"\n",
        "    k = len(df)\n",
        "    if k < 3:  # Need at least 3 studies for SJ\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "    try:\n",
        "        yi = df[effect_col].values\n",
        "        vi = df[var_col].values\n",
        "\n",
        "        valid_mask = np.isfinite(vi) & (vi > 0)\n",
        "        if not valid_mask.all():\n",
        "            yi = yi[valid_mask]\n",
        "            vi = vi[valid_mask]\n",
        "            k = len(yi)\n",
        "\n",
        "        if k < 3:\n",
        "            return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "        # Weights for typical average\n",
        "        wi = 1 / vi\n",
        "        sum_wi = wi.sum()\n",
        "\n",
        "        # Typical average (weighted mean)\n",
        "        y_bar = (wi * yi).sum() / sum_wi\n",
        "\n",
        "        # SJ estimator\n",
        "        numerator = ((yi - y_bar)**2 / vi).sum()\n",
        "        denominator = k - 1\n",
        "\n",
        "        tau_sq = (numerator / denominator) - (k / sum_wi)\n",
        "\n",
        "        return max(0.0, tau_sq)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"Error in SJ estimator: {e}, using DL fallback\")\n",
        "        return calculate_tau_squared_DL(df, effect_col, var_col)\n",
        "\n",
        "\n",
        "# --- 6. EXPORT EXCEL ---\n",
        "\n",
        "!pip install xlsxwriter\n",
        "import xlsxwriter\n",
        "\n",
        "# --- 1. HELPER: EXCLUSION LOG ---\n",
        "def _get_exclusion_log():\n",
        "    if 'ANALYSIS_CONFIG' in globals() and 'removed_records' in ANALYSIS_CONFIG:\n",
        "        return ANALYSIS_CONFIG['removed_records']\n",
        "    return pd.DataFrame([{'ID': 'All Data Kept', 'Reason': 'No records were removed.'}])\n",
        "\n",
        "# --- 2. HELPER: EXCEL FORMATTER ---\n",
        "def _apply_excel_formatting(writer, sheet_name, df):\n",
        "    workbook = writer.book\n",
        "    worksheet = writer.sheets[sheet_name]\n",
        "    header_fmt = workbook.add_format({'bold': True, 'valign': 'top', 'fg_color': '#1F4E78', 'font_color': '#FFFFFF', 'border': 1})\n",
        "    for col_num, value in enumerate(df.columns.values):\n",
        "        worksheet.write(0, col_num, value, header_fmt)\n",
        "    for i, col in enumerate(df.columns):\n",
        "        col_len = len(str(col))\n",
        "        sample_vals = df[col].head(20).astype(str)\n",
        "        max_val_len = sample_vals.map(len).max() if not sample_vals.empty else 0\n",
        "        worksheet.set_column(i, i, min(max(col_len, max_val_len) + 2, 50))\n",
        "\n",
        "# --- 3. HELPER: PROTOCOL SHEET FORMATTER ---\n",
        "def _apply_protocol_sheet_formatting(writer, sheet_name, df):\n",
        "    \"\"\"\n",
        "    Custom formatting for the Protocol & Settings sheet.\n",
        "    - Bold headers\n",
        "    - Bold Category column\n",
        "    - Auto-adjust column widths for readability\n",
        "    \"\"\"\n",
        "    workbook = writer.book\n",
        "    worksheet = writer.sheets[sheet_name]\n",
        "\n",
        "    # Define formats\n",
        "    header_fmt = workbook.add_format({\n",
        "        'bold': True,\n",
        "        'valign': 'top',\n",
        "        'fg_color': '#1F4E78',\n",
        "        'font_color': '#FFFFFF',\n",
        "        'border': 1\n",
        "    })\n",
        "\n",
        "    category_fmt = workbook.add_format({\n",
        "        'bold': True,\n",
        "        'valign': 'top'\n",
        "    })\n",
        "\n",
        "    # Apply header formatting\n",
        "    for col_num, value in enumerate(df.columns.values):\n",
        "        worksheet.write(0, col_num, value, header_fmt)\n",
        "\n",
        "    # Apply bold formatting to Category column (column 0)\n",
        "    for row_num in range(1, len(df) + 1):\n",
        "        cell_value = df.iloc[row_num - 1, 0]  # Category column\n",
        "        worksheet.write(row_num, 0, cell_value, category_fmt)\n",
        "\n",
        "    # Auto-adjust column widths\n",
        "    for i, col in enumerate(df.columns):\n",
        "        col_len = len(str(col))\n",
        "        sample_vals = df[col].head(50).astype(str)\n",
        "        max_val_len = sample_vals.map(len).max() if not sample_vals.empty else 0\n",
        "        # Make columns wider for better readability\n",
        "        col_width = min(max(col_len, max_val_len) + 3, 60)\n",
        "        worksheet.set_column(i, i, col_width)\n",
        "\n",
        "\n",
        "# --- 4. HELPER: SMART METADATA COLLECTOR (UPDATED) ---\n",
        "def _get_protocol_metadata(report_type):\n",
        "    \"\"\"\n",
        "    Captures comprehensive protocol settings and configuration.\n",
        "    Returns a DataFrame with columns: [Category, Parameter, Value]\n",
        "    \"\"\"\n",
        "    meta = []\n",
        "\n",
        "    # System Information\n",
        "    meta.append({'Category': 'System', 'Parameter': 'Timestamp', 'Value': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
        "\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        return pd.DataFrame(meta)\n",
        "\n",
        "    ac = ANALYSIS_CONFIG\n",
        "\n",
        "    try:\n",
        "        # === ANALYSIS SETTINGS ===\n",
        "        global_settings = ac.get('global_settings', {})\n",
        "\n",
        "        # Confidence Level (convert alpha to percentage)\n",
        "        alpha = global_settings.get('alpha', 0.05)\n",
        "        confidence_pct = (1 - alpha) * 100\n",
        "        meta.append({'Category': 'Settings', 'Parameter': 'Confidence Level', 'Value': f\"{confidence_pct:.0f}%\"})\n",
        "\n",
        "        # Inference Distribution\n",
        "        dist_type = global_settings.get('dist_type', 'norm')\n",
        "        dist_label = 't-distribution' if dist_type == 't' else 'Normal distribution'\n",
        "        meta.append({'Category': 'Settings', 'Parameter': 'Inference Distribution', 'Value': dist_label})\n",
        "\n",
        "        # Model Selection\n",
        "        overall_results = ac.get('overall_results', {})\n",
        "        model_choice = overall_results.get('model_choice', 'Unknown')\n",
        "        meta.append({'Category': 'Settings', 'Parameter': 'Model Selection', 'Value': model_choice})\n",
        "\n",
        "        # Heterogeneity Estimator (tau method)\n",
        "        tau_method = overall_results.get('tau_method', 'REML')\n",
        "        meta.append({'Category': 'Settings', 'Parameter': 'Heterogeneity Estimator', 'Value': tau_method})\n",
        "\n",
        "        # Knapp-Hartung Adjustment\n",
        "        kh_info = overall_results.get('knapp_hartung', {})\n",
        "        use_kh = kh_info.get('used', False)\n",
        "        kh_label = 'Yes' if use_kh else 'No'\n",
        "        meta.append({'Category': 'Settings', 'Parameter': 'Knapp-Hartung Adjustment', 'Value': kh_label})\n",
        "\n",
        "        # === DATA PROVENANCE ===\n",
        "\n",
        "        # Input Mode\n",
        "        data_type = ac.get('data_type', 'Unknown')\n",
        "        input_mode = 'Pre-Calculated' if data_type == 'pre_calculated' else 'Raw Data'\n",
        "        meta.append({'Category': 'Data', 'Parameter': 'Input Mode', 'Value': input_mode})\n",
        "\n",
        "        # Effect Size Information\n",
        "        es_config = ac.get('es_config', {})\n",
        "        effect_label = es_config.get('effect_label', 'Unknown')\n",
        "        effect_label_short = es_config.get('effect_label_short', 'Unknown')\n",
        "        meta.append({'Category': 'Data', 'Parameter': 'Effect Size Type', 'Value': f\"{effect_label} ({effect_label_short})\"})\n",
        "\n",
        "        # Effect Size Column Names\n",
        "        effect_col = ac.get('effect_col', es_config.get('effect_col', 'Unknown'))\n",
        "        var_col = ac.get('var_col', es_config.get('var_col', 'Unknown'))\n",
        "        meta.append({'Category': 'Data', 'Parameter': 'Effect Size Column', 'Value': effect_col})\n",
        "        meta.append({'Category': 'Data', 'Parameter': 'Variance Column', 'Value': var_col})\n",
        "\n",
        "        # Sample Size Information\n",
        "        analysis_data = ac.get('analysis_data')\n",
        "        if analysis_data is not None:\n",
        "            k_total = len(analysis_data)\n",
        "            meta.append({'Category': 'Data', 'Parameter': 'Total Observations (k)', 'Value': k_total})\n",
        "\n",
        "            # Count unique studies\n",
        "            if 'id' in analysis_data.columns:\n",
        "                n_studies = analysis_data['id'].nunique()\n",
        "                meta.append({'Category': 'Data', 'Parameter': 'Unique Studies', 'Value': n_studies})\n",
        "\n",
        "        # === REPORT-SPECIFIC METADATA ===\n",
        "\n",
        "        if report_type == 'cumulative' and 'cumulative_results' in ac:\n",
        "            cum_df = ac['cumulative_results']\n",
        "            if not cum_df.empty:\n",
        "                meta.append({'Category': 'Cumulative', 'Parameter': 'Total Steps', 'Value': len(cum_df)})\n",
        "                meta.append({'Category': 'Cumulative', 'Parameter': 'Year Range', 'Value': f\"{int(cum_df['year'].min())} - {int(cum_df['year'].max())}\"})\n",
        "                meta.append({'Category': 'Cumulative', 'Parameter': 'Initial Effect (Start)', 'Value': f\"{cum_df.iloc[0]['pooled_effect']:.4f}\"})\n",
        "                meta.append({'Category': 'Cumulative', 'Parameter': 'Final Effect (End)', 'Value': f\"{cum_df.iloc[-1]['pooled_effect']:.4f}\"})\n",
        "                meta.append({'Category': 'Cumulative', 'Parameter': 'Method', 'Value': 'Iterative REML'})\n",
        "\n",
        "        elif report_type == 'loo' and 'loo_3level_results' in ac:\n",
        "            loo = ac['loo_3level_results']\n",
        "            meta.append({'Category': 'Sensitivity', 'Parameter': 'Method', 'Value': 'Leave-One-Out (3-Level)'})\n",
        "            meta.append({'Category': 'Sensitivity', 'Parameter': 'Original Effect', 'Value': f\"{loo.get('original_effect', 0):.4f}\"})\n",
        "            meta.append({'Category': 'Sensitivity', 'Parameter': 'Significance Changers', 'Value': loo.get('n_sig_changers', 0)})\n",
        "\n",
        "        elif report_type == 'subgroup' and 'subgroup_config' in ac:\n",
        "            sub_config = ac['subgroup_config']\n",
        "            analysis_type = sub_config.get('analysis_type', 'Unknown')\n",
        "            moderator1 = sub_config.get('moderator1', 'Unknown')\n",
        "            meta.append({'Category': 'Subgroup', 'Parameter': 'Analysis Type', 'Value': analysis_type})\n",
        "            meta.append({'Category': 'Subgroup', 'Parameter': 'Moderator', 'Value': moderator1})\n",
        "            if 'moderator2' in sub_config and sub_config['moderator2']:\n",
        "                moderator2 = sub_config['moderator2']\n",
        "                meta.append({'Category': 'Subgroup', 'Parameter': 'Second Moderator', 'Value': moderator2})\n",
        "\n",
        "        elif report_type == 'regression' and 'meta_regression_RVE_results' in ac:\n",
        "            reg = ac['meta_regression_RVE_results']\n",
        "            moderator_col = reg.get('moderator_col_name', 'Unknown')\n",
        "            meta.append({'Category': 'Regression', 'Parameter': 'Moderator Variable', 'Value': moderator_col})\n",
        "            meta.append({'Category': 'Regression', 'Parameter': 'Model Type', 'Value': '3-Level REML'})\n",
        "\n",
        "        elif report_type == 'spline' and 'spline_model_results' in ac:\n",
        "            spline = ac['spline_model_results']\n",
        "            moderator = spline.get('moderator_col', 'Unknown')\n",
        "            n_knots = spline.get('n_knots', 'Unknown')\n",
        "            meta.append({'Category': 'Spline', 'Parameter': 'Moderator Variable', 'Value': moderator})\n",
        "            meta.append({'Category': 'Spline', 'Parameter': 'Number of Knots', 'Value': n_knots})\n",
        "\n",
        "        elif report_type == 'publication_bias':\n",
        "            meta.append({'Category': 'Publication Bias', 'Parameter': 'Tests Performed', 'Value': 'Egger Test, Trim & Fill'})\n",
        "\n",
        "    except Exception as e:\n",
        "        meta.append({'Category': 'Error', 'Parameter': 'Metadata Error', 'Value': str(e)})\n",
        "\n",
        "    return pd.DataFrame(meta)\n",
        "\n",
        "# --- 4. MAIN ORCHESTRATOR (UPDATED) ---\n",
        "def export_analysis_report(report_type='overall', filename_prefix=\"MetaAnalysis\"):\n",
        "    if 'ANALYSIS_CONFIG' not in globals(): return\n",
        "\n",
        "    buffer = io.BytesIO()\n",
        "    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:\n",
        "        try:\n",
        "            text_key = 'latest_text'\n",
        "\n",
        "            # ... (Existing blocks for overall, subgroup, regression, spline, pub_bias) ...\n",
        "\n",
        "            if report_type == 'overall':\n",
        "                text_key = 'overall_text'\n",
        "                res = ANALYSIS_CONFIG['overall_results']\n",
        "                simple_res = {k:v for k,v in res.items() if not isinstance(v, dict)}\n",
        "                pd.DataFrame([simple_res]).T.reset_index().to_excel(writer, sheet_name='Overall Results', index=False)\n",
        "\n",
        "            elif report_type == 'subgroup':\n",
        "                text_key = 'subgroup_text'\n",
        "                if 'subgroup_results' in ANALYSIS_CONFIG:\n",
        "                    ANALYSIS_CONFIG['subgroup_results']['results_df'].to_excel(writer, sheet_name='Subgroup Results', index=False)\n",
        "\n",
        "            elif report_type == 'regression':\n",
        "                text_key = 'regression_text'\n",
        "                if 'meta_regression_RVE_results' in ANALYSIS_CONFIG:\n",
        "                    reg = ANALYSIS_CONFIG['meta_regression_RVE_results']\n",
        "                    pd.DataFrame({'Term': ['Intercept', reg['moderator_col_name']], 'Beta': reg['betas'], 'SE': reg['std_errors_robust'], 'P-Value': [reg['p_intercept'], reg['p_slope']]}).to_excel(writer, sheet_name='Regression Results', index=False)\n",
        "\n",
        "            elif report_type == 'spline':\n",
        "                text_key = 'spline_text'\n",
        "                if 'spline_model_results' in ANALYSIS_CONFIG:\n",
        "                    res = ANALYSIS_CONFIG['spline_model_results']\n",
        "                    pd.DataFrame([{'Metric': 'Chi2', 'Value': res['omnibus_chi2']}, {'Metric': 'P-Value', 'Value': res['omnibus_p']}]).to_excel(writer, sheet_name='Spline Results', index=False)\n",
        "\n",
        "            elif report_type == 'publication_bias':\n",
        "                text_key = 'bias_text'\n",
        "                if 'funnel_results' in ANALYSIS_CONFIG:\n",
        "                    egg = ANALYSIS_CONFIG['funnel_results']\n",
        "                    pd.DataFrame([{'Test': 'Egger', 'Intercept': egg['intercept'], 'P-Value': egg['p_value']}]).to_excel(writer, sheet_name='Eggers Test', index=False)\n",
        "                if 'trimfill_results' in ANALYSIS_CONFIG:\n",
        "                    tf = ANALYSIS_CONFIG['trimfill_results']\n",
        "                    pd.DataFrame([{'Missing': tf['k0'], 'Original': tf['pooled_original'], 'Adjusted': tf['pooled_filled']}]).to_excel(writer, sheet_name='Trim Fill', index=False)\n",
        "\n",
        "            # === UPDATED: CUMULATIVE RESULTS ===\n",
        "            elif report_type == 'cumulative':\n",
        "                text_key = 'cumulative_text'\n",
        "                if 'cumulative_results' in ANALYSIS_CONFIG:\n",
        "                    # 1. Full Step-by-Step Table\n",
        "                    ANALYSIS_CONFIG['cumulative_results'].to_excel(writer, sheet_name='Cumulative Results', index=False)\n",
        "\n",
        "                    # 2. Summary Table (Start vs End)\n",
        "                    df = ANALYSIS_CONFIG['cumulative_results']\n",
        "                    if not df.empty:\n",
        "                        summary = df.iloc[[0, -1]].copy()\n",
        "                        summary.insert(0, 'Stage', ['Start', 'End'])\n",
        "                        summary.to_excel(writer, sheet_name='Cumulative Summary', index=False)\n",
        "\n",
        "            # === UPDATED: LOO RESULTS ===\n",
        "            elif report_type == 'loo':\n",
        "                text_key = 'loo_text'\n",
        "                if 'loo_3level_results' in ANALYSIS_CONFIG:\n",
        "                    # 1. Full Sensitivity Table\n",
        "                    res_df = ANALYSIS_CONFIG['loo_3level_results']['results_df']\n",
        "                    res_df.to_excel(writer, sheet_name='Sensitivity Results', index=False)\n",
        "\n",
        "                    # 2. Influential Studies (if any)\n",
        "                    influencers = res_df[res_df['changes_sig'] == True]\n",
        "                    if not influencers.empty:\n",
        "                        influencers.to_excel(writer, sheet_name='Influential Studies', index=False)\n",
        "                    else:\n",
        "                        pd.DataFrame([{'Result': 'Robust', 'Note': 'No single study changed significance.'}]).to_excel(writer, sheet_name='Influential Studies', index=False)\n",
        "\n",
        "            # --- COMMON SHEETS ---\n",
        "            if 'analysis_data' in ANALYSIS_CONFIG:\n",
        "                ANALYSIS_CONFIG['analysis_data'].to_excel(writer, sheet_name='Processed Data', index=False)\n",
        "                _apply_excel_formatting(writer, 'Processed Data', ANALYSIS_CONFIG['analysis_data'])\n",
        "\n",
        "            df_excl = _get_exclusion_log()\n",
        "            df_excl.to_excel(writer, sheet_name='Data Exclusions', index=False)\n",
        "            _apply_excel_formatting(writer, 'Data Exclusions', df_excl)\n",
        "\n",
        "            # --- GENERATED TEXT ---\n",
        "            final_text = ANALYSIS_CONFIG.get(text_key, \"\")\n",
        "            if final_text:\n",
        "                clean_text = _clean_html_tags(final_text)\n",
        "                df_text = pd.DataFrame({'Generated Interpretation': [clean_text]})\n",
        "                df_text.to_excel(writer, sheet_name='Report Text', index=False)\n",
        "                writer.sheets['Report Text'].set_column(0, 0, 100)\n",
        "                writer.sheets['Report Text'].set_row(1, 300, writer.book.add_format({'text_wrap': True, 'valign': 'top'}))\n",
        "\n",
        "            # --- PROTOCOL & SETTINGS (LAST SHEET) ---\n",
        "            # This comprehensive sheet captures all configuration settings used for this analysis\n",
        "            df_proto = _get_protocol_metadata(report_type)\n",
        "            df_proto.to_excel(writer, sheet_name='Protocol & Settings', index=False)\n",
        "            _apply_protocol_sheet_formatting(writer, 'Protocol & Settings', df_proto)\n",
        "\n",
        "        except Exception as e:\n",
        "            pd.DataFrame([{'Error': str(e)}]).to_excel(writer, sheet_name='Error_Log')\n",
        "\n",
        "    buffer.seek(0)\n",
        "    b64 = base64.b64encode(buffer.read()).decode()\n",
        "    filename = f\"{filename_prefix}_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
        "    payload = f\"var link = document.createElement('a'); link.href = 'data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}'; link.download = '{filename}'; document.body.appendChild(link); link.click(); document.body.removeChild(link);\"\n",
        "    display(Javascript(payload))\n",
        "\n",
        "\n",
        "# --- 7. PRESET FOR PLOTS ---\n",
        "\n",
        "PRESETS = {\n",
        "    'Custom': {},\n",
        "\n",
        "    # 1 Column: 8.5 cm -> 3.35 inches\n",
        "    'Cell Press 1-Col (85mm)': {\n",
        "        'width': 3.35, 'height': 3.35,\n",
        "        'title': 9, 'label': 8, 'tick': 7  # Fonts must be small to fit\n",
        "    },\n",
        "    # 1.5 Column: 11.4 cm -> 4.49 inches\n",
        "    'Cell Press 1.5-Col (114mm)': {\n",
        "        'width': 4.49, 'height': 4.00,\n",
        "        'title': 10, 'label': 9, 'tick': 8\n",
        "    },\n",
        "    # Full Width: 17.4 cm -> 6.85 inches\n",
        "    'Cell Press Full (174mm)': {\n",
        "        'width': 6.85, 'height': 5.50,\n",
        "        'title': 11, 'label': 10, 'tick': 9\n",
        "    },\n",
        "\n",
        "    # 1 Column: 13.4 cm -> 5.28 inches\n",
        "    'STAR Protocols 1-Col (134mm)': {\n",
        "        'width': 5.28, 'height': 5.00,\n",
        "        'title': 11, 'label': 10, 'tick': 9\n",
        "    },\n",
        "    # Full Width: 17.2 cm -> 6.77 inches\n",
        "    'STAR Protocols Full (172mm)': {\n",
        "        'width': 6.77, 'height': 6.00,\n",
        "        'title': 12, 'label': 11, 'tick': 10\n",
        "    },\n",
        "\n",
        "    # 1 Column: 5.5 cm -> 2.17 inches (Very narrow!)\n",
        "    'Cell 3-Col Layout (Narrow/55mm)': {\n",
        "        'width': 2.17, 'height': 2.50,\n",
        "        'title': 8, 'label': 7, 'tick': 6\n",
        "    },\n",
        "\n",
        "    # --- General / Thesis ---\n",
        "    'Thesis (A4 Portrait)':  {'width': 6.30, 'height': 8.00, 'title': 12, 'label': 11, 'tick': 10},\n",
        "    'Presentation (16:9)':   {'width': 13.3, 'height': 7.50, 'title': 18, 'label': 14, 'tick': 12}\n",
        "}\n",
        "\n",
        "preset_widget = widgets.Dropdown(\n",
        "    options=list(PRESETS.keys()),\n",
        "    value='Custom',\n",
        "    description='\ud83d\udccf Preset:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "def on_preset_change(change):\n",
        "    \"\"\"Updates size and font sliders based on selection\"\"\"\n",
        "    settings = PRESETS.get(change['new'], {})\n",
        "    if not settings: return # Do nothing for 'Custom'\n",
        "\n",
        "    # Update Widgets (checking if they exist to allow re-use across cells)\n",
        "    if 'width_widget' in globals(): width_widget.value = settings['width']\n",
        "    if 'height_widget' in globals(): height_widget.value = settings['height']\n",
        "    if 'title_font_widget' in globals(): title_font_widget.value = settings['title']\n",
        "    if 'label_font_widget' in globals(): label_font_widget.value = settings['label']\n",
        "    if 'tick_font_widget' in globals(): tick_font_widget.value = settings['tick']\n",
        "\n",
        "    # Specific handling for Cumulative Plot which uses slightly different names\n",
        "    if 'title_fontsize_widget' in globals(): title_fontsize_widget.value = settings['title']\n",
        "    if 'label_fontsize_widget' in globals(): label_fontsize_widget.value = settings['label']\n",
        "    if 'tick_fontsize_widget' in globals(): tick_fontsize_widget.value = settings['tick']\n",
        "\n",
        "preset_widget.observe(on_preset_change, names='value')\n",
        "\n",
        "\n",
        "# --- 8. DISPLAY MODULE INFO ---\n",
        "print(\"\\n\u2705 Setup complete. Proceed to next cell to load data.\\n\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \u2699\ufe0f 2. Data Ingestion & Column Mapping\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 2: DATA INGESTION & COLUMN MAPPING (DUAL-MODE REFACTOR)\n",
        "# Purpose: Load data (Sheets/CSV/Excel) and map columns to standard names.\n",
        "# Modes: 1) Raw Data (Means/SDs) or 2) Pre-calculated Effect Sizes\n",
        "# Output: Global 'raw_data_standardized' DataFrame\n",
        "# =============================================================================\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import pandas as pd\n",
        "import io\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "\n",
        "# --- Configuration: Required Columns & Synonyms ---\n",
        "# RAW DATA MODE: Experimental vs Control statistics\n",
        "RAW_COLUMN_SPECS = {\n",
        "    'id':  ['id', 'study', 'study_id', 'paper', 'author'],\n",
        "    'xe':  ['xe', 'mean_e', 'mean_exp', 'x_e', 'treatment_mean'],\n",
        "    'sde': ['sde', 'sd_e', 'sd_exp', 'sigma_e'],\n",
        "    'ne':  ['ne', 'n_e', 'n_exp', 'sample_e'],\n",
        "    'xc':  ['xc', 'mean_c', 'mean_ctrl', 'x_c', 'control_mean'],\n",
        "    'sdc': ['sdc', 'sd_c', 'sd_ctrl', 'sigma_c'],\n",
        "    'nc':  ['nc', 'n_c', 'n_ctrl', 'sample_c']\n",
        "}\n",
        "\n",
        "# PRE-CALCULATED MODE: Effect sizes already computed\n",
        "PRECALC_COLUMN_SPECS = {\n",
        "    'id':       ['id', 'study', 'study_id', 'paper', 'author'],\n",
        "    'yi':       ['yi', 'effect_size', 'es', 'hedges_g', 'lnrr', 'smd', 'effect', 'g', 'd'],\n",
        "    'variance': ['variance', 'vi', 'var', 'v'],\n",
        "    'se':       ['se', 'standard_error', 'stderr', 'se_es'],\n",
        "    'n_total':  ['n_total', 'n', 'sample_size', 'total_n', 'sample_n']\n",
        "}\n",
        "\n",
        "# Global placeholders\n",
        "temp_raw_df = None\n",
        "data_type_widget = None  # Will be created below\n",
        "\n",
        "# =============================================================================\n",
        "# HELPER: UNIVERSAL FILE EXTRACTOR\n",
        "# =============================================================================\n",
        "def get_uploaded_file_data(uploader_widget):\n",
        "    \"\"\"\n",
        "    Robustly extracts filename and binary content from ipywidgets.FileUpload\n",
        "    Handles differences between Widget versions 7.x (Colab default) and 8.x\n",
        "    \"\"\"\n",
        "    val = uploader_widget.value\n",
        "    if not val:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        # CASE A: Widgets 8.x (List or Tuple of dicts)\n",
        "        if isinstance(val, (tuple, list)):\n",
        "            file_obj = val[0]\n",
        "            fname = file_obj['name']\n",
        "            content = file_obj['content']\n",
        "\n",
        "        # CASE B: Widgets 7.x (Dictionary where Key=Filename)\n",
        "        elif isinstance(val, dict):\n",
        "            fname = list(val.keys())[0] # Get the first key\n",
        "            content = val[fname]['content']\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown widget format: {type(val)}\")\n",
        "\n",
        "        # Ensure content is bytes (sometimes it's a memoryview)\n",
        "        if hasattr(content, 'tobytes'):\n",
        "            content = content.tobytes()\n",
        "\n",
        "        return fname, content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Debug Info - Raw Type: {type(val)}\")\n",
        "        raise e\n",
        "\n",
        "# =============================================================================\n",
        "# UI PART 1: DATA LOADING (Tabs)\n",
        "# =============================================================================\n",
        "\n",
        "# --- Tab 1: Google Sheets Widgets ---\n",
        "btn_auth = widgets.Button(description=\"1. Connect Google Account\", button_style='warning', icon='google')\n",
        "txt_sheet_name = widgets.Text(value='tesis', description='Sheet Name:', layout=widgets.Layout(width='300px'))\n",
        "btn_fetch_ws = widgets.Button(description=\"2. Find Worksheets\", button_style='primary', disabled=True)\n",
        "dd_worksheets = widgets.Dropdown(description='Worksheet:', layout=widgets.Layout(width='300px'), disabled=True)\n",
        "btn_load_sheet = widgets.Button(description=\"3. Load Data\", button_style='success', disabled=True)\n",
        "\n",
        "gs_vbox = widgets.VBox([\n",
        "    widgets.HTML(\"<b>Step A: Load from Google Sheets</b>\"),\n",
        "    btn_auth,\n",
        "    widgets.HBox([txt_sheet_name, btn_fetch_ws]),\n",
        "    widgets.HBox([dd_worksheets, btn_load_sheet])\n",
        "])\n",
        "\n",
        "# --- Tab 2: Local File Widgets ---\n",
        "uploader = widgets.FileUpload(accept='.csv,.xlsx,.xls', multiple=False, description='Select Data')\n",
        "\n",
        "# New: Dropdown for Excel Sheets (Hidden by default)\n",
        "dd_local_sheets = widgets.Dropdown(\n",
        "    description='Select Sheet:',\n",
        "    layout=widgets.Layout(width='300px', display='none'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "btn_process_file = widgets.Button(description=\"Load Data File\", button_style='success', disabled=True)\n",
        "\n",
        "local_vbox = widgets.VBox([\n",
        "    widgets.HTML(\"<b>Step B: Upload Local File</b><br>1. Choose a .csv or .xlsx file (must include Mean, SD, and N).<br>2. Click 'Load Data File' to proceed.\"),\n",
        "    uploader,\n",
        "    dd_local_sheets,\n",
        "    btn_process_file\n",
        "])\n",
        "\n",
        "# --- Output Areas ---\n",
        "log_output = widgets.Output()\n",
        "mapping_output = widgets.Output()\n",
        "\n",
        "# =============================================================================\n",
        "# LOGIC PART 1: LOADERS\n",
        "# =============================================================================\n",
        "\n",
        "def on_auth_clicked(b):\n",
        "    with log_output:\n",
        "        print(\"\u23f3 Authenticating...\")\n",
        "        try:\n",
        "            auth.authenticate_user()\n",
        "            creds, _ = default()\n",
        "            global gc\n",
        "            gc = gspread.authorize(creds)\n",
        "            btn_auth.button_style = 'success'\n",
        "            btn_auth.description = \"Connected \u2713\"\n",
        "            btn_auth.disabled = True\n",
        "            btn_fetch_ws.disabled = False\n",
        "            print(\"\u2713 Authentication successful.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Auth failed: {e}\")\n",
        "\n",
        "def on_fetch_ws_clicked(b):\n",
        "    with log_output:\n",
        "        clear_output()\n",
        "        if 'gc' not in globals(): return print(\"\u274c Please connect Google Account first.\")\n",
        "\n",
        "        name = txt_sheet_name.value\n",
        "        print(f\"\ud83d\udd0e Looking for '{name}'...\")\n",
        "        try:\n",
        "            global spreadsheet\n",
        "            spreadsheet = gc.open(name)\n",
        "            titles = [ws.title for ws in spreadsheet.worksheets()]\n",
        "            dd_worksheets.options = titles\n",
        "            dd_worksheets.disabled = False\n",
        "            btn_load_sheet.disabled = False\n",
        "            print(f\"\u2713 Found {len(titles)} worksheets.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Error finding sheet: {e}\")\n",
        "\n",
        "def on_load_sheet_clicked(b):\n",
        "    with log_output:\n",
        "        print(f\"\ud83d\udce5 Downloading '{dd_worksheets.value}'...\")\n",
        "        try:\n",
        "            ws = spreadsheet.worksheet(dd_worksheets.value)\n",
        "            rows = ws.get_all_values()\n",
        "            if len(rows) < 2: raise ValueError(\"Sheet empty or no headers.\")\n",
        "\n",
        "            global temp_raw_df\n",
        "            temp_raw_df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "            initiate_mapping_interface(temp_raw_df)\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Error loading data: {e}\")\n",
        "\n",
        "# --- LOCAL FILE LOGIC (Corrected) ---\n",
        "\n",
        "def on_file_upload(change):\n",
        "    \"\"\"Analyze uploaded file immediately\"\"\"\n",
        "    with log_output:\n",
        "        clear_output()\n",
        "        try:\n",
        "            # 1. Reset UI\n",
        "            dd_local_sheets.layout.display = 'none'\n",
        "            btn_process_file.disabled = True\n",
        "\n",
        "            # 2. Get Safe File Data\n",
        "            fname, content_bytes = get_uploaded_file_data(uploader)\n",
        "            if not fname: return\n",
        "\n",
        "            print(f\"\ud83d\udd0e Analyzing '{fname}'...\")\n",
        "\n",
        "            # 3. If Excel, find sheets\n",
        "            if fname.endswith(('.xls', '.xlsx')):\n",
        "                # Use bytes wrapper\n",
        "                excel_file = pd.ExcelFile(io.BytesIO(content_bytes))\n",
        "                sheets = excel_file.sheet_names\n",
        "\n",
        "                if len(sheets) > 1:\n",
        "                    print(f\"\u2713 Found {len(sheets)} sheets. Please select one below.\")\n",
        "                    dd_local_sheets.options = sheets\n",
        "                    dd_local_sheets.layout.display = 'block'\n",
        "                    dd_local_sheets.value = sheets[0]\n",
        "                else:\n",
        "                    print(\"\u2713 Excel file ready (1 sheet found).\")\n",
        "                    dd_local_sheets.options = sheets\n",
        "                    dd_local_sheets.value = sheets[0]\n",
        "                    dd_local_sheets.layout.display = 'block'\n",
        "\n",
        "            else:\n",
        "                print(\"\u2713 CSV file ready.\")\n",
        "\n",
        "            btn_process_file.disabled = False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Error reading file structure: {e}\")\n",
        "\n",
        "def on_process_file_clicked(b):\n",
        "    \"\"\"Read the actual data based on selection\"\"\"\n",
        "    with log_output:\n",
        "        clear_output()\n",
        "        try:\n",
        "            fname, content_bytes = get_uploaded_file_data(uploader)\n",
        "            content = io.BytesIO(content_bytes)\n",
        "\n",
        "            global temp_raw_df\n",
        "\n",
        "            if fname.endswith('.csv'):\n",
        "                print(\"\ud83d\udce5 Reading CSV...\")\n",
        "                temp_raw_df = pd.read_csv(content)\n",
        "            else:\n",
        "                sheet_target = dd_local_sheets.value\n",
        "                print(f\"\ud83d\udce5 Reading Excel Sheet: '{sheet_target}'...\")\n",
        "                temp_raw_df = pd.read_excel(content, sheet_name=sheet_target)\n",
        "\n",
        "            initiate_mapping_interface(temp_raw_df)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c File processing error: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# LOGIC PART 2: COLUMN MAPPING (The \"Bridge\") - REFACTORED FOR DUAL MODE\n",
        "# =============================================================================\n",
        "\n",
        "def initiate_mapping_interface(df):\n",
        "    \"\"\"Analyzes columns, guesses matches, and shows detailed mapping widgets.\"\"\"\n",
        "    global temp_raw_df\n",
        "    temp_raw_df = df  # Store for later use when data type changes\n",
        "\n",
        "    with log_output:\n",
        "        print(f\"\u2713 Data loaded! ({len(df)} rows, {len(df.columns)} columns)\")\n",
        "        print(\"\u2b07 Please select data type and verify column names below.\")\n",
        "\n",
        "    with mapping_output:\n",
        "        clear_output()\n",
        "\n",
        "        # --- 1. DATA TYPE SELECTION (NEW) ---\n",
        "        global data_type_widget\n",
        "        if data_type_widget is None:\n",
        "            data_type_widget = widgets.RadioButtons(\n",
        "                options=[\n",
        "                    ('Raw Data (Means/SDs)', 'raw'),\n",
        "                    ('Pre-calculated (Effect/SE)', 'pre_calculated')\n",
        "                ],\n",
        "                value='raw',\n",
        "                description='Data Type:',\n",
        "                style={'description_width': 'initial'},\n",
        "                layout=widgets.Layout(width='600px')\n",
        "            )\n",
        "            # Observer to re-render mapping when data type changes\n",
        "            data_type_widget.observe(lambda change: render_column_mapping(df, change['new']), names='value')\n",
        "\n",
        "        # Header\n",
        "        header_html = \"\"\"\n",
        "        <h3 style='color:#2E86AB; margin-bottom:10px'>Step 2: Select Data Type & Map Columns</h3>\n",
        "        <div style='background-color:#e7f2fa; padding:10px; border-radius:5px; color:#333; margin-bottom:15px'>\n",
        "            <b>Choose your data type:</b><br>\n",
        "            \u2022 <b>Raw Data:</b> You have means, SDs, and sample sizes for Treatment and Control groups<br>\n",
        "            \u2022 <b>Pre-calculated:</b> You already have computed effect sizes (e.g., from published papers)\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(header_html))\n",
        "        display(data_type_widget)\n",
        "\n",
        "        # Container for dynamic column mapping\n",
        "        global mapping_container\n",
        "        mapping_container = widgets.Output()\n",
        "        display(mapping_container)\n",
        "\n",
        "        # Initial render\n",
        "        render_column_mapping(df, data_type_widget.value)\n",
        "\n",
        "def render_column_mapping(df, data_type):\n",
        "    \"\"\"Renders the appropriate column mapping UI based on data type\"\"\"\n",
        "    with mapping_container:\n",
        "        clear_output()\n",
        "\n",
        "        if data_type == 'raw':\n",
        "            render_raw_mapping(df)\n",
        "        else:\n",
        "            render_precalc_mapping(df)\n",
        "\n",
        "def render_raw_mapping(df):\n",
        "    \"\"\"Original column mapping for raw data\"\"\"\n",
        "    COLUMN_SPECS = RAW_COLUMN_SPECS\n",
        "\n",
        "    FIELD_INFO = {\n",
        "        'id':  {'label': 'Study ID / Label:', 'desc': 'Unique name for the study or paper (e.g., \"Smith 2020\").'},\n",
        "        'xe':  {'label': 'Experimental Mean (xe):', 'desc': 'Mean outcome for the Treatment group.'},\n",
        "        'sde': {'label': 'Experimental SD (sde):', 'desc': 'Standard Deviation for the Treatment group.'},\n",
        "        'ne':  {'label': 'Experimental N (ne):', 'desc': 'Sample size for the Treatment group.'},\n",
        "        'xc':  {'label': 'Control Mean (xc):', 'desc': 'Mean outcome for the Control group.'},\n",
        "        'sdc': {'label': 'Control SD (sdc):', 'desc': 'Standard Deviation for the Control group.'},\n",
        "        'nc':  {'label': 'Control N (nc):', 'desc': 'Sample size for the Control group.'}\n",
        "    }\n",
        "\n",
        "    cols_lower = [str(c).lower().strip() for c in df.columns]\n",
        "    mapping_widgets = {}\n",
        "    ui_rows = []\n",
        "\n",
        "    # Header\n",
        "    ui_rows.append(widgets.HTML(\"<hr><h4 style='color:#2E86AB; margin-top:15px;'>Map Your Columns (Raw Data Mode)</h4>\"))\n",
        "\n",
        "    # Build Widgets\n",
        "    for std_name, synonyms in COLUMN_SPECS.items():\n",
        "        # Auto-Guess Logic\n",
        "        guessed_val = None\n",
        "        for syn in synonyms:\n",
        "            if syn in cols_lower:\n",
        "                guessed_val = df.columns[cols_lower.index(syn)]\n",
        "                break\n",
        "\n",
        "        # Create the Dropdown\n",
        "        w = widgets.Dropdown(\n",
        "            options=list(df.columns),\n",
        "            value=guessed_val,\n",
        "            description=FIELD_INFO[std_name]['label'],\n",
        "            style={'description_width': '180px'},\n",
        "            layout=widgets.Layout(width='600px')\n",
        "        )\n",
        "        mapping_widgets[std_name] = w\n",
        "\n",
        "        row_box = widgets.VBox([\n",
        "            w,\n",
        "            widgets.HTML(f\"<div style='margin-left:185px; font-size:11px; color:#666; margin-bottom:8px'><i>{FIELD_INFO[std_name]['desc']}</i></div>\")\n",
        "        ])\n",
        "        ui_rows.append(row_box)\n",
        "\n",
        "    # Save Button\n",
        "    btn_finalize = widgets.Button(\n",
        "        description=\"\u2713 Confirm Mapping & Finalize Data\",\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='600px', height='40px', margin='20px 0 0 0'),\n",
        "        icon='check-circle'\n",
        "    )\n",
        "\n",
        "    def on_finalize_clicked(b):\n",
        "        try:\n",
        "            col_map = {k: w.value for k, w in mapping_widgets.items()}\n",
        "\n",
        "            # Check for None\n",
        "            if None in col_map.values():\n",
        "                missing = [k for k, v in col_map.items() if v is None]\n",
        "                raise ValueError(f\"Please select a column for: {', '.join(missing)}\")\n",
        "\n",
        "            # Check for duplicates\n",
        "            if len(set(col_map.values())) != len(col_map.values()):\n",
        "                raise ValueError(\"Duplicate mapping detected. You cannot map one column to two fields.\")\n",
        "\n",
        "            global raw_data_standardized\n",
        "            mapped_cols = list(col_map.values())\n",
        "            extra_cols = [c for c in df.columns if c not in mapped_cols]\n",
        "\n",
        "\n",
        "            # --- SANITIZATION & VALIDATION (RAW) ---\n",
        "\n",
        "\n",
        "            mapped_df = df[mapped_cols + extra_cols].copy()\n",
        "\n",
        "\n",
        "            mapped_df.rename(columns={v: k for k, v in col_map.items()}, inplace=True)\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # 1. Convert numeric columns\n",
        "\n",
        "\n",
        "            numeric_fields = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "\n",
        "\n",
        "            present_numeric_fields = [f for f in numeric_fields if f in mapped_df.columns]\n",
        "\n",
        "\n",
        "            error_msgs = []\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            for field in present_numeric_fields:\n",
        "\n",
        "\n",
        "                # Attempt conversion\n",
        "\n",
        "\n",
        "                # Keep track of original non-numeric values for error reporting\n",
        "\n",
        "\n",
        "                non_numeric_mask = pd.to_numeric(mapped_df[field], errors='coerce').isna() & mapped_df[field].notna()\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "                if non_numeric_mask.any():\n",
        "\n",
        "\n",
        "                    bad_rows = mapped_df.index[non_numeric_mask].tolist()\n",
        "\n",
        "\n",
        "                    # Limit to first 3 bad rows\n",
        "\n",
        "\n",
        "                    bad_rows_str = \", \".join([str(r+1) for r in bad_rows[:3]])\n",
        "\n",
        "\n",
        "                    if len(bad_rows) > 3: bad_rows_str += \"...\"\n",
        "\n",
        "\n",
        "                    col_name = col_map.get(field, field)\n",
        "\n",
        "\n",
        "                    error_msgs.append(f\"Column '<b>{col_name}</b>' contains non-numeric values in rows: {bad_rows_str}\")\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "                # Apply coercion\n",
        "\n",
        "\n",
        "                mapped_df[field] = pd.to_numeric(mapped_df[field], errors='coerce')\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # 2. Check for missing required values (after coercion)\n",
        "\n",
        "\n",
        "            if present_numeric_fields:\n",
        "\n",
        "\n",
        "                valid_rows = mapped_df[present_numeric_fields].dropna()\n",
        "\n",
        "\n",
        "                if len(valid_rows) == 0:\n",
        "\n",
        "\n",
        "                    error_msgs.append(\"No valid data rows found after numeric conversion. Please check your decimal separators and data format.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "\n",
        "\n",
        "                # If no numeric fields are mapped, something is wrong, but validation above handles missing keys\n",
        "\n",
        "\n",
        "                pass\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            if error_msgs:\n",
        "\n",
        "\n",
        "                # DISPLAY FRIENDLY ERROR\n",
        "\n",
        "\n",
        "                error_html = \"<div style='background-color:#f8d7da; color:#721c24; padding:15px; border-radius:5px; border:1px solid #f5c6cb; margin-bottom:15px'><b>\\u26a0\\ufe0f Data Validation Error:</b><ul style='margin-bottom:0; padding-left:20px'>\"\n",
        "\n",
        "\n",
        "                for msg in error_msgs:\n",
        "\n",
        "\n",
        "                    error_html += f\"<li>{msg}</li>\"\n",
        "\n",
        "\n",
        "                error_html += \"</ul></div>\"\n",
        "\n",
        "\n",
        "                clear_output()\n",
        "\n",
        "\n",
        "                display(HTML(error_html))\n",
        "\n",
        "\n",
        "                return # STOP execution\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # If passed, assign to global\n",
        "\n",
        "\n",
        "            raw_data_standardized = mapped_df\n",
        "\n",
        "\n",
        "            # Store data type in a temporary global (will be saved to ANALYSIS_CONFIG in Cell 3)\n",
        "            global DATA_TYPE_SELECTED\n",
        "            DATA_TYPE_SELECTED = 'raw'\n",
        "\n",
        "            clear_output()\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style='background-color:#d4edda; color:#155724; padding:15px; border-radius:5px; border:1px solid #c3e6cb'>\n",
        "                <b>\u2705 SUCCESS! Data Ready (Raw Mode).</b><br>\n",
        "                \u2022 {len(raw_data_standardized)} Rows loaded.<br>\n",
        "                \u2022 Moderators detected: {len(extra_cols)} ({', '.join(extra_cols[:5])}...)<br>\n",
        "                <br>Please proceed to the next cell to configure analysis filters.\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "            display(raw_data_standardized.head(3))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Error: {e}\")\n",
        "\n",
        "    btn_finalize.on_click(on_finalize_clicked)\n",
        "    ui_rows.append(btn_finalize)\n",
        "\n",
        "    display(widgets.VBox(ui_rows, layout=widgets.Layout(padding='10px')))\n",
        "\n",
        "def render_precalc_mapping(df):\n",
        "    \"\"\"New column mapping for pre-calculated effect sizes\"\"\"\n",
        "    COLUMN_SPECS = PRECALC_COLUMN_SPECS\n",
        "\n",
        "    FIELD_INFO = {\n",
        "        'id':       {'label': 'Study ID / Label:', 'desc': 'Unique identifier for each study.', 'required': True},\n",
        "        'yi':       {'label': 'Effect Size (yi):', 'desc': 'The calculated effect size (e.g., Hedges\\' g, lnRR, etc.).', 'required': True},\n",
        "        'variance': {'label': 'Variance (vi):', 'desc': 'The variance of the effect size.', 'required': False},\n",
        "        'se':       {'label': 'Standard Error (SE):', 'desc': 'The standard error of the effect size (will convert to variance if needed).', 'required': False},\n",
        "        'n_total':  {'label': 'Sample Size (n_total):', 'desc': 'Total sample size (OPTIONAL - useful for diagnostics).', 'required': False}\n",
        "    }\n",
        "\n",
        "    cols_lower = [str(c).lower().strip() for c in df.columns]\n",
        "    mapping_widgets = {}\n",
        "    ui_rows = []\n",
        "\n",
        "    # Header\n",
        "    ui_rows.append(widgets.HTML(\"\"\"\n",
        "    <hr>\n",
        "    <h4 style='color:#2E86AB; margin-top:15px;'>Map Your Columns (Pre-calculated Mode)</h4>\n",
        "    <div style='background-color:#e3f2fd; padding:10px; border-radius:5px; margin-bottom:10px;'>\n",
        "        <b>\ud83d\udca1 About Pre-calculated Effect Sizes:</b><br>\n",
        "        Use this mode if you already have calculated effect sizes (e.g., from published papers).<br>\n",
        "        You'll need:<br>\n",
        "        \u2022 <b>Effect Size (yi):</b> The standardized effect (g, lnRR, etc.)<br>\n",
        "        \u2022 <b>Variance OR Standard Error:</b> The uncertainty measure (map at least one)<br>\n",
        "        \u2022 <b>Sample Size (optional):</b> Helps with some diagnostics\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    # Build Widgets (in specific order)\n",
        "    field_order = ['id', 'yi', 'variance', 'se', 'n_total']\n",
        "\n",
        "    for std_name in field_order:\n",
        "        synonyms = COLUMN_SPECS[std_name]\n",
        "        info = FIELD_INFO[std_name]\n",
        "\n",
        "        # Auto-Guess Logic\n",
        "        guessed_val = None\n",
        "        for syn in synonyms:\n",
        "            if syn in cols_lower:\n",
        "                guessed_val = df.columns[cols_lower.index(syn)]\n",
        "                break\n",
        "\n",
        "        # Add \"None\" option for optional fields\n",
        "        options = ['None'] + list(df.columns) if not info['required'] else list(df.columns)\n",
        "\n",
        "        # Create the Dropdown\n",
        "        w = widgets.Dropdown(\n",
        "            options=options,\n",
        "            value=guessed_val if guessed_val is not None else ('None' if not info['required'] else None),\n",
        "            description=info['label'],\n",
        "            style={'description_width': '180px'},\n",
        "            layout=widgets.Layout(width='600px')\n",
        "        )\n",
        "        mapping_widgets[std_name] = w\n",
        "\n",
        "        # Required indicator\n",
        "        req_text = \" <b style='color:#c0392b;'>(Required)</b>\" if info['required'] else \" <i>(Optional)</i>\"\n",
        "\n",
        "        row_box = widgets.VBox([\n",
        "            w,\n",
        "            widgets.HTML(f\"<div style='margin-left:185px; font-size:11px; color:#666; margin-bottom:8px'><i>{info['desc']}</i>{req_text}</div>\")\n",
        "        ])\n",
        "        ui_rows.append(row_box)\n",
        "\n",
        "    # Save Button\n",
        "    btn_finalize = widgets.Button(\n",
        "        description=\"\u2713 Confirm Mapping & Finalize Data\",\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='600px', height='40px', margin='20px 0 0 0'),\n",
        "        icon='check-circle'\n",
        "    )\n",
        "\n",
        "    def on_finalize_clicked(b):\n",
        "        try:\n",
        "            col_map = {k: w.value for k, w in mapping_widgets.items()}\n",
        "\n",
        "            # Remove 'None' mappings\n",
        "            col_map = {k: v for k, v in col_map.items() if v != 'None'}\n",
        "\n",
        "            # Validation: Required fields\n",
        "            if 'id' not in col_map or 'yi' not in col_map:\n",
        "                raise ValueError(\"Please map required fields: Study ID and Effect Size (yi)\")\n",
        "\n",
        "            # Validation: Must have variance OR se\n",
        "            if 'variance' not in col_map and 'se' not in col_map:\n",
        "                raise ValueError(\"Please map either Variance (vi) OR Standard Error (SE)\")\n",
        "\n",
        "            # Check for duplicates (excluding None)\n",
        "            mapped_values = list(col_map.values())\n",
        "            if len(set(mapped_values)) != len(mapped_values):\n",
        "                raise ValueError(\"Duplicate mapping detected. You cannot map one column to two fields.\")\n",
        "\n",
        "            global raw_data_standardized\n",
        "            mapped_cols = list(col_map.values())\n",
        "            extra_cols = [c for c in df.columns if c not in mapped_cols]\n",
        "\n",
        "\n",
        "            # --- SANITIZATION & VALIDATION (PRE-CALC) ---\n",
        "\n",
        "\n",
        "            mapped_df = df[mapped_cols + extra_cols].copy()\n",
        "\n",
        "\n",
        "            mapped_df.rename(columns={v: k for k, v in col_map.items()}, inplace=True)\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            error_msgs = []\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # 1. Validate 'yi' (Effect Size) - MUST be numeric\n",
        "\n",
        "\n",
        "            if 'yi' in mapped_df.columns:\n",
        "\n",
        "\n",
        "                non_numeric_mask = pd.to_numeric(mapped_df['yi'], errors='coerce').isna() & mapped_df['yi'].notna()\n",
        "\n",
        "\n",
        "                if non_numeric_mask.any():\n",
        "\n",
        "\n",
        "                    bad_rows = mapped_df.index[non_numeric_mask].tolist()\n",
        "\n",
        "\n",
        "                    bad_rows_str = \", \".join([str(r+1) for r in bad_rows[:3]])\n",
        "\n",
        "\n",
        "                    if len(bad_rows) > 3: bad_rows_str += \"...\"\n",
        "\n",
        "\n",
        "                    col_name = col_map.get('yi', 'yi')\n",
        "\n",
        "\n",
        "                    error_msgs.append(f\"Effect Size Column '<b>{col_name}</b>' contains non-numeric values in rows: {bad_rows_str}\")\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "                mapped_df['yi'] = pd.to_numeric(mapped_df['yi'], errors='coerce')\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # 2. Validate Variance/SE\n",
        "\n",
        "\n",
        "            # We know at least one exists from previous check\n",
        "\n",
        "\n",
        "            for v_field in ['variance', 'se']:\n",
        "\n",
        "\n",
        "                if v_field in mapped_df.columns:\n",
        "\n",
        "\n",
        "                    non_numeric_mask = pd.to_numeric(mapped_df[v_field], errors='coerce').isna() & mapped_df[v_field].notna()\n",
        "\n",
        "\n",
        "                    if non_numeric_mask.any():\n",
        "\n",
        "\n",
        "                        bad_rows = mapped_df.index[non_numeric_mask].tolist()\n",
        "\n",
        "\n",
        "                        bad_rows_str = \", \".join([str(r+1) for r in bad_rows[:3]])\n",
        "\n",
        "\n",
        "                        if len(bad_rows) > 3: bad_rows_str += \"...\"\n",
        "\n",
        "\n",
        "                        col_name = col_map.get(v_field, v_field)\n",
        "\n",
        "\n",
        "                        error_msgs.append(f\"Column '<b>{col_name}</b>' contains non-numeric values in rows: {bad_rows_str}\")\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "                    mapped_df[v_field] = pd.to_numeric(mapped_df[v_field], errors='coerce')\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # 3. Validate n_total if present\n",
        "\n",
        "\n",
        "            if 'n_total' in mapped_df.columns:\n",
        "\n",
        "\n",
        "                 mapped_df['n_total'] = pd.to_numeric(mapped_df['n_total'], errors='coerce')\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # Final check for validity\n",
        "\n",
        "\n",
        "            valid_mask = mapped_df['yi'].notna()\n",
        "\n",
        "\n",
        "            if 'variance' in mapped_df.columns:\n",
        "\n",
        "\n",
        "                valid_mask &= mapped_df['variance'].notna()\n",
        "\n",
        "\n",
        "            elif 'se' in mapped_df.columns:\n",
        "\n",
        "\n",
        "                valid_mask &= mapped_df['se'].notna()\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            if valid_mask.sum() == 0:\n",
        "\n",
        "\n",
        "                error_msgs.append(\"No valid rows found where both Effect Size and Variance/SE are numeric.\")\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            if error_msgs:\n",
        "\n",
        "\n",
        "                # DISPLAY FRIENDLY ERROR\n",
        "\n",
        "\n",
        "                error_html = \"<div style='background-color:#f8d7da; color:#721c24; padding:15px; border-radius:5px; border:1px solid #f5c6cb; margin-bottom:15px'><b>\\u26a0\\ufe0f Data Validation Error:</b><ul style='margin-bottom:0; padding-left:20px'>\"\n",
        "\n",
        "\n",
        "                for msg in error_msgs:\n",
        "\n",
        "\n",
        "                    error_html += f\"<li>{msg}</li>\"\n",
        "\n",
        "\n",
        "                error_html += \"</ul></div>\"\n",
        "\n",
        "\n",
        "                clear_output()\n",
        "\n",
        "\n",
        "                display(HTML(error_html))\n",
        "\n",
        "\n",
        "                return # STOP execution\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            # If passed, assign to global\n",
        "\n",
        "\n",
        "            raw_data_standardized = mapped_df\n",
        "\n",
        "\n",
        "            # Store metadata for Cell 6 to use\n",
        "            global DATA_TYPE_SELECTED, VARIANCE_TYPE_SELECTED\n",
        "            DATA_TYPE_SELECTED = 'pre_calculated'\n",
        "\n",
        "            # Determine which variance type was mapped\n",
        "            if 'variance' in col_map and 'se' in col_map:\n",
        "                VARIANCE_TYPE_SELECTED = 'both'\n",
        "            elif 'variance' in col_map:\n",
        "                VARIANCE_TYPE_SELECTED = 'variance'\n",
        "            else:\n",
        "                VARIANCE_TYPE_SELECTED = 'se'\n",
        "\n",
        "            clear_output()\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style='background-color:#d4edda; color:#155724; padding:15px; border-radius:5px; border:1px solid #c3e6cb'>\n",
        "                <b>\u2705 SUCCESS! Data Ready (Pre-calculated Mode).</b><br>\n",
        "                \u2022 {len(raw_data_standardized)} Rows loaded.<br>\n",
        "                \u2022 Effect Size Column: {col_map['yi']}<br>\n",
        "                \u2022 Variance Type: {VARIANCE_TYPE_SELECTED.upper()}<br>\n",
        "                \u2022 Additional Columns: {len(extra_cols)} ({', '.join(extra_cols[:5])}...)<br>\n",
        "                <br>Please proceed to the next cell to configure analysis filters.\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "            display(raw_data_standardized.head(3))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Error: {e}\")\n",
        "\n",
        "    btn_finalize.on_click(on_finalize_clicked)\n",
        "    ui_rows.append(btn_finalize)\n",
        "\n",
        "    display(widgets.VBox(ui_rows, layout=widgets.Layout(padding='10px')))\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALIZE UI\n",
        "# =============================================================================\n",
        "\n",
        "# Bind inputs\n",
        "btn_auth.on_click(on_auth_clicked)\n",
        "btn_fetch_ws.on_click(on_fetch_ws_clicked)\n",
        "btn_load_sheet.on_click(on_load_sheet_clicked)\n",
        "uploader.observe(on_file_upload, names='value')\n",
        "btn_process_file.on_click(on_process_file_clicked)\n",
        "\n",
        "# Display\n",
        "tabs = widgets.Tab(children=[gs_vbox, local_vbox])\n",
        "tabs.set_title(0, \"Google Sheets\")\n",
        "tabs.set_title(1, \"Upload Excel/CSV\")\n",
        "\n",
        "display(HTML(\"<h3 style='color:#2E86AB'>Step 1: Import Data Source</h3>\"))\n",
        "display(tabs)\n",
        "display(log_output)\n",
        "display(widgets.HTML(\"<hr style='border-top: 1px dashed #ccc;'>\"))\n",
        "display(mapping_output)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eBLUqJAdH8WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \u2699\ufe0f 3. Global Filtering\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 3: DATA CLEANING & ANALYSIS CONFIGURATION\n",
        "# Purpose: Convert data types and apply GLOBAL filters (Pre-filters).\n",
        "# Dependencies: Cell 2 (global 'raw_data_standardized')\n",
        "# Output: Global 'ANALYSIS_CONFIG' dictionary\n",
        "# Note: SKIP this cell if using Pre-calculated mode\n",
        "# =============================================================================\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- CHECK IF PRE-CALCULATED MODE ---\n",
        "data_type_mode = globals().get('DATA_TYPE_SELECTED', 'raw')\n",
        "\n",
        "if data_type_mode == 'pre_calculated':\n",
        "    display(HTML(\"\"\"\n",
        "    <div style='background-color:#fff3cd; border-left: 5px solid #ffc107; padding: 20px; border-radius:5px; margin-bottom:20px;'>\n",
        "        <h3 style='color:#856404; margin-top:0;'>\u23ed\ufe0f SKIP THIS CELL (Pre-calculated Mode)</h3>\n",
        "        <p style='color:#856404; margin-bottom:10px;'>\n",
        "            This cell is for <b>Raw Data Mode</b> only (configuring filters based on means and SDs).\n",
        "        </p>\n",
        "        <p style='color:#856404; margin-bottom:0;'>\n",
        "            <b>\u2713 Action:</b> Skip directly to <b>Cell 5: DETECT & SELECT EFFECT SIZE TYPE</b>\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    # Initialize minimal ANALYSIS_CONFIG for pre-calculated mode\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        ANALYSIS_CONFIG = {\n",
        "            'prefilter_col': 'None',\n",
        "            'prefilter_values': [],\n",
        "            'factor1': 'None',\n",
        "            'factor2': 'None',\n",
        "            'min_papers': 1,\n",
        "            'min_obs': 1,\n",
        "            'clean_dataframe': raw_data_standardized.copy() if 'raw_data_standardized' in globals() else None\n",
        "        }\n",
        "\n",
        "else:\n",
        "    # RAW DATA MODE: Full configuration\n",
        "    # --- 1. INITIALIZATION & SAFETY CHECK ---\n",
        "    if 'raw_data_standardized' not in globals():\n",
        "        display(HTML(\"<div style='background-color:#f8d7da; color:#721c24; padding:10px; border-radius:5px;'>\u274c <b>Error:</b> Data not found. Please run Cell 2 first.</div>\"))\n",
        "    else:\n",
        "        # --- 2. DATA TYPE CONVERSION (The \"Pre-Clean\") ---\n",
        "        # We work on a copy to preserve the original load\n",
        "        df_config = raw_data_standardized.copy()\n",
        "\n",
        "        # Force numeric conversion for statistics columns\n",
        "        numeric_cols = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "        for col in numeric_cols:\n",
        "            # Coerce errors to NaN (e.g., if someone wrote \"n/a\" in a number field)\n",
        "            df_config[col] = pd.to_numeric(df_config[col], errors='coerce')\n",
        "\n",
        "        # Identify Moderators (Any column that isn't a required stat or ID)\n",
        "        reserved_cols = numeric_cols + ['id']\n",
        "        available_moderators = [c for c in df_config.columns if c not in reserved_cols]\n",
        "\n",
        "        # Handle case where no moderators exist\n",
        "        if not available_moderators:\n",
        "            available_moderators = ['None']\n",
        "\n",
        "        # --- 3. WIDGET DEFINITIONS ---\n",
        "\n",
        "        # A. PRE-FILTER SECTION (Global Inclusion/Exclusion)\n",
        "        # --------------------------------------------------\n",
        "        dd_prefilter_mod = widgets.Dropdown(\n",
        "            options=['None'] + available_moderators,\n",
        "            value='None',\n",
        "            description='Filter Variable:',\n",
        "            style={'description_width': '120px'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        # Container for the checkboxes (populated dynamically)\n",
        "        vbox_prefilter_values = widgets.VBox([])\n",
        "\n",
        "        def on_prefilter_change(change):\n",
        "            \"\"\"Updates checkboxes when a moderator is selected\"\"\"\n",
        "            col = change['new']\n",
        "            if col == 'None':\n",
        "                vbox_prefilter_values.children = []\n",
        "                return\n",
        "\n",
        "            # Get unique values from the column\n",
        "            unique_vals = df_config[col].dropna().unique()\n",
        "\n",
        "            # Create a checkbox for each value\n",
        "            checks = []\n",
        "            checks.append(widgets.HTML(f\"<i>Select which values of <b>{col}</b> to KEEP in the analysis:</i>\"))\n",
        "            for val in unique_vals:\n",
        "                count = len(df_config[df_config[col] == val])\n",
        "                checks.append(widgets.Checkbox(value=True, description=f\"{val} (n={count})\"))\n",
        "\n",
        "            vbox_prefilter_values.children = checks\n",
        "\n",
        "        dd_prefilter_mod.observe(on_prefilter_change, names='value')\n",
        "\n",
        "        # B. SAVE BUTTON\n",
        "        # --------------\n",
        "        btn_save_config = widgets.Button(\n",
        "            description=\"\u25b6 Save Configuration\",\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='400px', height='50px'),\n",
        "            icon='check'\n",
        "        )\n",
        "\n",
        "        output_config = widgets.Output()\n",
        "\n",
        "        def on_save_config_clicked(b):\n",
        "            with output_config:\n",
        "                clear_output()\n",
        "                try:\n",
        "                    # 1. Capture Pre-filter values\n",
        "                    kept_values = []\n",
        "                    if dd_prefilter_mod.value != 'None':\n",
        "                        # The first child is HTML text, so we skip it [1:]\n",
        "                        for cb in vbox_prefilter_values.children[1:]:\n",
        "                            if cb.value:\n",
        "                                # Extract value name from description \"Name (n=5)\"\n",
        "                                val_name = cb.description.rsplit(' (n=', 1)[0]\n",
        "                                kept_values.append(val_name)\n",
        "\n",
        "                    # 2. Build Config Dictionary\n",
        "                    global ANALYSIS_CONFIG\n",
        "                    ANALYSIS_CONFIG = {\n",
        "                        'prefilter_col': dd_prefilter_mod.value,\n",
        "                        'prefilter_values': kept_values,\n",
        "                        # We set defaults for legacy compatibility with Cell 4\n",
        "                        'factor1': 'None',\n",
        "                        'factor2': 'None',\n",
        "                        'min_papers': 1,\n",
        "                        'min_obs': 1,\n",
        "                        'clean_dataframe': df_config\n",
        "                    }\n",
        "\n",
        "                    # 3. Success Message\n",
        "                    print(\"=\"*60)\n",
        "                    print(\"\u2705 CONFIGURATION SAVED\")\n",
        "                    print(\"=\"*60)\n",
        "                    if dd_prefilter_mod.value != 'None':\n",
        "                        print(f\"\u2022 Global Filter: {ANALYSIS_CONFIG['prefilter_col']} ({len(kept_values)} values kept)\")\n",
        "                    else:\n",
        "                        print(\"\u2022 Global Filter: None (All data included)\")\n",
        "                    print(\"\\n\u2b07 You may now proceed to Cell 4 to clean and prepare data.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"\u274c Error saving config: {e}\")\n",
        "\n",
        "        btn_save_config.on_click(on_save_config_clicked)\n",
        "\n",
        "        # --- 4. LAYOUT & DISPLAY ---\n",
        "\n",
        "        # Create container box\n",
        "        box_pre = widgets.VBox([\n",
        "            widgets.HTML(\"<h4 style='color:#444'>Global Data Filtering (Optional)</h4><p style='font-size:11px; margin-top:0'>Exclude specific regions, species, or types from the <b>entire</b> analysis.</p>\"),\n",
        "            dd_prefilter_mod,\n",
        "            vbox_prefilter_values\n",
        "        ], layout=widgets.Layout(border='1px solid #ddd', padding='10px', margin='0 0 10px 0', width='95%'))\n",
        "\n",
        "        # Final Display\n",
        "        display(widgets.HTML(f\"<h3 style='color:#2E86AB'>Step 3: Configure Analysis</h3>\"))\n",
        "        display(widgets.HTML(f\"<i>Dataset loaded with <b>{len(df_config)}</b> rows.</i>\"))\n",
        "        display(box_pre)\n",
        "        display(widgets.HTML(\"<hr>\"))\n",
        "        display(btn_save_config, output_config)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d3R6H3L3JD9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \u2699\ufe0f 4. Data Cleaning & Pre-processing\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 4: APPLY CONFIGURATION & PREPARE DATA\n",
        "# Purpose: Apply filters and prepare data for effect size calculation\n",
        "# Note: SKIP this cell if using Pre-calculated mode\n",
        "# =============================================================================\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# DECLARE GLOBALS AT THE TOP (before any assignments)\n",
        "global raw_data, data_filtered\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SHARED CONTROL GROUP DETECTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def detect_shared_controls(df):\n",
        "    \"\"\"\n",
        "    Detects rows within the same study (id) that share control group data.\n",
        "\n",
        "    Logic:\n",
        "    - Group by 'id'\n",
        "    - Within each study, identify rows with identical nc, xc, and sdc\n",
        "    - Assign a unique shared_group_id to rows sharing controls\n",
        "    - Rows that don't share controls get None\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        Dataframe with columns: id, nc, xc, sdc\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        Original dataframe with added column 'shared_group_id'\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Create a copy to avoid modifying the original\n",
        "    df = df.copy()\n",
        "\n",
        "    # Initialize the shared_group_id column\n",
        "    df['shared_group_id'] = None\n",
        "\n",
        "    # Check if required columns exist\n",
        "    required_cols = ['id', 'nc', 'xc', 'sdc']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        return df\n",
        "\n",
        "    shared_count = 0\n",
        "    group_counter = 0\n",
        "\n",
        "    # Group by study ID\n",
        "    for study_id, group in df.groupby('id'):\n",
        "        # Skip if only one row in the study (no potential for sharing)\n",
        "        if len(group) == 1:\n",
        "            continue\n",
        "\n",
        "        # Create a composite key for control characteristics\n",
        "        # Round to handle floating point comparison issues\n",
        "        group = group.copy()\n",
        "        group['_control_key'] = (\n",
        "            group['nc'].fillna(-999).astype(str) + '_' +\n",
        "            group['xc'].fillna(-999).round(6).astype(str) + '_' +\n",
        "            group['sdc'].fillna(-999).round(6).astype(str)\n",
        "        )\n",
        "\n",
        "        # Find groups of rows with identical control data\n",
        "        control_groups = group.groupby('_control_key')\n",
        "\n",
        "        for control_key, control_group in control_groups:\n",
        "            # Only assign shared_group_id if 2+ rows share the same control\n",
        "            if len(control_group) >= 2:\n",
        "                # Create a unique group identifier\n",
        "                group_counter += 1\n",
        "                shared_id = f\"{study_id}_shared_grp_{group_counter}\"\n",
        "\n",
        "                # Assign this ID to all rows in the dataframe that match\n",
        "                df.loc[control_group.index, 'shared_group_id'] = shared_id\n",
        "                shared_count += len(control_group)\n",
        "\n",
        "    return df, shared_count\n",
        "\n",
        "# --- CHECK IF PRE-CALCULATED MODE ---\n",
        "data_type_mode = globals().get('DATA_TYPE_SELECTED', 'raw')\n",
        "\n",
        "if data_type_mode == 'pre_calculated':\n",
        "    display(HTML(\"\"\"\n",
        "    <div style='background-color:#fff3cd; border-left: 5px solid #ffc107; padding: 20px; border-radius:5px; margin-bottom:20px;'>\n",
        "        <h3 style='color:#856404; margin-top:0;'>\u23ed\ufe0f SKIP THIS CELL (Pre-calculated Mode)</h3>\n",
        "        <p style='color:#856404; margin-bottom:10px;'>\n",
        "            This cell applies filtering rules for <b>Raw Data Mode</b>.\n",
        "        </p>\n",
        "        <p style='color:#856404; margin-bottom:0;'>\n",
        "            <b>\u2713 Action:</b> Skip directly to <b>Cell 5: DETECT & SELECT EFFECT SIZE TYPE</b>\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    # For pre-calculated mode, just pass through the data\n",
        "    # No filtering needed - user's effect sizes are already calculated\n",
        "    if 'raw_data_standardized' in globals():\n",
        "        raw_data = raw_data_standardized.copy()\n",
        "        data_filtered = raw_data_standardized.copy()\n",
        "\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color:#d4edda; color:#155724; padding:15px; border-radius:5px; margin-top:10px;'>\n",
        "            <b>\u2713 Pre-calculated Mode: Data Passed Through</b><br>\n",
        "            \u2022 {len(data_filtered)} observations ready for analysis<br>\n",
        "            \u2022 No filtering applied (data already processed)\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "    else:\n",
        "        display(HTML(\"\"\"\n",
        "        <div style='background-color:#f8d7da; color:#721c24; padding:15px; border-radius:5px;'>\n",
        "            <b>\u274c Error:</b> raw_data_standardized not found. Please run Cell 2 first.\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "else:\n",
        "    # RAW DATA MODE: Apply full filtering logic\n",
        "    # --- UI SETUP ---\n",
        "    tab_summary = widgets.Output()\n",
        "    tab_removed = widgets.Output()\n",
        "\n",
        "    tabs = widgets.Tab(children=[tab_summary, tab_removed])\n",
        "    tabs.set_title(0, '\ud83d\udcca Data Summary')\n",
        "    tabs.set_title(1, '\ud83d\uddd1\ufe0f Removed Data')\n",
        "\n",
        "    display(tabs)\n",
        "\n",
        "    # Use the summary tab for the main progress updates initially\n",
        "    with tab_summary:\n",
        "        clear_output()\n",
        "        print(\"\u23f3 Applying filters and cleaning data...\")\n",
        "\n",
        "        try:\n",
        "            # --- 1. Safety Check & Legacy Translation ---\n",
        "            if 'ANALYSIS_CONFIG' not in globals():\n",
        "                raise NameError(\"Configuration not set. Please run Cell 3 and click 'Save Configuration'.\")\n",
        "\n",
        "            # Bridge: Ensure legacy keys exist for the downstream pipeline\n",
        "            if 'filterCol1' not in ANALYSIS_CONFIG:\n",
        "                ANALYSIS_CONFIG['filterCol1'] = ANALYSIS_CONFIG.get('factor1', 'None')\n",
        "            if 'filterCol2' not in ANALYSIS_CONFIG:\n",
        "                ANALYSIS_CONFIG['filterCol2'] = ANALYSIS_CONFIG.get('factor2', 'None')\n",
        "            if 'minPapers' not in ANALYSIS_CONFIG:\n",
        "                ANALYSIS_CONFIG['minPapers'] = ANALYSIS_CONFIG.get('min_papers', 1)\n",
        "            if 'minObservations' not in ANALYSIS_CONFIG:\n",
        "                ANALYSIS_CONFIG['minObservations'] = ANALYSIS_CONFIG.get('min_obs', 1)\n",
        "\n",
        "            # --- 2. Load & Clean Data ---\n",
        "            if 'clean_dataframe' not in ANALYSIS_CONFIG:\n",
        "                raise ValueError(\"Dataframe missing from config. Please re-run Cell 3.\")\n",
        "\n",
        "            raw_data = ANALYSIS_CONFIG['clean_dataframe'].copy()\n",
        "            original_rows = len(raw_data)\n",
        "            cleaning_log = []\n",
        "            removed_records = [] # List to store removed dataframes\n",
        "\n",
        "            # Ensure ID is string\n",
        "            if 'id' in raw_data.columns:\n",
        "                raw_data['id'] = raw_data['id'].astype(str).str.strip()\n",
        "\n",
        "            # Check Essential Cols\n",
        "            essential_cols = ['xe', 'ne', 'xc', 'nc']\n",
        "            missing_cols = [c for c in essential_cols if c not in raw_data.columns]\n",
        "            if missing_cols:\n",
        "                raise ValueError(f\"Critical columns missing from data: {missing_cols}\")\n",
        "\n",
        "            # A. Drop missing values\n",
        "            mask_missing = raw_data[essential_cols].isna().any(axis=1)\n",
        "            if mask_missing.sum() > 0:\n",
        "                dropped = raw_data[mask_missing].copy()\n",
        "                dropped['Reason'] = 'Missing Essential Data (Mean or N)'\n",
        "                removed_records.append(dropped)\n",
        "\n",
        "                raw_data = raw_data[~mask_missing].copy()\n",
        "                cleaning_log.append(f\"Removed {mask_missing.sum()} rows with missing means or sample sizes\")\n",
        "\n",
        "            # B. Ensure N >= 1\n",
        "            # First convert to numeric safely\n",
        "            for col in ['ne', 'nc']:\n",
        "                raw_data[col] = pd.to_numeric(raw_data[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "            mask_invalid_n = (raw_data['ne'] < 1) | (raw_data['nc'] < 1)\n",
        "            if mask_invalid_n.sum() > 0:\n",
        "                dropped = raw_data[mask_invalid_n].copy()\n",
        "                dropped['Reason'] = 'Invalid Sample Size (N < 1)'\n",
        "                removed_records.append(dropped)\n",
        "\n",
        "                raw_data = raw_data[~mask_invalid_n].copy()\n",
        "                cleaning_log.append(f\"Removed {mask_invalid_n.sum()} rows where N < 1\")\n",
        "\n",
        "            final_rows = len(raw_data)\n",
        "\n",
        "            # --- 3. Identify Moderators ---\n",
        "            excluded_cols = ['id', 'xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "            global available_moderators\n",
        "            available_moderators = [col for col in raw_data.columns if col not in excluded_cols]\n",
        "\n",
        "            # --- 4. Apply Pre-filter ---\n",
        "            data_filtered = raw_data.copy()\n",
        "\n",
        "            prefilter_col = ANALYSIS_CONFIG.get('prefilter_col', 'None')\n",
        "            selected_values = ANALYSIS_CONFIG.get('prefilter_values', [])\n",
        "            rows_dropped_filter = 0\n",
        "\n",
        "            if prefilter_col != 'None' and selected_values:\n",
        "                # Identify rows that DO NOT match the selection\n",
        "                mask_filtered_out = ~data_filtered[prefilter_col].isin(selected_values)\n",
        "\n",
        "                if mask_filtered_out.sum() > 0:\n",
        "                    dropped = data_filtered[mask_filtered_out].copy()\n",
        "                    dropped['Reason'] = f\"Filtered by User ('{prefilter_col}')\"\n",
        "                    removed_records.append(dropped)\n",
        "\n",
        "                    data_filtered = data_filtered[~mask_filtered_out].copy()\n",
        "                    rows_dropped_filter = mask_filtered_out.sum()\n",
        "                    cleaning_log.append(f\"Filtered out {rows_dropped_filter} rows based on selection in '{prefilter_col}'\")\n",
        "\n",
        "            # --- 5. Detect Shared Controls ---\n",
        "            data_filtered, n_shared = detect_shared_controls(data_filtered)\n",
        "            if n_shared > 0:\n",
        "                n_shared_groups = data_filtered['shared_group_id'].notna().sum()\n",
        "                cleaning_log.append(f\"Detected {n_shared} observations in shared control groups\")\n",
        "\n",
        "            # --- 6. Save Metadata ---\n",
        "            global LOAD_METADATA\n",
        "            LOAD_METADATA = {\n",
        "                'timestamp': datetime.datetime.now(),\n",
        "                'original_rows': original_rows,\n",
        "                'final_rows_cleaned': final_rows,\n",
        "                'final_rows_filtered': len(data_filtered),\n",
        "                'cleaning_log': cleaning_log,\n",
        "                'available_moderators': available_moderators\n",
        "            }\n",
        "\n",
        "            if removed_records:\n",
        "                ANALYSIS_CONFIG['removed_records'] = pd.concat(removed_records)\n",
        "            else:\n",
        "                ANALYSIS_CONFIG['removed_records'] = pd.DataFrame()\n",
        "            # Update Config\n",
        "            ANALYSIS_CONFIG['n_observations_pre_filter'] = final_rows\n",
        "            ANALYSIS_CONFIG['n_observations_post_filter'] = len(data_filtered)\n",
        "            ANALYSIS_CONFIG['n_papers_post_filter'] = data_filtered['id'].nunique()\n",
        "\n",
        "            # --- 7. RENDER TABS ---\n",
        "\n",
        "            # --- TAB 1: SUMMARY ---\n",
        "            clear_output()\n",
        "\n",
        "            # Build Filter Info\n",
        "            filter_status = \"None\"\n",
        "            if prefilter_col != 'None':\n",
        "                filter_status = f\"Filtered by <b>{prefilter_col}</b> (Dropped {rows_dropped_filter} rows)\"\n",
        "\n",
        "            # Calculate total removed\n",
        "            total_removed = original_rows - len(data_filtered)\n",
        "\n",
        "            html_card = f\"\"\"\n",
        "            <div style=\"font-family: sans-serif; border: 1px solid #c3e6cb; border-radius: 8px; overflow: hidden; max-width: 800px;\">\n",
        "                <div style=\"background-color: #d4edda; padding: 15px; color: #155724;\">\n",
        "                    <h3 style=\"margin: 0;\">\u2705 Data Successfully Prepared</h3>\n",
        "                </div>\n",
        "\n",
        "                <div style=\"padding: 20px;\">\n",
        "                    <div style=\"display: flex; gap: 20px; margin-bottom: 20px;\">\n",
        "                        <div style=\"flex: 1; background: #f8f9fa; padding: 10px; border-radius: 5px; text-align: center;\">\n",
        "                            <div style=\"font-size: 24px; font-weight: bold; color: #2E86AB;\">{len(data_filtered)}</div>\n",
        "                            <div style=\"font-size: 12px; color: #666;\">Rows for Analysis</div>\n",
        "                        </div>\n",
        "                        <div style=\"flex: 1; background: #f8f9fa; padding: 10px; border-radius: 5px; text-align: center;\">\n",
        "                            <div style=\"font-size: 24px; font-weight: bold; color: #2E86AB;\">{data_filtered['id'].nunique()}</div>\n",
        "                            <div style=\"font-size: 12px; color: #666;\">Unique Studies</div>\n",
        "                        </div>\n",
        "                        <div style=\"flex: 1; background: #fff3cd; padding: 10px; border-radius: 5px; text-align: center;\">\n",
        "                            <div style=\"font-size: 24px; font-weight: bold; color: #856404;\">{total_removed}</div>\n",
        "                            <div style=\"font-size: 12px; color: #666;\">Total Removed</div>\n",
        "                        </div>\n",
        "                    </div>\n",
        "\n",
        "                    <table style=\"width: 100%; font-size: 13px; color: #333; border-collapse: collapse;\">\n",
        "                        <tr style=\"border-bottom: 1px solid #eee;\">\n",
        "                            <td style=\"padding: 8px; font-weight: bold;\">Subgroup Analysis:</td>\n",
        "                            <td style=\"padding: 8px;\">{ANALYSIS_CONFIG['filterCol1']} & {ANALYSIS_CONFIG['filterCol2']}</td>\n",
        "                        </tr>\n",
        "                        <tr style=\"border-bottom: 1px solid #eee;\">\n",
        "                            <td style=\"padding: 8px; font-weight: bold;\">Pre-Filter Status:</td>\n",
        "                            <td style=\"padding: 8px;\">{filter_status}</td>\n",
        "                        </tr>\n",
        "                        <tr>\n",
        "                            <td style=\"padding: 8px; font-weight: bold;\">Status:</td>\n",
        "                            <td style=\"padding: 8px;\">Ready for Meta-Analysis Models \u25b6</td>\n",
        "                        </tr>\n",
        "                    </table>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(html_card))\n",
        "\n",
        "            # --- TAB 2: REMOVED DATA ---\n",
        "            with tab_removed:\n",
        "                clear_output()\n",
        "                if removed_records:\n",
        "                    all_removed_df = pd.concat(removed_records)\n",
        "\n",
        "                    display(HTML(f\"<h4 style='color:#c0392b; margin-top:0;'>\ud83d\uddd1\ufe0f Removed Observations ({len(all_removed_df)})</h4>\"))\n",
        "\n",
        "                    # Select useful columns to display\n",
        "                    base_cols = ['id', 'Reason']\n",
        "                    data_cols = ['xe', 'ne', 'xc', 'nc']\n",
        "                    # Add moderator info if available\n",
        "                    extra_cols = [c for c in raw_data.columns if c not in base_cols + data_cols and c in ['Year', 'Species', 'Region', prefilter_col]]\n",
        "                    # Remove None/duplicates\n",
        "                    extra_cols = [c for c in extra_cols if c != 'None']\n",
        "\n",
        "                    cols_to_show = base_cols + data_cols + extra_cols\n",
        "                    # Ensure columns exist\n",
        "                    cols_to_show = [c for c in cols_to_show if c in all_removed_df.columns]\n",
        "\n",
        "                    display(all_removed_df[cols_to_show])\n",
        "                else:\n",
        "                    display(HTML(\"\"\"\n",
        "                    <div style='padding:15px; background:#d4edda; color:#155724; border-radius:5px;'>\n",
        "                        <b>\u2705 No data removed.</b><br>\n",
        "                        All loaded rows passed the quality checks and filter criteria.\n",
        "                    </div>\n",
        "                    \"\"\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            clear_output()\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style=\"border: 1px solid #f5c6cb; border-radius: 8px; padding: 20px; background-color: #f8d7da; color: #721c24;\">\n",
        "                <h3 style=\"margin-top: 0;\">\u274c Error Preparing Data</h3>\n",
        "                <pre style=\"background: rgba(255,255,255,0.5); padding: 10px; border-radius: 5px;\">{e}</pre>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "            traceback.print_exc(file=sys.stdout)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4VzL6TS_I81d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udd2c 5. Effect Size Selection & Diagnostics\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 5: EFFECT SIZE TYPE DETECTION AND SELECTION (DUAL-MODE REFACTOR)\n",
        "# Purpose: Analyze data characteristics and recommend appropriate effect size\n",
        "# Modes: 1) Raw Data (auto-detection) or 2) Pre-calculated (manual selection)\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# --- CHECK DATA TYPE MODE ---\n",
        "data_type_mode = globals().get('DATA_TYPE_SELECTED', 'raw')\n",
        "\n",
        "# =============================================================================\n",
        "# MODE 1: RAW DATA - INTELLIGENT RECOMMENDATION\n",
        "# =============================================================================\n",
        "if data_type_mode == 'raw':\n",
        "    # --- 1. STABILITY FIX: USE RAW DATA IF AVAILABLE ---\n",
        "    target_df = raw_data if 'raw_data' in globals() else data_filtered\n",
        "\n",
        "    # --- 2. ANALYZE DATA ---\n",
        "    xe_stats = target_df['xe'].describe()\n",
        "    xc_stats = target_df['xc'].describe()\n",
        "\n",
        "    # Standard Deviations\n",
        "    has_sde = 'sde' in target_df.columns and target_df['sde'].notna().any()\n",
        "    has_sdc = 'sdc' in target_df.columns and target_df['sdc'].notna().any()\n",
        "    sd_availability = target_df[['sde', 'sdc']].notna().all(axis=1).sum() if has_sde and has_sdc else 0\n",
        "    sd_pct = (sd_availability / len(target_df)) * 100 if len(target_df) > 0 else 0\n",
        "\n",
        "    # 1. Normalization Check\n",
        "    control_near_one = ((target_df['xc'] >= 0.95) & (target_df['xc'] <= 1.05)).sum()\n",
        "    control_exactly_one = (target_df['xc'] == 1.0).sum()\n",
        "    pct_control_near_one = (control_near_one / len(target_df)) * 100\n",
        "    pct_control_exactly_one = (control_exactly_one / len(target_df)) * 100\n",
        "\n",
        "    # 2. Negative Values\n",
        "    n_negative_xe = (target_df['xe'] < 0).sum()\n",
        "    n_negative_xc = (target_df['xc'] < 0).sum()\n",
        "    has_negative = n_negative_xe > 0 or n_negative_xc > 0\n",
        "\n",
        "    # 3. Zero Values\n",
        "    n_zero_xe = (target_df['xe'] == 0).sum()\n",
        "    n_zero_xc = (target_df['xc'] == 0).sum()\n",
        "    has_zero = n_zero_xe > 0 or n_zero_xc > 0\n",
        "\n",
        "    # 4. Scale Heterogeneity\n",
        "    xe_range = xe_stats['max'] - xe_stats['min']\n",
        "    xc_range = xc_stats['max'] - xc_stats['min']\n",
        "    scale_ratio = max(xe_range, xc_range) / (min(xe_range, xc_range) + 0.0001)\n",
        "\n",
        "    # --- 3. RECOMMENDATION LOGIC ---\n",
        "    score_lnRR = 0\n",
        "    score_hedges_g = 0\n",
        "    reasons = []\n",
        "\n",
        "    # Rule 1: Negatives (The \"Hard\" Constraint)\n",
        "    if has_negative:\n",
        "        score_hedges_g += 10\n",
        "        reasons.append(('Negative Values', '+++', 'Hedges g', 'Ratio metrics (lnRR) mathematically fail with negative numbers.'))\n",
        "    else:\n",
        "        score_lnRR += 2\n",
        "        reasons.append(('All Positive', '+', 'lnRR', 'Data is compatible with ratio-based metrics.'))\n",
        "\n",
        "    # Rule 2: Normalization\n",
        "    if pct_control_exactly_one > 50:\n",
        "        score_lnRR += 5\n",
        "        reasons.append(('Fold-Change Data', '+++', 'lnRR', 'Controls set to 1.0 implies data is already a ratio.'))\n",
        "    elif pct_control_near_one > 30:\n",
        "        score_lnRR += 3\n",
        "        reasons.append(('Normalized Data', '++', 'lnRR', 'Controls clustered around 1.0 suggests ratio data.'))\n",
        "    elif 0.8 < xc_stats['mean'] < 1.2:\n",
        "        score_lnRR += 1\n",
        "        reasons.append(('Unity Baseline', '+', 'lnRR', 'Control group mean is close to 1.0.'))\n",
        "\n",
        "    # Rule 3: Heterogeneity\n",
        "    if scale_ratio > 100:\n",
        "        score_lnRR += 3\n",
        "        reasons.append(('High Scale Variance', '+++', 'lnRR', 'Studies measure vastly different scales. Ratios handle this best.'))\n",
        "    elif scale_ratio > 10:\n",
        "        score_lnRR += 2\n",
        "        reasons.append(('Moderate Scale Variance', '++', 'lnRR', 'Ratios normalize scale differences effectively.'))\n",
        "    else:\n",
        "        score_hedges_g += 1\n",
        "        reasons.append(('Consistent Scales', '+', 'Hedges g', 'Scales are similar across studies; standardized differences work well.'))\n",
        "\n",
        "    # Rule 4: Zeros\n",
        "    if has_zero:\n",
        "        score_hedges_g += 2\n",
        "        reasons.append(('Zero Values', '++', 'Hedges g', 'log(0) is undefined. lnRR requires adding arbitrary constants.'))\n",
        "\n",
        "    # Rule 5: SD Availability\n",
        "    if sd_pct > 80:\n",
        "        score_hedges_g += 1\n",
        "        reasons.append(('Good SD Data', '+', 'Hedges g', 'Hedges g requires SDs. Your data has good coverage.'))\n",
        "    elif sd_pct < 20:\n",
        "        reasons.append(('Missing SDs', '\u26a0', 'Neither', 'Hedges g requires imputation. Response Ratios might be safer if SDs are rare.'))\n",
        "\n",
        "    # Winner\n",
        "    score_diff = abs(score_lnRR - score_hedges_g)\n",
        "    if score_lnRR > score_hedges_g:\n",
        "        recommended_type = 'lnRR'\n",
        "        confidence = \"High\" if score_diff >= 5 else \"Moderate\" if score_diff >= 3 else \"Low\"\n",
        "    elif score_hedges_g > score_lnRR:\n",
        "        recommended_type = 'hedges_g'\n",
        "        confidence = \"High\" if score_diff >= 5 else \"Moderate\" if score_diff >= 3 else \"Low\"\n",
        "    else:\n",
        "        recommended_type = 'hedges_g'\n",
        "        confidence = \"Low\"\n",
        "\n",
        "    # --- 4. SETUP UI ---\n",
        "    tab_main = widgets.Output()\n",
        "    tab_patterns = widgets.Output()\n",
        "    tab_logic = widgets.Output()\n",
        "\n",
        "    tabs = widgets.Tab(children=[tab_main, tab_patterns, tab_logic])\n",
        "    tabs.set_title(0, '\ud83d\udca1 Recommendation')\n",
        "    tabs.set_title(1, '\ud83d\udcca Data Patterns')\n",
        "    tabs.set_title(2, '\ud83e\udde0 Decision Logic')\n",
        "\n",
        "    # --- TAB 2: DATA PATTERNS (Educational) ---\n",
        "    with tab_patterns:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='padding:10px; font-size:14px; line-height:1.6;'>\n",
        "            <h4 style='margin-top:0; color:#2E86AB;'>\ud83d\udd0d Diagnostic Checks</h4>\n",
        "            <p>We analyzed <b>{len(target_df)} observations</b> to determine the statistical properties of your dataset.\n",
        "            Here is what we found:</p>\n",
        "\n",
        "            <hr>\n",
        "\n",
        "            <b>1\ufe0f\u20e3 Control Group Normalization</b><br>\n",
        "            Values near 1.0 often indicate \"Fold-Change\" data (e.g., gene expression normalized to a control).<br>\n",
        "            \u2022 <b>Result:</b> {pct_control_exactly_one:.1f}% of controls are exactly 1.0.<br>\n",
        "            \u2022 <b>Implication:</b> {'Strong evidence for Ratio data.' if pct_control_exactly_one > 50 else 'No strong evidence of pre-normalization.'}\n",
        "            <br><br>\n",
        "\n",
        "            <b>2\ufe0f\u20e3 Negative Values</b><br>\n",
        "            Log-based metrics (like lnRR) <i>cannot</i> mathematically handle negative numbers.<br>\n",
        "            \u2022 <b>Result:</b> Found {n_negative_xe + n_negative_xc} negative values.<br>\n",
        "            \u2022 <b>Implication:</b> {'\u274c MUST use Standardized Difference (Hedges g).' if has_negative else '\u2713 Compatible with Ratio metrics.'}\n",
        "            <br><br>\n",
        "\n",
        "            <b>3\ufe0f\u20e3 Zero Values</b><br>\n",
        "            Log of zero is undefined. Zeros require adding a \"small constant\" to work with lnRR.<br>\n",
        "            \u2022 <b>Result:</b> Found {n_zero_xe + n_zero_xc} zero values.<br>\n",
        "            \u2022 <b>Implication:</b> {'\u26a0\ufe0f lnRR will require adjustment.' if has_zero else '\u2713 Clean data.'}\n",
        "            <br><br>\n",
        "\n",
        "            <b>4\ufe0f\u20e3 Scale Heterogeneity</b><br>\n",
        "            Do studies measure things on the same scale (e.g., all in grams) or different scales (grams vs. tons)?<br>\n",
        "            \u2022 <b>Result:</b> Largest value is {scale_ratio:.1f}\u00d7 larger than the smallest range.<br>\n",
        "            \u2022 <b>Implication:</b> {'High variation favors Ratios (lnRR).' if scale_ratio > 10 else 'Low variation allows Standardized Differences.'}\n",
        "            <br><br>\n",
        "\n",
        "            <b>5\ufe0f\u20e3 Data Completeness</b><br>\n",
        "            Standardized differences (Hedges' g) require Standard Deviations (SD) to calculate.<br>\n",
        "            \u2022 <b>Result:</b> {sd_pct:.1f}% of rows have valid SDs.<br>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "    # --- TAB 3: LOGIC (Educational) ---\n",
        "    with tab_logic:\n",
        "        # Create HTML table rows\n",
        "        rows_html = \"\"\n",
        "        for r in reasons:\n",
        "            rows_html += f\"<tr><td><b>{r[0]}</b></td><td>{r[1]}</td><td>{r[2]}</td><td>{r[3]}</td></tr>\"\n",
        "\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='padding:10px; font-size:14px;'>\n",
        "            <h4 style='margin-top:0; color:#2E86AB;'>\ud83e\udde0 How the Algorithm Decides</h4>\n",
        "            <p>We use a weighted scoring system to recommend the most statistically appropriate effect size.\n",
        "            Some factors (like negative values) are \"hard constraints,\" while others are preferences.</p>\n",
        "\n",
        "            <table style='width:100%; border-collapse:collapse; margin-top:10px;'>\n",
        "                <tr style='background-color:#f0f0f0; text-align:left; border-bottom:2px solid #ddd;'>\n",
        "                    <th style='padding:8px;'>Diagnostic Factor</th>\n",
        "                    <th style='padding:8px;'>Weight</th>\n",
        "                    <th style='padding:8px;'>Favors</th>\n",
        "                    <th style='padding:8px;'>Educational Note</th>\n",
        "                </tr>\n",
        "                {rows_html}\n",
        "            </table>\n",
        "\n",
        "            <div style='margin-top:20px; padding:10px; background-color:#eef; border-radius:5px;'>\n",
        "                <b>Final Score:</b><br>\n",
        "                \ud83d\udcca <b>log Response Ratio (lnRR):</b> {score_lnRR} points<br>\n",
        "                \ud83d\udcca <b>Hedges' g (SMD):</b> {score_hedges_g} points\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "    # --- TAB 1: MAIN (Selection) ---\n",
        "    with tab_main:\n",
        "        # 1. Recommendation Box\n",
        "        if recommended_type == 'lnRR':\n",
        "            html_rec = f\"\"\"\n",
        "            <div style='background-color: #d4edda; border-left: 5px solid #28a745; padding: 15px; margin-bottom: 20px;'>\n",
        "                <h3 style='color: #155724; margin-top: 0;'>\ud83d\udca1 Recommendation: log Response Ratio (lnRR)</h3>\n",
        "                <p style='color: #155724; margin-bottom: 0;'><b>Why?</b> Your data appears to be <b>ratio-based</b> (e.g., fold-changes, growth rates).\n",
        "                lnRR is the natural metric for this data type because it handles scale differences and has a direct biological interpretation (% change).</p>\n",
        "            </div>\"\"\"\n",
        "        else:\n",
        "            html_rec = f\"\"\"\n",
        "            <div style='background-color: #d1ecf1; border-left: 5px solid #17a2b8; padding: 15px; margin-bottom: 20px;'>\n",
        "                <h3 style='color: #0c5460; margin-top: 0;'>\ud83d\udca1 Recommendation: Hedges' g (SMD)</h3>\n",
        "                <p style='color: #0c5460; margin-bottom: 0;'><b>Why?</b> Your data appears to be <b>absolute measurements</b> on potentially different scales.\n",
        "                Hedges' g is ideal here because it standardizes effects into \"SD units,\" making them comparable even if units differ.</p>\n",
        "            </div>\"\"\"\n",
        "\n",
        "        display(HTML(html_rec))\n",
        "\n",
        "        # 2. Selection Widget\n",
        "        effect_size_widget = widgets.RadioButtons(\n",
        "            options=[\n",
        "                ('log Response Ratio (lnRR) - for ratio/fold-change data', 'lnRR'),\n",
        "                (\"Hedges' g - for standardized mean differences (corrected)\", 'hedges_g'),\n",
        "                (\"Cohen's d - for standardized mean differences (uncorrected)\", 'cohen_d'),\n",
        "                ('log Odds Ratio (logOR) - for binary outcomes', 'log_or')\n",
        "            ],\n",
        "            value=recommended_type,\n",
        "            description='Select Type:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='600px')\n",
        "        )\n",
        "\n",
        "        # 3. Info Panel\n",
        "        info_output = widgets.Output()\n",
        "        info_panels = {\n",
        "            'lnRR': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>\ud83c\udf93 About lnRR:</b> Calculates the log-ratio of means (ln(Xe/Xc)). Essential for data where 'doubling' is the same magnitude of effect as 'halving'. Commonly used in ecology for biomass, abundance, and size.</div>\",\n",
        "            'hedges_g': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>\ud83c\udf93 About Hedges' g:</b> A variation of Cohen's d that includes a correction factor (J) for small sample sizes. It prevents overestimation of effects in small studies, making it the gold standard for SMD in meta-analysis.</div>\",\n",
        "            'cohen_d': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>\ud83c\udf93 About Cohen's d:</b> The classic standardized mean difference. It is slightly biased (too high) when sample sizes are small (N < 20). Hedges' g is usually preferred.</div>\",\n",
        "            'log_or': \"<div style='padding:10px; background:#fff; border:1px solid #ddd; color:#555; font-size:13px;'><b>\ud83c\udf93 About logOR:</b> The log-odds ratio. Strictly for binary 'Yes/No' or 'Event/Non-event' data. Do not use for continuous measurements like weight or length.</div>\"\n",
        "        }\n",
        "\n",
        "        def update_info(change):\n",
        "            with info_output:\n",
        "                clear_output()\n",
        "                display(HTML(info_panels[change['new']]))\n",
        "\n",
        "        effect_size_widget.observe(update_info, names='value')\n",
        "        with info_output: display(HTML(info_panels[recommended_type]))\n",
        "\n",
        "        # 4. Confirm Button\n",
        "        proceed_button = widgets.Button(\n",
        "            description='\u2713 Confirm Selection',\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='300px', height='40px'),\n",
        "            style={'font_weight': 'bold'}\n",
        "        )\n",
        "        proceed_output = widgets.Output()\n",
        "\n",
        "        def on_proceed(b):\n",
        "            with proceed_output:\n",
        "                clear_output()\n",
        "                sel = effect_size_widget.value\n",
        "                print(f\"\u2713 Confirmed Selection: {sel}\")\n",
        "\n",
        "                # --- CONFIGURATION ---\n",
        "                es_configs = {\n",
        "                    'lnRR': {\n",
        "                        'effect_col': 'lnRR', 'var_col': 'var_lnRR', 'se_col': 'SE_lnRR',\n",
        "                        'ci_lower_col': 'CI_lower_lnRR', 'ci_upper_col': 'CI_upper_lnRR',\n",
        "                        'effect_label': 'log Response Ratio', 'effect_label_short': 'lnRR',\n",
        "                        'has_fold_change': True, 'null_value': 0, 'scale': 'log', 'allows_negative': False\n",
        "                    },\n",
        "                    'hedges_g': {\n",
        "                        'effect_col': 'hedges_g', 'var_col': 'Vg', 'se_col': 'SE_g',\n",
        "                        'ci_lower_col': 'CI_lower_g', 'ci_upper_col': 'CI_upper_g',\n",
        "                        'effect_label': \"Hedges' g\", 'effect_label_short': 'g',\n",
        "                        'has_fold_change': False, 'null_value': 0, 'scale': 'standardized', 'allows_negative': True\n",
        "                    },\n",
        "                    'cohen_d': {\n",
        "                        'effect_col': 'cohen_d', 'var_col': 'Vd', 'se_col': 'SE_d',\n",
        "                        'ci_lower_col': 'CI_lower_d', 'ci_upper_col': 'CI_upper_d',\n",
        "                        'effect_label': \"Cohen's d\", 'effect_label_short': 'd',\n",
        "                        'has_fold_change': False, 'null_value': 0, 'scale': 'standardized', 'allows_negative': True\n",
        "                    },\n",
        "                    'log_or': {\n",
        "                        'effect_col': 'log_OR', 'var_col': 'var_log_OR', 'se_col': 'SE_log_OR',\n",
        "                        'ci_lower_col': 'CI_lower_log_OR', 'ci_upper_col': 'CI_upper_log_OR',\n",
        "                        'effect_label': 'log Odds Ratio', 'effect_label_short': 'logOR',\n",
        "                        'has_fold_change': True, 'null_value': 0, 'scale': 'log', 'allows_negative': False\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                ANALYSIS_CONFIG['effect_size_type'] = sel\n",
        "                ANALYSIS_CONFIG['es_config'] = es_configs[sel]\n",
        "                ANALYSIS_CONFIG['data_type'] = 'raw'  # Store mode\n",
        "\n",
        "                # Pre-set global vars\n",
        "                ANALYSIS_CONFIG['effect_col'] = es_configs[sel]['effect_col']\n",
        "                ANALYSIS_CONFIG['var_col'] = es_configs[sel]['var_col']\n",
        "                ANALYSIS_CONFIG['se_col'] = es_configs[sel]['se_col']\n",
        "\n",
        "                print(f\"\u2713 Configuration saved. Please run the next cell to calculate values.\")\n",
        "\n",
        "        proceed_button.on_click(on_proceed)\n",
        "\n",
        "        display(widgets.VBox([\n",
        "            effect_size_widget,\n",
        "            info_output,\n",
        "            widgets.HTML(\"<br>\"),\n",
        "            proceed_button,\n",
        "            proceed_output\n",
        "        ]))\n",
        "\n",
        "    # --- DISPLAY ---\n",
        "    display(tabs)\n",
        "\n",
        "# =============================================================================\n",
        "# MODE 2: PRE-CALCULATED - MANUAL SELECTION\n",
        "# =============================================================================\n",
        "else:\n",
        "    display(HTML(\"\"\"\n",
        "    <div style='background-color:#fff3cd; border-left: 5px solid #ffc107; padding: 15px; margin-bottom: 20px;'>\n",
        "        <h3 style='color:#856404; margin-top: 0;'>\ud83d\udcca Pre-calculated Effect Size Mode</h3>\n",
        "        <p style='color:#856404; margin-bottom: 0;'>Since you uploaded pre-calculated effect sizes,\n",
        "        we cannot analyze the raw data characteristics. Please manually select the type of effect size\n",
        "        you provided below.</p>\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    # Effect Size Type Descriptions\n",
        "    ES_TYPE_INFO = {\n",
        "        'hedges_g': {\n",
        "            'label': \"Hedges' g (Standardized Mean Difference)\",\n",
        "            'desc': \"Standardized mean difference corrected for small sample bias. Measures the difference between groups in standard deviation units. Use this for continuous outcomes measured on different scales.\"\n",
        "        },\n",
        "        'lnRR': {\n",
        "            'label': 'log Response Ratio (lnRR)',\n",
        "            'desc': 'The natural log of the ratio of means (ln(Treatment/Control)). Ideal for ratio-based data like fold-changes, growth rates, or proportional changes. Commonly used in ecology and biology.'\n",
        "        },\n",
        "        'log_or': {\n",
        "            'label': 'log Odds Ratio (logOR)',\n",
        "            'desc': 'The natural log of the odds ratio. Used exclusively for binary outcomes (Yes/No, Event/Non-event). NOT suitable for continuous measurements.'\n",
        "        },\n",
        "        'fisher_z': {\n",
        "            'label': \"Fisher's z (Correlation)\",\n",
        "            'desc': \"Fisher's z-transformation of correlation coefficients. Use this if your effect sizes are correlations (Pearson's r, Spearman's rho, etc.) that have been transformed.\"\n",
        "        },\n",
        "        'cohen_d': {\n",
        "            'label': \"Cohen's d (Uncorrected SMD)\",\n",
        "            'desc': \"Standardized mean difference without small sample correction. Similar to Hedges' g but may overestimate effects in small studies. Hedges' g is generally preferred.\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Dropdown for effect size type\n",
        "    es_type_dropdown = widgets.Dropdown(\n",
        "        options=[(v['label'], k) for k, v in ES_TYPE_INFO.items()],\n",
        "        value='hedges_g',\n",
        "        description='Effect Size Type:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='700px')\n",
        "    )\n",
        "\n",
        "    # Dynamic info panel\n",
        "    info_panel = widgets.Output()\n",
        "\n",
        "    def update_es_info(change):\n",
        "        with info_panel:\n",
        "            clear_output()\n",
        "            es_type = change['new']\n",
        "            info = ES_TYPE_INFO[es_type]\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style='padding:15px; background:#f8f9fa; border:1px solid #dee2e6; border-radius:5px; margin-top:10px;'>\n",
        "                <b style='color:#2E86AB;'>\ud83d\udcd6 About {info['label']}:</b><br>\n",
        "                <p style='margin-top:5px; margin-bottom:0; color:#555; font-size:13px;'>{info['desc']}</p>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "    es_type_dropdown.observe(update_es_info, names='value')\n",
        "\n",
        "    # Initial display\n",
        "    with info_panel:\n",
        "        info = ES_TYPE_INFO['hedges_g']\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='padding:15px; background:#f8f9fa; border:1px solid #dee2e6; border-radius:5px; margin-top:10px;'>\n",
        "            <b style='color:#2E86AB;'>\ud83d\udcd6 About {info['label']}:</b><br>\n",
        "            <p style='margin-top:5px; margin-bottom:0; color:#555; font-size:13px;'>{info['desc']}</p>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "    # Confirm button\n",
        "    confirm_button = widgets.Button(\n",
        "        description='\u2713 Confirm Effect Size Type',\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='300px', height='40px', margin='20px 0 0 0'),\n",
        "        icon='check-circle'\n",
        "    )\n",
        "\n",
        "    confirm_output = widgets.Output()\n",
        "\n",
        "    def on_confirm_es_type(b):\n",
        "        with confirm_output:\n",
        "            clear_output()\n",
        "            sel = es_type_dropdown.value\n",
        "            print(f\"\u2713 Effect Size Type Confirmed: {ES_TYPE_INFO[sel]['label']}\")\n",
        "\n",
        "            # Configuration mapping\n",
        "            es_configs = {\n",
        "                'hedges_g': {\n",
        "                    'effect_col': 'hedges_g', 'var_col': 'Vg', 'se_col': 'SE_g',\n",
        "                    'ci_lower_col': 'CI_lower_g', 'ci_upper_col': 'CI_upper_g',\n",
        "                    'effect_label': \"Hedges' g\", 'effect_label_short': 'g',\n",
        "                    'has_fold_change': False, 'null_value': 0, 'scale': 'standardized', 'allows_negative': True\n",
        "                },\n",
        "                'lnRR': {\n",
        "                    'effect_col': 'lnRR', 'var_col': 'var_lnRR', 'se_col': 'SE_lnRR',\n",
        "                    'ci_lower_col': 'CI_lower_lnRR', 'ci_upper_col': 'CI_upper_lnRR',\n",
        "                    'effect_label': 'log Response Ratio', 'effect_label_short': 'lnRR',\n",
        "                    'has_fold_change': True, 'null_value': 0, 'scale': 'log', 'allows_negative': False\n",
        "                },\n",
        "                'log_or': {\n",
        "                    'effect_col': 'log_OR', 'var_col': 'var_log_OR', 'se_col': 'SE_log_OR',\n",
        "                    'ci_lower_col': 'CI_lower_log_OR', 'ci_upper_col': 'CI_upper_log_OR',\n",
        "                    'effect_label': 'log Odds Ratio', 'effect_label_short': 'logOR',\n",
        "                    'has_fold_change': True, 'null_value': 0, 'scale': 'log', 'allows_negative': False\n",
        "                },\n",
        "                'fisher_z': {\n",
        "                    'effect_col': 'fisher_z', 'var_col': 'var_fisher_z', 'se_col': 'SE_fisher_z',\n",
        "                    'ci_lower_col': 'CI_lower_z', 'ci_upper_col': 'CI_upper_z',\n",
        "                    'effect_label': \"Fisher's z\", 'effect_label_short': 'z',\n",
        "                    'has_fold_change': False, 'null_value': 0, 'scale': 'transformed', 'allows_negative': True\n",
        "                },\n",
        "                'cohen_d': {\n",
        "                    'effect_col': 'cohen_d', 'var_col': 'Vd', 'se_col': 'SE_d',\n",
        "                    'ci_lower_col': 'CI_lower_d', 'ci_upper_col': 'CI_upper_d',\n",
        "                    'effect_label': \"Cohen's d\", 'effect_label_short': 'd',\n",
        "                    'has_fold_change': False, 'null_value': 0, 'scale': 'standardized', 'allows_negative': True\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Initialize ANALYSIS_CONFIG if it doesn't exist (pre-calculated mode may skip Cell 3)\n",
        "            if 'ANALYSIS_CONFIG' not in globals():\n",
        "                global ANALYSIS_CONFIG\n",
        "                ANALYSIS_CONFIG = {\n",
        "                    'prefilter_col': 'None',\n",
        "                    'prefilter_values': [],\n",
        "                    'factor1': 'None',\n",
        "                    'factor2': 'None',\n",
        "                    'min_papers': 1,\n",
        "                    'min_obs': 1\n",
        "                }\n",
        "\n",
        "            ANALYSIS_CONFIG['effect_size_type'] = sel\n",
        "            ANALYSIS_CONFIG['es_config'] = es_configs[sel]\n",
        "            ANALYSIS_CONFIG['data_type'] = 'pre_calculated'  # Store mode\n",
        "            ANALYSIS_CONFIG['variance_type'] = globals().get('VARIANCE_TYPE_SELECTED', 'variance')\n",
        "\n",
        "            # Pre-set global vars\n",
        "            ANALYSIS_CONFIG['effect_col'] = es_configs[sel]['effect_col']\n",
        "            ANALYSIS_CONFIG['var_col'] = es_configs[sel]['var_col']\n",
        "            ANALYSIS_CONFIG['se_col'] = es_configs[sel]['se_col']\n",
        "\n",
        "            print(f\"\u2713 Configuration saved. Please run the next cell to prepare your data.\")\n",
        "\n",
        "    confirm_button.on_click(on_confirm_es_type)\n",
        "\n",
        "    # Display UI\n",
        "    display(widgets.VBox([\n",
        "        es_type_dropdown,\n",
        "        info_panel,\n",
        "        confirm_button,\n",
        "        confirm_output\n",
        "    ], layout=widgets.Layout(padding='10px')))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y_DSJBpuxpBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83e\uddee 6. Effect Size Calculation\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 5: EFFECT SIZE CALCULATION\n",
        "# Purpose: Calculate effect sizes (lnRR, g, d, logOR), variances, and weights.\n",
        "# Logic: Uses exact Gamma for Hedges' g point estimate, and large-sample\n",
        "#        approximation for variance (matching R 'metafor').\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from scipy.special import gamma\n",
        "\n",
        "# =============================================================================\n",
        "# VCV MATRIX CONSTRUCTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def build_vcv_matrices(df, effect_type, var_col_name):\n",
        "    \"\"\"\n",
        "    Constructs Variance-Covariance (VCV) matrices for studies with shared controls.\n",
        "\n",
        "    Logic:\n",
        "    - For each unique study ID:\n",
        "      - If NO shared controls: Create diagonal matrix from variances (vi)\n",
        "      - If HAS shared controls: Create full matrix with covariances\n",
        "\n",
        "    Formulas (Gleser & Olkin, 2009):\n",
        "    - lnRR: Cov = SD_c^2 / (N_c * Mean_c^2)\n",
        "    - Hedges' g / SMD: Cov \u2248 1 / N_c (simplified approximation)\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        Dataframe with columns: id, shared_group_id, nc, xc, sdc, and variance column\n",
        "    effect_type : str\n",
        "        Type of effect size ('lnRR', 'hedges_g', 'cohen_d', 'log_or')\n",
        "    var_col_name : str\n",
        "        Name of the variance column (e.g., 'Vg', 'var_lnRR', 'Vd')\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary where Key = Study ID, Value = Numpy Matrix\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    vcv_matrices = {}\n",
        "\n",
        "    # Required columns check\n",
        "    if var_col_name not in df.columns or 'id' not in df.columns:\n",
        "        print(f\"\u26a0\ufe0f Warning: Missing required columns for VCV construction ({var_col_name}, id)\")\n",
        "        return vcv_matrices\n",
        "\n",
        "    # Group by study ID\n",
        "    for study_id, study_group in df.groupby('id'):\n",
        "        k = len(study_group)  # Number of effect sizes in this study\n",
        "\n",
        "        # Create k x k matrix\n",
        "        vcv = np.zeros((k, k))\n",
        "\n",
        "        # Get indices for this study in the dataframe\n",
        "        indices = study_group.index.tolist()\n",
        "\n",
        "        # Fill diagonal with variances\n",
        "        for i in range(k):\n",
        "            vcv[i, i] = study_group.iloc[i][var_col_name]\n",
        "\n",
        "        # Check if study has shared controls\n",
        "        if 'shared_group_id' in study_group.columns:\n",
        "            shared_groups = study_group[study_group['shared_group_id'].notna()].groupby('shared_group_id')\n",
        "\n",
        "            for shared_id, shared_rows in shared_groups:\n",
        "                # Get positions of rows sharing this control\n",
        "                shared_positions = [indices.index(idx) for idx in shared_rows.index]\n",
        "\n",
        "                # Calculate covariance for this shared control group\n",
        "                if len(shared_positions) >= 2:\n",
        "                    # Get control group statistics from first row (they should be identical)\n",
        "                    nc = shared_rows.iloc[0]['nc']\n",
        "\n",
        "                    if effect_type == 'lnRR':\n",
        "                        # For lnRR: Cov = SD_c^2 / (N_c * Mean_c^2)\n",
        "                        xc = shared_rows.iloc[0]['xc']\n",
        "\n",
        "                        # Use imputed SD if available, otherwise use original\n",
        "                        if 'sdc_imputed' in shared_rows.columns:\n",
        "                            sdc = shared_rows.iloc[0]['sdc_imputed']\n",
        "                        else:\n",
        "                            sdc = shared_rows.iloc[0]['sdc'] if 'sdc' in shared_rows.columns else 0\n",
        "\n",
        "                        if nc > 0 and xc != 0:\n",
        "                            cov = (sdc ** 2) / (nc * (xc ** 2))\n",
        "                        else:\n",
        "                            cov = 0\n",
        "\n",
        "                    elif effect_type in ['hedges_g', 'cohen_d']:\n",
        "                        # For SMD: Cov \u2248 1 / N_c (simplified)\n",
        "                        # More precise: Cov = 1/N_c + d1*d2/(2*N_total)\n",
        "                        # Using simplified version for now\n",
        "                        if nc > 0:\n",
        "                            cov = 1 / nc\n",
        "                        else:\n",
        "                            cov = 0\n",
        "\n",
        "                    else:\n",
        "                        # For other effect types, use simplified covariance\n",
        "                        if nc > 0:\n",
        "                            cov = 1 / nc\n",
        "                        else:\n",
        "                            cov = 0\n",
        "\n",
        "                    # Fill off-diagonal elements for this shared control group\n",
        "                    for i in shared_positions:\n",
        "                        for j in shared_positions:\n",
        "                            if i != j:\n",
        "                                vcv[i, j] = cov\n",
        "\n",
        "        # Store the matrix\n",
        "        vcv_matrices[study_id] = vcv\n",
        "\n",
        "    return vcv_matrices\n",
        "\n",
        "\n",
        "# --- 1. SETUP TABS ---\n",
        "tab_summary = widgets.Output()\n",
        "tab_diag = widgets.Output()\n",
        "tab_stats = widgets.Output()\n",
        "tab_interp = widgets.Output()\n",
        "tab_removed = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_summary, tab_diag, tab_stats, tab_interp, tab_removed]) # <--- Added here\n",
        "tabs.set_title(0, '\ud83d\udcca Summary')\n",
        "tabs.set_title(1, '\ud83d\udcc9 Diagnostics')\n",
        "tabs.set_title(2, '\ud83d\udccf Detailed Stats')\n",
        "tabs.set_title(3, '\ud83e\udde0 Interpretation')\n",
        "tabs.set_title(4, '\ud83d\uddd1\ufe0f Removed Data')\n",
        "\n",
        "# --- 2. CALCULATION ENGINE ---\n",
        "def run_calculation():\n",
        "    # Logs for different tabs\n",
        "    log_diag = []\n",
        "    log_summary = []\n",
        "\n",
        "    # --- CONFIG CHECK ---\n",
        "    try:\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "             print(\"\u274c ERROR: ANALYSIS_CONFIG not found. Run previous config cell first.\")\n",
        "             return\n",
        "        effect_size_type = ANALYSIS_CONFIG['effect_size_type']\n",
        "        es_config = ANALYSIS_CONFIG['es_config']\n",
        "        log_summary.append(f\"Configuration: {es_config['effect_label']} ({es_config['effect_label_short']})\")\n",
        "    except KeyError as e:\n",
        "        print(f\"\u274c ERROR: Configuration keys missing: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- DATA LOADING ---\n",
        "    if 'data_filtered' not in globals():\n",
        "        print(\"\u274c ERROR: Data not found. Run filtering cell first.\")\n",
        "        return\n",
        "\n",
        "    df = data_filtered.copy()\n",
        "    initial_obs = len(df)\n",
        "    initial_papers = df['id'].nunique()\n",
        "\n",
        "    # --- VALIDATION ---\n",
        "    req_cols = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc']\n",
        "    missing = [c for c in req_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        print(f\"\u274c ERROR: Missing columns: {missing}\")\n",
        "        return\n",
        "\n",
        "    # --- IMPUTATION (SD) ---\n",
        "    log_diag.append(\"<b>1. Standard Deviation Imputation</b>\")\n",
        "\n",
        "    # Handle zeros in SD\n",
        "    if 'sde' in df.columns: df['sde'] = df['sde'].replace(0, np.nan)\n",
        "    if 'sdc' in df.columns: df['sdc'] = df['sdc'].replace(0, np.nan)\n",
        "\n",
        "    # Calculate CV\n",
        "    valid_e = (df['sde'] > 0) & (df['xe'] > 0)\n",
        "    valid_c = (df['sdc'] > 0) & (df['xc'] > 0)\n",
        "\n",
        "    # Calculate median CV for imputation (use default 0.1 if no valid data)\n",
        "    cv_e = (df.loc[valid_e, 'sde'] / df.loc[valid_e, 'xe']).median() if valid_e.any() else 0.1\n",
        "    cv_c = (df.loc[valid_c, 'sdc'] / df.loc[valid_c, 'xc']).median() if valid_c.any() else 0.1\n",
        "\n",
        "    df['sde_imputed'] = df['sde'].fillna(df['xe'] * cv_e)\n",
        "    df['sdc_imputed'] = df['sdc'].fillna(df['xc'] * cv_c)\n",
        "\n",
        "    n_imp_e = df['sde'].isna().sum()\n",
        "    n_imp_c = df['sdc'].isna().sum()\n",
        "\n",
        "    log_diag.append(f\"\u2022 Imputed {n_imp_e} Exp SDs (using CV={cv_e:.4f})\")\n",
        "    log_diag.append(f\"\u2022 Imputed {n_imp_c} Ctl SDs (using CV={cv_c:.4f})\")\n",
        "\n",
        "    # --- CLEANING (Negative/Zero) ---\n",
        "    log_diag.append(\"<br><b>2. Data Cleaning</b>\")\n",
        "\n",
        "    #List to store removed rows\n",
        "    removed_records = []\n",
        "\n",
        "    if effect_size_type in ['lnRR', 'log_or']:\n",
        "        # Remove negatives\n",
        "        neg_mask = (df['xe'] < 0) | (df['xc'] < 0)\n",
        "        n_neg = neg_mask.sum()\n",
        "        if n_neg > 0:\n",
        "            df = df[~neg_mask]\n",
        "            log_diag.append(f\"\u2022 Removed {n_neg} rows with negative values (invalid for {effect_size_type})\")\n",
        "\n",
        "        # Handle zeros\n",
        "        zero_mask = (df['xe'] == 0) | (df['xc'] == 0)\n",
        "        n_zero = zero_mask.sum()\n",
        "        if n_zero > 0:\n",
        "            df.loc[zero_mask, ['xe', 'xc']] += 0.001\n",
        "            log_diag.append(f\"\u2022 Adjusted {n_zero} rows with zero values (added 0.001)\")\n",
        "\n",
        "    # --- CALCULATION ---\n",
        "    # Initialize dynamic column names to avoid KeyErrors later\n",
        "    effect_col = es_config['effect_col']\n",
        "    var_col = es_config['var_col']\n",
        "    se_col = es_config['se_col']\n",
        "\n",
        "    if effect_size_type == 'lnRR':\n",
        "        df[effect_col] = np.log(df['xe'] / df['xc'])\n",
        "        df[var_col] = (df['sde_imputed']**2 / (df['ne']*df['xe']**2)) + (df['sdc_imputed']**2 / (df['nc']*df['xc']**2))\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "        # Fold Change for interpretation\n",
        "        df['Response_Ratio'] = np.exp(df[effect_col])\n",
        "        df['fold_change'] = df.apply(lambda r: r['Response_Ratio'] if r[effect_col]>=0 else -1/r['Response_Ratio'], axis=1)\n",
        "        df['Percent_Change'] = (df['Response_Ratio'] - 1) * 100\n",
        "\n",
        "    elif effect_size_type == 'hedges_g':\n",
        "        # 1. Calculate Cohen's d\n",
        "        df['df'] = df['ne'] + df['nc'] - 2\n",
        "        df['sp'] = np.sqrt(((df['ne']-1)*df['sde_imputed']**2 + (df['nc']-1)*df['sdc_imputed']**2) / df['df'])\n",
        "        df['d'] = (df['xe'] - df['xc']) / df['sp']\n",
        "\n",
        "        # 2. Calculate Correction Factor (J) - Exact Gamma Method\n",
        "        m = df['df']\n",
        "        df['J'] = gamma(m/2) / (np.sqrt(m/2) * gamma((m-1)/2))\n",
        "\n",
        "        # 3. Calculate Hedges' g\n",
        "        df[effect_col] = df['d'] * df['J']\n",
        "\n",
        "        # 4. Calculate Variance (Large Sample Approximation)\n",
        "        # Matches R (metafor) and Borenstein et al.\n",
        "        df[var_col] = (1/df['ne']) + (1/df['nc']) + (df[effect_col]**2 / (2*(df['ne'] + df['nc'])))\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    elif effect_size_type == 'cohen_d':\n",
        "        df['df'] = df['ne'] + df['nc'] - 2\n",
        "        df['sp'] = np.sqrt(((df['ne']-1)*df['sde_imputed']**2 + (df['nc']-1)*df['sdc_imputed']**2) / df['df'])\n",
        "        df[effect_col] = (df['xe'] - df['xc']) / df['sp']\n",
        "        df[var_col] = (df['ne']+df['nc']) / (df['ne']*df['nc']) + (df[effect_col]**2)/(2*(df['ne']+df['nc']))\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    elif effect_size_type == 'log_or':\n",
        "        # Simplified logOR\n",
        "        df[effect_col] = np.log(df['xe'] / df['xc'])\n",
        "        df[var_col] = (1/df['xe'] + 1/df['ne'] + 1/df['xc'] + 1/df['nc'])\n",
        "        df[se_col] = np.sqrt(df[var_col])\n",
        "\n",
        "    # --- CI & WEIGHTS ---\n",
        "    ci_lower_col = es_config.get('ci_lower_col', f\"CI_lower_{es_config['effect_label_short']}\")\n",
        "    ci_upper_col = es_config.get('ci_upper_col', f\"CI_upper_{es_config['effect_label_short']}\")\n",
        "\n",
        "    df[ci_lower_col] = df[effect_col] - 1.96 * df[se_col]\n",
        "    df[ci_upper_col] = df[effect_col] + 1.96 * df[se_col]\n",
        "    df['w_fixed'] = 1 / df[var_col]\n",
        "\n",
        "    # --- FINAL CLEANING ---\n",
        "    #df = df.dropna(subset=[effect_col, var_col]).copy()\n",
        "    #df = df[df[var_col] > 0].copy()\n",
        "\n",
        "    # 1. Check for NaN results\n",
        "    mask_nan = df[[effect_col, var_col]].isna().any(axis=1)\n",
        "    if mask_nan.sum() > 0:\n",
        "        dropped_nan = df[mask_nan].copy()\n",
        "        dropped_nan['Reason'] = 'Calculation Failed (Missing Data/NaN)'\n",
        "        removed_records.append(dropped_nan)\n",
        "        df = df[~mask_nan].copy()\n",
        "\n",
        "    # 2. Check for Zero Variance\n",
        "    mask_zero_var = df[var_col] <= 0\n",
        "    if mask_zero_var.sum() > 0:\n",
        "        dropped_zero = df[mask_zero_var].copy()\n",
        "        dropped_zero['Reason'] = 'Zero or Negative Variance'\n",
        "        removed_records.append(dropped_zero)\n",
        "        df = df[~mask_zero_var].copy()\n",
        "\n",
        "    # --- UPDATE CONFIG ---\n",
        "    ANALYSIS_CONFIG['analysis_data'] = df\n",
        "    ANALYSIS_CONFIG['effect_col'] = effect_col\n",
        "    ANALYSIS_CONFIG['var_col'] = var_col\n",
        "    ANALYSIS_CONFIG['se_col'] = se_col\n",
        "    ANALYSIS_CONFIG['ci_lower_col'] = ci_lower_col\n",
        "    ANALYSIS_CONFIG['ci_upper_col'] = ci_upper_col\n",
        "\n",
        "\n",
        "    # --- BUILD VCV MATRICES ---\n",
        "    # Construct variance-covariance matrices for studies with shared controls\n",
        "    vcv_matrices = build_vcv_matrices(df, effect_size_type, var_col)\n",
        "    ANALYSIS_CONFIG['vcv_matrices'] = vcv_matrices\n",
        "\n",
        "    # Log the number of studies with shared controls\n",
        "    n_studies_with_vcv = len([k for k, v in vcv_matrices.items() if v.shape[0] > 1 or (v.shape[0] > 0 and 'shared_group_id' in df.columns and df[df['id']==k]['shared_group_id'].notna().any())])\n",
        "    if n_studies_with_vcv > 0:\n",
        "        log_diag.append(f\"<br><b>3. VCV Matrices</b>\")\n",
        "        log_diag.append(f\"\u2022 Built {len(vcv_matrices)} VCV matrices ({n_studies_with_vcv} studies with shared controls)\")\n",
        "\n",
        "    # --- POPULATE TABS ---\n",
        "\n",
        "# 1. SUMMARY TAB (ENHANCED)\n",
        "    with tab_summary:\n",
        "        clear_output()\n",
        "        final_n = len(df)\n",
        "        final_papers = df['id'].nunique()\n",
        "\n",
        "        # --- 1. KPI Cards ---\n",
        "        html_sum = f\"\"\"\n",
        "        <div style='display:flex; gap:20px; margin-bottom:20px;'>\n",
        "            <div style='background:#e8f5e9; padding:15px; border-radius:8px; flex:1; text-align:center; border:1px solid #c3e6cb'>\n",
        "                <h2 style='margin:0; color:#2e7d32;'>{final_n}</h2>\n",
        "                <p style='margin:0; color:#1b5e20; font-size:12px; text-transform:uppercase; letter-spacing:1px;'>Observations</p>\n",
        "            </div>\n",
        "            <div style='background:#e3f2fd; padding:15px; border-radius:8px; flex:1; text-align:center; border:1px solid #bbdefb'>\n",
        "                <h2 style='margin:0; color:#1565c0;'>{final_papers}</h2>\n",
        "                <p style='margin:0; color:#0d47a1; font-size:12px; text-transform:uppercase; letter-spacing:1px;'>Studies</p>\n",
        "            </div>\n",
        "            <div style='background:#fff3e0; padding:15px; border-radius:8px; flex:1; text-align:center; border:1px solid #ffe0b2'>\n",
        "                <h2 style='margin:0; color:#e65100;'>{initial_obs - final_n}</h2>\n",
        "                <p style='margin:0; color:#bf360c; font-size:12px; text-transform:uppercase; letter-spacing:1px;'>Removed</p>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(html_sum))\n",
        "\n",
        "        if not df.empty:\n",
        "            # --- 2. Statistics Table ---\n",
        "            desc = df[effect_col].describe()\n",
        "            stats_html = f\"\"\"\n",
        "            <table style='width:100%; border-collapse:collapse; margin-bottom:20px;'>\n",
        "                <tr style='border-bottom:2px solid #eee;'><th style='text-align:left; padding:8px; color:#555;'>Statistic</th><th style='text-align:right; padding:8px; color:#555;'>Value</th></tr>\n",
        "                <tr><td style='padding:8px;'><b>Mean Effect:</b></td><td style='text-align:right; padding:8px;'>{desc['mean']:.4f}</td></tr>\n",
        "                <tr style='background-color:#f9f9f9;'><td style='padding:8px;'><b>Median:</b></td><td style='text-align:right; padding:8px;'>{desc['50%']:.4f}</td></tr>\n",
        "                <tr><td style='padding:8px;'><b>Min / Max:</b></td><td style='text-align:right; padding:8px;'>{desc['min']:.4f} / {desc['max']:.4f}</td></tr>\n",
        "                <tr style='background-color:#f9f9f9;'><td style='padding:8px;'><b>Standard Deviation:</b></td><td style='text-align:right; padding:8px;'>{desc['std']:.4f}</td></tr>\n",
        "            </table>\n",
        "            \"\"\"\n",
        "            display(HTML(stats_html))\n",
        "\n",
        "            # --- 3. Distribution Plot (Histogram) ---\n",
        "            display(HTML(\"<h4 style='color:#2E86AB; margin:0 0 10px 0;'>\ud83d\udcca Distribution of Effect Sizes</h4>\"))\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "\n",
        "            # Plot Histogram\n",
        "            counts, bins, patches = ax.hist(df[effect_col], bins='auto', color='#2E86AB', alpha=0.7, rwidth=0.9, edgecolor='black', linewidth=0.5)\n",
        "\n",
        "            # Add Mean Line\n",
        "            ax.axvline(desc['mean'], color='#e74c3c', linestyle='--', linewidth=2, label=f\"Mean: {desc['mean']:.2f}\")\n",
        "            ax.axvline(0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
        "\n",
        "            # Styling\n",
        "            ax.set_xlabel(es_config['effect_label'], fontsize=10, fontweight='bold')\n",
        "            ax.set_ylabel(\"Frequency\", fontsize=10)\n",
        "            ax.legend(frameon=False)\n",
        "            ax.grid(axis='y', linestyle=':', alpha=0.3)\n",
        "\n",
        "            # Remove top/right spines for cleaner look\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        else:\n",
        "            print(\"\u26a0\ufe0f No valid data remaining.\")\n",
        "\n",
        "# 2. DIAGNOSTICS TAB\n",
        "    with tab_diag:\n",
        "        clear_output()\n",
        "\n",
        "        # --- Processing Log ---\n",
        "        display(HTML(\"<h4 style='color:#2E86AB; margin-bottom:5px;'>\ud83d\udd0d Processing Log</h4>\"))\n",
        "        for line in log_diag:\n",
        "            display(HTML(f\"<div style='margin-left:15px; font-size:13px;'>{line}</div>\"))\n",
        "\n",
        "        # --- Outlier Check ---\n",
        "        if not df.empty:\n",
        "            # Calculate IQR\n",
        "            q1, q3 = df[effect_col].quantile([0.25, 0.75])\n",
        "            iqr = q3 - q1\n",
        "            lower_fence = q1 - 1.5 * iqr\n",
        "            upper_fence = q3 + 1.5 * iqr\n",
        "\n",
        "            # Identify Outliers\n",
        "            outliers = df[(df[effect_col] < lower_fence) | (df[effect_col] > upper_fence)].copy()\n",
        "\n",
        "            display(HTML(\"<hr>\"))\n",
        "            display(HTML(\"<h4 style='color:#2E86AB; margin-bottom:10px;'>\u26a0\ufe0f Outlier Analysis (IQR Method)</h4>\"))\n",
        "\n",
        "            if len(outliers) > 0:\n",
        "                # 1. Explanation Box\n",
        "                outlier_msg = f\"\"\"\n",
        "                <div style='background-color:#fff3cd; border-left: 5px solid #ffc107; padding:15px; margin-bottom:15px; color:#856404;'>\n",
        "                    <b>\u26a0\ufe0f Found {len(outliers)} Potential Outliers</b><br>\n",
        "                    <div style='font-size:13px; margin-top:5px;'>\n",
        "                    These observations fall outside the standard statistical range (1.5 \u00d7 IQR).<br>\n",
        "                    \u2022 <b>Acceptable Range:</b> {lower_fence:.3f} to {upper_fence:.3f}<br>\n",
        "                    \u2022 <b>Extreme Values:</b> {outliers[effect_col].min():.3f} to {outliers[effect_col].max():.3f}<br><br>\n",
        "                    <i><b>Action:</b> Check the table below. If these are typos (e.g., 100 instead of 10), fix your source file. If they are real biological variation, keep them.</i>\n",
        "                    </div>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "                display(HTML(outlier_msg))\n",
        "\n",
        "                # 2. Display Table (Select useful columns)\n",
        "                cols_to_show = ['id', effect_col, 'xe', 'xc', 'ne', 'nc']\n",
        "                # Add 'year' if it exists for context\n",
        "                if 'year' in outliers.columns:\n",
        "                    cols_to_show.insert(1, 'year')\n",
        "\n",
        "                # Filter list to only columns that actually exist\n",
        "                final_cols = [c for c in cols_to_show if c in outliers.columns]\n",
        "\n",
        "                # Sort by effect size (most extreme first)\n",
        "                display(outliers[final_cols].sort_values(by=effect_col, key=abs, ascending=False))\n",
        "\n",
        "            else:\n",
        "                # Success Message\n",
        "                display(HTML(f\"\"\"\n",
        "                <div style='padding:15px; background:#d4edda; border-radius:4px; color:#155724; border:1px solid #c3e6cb;'>\n",
        "                    <b>\u2713 No statistical outliers detected.</b><br>\n",
        "                    All {len(df)} effect sizes fall within the expected statistical range [{lower_fence:.3f}, {upper_fence:.3f}].\n",
        "                </div>\n",
        "                \"\"\"))\n",
        "\n",
        "# 3. DETAILED STATS TAB (WITH INTERPRETATION GUIDE)\n",
        "    with tab_stats:\n",
        "        clear_output()\n",
        "        if not df.empty:\n",
        "            # --- 1. Calculate Statistics ---\n",
        "            es_data = df[effect_col]\n",
        "            skew = es_data.skew()\n",
        "            kurt = es_data.kurt()\n",
        "\n",
        "            # Normality Test (Shapiro-Wilk)\n",
        "            if len(df) < 5000:\n",
        "                shapiro_stat, shapiro_p = stats.shapiro(es_data)\n",
        "                normality_str = f\"W = {shapiro_stat:.3f}, p = {shapiro_p:.3f}\"\n",
        "                is_normal = shapiro_p > 0.05\n",
        "            else:\n",
        "                normality_str = \"N > 5000 (Test omitted)\"\n",
        "                is_normal = True # Assume normal for large N\n",
        "\n",
        "            norm_verdict = \"Likely Normal\" if is_normal else \"Deviates from Normal\"\n",
        "            norm_color = \"#28a745\" if is_normal else \"#dc3545\"\n",
        "\n",
        "            # --- 2. Statistics Table ---\n",
        "            stats_html = f\"\"\"\n",
        "            <h4 style='color:#2E86AB;'>\ud83d\udccf Descriptive Statistics</h4>\n",
        "            <table style='width:100%; border-collapse:collapse; margin-bottom:20px; font-size:13px;'>\n",
        "                <tr style='background-color:#f1f3f5; border-bottom:2px solid #dee2e6;'>\n",
        "                    <th style='padding:8px; text-align:left;'>Metric</th>\n",
        "                    <th style='padding:8px; text-align:right;'>Effect Size</th>\n",
        "                    <th style='padding:8px; text-align:right;'>Standard Error</th>\n",
        "                    <th style='padding:8px; text-align:right;'>Variance</th>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding:8px; border-bottom:1px solid #eee;'><b>Count (N)</b></td>\n",
        "                    <td style='padding:8px; text-align:right;'>{es_data.count()}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[se_col].count()}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[var_col].count()}</td>\n",
        "                </tr>\n",
        "                <tr style='background-color:#f9f9f9;'>\n",
        "                    <td style='padding:8px; border-bottom:1px solid #eee;'><b>Mean</b></td>\n",
        "                    <td style='padding:8px; text-align:right;'>{es_data.mean():.4f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[se_col].mean():.4f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[var_col].mean():.4f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding:8px; border-bottom:1px solid #eee;'><b>Median</b></td>\n",
        "                    <td style='padding:8px; text-align:right;'>{es_data.median():.4f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[se_col].median():.4f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[var_col].median():.4f}</td>\n",
        "                </tr>\n",
        "                <tr style='background-color:#f9f9f9;'>\n",
        "                    <td style='padding:8px; border-bottom:1px solid #eee;'><b>Std. Dev.</b></td>\n",
        "                    <td style='padding:8px; text-align:right;'>{es_data.std():.4f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[se_col].std():.4f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>{df[var_col].std():.4f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding:8px; border-bottom:1px solid #eee;'><b>Skewness</b></td>\n",
        "                    <td style='padding:8px; text-align:right;'>{skew:.3f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>-</td>\n",
        "                    <td style='padding:8px; text-align:right;'>-</td>\n",
        "                </tr>\n",
        "                <tr style='background-color:#f9f9f9;'>\n",
        "                    <td style='padding:8px; border-bottom:1px solid #eee;'><b>Kurtosis</b></td>\n",
        "                    <td style='padding:8px; text-align:right;'>{kurt:.3f}</td>\n",
        "                    <td style='padding:8px; text-align:right;'>-</td>\n",
        "                    <td style='padding:8px; text-align:right;'>-</td>\n",
        "                </tr>\n",
        "            </table>\n",
        "            \"\"\"\n",
        "            display(HTML(stats_html))\n",
        "\n",
        "            # --- 3. Normality Assessment Card ---\n",
        "            norm_html = f\"\"\"\n",
        "            <div style='display:flex; align-items:center; background-color:#fff; border:1px solid #ddd; border-left:5px solid {norm_color}; padding:15px; border-radius:5px; margin-bottom:20px;'>\n",
        "                <div style='flex:1;'>\n",
        "                    <h5 style='margin:0; color:#555;'>Normality Check (Shapiro-Wilk)</h5>\n",
        "                    <div style='font-size:14px; margin-top:5px;'>{normality_str}</div>\n",
        "                </div>\n",
        "                <div style='font-weight:bold; color:{norm_color}; font-size:16px;'>\n",
        "                    {norm_verdict}\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(norm_html))\n",
        "\n",
        "            # --- 4. Guidance Logic ---\n",
        "            advice_items = []\n",
        "            if not is_normal and len(df) < 30:\n",
        "                advice_items.append(\"<li><b>Small, non-normal sample:</b> Random-Effects models may be unstable. Check for outliers in the 'Diagnostics' tab.</li>\")\n",
        "            if abs(skew) > 1:\n",
        "                advice_items.append(\"<li><b>High Skewness:</b> The data is not symmetric. This often indicates a few strong outliers or a natural limit (e.g., values can't be negative).</li>\")\n",
        "            if abs(kurt) > 3:\n",
        "                advice_items.append(\"<li><b>High Kurtosis:</b> The data has 'heavy tails' (more extreme values than expected).</li>\")\n",
        "\n",
        "            if not advice_items:\n",
        "                advice_items.append(\"<li><b>Data looks good!</b> The distribution satisfies standard meta-analysis assumptions.</li>\")\n",
        "\n",
        "            advice_html = f\"\"\"\n",
        "            <div style='background-color:#e3f2fd; padding:15px; border-radius:5px; margin-bottom:20px;'>\n",
        "                <b style='color:#0d47a1;'>\ud83d\udca1 What should I do?</b>\n",
        "                <ul style='margin-top:5px; margin-bottom:0; color:#0d47a1; padding-left:20px;'>\n",
        "                    {''.join(advice_items)}\n",
        "                </ul>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(advice_html))\n",
        "\n",
        "            # --- 5. Q-Q Plot ---\n",
        "            display(HTML(\"<h4 style='color:#2E86AB; margin:0 0 10px 0;'>\ud83d\udcc8 Q-Q Plot (Normality Check)</h4>\"))\n",
        "            fig, ax = plt.subplots(figsize=(6, 4))\n",
        "            stats.probplot(es_data, dist=\"norm\", plot=ax)\n",
        "            ax.get_lines()[0].set_marker('o')\n",
        "            ax.get_lines()[0].set_markersize(5.0)\n",
        "            ax.get_lines()[0].set_markerfacecolor('#4a90e2')\n",
        "            ax.get_lines()[0].set_markeredgecolor('white')\n",
        "            ax.get_lines()[1].set_linewidth(2.0)\n",
        "            ax.get_lines()[1].set_color('#e74c3c')\n",
        "            ax.set_title(\"\")\n",
        "            ax.set_xlabel(\"Theoretical Quantiles\", fontsize=10)\n",
        "            ax.set_ylabel(\"Ordered Values (Effect Sizes)\", fontsize=10)\n",
        "            ax.grid(True, linestyle=':', alpha=0.3)\n",
        "            sns.despine()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # --- 6. Data Preview ---\n",
        "            display(HTML(\"<h4 style='color:#2E86AB; margin-top:20px;'>\ud83d\udccb Data Preview</h4>\"))\n",
        "            cols_show = ['id', 'xe', 'xc', 'ne', 'nc', effect_col, se_col]\n",
        "            cols_exist = [c for c in cols_show if c in df.columns]\n",
        "            display(df[cols_exist].head(5))\n",
        "\n",
        "        else:\n",
        "            print(\"\u26a0\ufe0f No valid data remaining.\")\n",
        "\n",
        "# 4. INTERPRETATION TAB (ENHANCED)\n",
        "    with tab_interp:\n",
        "        clear_output()\n",
        "        if not df.empty:\n",
        "            # --- 1. Logic: Categorize Studies ---\n",
        "            null_val = es_config.get('null_value', 0)\n",
        "\n",
        "            # A. Significance Classification\n",
        "            sig_pos = ((df[ci_lower_col] > null_val)).sum()\n",
        "            sig_neg = ((df[ci_upper_col] < null_val)).sum()\n",
        "            non_sig = len(df) - sig_pos - sig_neg\n",
        "\n",
        "            # B. Magnitude Classification (Cohen's Benchmarks)\n",
        "            # We use absolute values to measure \"strength\" regardless of direction\n",
        "            abs_eff = df[effect_col].abs()\n",
        "\n",
        "            if effect_size_type in ['hedges_g', 'cohen_d']:\n",
        "                # Standard benchmarks for SMD\n",
        "                bins = [-1, 0.2, 0.5, 0.8, 999]\n",
        "                labels = ['Negligible (<0.2)', 'Small (0.2-0.5)', 'Medium (0.5-0.8)', 'Large (>0.8)']\n",
        "            else:\n",
        "                # Benchmarks for lnRR (approximate)\n",
        "                bins = [-1, 0.1, 0.3, 0.5, 999]\n",
        "                labels = ['Negligible (<0.1)', 'Small (0.1-0.3)', 'Medium (0.3-0.5)', 'Large (>0.5)']\n",
        "\n",
        "            mag_counts = pd.cut(abs_eff, bins=bins, labels=labels).value_counts().sort_index()\n",
        "\n",
        "            # --- 2. HTML Headline Cards ---\n",
        "            # Determine dominant direction\n",
        "            if sig_pos > sig_neg:\n",
        "                direction_text = \"Favors Treatment\"\n",
        "                dir_color = \"#28a745\" # Green\n",
        "            elif sig_neg > sig_pos:\n",
        "                direction_text = \"Favors Control\"\n",
        "                dir_color = \"#dc3545\" # Red\n",
        "            else:\n",
        "                direction_text = \"Ambiguous / Balanced\"\n",
        "                dir_color = \"#6c757d\" # Gray\n",
        "\n",
        "            html_cards = f\"\"\"\n",
        "            <div style='display:flex; gap:20px; margin-bottom:20px;'>\n",
        "                <div style='flex:1; background:#f8f9fa; padding:15px; border-radius:8px; border-top: 5px solid {dir_color}; box-shadow: 0 2px 4px rgba(0,0,0,0.05);'>\n",
        "                    <h4 style='margin:0; color:#555; font-size:12px; text-transform:uppercase;'>Direction</h4>\n",
        "                    <div style='font-size:20px; font-weight:bold; color:{dir_color}; margin-top:5px;'>{direction_text}</div>\n",
        "                    <div style='font-size:12px; color:#777;'>Based on significant studies</div>\n",
        "                </div>\n",
        "                <div style='flex:1; background:#f8f9fa; padding:15px; border-radius:8px; border-top: 5px solid #17a2b8; box-shadow: 0 2px 4px rgba(0,0,0,0.05);'>\n",
        "                    <h4 style='margin:0; color:#555; font-size:12px; text-transform:uppercase;'>Significance Rate</h4>\n",
        "                    <div style='font-size:20px; font-weight:bold; color:#17a2b8; margin-top:5px;'>{((sig_pos+sig_neg)/len(df))*100:.1f}%</div>\n",
        "                    <div style='font-size:12px; color:#777;'>Of studies show a clear effect</div>\n",
        "                </div>\n",
        "                <div style='flex:1; background:#f8f9fa; padding:15px; border-radius:8px; border-top: 5px solid #6610f2; box-shadow: 0 2px 4px rgba(0,0,0,0.05);'>\n",
        "                    <h4 style='margin:0; color:#555; font-size:12px; text-transform:uppercase;'>Dominant Magnitude</h4>\n",
        "                    <div style='font-size:20px; font-weight:bold; color:#6610f2; margin-top:5px;'>{mag_counts.idxmax().split(' ')[0]}</div>\n",
        "                    <div style='font-size:12px; color:#777;'>Most common effect size strength</div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(html_cards))\n",
        "\n",
        "            # --- 3. Visualizations (Pie + Bar) ---\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4.5))\n",
        "\n",
        "            # Chart A: Significance Pie (Vote Counting)\n",
        "            sizes = [sig_pos, sig_neg, non_sig]\n",
        "            pie_labels = ['Sig. Positive', 'Sig. Negative', 'Non-Significant']\n",
        "            colors = ['#28a745', '#dc3545', '#e2e6ea'] # Green, Red, Gray\n",
        "            explode = (0.05, 0.05, 0)\n",
        "\n",
        "            # Filter out zeros for cleaner chart\n",
        "            pie_data = [(s, l, c, e) for s, l, c, e in zip(sizes, pie_labels, colors, explode) if s > 0]\n",
        "            if pie_data:\n",
        "                ax1.pie([x[0] for x in pie_data], labels=[x[1] for x in pie_data],\n",
        "                       colors=[x[2] for x in pie_data], explode=[x[3] for x in pie_data],\n",
        "                       autopct='%1.1f%%', startangle=90, textprops={'fontsize': 9})\n",
        "                ax1.set_title(\"Vote Counting (Significance)\", fontweight='bold', fontsize=11)\n",
        "\n",
        "            # Chart B: Magnitude Bar Chart\n",
        "            y_pos = np.arange(len(labels))\n",
        "            ax2.barh(y_pos, mag_counts.values, color='#6610f2', alpha=0.7, edgecolor='black', height=0.6)\n",
        "            ax2.set_yticks(y_pos)\n",
        "            ax2.set_yticklabels(labels)\n",
        "            ax2.set_xlabel(\"Number of Studies\")\n",
        "            ax2.set_title(f\"Effect Magnitude Distribution ({es_config['effect_label_short']})\", fontweight='bold', fontsize=11)\n",
        "            ax2.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "\n",
        "            # Remove spines\n",
        "            for ax in [ax1, ax2]:\n",
        "                ax.spines['top'].set_visible(False)\n",
        "                ax.spines['right'].set_visible(False)\n",
        "                if ax == ax1: ax.axis('equal') # Equal aspect ratio ensures pie is drawn as a circle.\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # --- 4. Narrative Summary ---\n",
        "            narrative = f\"\"\"\n",
        "            <div style='margin-top:20px; padding:15px; background-color:#fff; border:1px solid #ddd; border-left:4px solid #2E86AB;'>\n",
        "                <h4 style='margin-top:0; color:#2E86AB;'>\ud83d\udcdd Automated Interpretation</h4>\n",
        "                <p style='font-size:14px; line-height:1.6; color:#333;'>\n",
        "                    This meta-analysis includes <b>{len(df)} observations</b>.\n",
        "                    Analysis of the individual confidence intervals reveals that <b>{sig_pos} studies ({sig_pos/len(df):.1%})</b> show a statistically significant positive effect,\n",
        "                    while <b>{sig_neg} studies ({sig_neg/len(df):.1%})</b> show a significant negative effect.\n",
        "                    The remaining <b>{non_sig} studies ({non_sig/len(df):.1%})</b> did not reach statistical significance individually.\n",
        "                </p>\n",
        "                <p style='font-size:14px; line-height:1.6; color:#333; margin-bottom:0;'>\n",
        "                     regarding magnitude, the most common effect size category is <b>{mag_counts.idxmax()}</b>.\n",
        "                    This suggests that while results may vary, the typical strength of the observed phenomenon is often {mag_counts.idxmax().split(' ')[0].lower()}.\n",
        "                </p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(narrative))\n",
        "# 5. REMOVED DATA TAB (ENHANCED)\n",
        "    with tab_removed:\n",
        "        clear_output()\n",
        "        if removed_records:\n",
        "            all_removed = pd.concat(removed_records)\n",
        "            # Select relevant columns\n",
        "            cols_to_show = ['id', 'Reason', 'xe', 'xc', 'ne', 'nc']\n",
        "            extra_cols = [c for c in df.columns if c not in cols_to_show and c in ['Year', 'Species', 'Region']]\n",
        "            final_cols = cols_to_show + extra_cols\n",
        "            final_cols = [c for c in final_cols if c in all_removed.columns]\n",
        "\n",
        "            display(HTML(f\"<h4 style='color:#c0392b'>\ud83d\uddd1\ufe0f {len(all_removed)} Rows Excluded from Analysis</h4>\"))\n",
        "\n",
        "            explanation_html = r\"\"\"\n",
        "            <div style='background-color:#fff3cd; border-left: 5px solid #ffeeba; padding:15px; margin-bottom:20px; color:#856404;'>\n",
        "                <b>\ud83d\udca1 Common Reasons for Removal:</b>\n",
        "                <ul style='margin-top:5px; margin-bottom:0; padding-left:20px;'>\n",
        "                    <li><b>Calculation Failed (N=1):</b> Variance cannot be calculated if Sample Size is 1 (dividing by N-1 means dividing by zero). Hedges' g requires valid variance.</li>\n",
        "                    <li><b>Zero Variance:</b> If SD is 0, the inverse-variance weight becomes infinite.</li>\n",
        "                    <li><b>Negative Values:</b> Log-based metrics (lnRR) cannot process negative numbers.</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(explanation_html))\n",
        "\n",
        "            # Display the table\n",
        "            display(all_removed[final_cols])\n",
        "\n",
        "        else:\n",
        "            display(HTML(\"<div style='padding:15px; background:#d4edda; color:#155724;'><b>\u2705 Clean Run:</b> No observations were removed.</div>\"))\n",
        "# =============================================================================\n",
        "# EXECUTION: MODE BRANCHING\n",
        "# =============================================================================\n",
        "\n",
        "# Check which mode we're in\n",
        "data_type_mode = ANALYSIS_CONFIG.get('data_type', 'raw')\n",
        "\n",
        "if data_type_mode == 'raw':\n",
        "    # RAW MODE: Run existing calculation\n",
        "    run_calculation()\n",
        "    display(tabs)\n",
        "\n",
        "else:\n",
        "    # PRE-CALCULATED MODE: Standardize and validate\n",
        "    # Re-populate the same tabs with pre-calculated data\n",
        "\n",
        "    # --- CONFIG CHECK ---\n",
        "    try:\n",
        "        effect_size_type = ANALYSIS_CONFIG['effect_size_type']\n",
        "        es_config = ANALYSIS_CONFIG['es_config']\n",
        "        variance_type = ANALYSIS_CONFIG.get('variance_type', 'variance')\n",
        "    except KeyError as e:\n",
        "        print(f\"\u274c ERROR: Configuration missing: {e}\")\n",
        "    else:\n",
        "        # --- DATA LOADING ---\n",
        "        if 'data_filtered' not in globals():\n",
        "            print(\"\u274c ERROR: Data not found. Run filtering cell first.\")\n",
        "        else:\n",
        "            df = data_filtered.copy()\n",
        "            initial_obs = len(df)\n",
        "            removed_records = []\n",
        "            log_diag = []\n",
        "\n",
        "            log_diag.append(\"<b>1. Pre-calculated Data Mode</b>\")\n",
        "            log_diag.append(f\"\u2022 Effect Size Type: {es_config['effect_label']}\")\n",
        "\n",
        "            # --- VARIANCE HANDLING ---\n",
        "            if variance_type == 'se':\n",
        "                if 'se' in df.columns:\n",
        "                    df['se'] = pd.to_numeric(df['se'], errors='coerce')\n",
        "                    df['vi'] = df['se'] ** 2\n",
        "                    log_diag.append(\"\u2022 Converted SE to Variance (vi = se\u00b2)\")\n",
        "                else:\n",
        "                    print(\"\u274c ERROR: SE column not found\")\n",
        "            elif variance_type == 'variance':\n",
        "                if 'variance' in df.columns:\n",
        "                    df['variance'] = pd.to_numeric(df['variance'], errors='coerce')\n",
        "                    df['vi'] = df['variance']\n",
        "                    log_diag.append(\"\u2022 Using Variance column\")\n",
        "                else:\n",
        "                    print(\"\u274c ERROR: Variance column not found\")\n",
        "            elif variance_type == 'both':\n",
        "                if 'variance' in df.columns:\n",
        "                    df['variance'] = pd.to_numeric(df['variance'], errors='coerce')\n",
        "                    df['vi'] = df['variance']\n",
        "                    log_diag.append(\"\u2022 Using Variance (both provided)\")\n",
        "                elif 'se' in df.columns:\n",
        "                    df['se'] = pd.to_numeric(df['se'], errors='coerce')\n",
        "                    df['vi'] = df['se'] ** 2\n",
        "                    log_diag.append(\"\u2022 Using SE and converting to Variance\")\n",
        "\n",
        "            # --- STANDARDIZE NAMES ---\n",
        "            effect_col = es_config['effect_col']\n",
        "            var_col = es_config['var_col']\n",
        "            se_col = es_config['se_col']\n",
        "            ci_lower_col = es_config['ci_lower_col']\n",
        "            ci_upper_col = es_config['ci_upper_col']\n",
        "\n",
        "            if 'yi' in df.columns:\n",
        "                df[effect_col] = df['yi']\n",
        "            df[var_col] = df['vi']\n",
        "\n",
        "            # Convert to numeric (coerce errors to NaN)\n",
        "            df[effect_col] = pd.to_numeric(df[effect_col], errors='coerce')\n",
        "            df[var_col] = pd.to_numeric(df[var_col], errors='coerce')\n",
        "\n",
        "            log_diag.append(f\"\u2022 Renamed: yi \u2192 {effect_col}, vi \u2192 {var_col}\")\n",
        "\n",
        "            # --- CRITICAL VALIDATION ---\n",
        "            log_diag.append(\"<br><b>2. Data Validation</b>\")\n",
        "\n",
        "            # Check missing values\n",
        "            mask_missing = df[[effect_col, var_col]].isna().any(axis=1)\n",
        "            if mask_missing.sum() > 0:\n",
        "                log_diag.append(f\"\u2022 \u26a0\ufe0f Removed {mask_missing.sum()} rows with missing values\")\n",
        "                dropped = df[mask_missing].copy()\n",
        "                dropped['Reason'] = 'Missing Effect Size or Variance'\n",
        "                removed_records.append(dropped)\n",
        "                df = df[~mask_missing].copy()\n",
        "\n",
        "            # Check negative variance (CRITICAL)\n",
        "            mask_neg_var = df[var_col] < 0\n",
        "            if mask_neg_var.sum() > 0:\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"\u274c CRITICAL ERROR: NEGATIVE VARIANCE DETECTED\")\n",
        "                print(\"=\"*60)\n",
        "                print(f\"Found {mask_neg_var.sum()} rows with negative variance.\")\n",
        "                print(\"Variance must always be positive. Please fix your data.\")\n",
        "                print(\"\\nProblematic rows:\")\n",
        "                print(df[mask_neg_var][['id', effect_col, var_col]].head(10))\n",
        "            else:\n",
        "                # Check zero variance\n",
        "                mask_zero_var = df[var_col] == 0\n",
        "                if mask_zero_var.sum() > 0:\n",
        "                    log_diag.append(f\"\u2022 \u26a0\ufe0f Removed {mask_zero_var.sum()} rows with zero variance (infinite weight)\")\n",
        "                    dropped = df[mask_zero_var].copy()\n",
        "                    dropped['Reason'] = 'Zero Variance (Infinite Weight)'\n",
        "                    removed_records.append(dropped)\n",
        "                    df = df[~mask_zero_var].copy()\n",
        "\n",
        "                log_diag.append(\"\u2022 \u2713 Validation passed\")\n",
        "\n",
        "                # --- CALCULATE DERIVED COLUMNS ---\n",
        "                log_diag.append(\"<br><b>3. Calculate Derived Statistics</b>\")\n",
        "\n",
        "                df[se_col] = np.sqrt(df[var_col])\n",
        "                df[ci_lower_col] = df[effect_col] - 1.96 * df[se_col]\n",
        "                df[ci_upper_col] = df[effect_col] + 1.96 * df[se_col]\n",
        "                df['w_fixed'] = 1 / df[var_col]\n",
        "\n",
        "                log_diag.append(f\"\u2022 Calculated SE, CI, and weights\")\n",
        "\n",
        "                # Handle optional n_total\n",
        "                if 'n_total' not in df.columns:\n",
        "                    df['n_total'] = np.nan\n",
        "\n",
        "                # Add interpretation columns for lnRR\n",
        "                if effect_size_type == 'lnRR':\n",
        "                    df['Response_Ratio'] = np.exp(df[effect_col])\n",
        "                    df['fold_change'] = df.apply(lambda r: r['Response_Ratio'] if r[effect_col]>=0 else -1/r['Response_Ratio'], axis=1)\n",
        "                    df['Percent_Change'] = (df['Response_Ratio'] - 1) * 100\n",
        "                    log_diag.append(\"\u2022 Added interpretation columns\")\n",
        "\n",
        "                # --- UPDATE CONFIG ---\n",
        "                ANALYSIS_CONFIG['analysis_data'] = df\n",
        "                ANALYSIS_CONFIG['effect_col'] = effect_col\n",
        "                ANALYSIS_CONFIG['var_col'] = var_col\n",
        "                ANALYSIS_CONFIG['se_col'] = se_col\n",
        "                ANALYSIS_CONFIG['ci_lower_col'] = ci_lower_col\n",
        "                ANALYSIS_CONFIG['ci_upper_col'] = ci_upper_col\n",
        "\n",
        "                final_n = len(df)\n",
        "\n",
        "\n",
        "                # --- BUILD VCV MATRICES ---\n",
        "                vcv_matrices = build_vcv_matrices(df, effect_size_type, var_col)\n",
        "                ANALYSIS_CONFIG['vcv_matrices'] = vcv_matrices\n",
        "                log_diag.append(f\"\u2022 Built VCV matrices for {len(vcv_matrices)} studies\")\n",
        "\n",
        "                # --- POPULATE TABS (Simplified version) ---\n",
        "                with tab_summary:\n",
        "                    clear_output()\n",
        "                    html_sum = f\"\"\"\n",
        "                    <div style='display:flex; gap:20px; margin-bottom:20px;'>\n",
        "                        <div style='background:#e8f5e9; padding:15px; border-radius:8px; flex:1; text-align:center; border:1px solid #c3e6cb'>\n",
        "                            <h2 style='margin:0; color:#2e7d32;'>{final_n}</h2>\n",
        "                            <p style='margin:0; color:#1b5e20; font-size:12px;'>OBSERVATIONS</p>\n",
        "                        </div>\n",
        "                        <div style='background:#e3f2fd; padding:15px; border-radius:8px; flex:1; text-align:center; border:1px solid #bbdefb'>\n",
        "                            <h2 style='margin:0; color:#1565c0;'>{df['id'].nunique()}</h2>\n",
        "                            <p style='margin:0; color:#0d47a1; font-size:12px;'>STUDIES</p>\n",
        "                        </div>\n",
        "                        <div style='background:#fff3e0; padding:15px; border-radius:8px; flex:1; text-align:center; border:1px solid #ffe0b2'>\n",
        "                            <h2 style='margin:0; color:#e65100;'>{initial_obs - final_n}</h2>\n",
        "                            <p style='margin:0; color:#bf360c; font-size:12px;'>REMOVED</p>\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div style='background:#d1ecf1; padding:15px; border-radius:5px; color:#0c5460; margin-bottom:15px;'>\n",
        "                        <b>\ud83d\udcca Pre-calculated Mode:</b> Data standardized and validated successfully.\n",
        "                    </div>\n",
        "                    \"\"\"\n",
        "                    display(HTML(html_sum))\n",
        "\n",
        "                    # Show basic stats\n",
        "                    desc = df[effect_col].describe()\n",
        "                    display(HTML(f\"<p><b>Mean Effect:</b> {desc['mean']:.4f} | <b>Median:</b> {desc['50%']:.4f} | <b>Range:</b> [{desc['min']:.4f}, {desc['max']:.4f}]</p>\"))\n",
        "                    display(df[['id', effect_col, se_col, var_col]].head(5))\n",
        "\n",
        "                with tab_diag:\n",
        "                    clear_output()\n",
        "                    display(HTML(\"<h4 style='color:#2E86AB;'>Processing Log</h4>\"))\n",
        "                    for line in log_diag:\n",
        "                        display(HTML(f\"<div style='font-size:13px;'>{line}</div>\"))\n",
        "\n",
        "                with tab_removed:\n",
        "                    clear_output()\n",
        "                    if removed_records:\n",
        "                        all_removed = pd.concat(removed_records)\n",
        "                        display(HTML(f\"<h4>\ud83d\uddd1\ufe0f {len(all_removed)} Rows Removed</h4>\"))\n",
        "                        display(all_removed[['id', 'Reason', effect_col, var_col]].head(20))\n",
        "                    else:\n",
        "                        display(HTML(\"<div style='padding:15px; background:#d4edda;'>\u2705 No rows removed</div>\"))\n",
        "\n",
        "                # --- STATS TAB ---\n",
        "                with tab_stats:\n",
        "                    clear_output()\n",
        "                    display(HTML(\"<h4 style='color:#2E86AB;'>\ud83d\udccf Descriptive Statistics</h4>\"))\n",
        "\n",
        "                    desc = df[effect_col].describe()\n",
        "                    stats_html = f\"\"\"\n",
        "                    <table style='width:100%; border-collapse:collapse;'>\n",
        "                        <tr style='background:#f1f3f5;'><th style='padding:8px;'>Stat</th><th style='padding:8px; text-align:right;'>Value</th></tr>\n",
        "                        <tr><td style='padding:8px;'>Mean</td><td style='padding:8px; text-align:right;'>{desc['mean']:.4f}</td></tr>\n",
        "                        <tr><td style='padding:8px;'>Median</td><td style='padding:8px; text-align:right;'>{desc['50%']:.4f}</td></tr>\n",
        "                        <tr><td style='padding:8px;'>Min / Max</td><td style='padding:8px; text-align:right;'>{desc['min']:.4f} / {desc['max']:.4f}</td></tr>\n",
        "                    </table>\n",
        "                    \"\"\"\n",
        "                    display(HTML(stats_html))\n",
        "                    display(df[['id', effect_col, se_col]].head(10))\n",
        "\n",
        "                # --- INTERPRETATION TAB ---\n",
        "                with tab_interp:\n",
        "                    clear_output()\n",
        "                    display(HTML(\"<h4 style='color:#2E86AB;'>\ud83e\udde0 Effect Size Interpretation</h4>\"))\n",
        "\n",
        "                    null_val = es_config.get('null_value', 0)\n",
        "                    sig_pos = ((df[ci_lower_col] > null_val)).sum()\n",
        "                    sig_neg = ((df[ci_upper_col] < null_val)).sum()\n",
        "                    non_sig = len(df) - sig_pos - sig_neg\n",
        "\n",
        "                    display(HTML(f\"\"\"\n",
        "                    <div style='background:#e3f2fd; padding:15px; border-radius:5px;'>\n",
        "                        <b>Significance Summary:</b><br>\n",
        "                        \u2022 Positive: {sig_pos} ({sig_pos/len(df)*100:.1f}%)<br>\n",
        "                        \u2022 Negative: {sig_neg} ({sig_neg/len(df)*100:.1f}%)<br>\n",
        "                        \u2022 Non-significant: {non_sig} ({non_sig/len(df)*100:.1f}%)<br>\n",
        "                        <br><b>Mean Effect:</b> {df[effect_col].mean():.3f}\n",
        "                    </div>\n",
        "                    \"\"\"))\n",
        "\n",
        "\n",
        "                display(tabs)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0k6tVUVh07VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 7. Overall Meta-Analysis: DATA LAYER (Model)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 1/4: DATA LAYER - OVERALL META-ANALYSIS\n",
        "# Purpose: Centralized data management for overall meta-analysis\n",
        "# Dependencies: ANALYSIS_CONFIG global dictionary\n",
        "# Math validated: 2-level and 3-level random-effects models\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA CLASSES\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class OverallConfig:\n",
        "    \"\"\"Configuration for overall meta-analysis\"\"\"\n",
        "    effect_col: str\n",
        "    var_col: str\n",
        "    alpha: float = 0.05\n",
        "    dist_type: str = 't'  # 't' or 'norm'\n",
        "    use_kh: bool = True\n",
        "    tau_method: str = 'REML'  # 'REML', 'DL', 'ML'\n",
        "    model_choice: str = 'Auto-Select (Best AIC)'\n",
        "    match_r_ll: bool = False\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration\"\"\"\n",
        "        if not self.effect_col:\n",
        "            raise ValueError(\"effect_col cannot be empty\")\n",
        "        if not self.var_col:\n",
        "            raise ValueError(\"var_col cannot be empty\")\n",
        "        if self.alpha <= 0 or self.alpha >= 1:\n",
        "            raise ValueError(f\"alpha must be between 0 and 1, got {self.alpha}\")\n",
        "        if self.dist_type not in ['t', 'norm']:\n",
        "            raise ValueError(f\"dist_type must be 't' or 'norm', got {self.dist_type}\")\n",
        "        if self.tau_method not in ['REML', 'DL', 'ML']:\n",
        "            raise ValueError(f\"tau_method must be REML, DL, or ML, got {self.tau_method}\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class OverallResult:\n",
        "    \"\"\"Complete overall meta-analysis result\"\"\"\n",
        "    # Fixed-effect results\n",
        "    mu_fixed: float\n",
        "    se_fixed: float\n",
        "    ci_lower_fixed: float\n",
        "    ci_upper_fixed: float\n",
        "\n",
        "    # Random-effects results (2-level)\n",
        "    mu_random: float\n",
        "    se_random: float\n",
        "    ci_lower_random: float\n",
        "    ci_upper_random: float\n",
        "    p_value_random: float\n",
        "\n",
        "    # Heterogeneity statistics\n",
        "    Q: float\n",
        "    df_Q: int\n",
        "    p_Q: float\n",
        "    I2: float\n",
        "    tau_squared: float\n",
        "\n",
        "    # Sample size\n",
        "    k_obs: int\n",
        "    k_studies: int\n",
        "\n",
        "    # Model info\n",
        "    tau_method: str = 'REML'\n",
        "    use_kh: bool = True\n",
        "    dist_type: str = 't'\n",
        "    alpha: float = 0.05\n",
        "\n",
        "    # Model comparison\n",
        "    aic_2level: float = 0.0\n",
        "    ll_2level: float = 0.0\n",
        "\n",
        "    # 3-level results (optional)\n",
        "    has_3level: bool = False\n",
        "    mu_3level: Optional[float] = None\n",
        "    se_3level: Optional[float] = None\n",
        "    ci_lower_3level: Optional[float] = None\n",
        "    ci_upper_3level: Optional[float] = None\n",
        "    p_value_3level: Optional[float] = None\n",
        "    tau_squared_3level: Optional[float] = None\n",
        "    sigma_squared_3level: Optional[float] = None\n",
        "    icc_l3: Optional[float] = None\n",
        "    icc_l2: Optional[float] = None\n",
        "    aic_3level: Optional[float] = None\n",
        "    ll_3level: Optional[float] = None\n",
        "\n",
        "    # Model selection\n",
        "    best_model: str = \"2-Level\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA MANAGER CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class OverallDataManager:\n",
        "    \"\"\"\n",
        "    Centralized data access layer for overall meta-analysis.\n",
        "    Handles all interactions with ANALYSIS_CONFIG and data validation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize data manager.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self._config = analysis_config\n",
        "        self._validate_prerequisites()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # VALIDATION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _validate_prerequisites(self) -> None:\n",
        "        \"\"\"Validate that required configuration exists\"\"\"\n",
        "        if 'effect_col' not in self._config:\n",
        "            warnings.warn(\"effect_col not in ANALYSIS_CONFIG, using default 'hedges_g'\")\n",
        "        if 'var_col' not in self._config:\n",
        "            warnings.warn(\"var_col not in ANALYSIS_CONFIG, using default 'Vg'\")\n",
        "\n",
        "    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Validate that data is suitable for meta-analysis.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if df is None or len(df) == 0:\n",
        "            return False, \"No data available\"\n",
        "\n",
        "        if self.effect_col not in df.columns:\n",
        "            return False, f\"Effect column '{self.effect_col}' not found\"\n",
        "\n",
        "        if self.var_col not in df.columns:\n",
        "            return False, f\"Variance column '{self.var_col}' not found\"\n",
        "\n",
        "        # Check for minimum observations\n",
        "        n_valid = df[[self.effect_col, self.var_col]].notna().all(axis=1).sum()\n",
        "        if n_valid < 2:\n",
        "            return False, f\"Need at least 2 valid observations, found {n_valid}\"\n",
        "\n",
        "        return True, None\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROPERTY ACCESSORS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def analysis_data(self) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Get analysis dataset\"\"\"\n",
        "        if 'analysis_data' in self._config:\n",
        "            return self._config['analysis_data'].copy()\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def effect_col(self) -> str:\n",
        "        \"\"\"Get effect size column name\"\"\"\n",
        "        return self._config.get('effect_col', 'hedges_g')\n",
        "\n",
        "    @property\n",
        "    def var_col(self) -> str:\n",
        "        \"\"\"Get variance column name\"\"\"\n",
        "        return self._config.get('var_col', 'Vg')\n",
        "\n",
        "    @property\n",
        "    def es_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get effect size configuration\"\"\"\n",
        "        return self._config.get('es_config', {})\n",
        "\n",
        "    @property\n",
        "    def vcv_matrices(self) -> Dict[Any, np.ndarray]:\n",
        "        \"\"\"Get variance-covariance matrices for 3-level model\"\"\"\n",
        "        return self._config.get('vcv_matrices', {})\n",
        "\n",
        "    @property\n",
        "    def global_settings(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get global settings (with defaults)\"\"\"\n",
        "        return self._config.get('global_settings', {\n",
        "            'alpha': 0.05,\n",
        "            'dist_type': 't'\n",
        "        })\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA EXTRACTION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def prepare_data(\n",
        "        self,\n",
        "        df: Optional[pd.DataFrame] = None\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Prepare and clean data for meta-analysis.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to prepare (uses analysis_data if None)\n",
        "\n",
        "        Returns:\n",
        "            Cleaned DataFrame\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If data cannot be prepared\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            df = self.analysis_data\n",
        "\n",
        "        if df is None:\n",
        "            raise ValueError(\"No data available for analysis\")\n",
        "\n",
        "        # Validate\n",
        "        is_valid, error_msg = self.validate_data(df)\n",
        "        if not is_valid:\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        # Create working copy\n",
        "        clean_df = df.copy()\n",
        "\n",
        "        # Remove missing values\n",
        "        clean_df = clean_df.dropna(subset=[self.effect_col, self.var_col]).copy()\n",
        "\n",
        "        # Remove zero or negative variances\n",
        "        clean_df = clean_df[clean_df[self.var_col] > 0].copy()\n",
        "\n",
        "        # Final check\n",
        "        if len(clean_df) == 0:\n",
        "            raise ValueError(\"No valid data after cleaning\")\n",
        "\n",
        "        return clean_df\n",
        "\n",
        "    def check_3level_feasibility(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"\n",
        "        Check if 3-level model is feasible (nested data structure).\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to check\n",
        "\n",
        "        Returns:\n",
        "            True if 3-level model can be fitted\n",
        "        \"\"\"\n",
        "        if 'id' not in df.columns:\n",
        "            return False\n",
        "\n",
        "        # Need multiple observations per study\n",
        "        return len(df) > df['id'].nunique()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RESULT PERSISTENCE METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def save_overall_results(self, result: OverallResult) -> None:\n",
        "        \"\"\"\n",
        "        Save overall analysis results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: OverallResult object\n",
        "        \"\"\"\n",
        "        import datetime\n",
        "\n",
        "        self._config['overall_results'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "\n",
        "            # Fixed-effect\n",
        "            'pooled_effect_fixed': result.mu_fixed,\n",
        "            'pooled_SE_fixed': result.se_fixed,\n",
        "            'ci_lower_fixed': result.ci_lower_fixed,\n",
        "            'ci_upper_fixed': result.ci_upper_fixed,\n",
        "\n",
        "            # Random-effects (2-level)\n",
        "            'pooled_effect_random': result.mu_random,\n",
        "            'pooled_SE_random_reported': result.se_random,\n",
        "            'ci_lower_random_reported': result.ci_lower_random,\n",
        "            'ci_upper_random_reported': result.ci_upper_random,\n",
        "            'p_value_random_reported': result.p_value_random,\n",
        "\n",
        "            # Heterogeneity\n",
        "            'Qt': result.Q,\n",
        "            'I_squared': result.I2,\n",
        "            'tau_squared': result.tau_squared,\n",
        "            'p_Q': result.p_Q,\n",
        "\n",
        "            # Sample size\n",
        "            'k': result.k_obs,\n",
        "            'k_papers': result.k_studies,\n",
        "\n",
        "            # Model info\n",
        "            'tau_method': result.tau_method,\n",
        "            'knapp_hartung': {'used': result.use_kh},\n",
        "            'dist_type': result.dist_type,\n",
        "\n",
        "            # Model comparison\n",
        "            'aic_2level': result.aic_2level,\n",
        "            'best_model': result.best_model\n",
        "        }\n",
        "\n",
        "        # Save 3-level results if available\n",
        "        if result.has_3level:\n",
        "            self._config['three_level_results'] = {\n",
        "                'status': 'completed',\n",
        "                'pooled_effect': result.mu_3level,\n",
        "                'se': result.se_3level,\n",
        "                'ci_lower': result.ci_lower_3level,\n",
        "                'ci_upper': result.ci_upper_3level,\n",
        "                'p_value': result.p_value_3level,\n",
        "                'tau_squared': result.tau_squared_3level,\n",
        "                'sigma_squared': result.sigma_squared_3level,\n",
        "                'icc_l3': result.icc_l3,\n",
        "                'icc_l2': result.icc_l2,\n",
        "                'aic': result.aic_3level\n",
        "            }\n",
        "\n",
        "    def save_global_settings(\n",
        "        self,\n",
        "        alpha: float,\n",
        "        dist_type: str,\n",
        "        tau_method: str,\n",
        "        use_kh: bool,\n",
        "        model_choice: str\n",
        "    ) -> None:\n",
        "        \"\"\"Save global analysis settings\"\"\"\n",
        "        self._config['global_settings'] = {\n",
        "            'alpha': alpha,\n",
        "            'dist_type': dist_type,\n",
        "            'ci_percent': (1 - alpha) * 100,\n",
        "            'tau_method': tau_method,\n",
        "            'use_kh': use_kh,\n",
        "            'model_choice': model_choice\n",
        "        }\n",
        "\n",
        "    def save_publication_text(self, text: str) -> None:\n",
        "        \"\"\"Save publication-ready text\"\"\"\n",
        "        self._config['overall_text'] = text\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTILITY METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def summary_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get summary of current configuration\"\"\"\n",
        "        df = self.analysis_data\n",
        "\n",
        "        return {\n",
        "            'effect_col': self.effect_col,\n",
        "            'var_col': self.var_col,\n",
        "            'n_observations': len(df) if df is not None else 0,\n",
        "            'n_studies': df['id'].nunique() if df is not None and 'id' in df.columns else 0,\n",
        "            'has_vcv': len(self.vcv_matrices) > 0,\n",
        "            'can_do_3level': self.check_3level_feasibility(df) if df is not None else False\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Overall Meta-Analysis Data Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - OverallConfig\")\n",
        "    print(\"   - OverallResult\")\n",
        "    print(\"   - OverallDataManager\")\n",
        "\n",
        "#@title \ud83d\udcca 7. Overall Meta-Analysis: ANALYSIS LAYER (Business Logic)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 2/4: ANALYSIS LAYER - OVERALL META-ANALYSIS\n",
        "# Purpose: Pure statistical computation without UI dependencies\n",
        "# Dependencies:\n",
        "#   - Data Layer (OverallDataManager, OverallResult)\n",
        "#   - calculate_tau_squared (from Cell 4.5 - tau\u00b2 estimators)\n",
        "# Math validated: Fixed-effect, 2-level RE, 3-level RE with matrices\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, chi2, t\n",
        "from scipy.optimize import minimize\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# FIXED-EFFECT ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "class FixedEffectEngine:\n",
        "    \"\"\"\n",
        "    Fixed-effect meta-analysis engine.\n",
        "\n",
        "    Mathematical implementation: Standard inverse-variance weighting.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate(\n",
        "        y: np.ndarray,\n",
        "        v: np.ndarray,\n",
        "        alpha: float = 0.05,\n",
        "        dist_type: str = 't'\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate fixed-effect pooled estimate.\n",
        "\n",
        "        MATH PRESERVED: Original inverse-variance weighting\n",
        "\n",
        "        Args:\n",
        "            y: Effect sizes\n",
        "            v: Variances\n",
        "            alpha: Significance level\n",
        "            dist_type: 't' or 'norm'\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with mu, se, ci_lower, ci_upper\n",
        "        \"\"\"\n",
        "        # Inverse-variance weights\n",
        "        w = 1 / v\n",
        "        sum_w = np.sum(w)\n",
        "\n",
        "        # Pooled estimate\n",
        "        mu = np.sum(w * y) / sum_w\n",
        "        se = np.sqrt(1 / sum_w)\n",
        "\n",
        "        # Critical value\n",
        "        q = 1 - (alpha / 2)\n",
        "        if dist_type == 't':\n",
        "            crit_val = t.ppf(q, len(y) - 1)\n",
        "        else:\n",
        "            crit_val = norm.ppf(q)\n",
        "\n",
        "        # Confidence interval\n",
        "        ci_lower = mu - crit_val * se\n",
        "        ci_upper = mu + crit_val * se\n",
        "\n",
        "        return {\n",
        "            'mu': mu,\n",
        "            'se': se,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HETEROGENEITY STATISTICS ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "class HeterogeneityEngine:\n",
        "    \"\"\"\n",
        "    Calculate heterogeneity statistics (Q, I\u00b2, \u03c4\u00b2).\n",
        "\n",
        "    Mathematical implementation validated against metafor.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_Q_statistics(\n",
        "        y: np.ndarray,\n",
        "        v: np.ndarray,\n",
        "        mu: float\n",
        "    ) -> Tuple[float, int, float]:\n",
        "        \"\"\"\n",
        "        Calculate Cochran's Q statistic.\n",
        "\n",
        "        MATH PRESERVED: Original Q calculation\n",
        "\n",
        "        Args:\n",
        "            y: Effect sizes\n",
        "            v: Variances\n",
        "            mu: Pooled estimate (from fixed-effect)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (Q, df, p_value)\n",
        "        \"\"\"\n",
        "        w = 1 / v\n",
        "        Q = np.sum(w * (y - mu)**2)\n",
        "        df_Q = len(y) - 1\n",
        "        p_Q = 1 - chi2.cdf(Q, df_Q) if df_Q > 0 else 1.0\n",
        "\n",
        "        return Q, df_Q, p_Q\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_I2(Q: float, df_Q: int) -> float:\n",
        "        \"\"\"\n",
        "        Calculate I\u00b2 statistic.\n",
        "\n",
        "        Args:\n",
        "            Q: Q statistic\n",
        "            df_Q: Degrees of freedom\n",
        "\n",
        "        Returns:\n",
        "            I\u00b2 percentage\n",
        "        \"\"\"\n",
        "        if Q <= df_Q:\n",
        "            return 0.0\n",
        "        return ((Q - df_Q) / Q) * 100 if Q > 0 else 0.0\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_tau2_DL(\n",
        "        Q: float,\n",
        "        df_Q: int,\n",
        "        w: np.ndarray\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate \u03c4\u00b2 using DerSimonian-Laird method.\n",
        "\n",
        "        MATH PRESERVED: Original DL estimator\n",
        "\n",
        "        Args:\n",
        "            Q: Q statistic\n",
        "            df_Q: Degrees of freedom\n",
        "            w: Fixed-effect weights\n",
        "\n",
        "        Returns:\n",
        "            \u03c4\u00b2 estimate\n",
        "        \"\"\"\n",
        "        C = np.sum(w) - np.sum(w**2) / np.sum(w)\n",
        "        if C <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        tau2 = max(0, (Q - df_Q) / C)\n",
        "        return tau2\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# TWO-LEVEL RANDOM-EFFECTS ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "class TwoLevelEngine:\n",
        "    \"\"\"\n",
        "    Two-level random-effects meta-analysis with multiple \u03c4\u00b2 estimators.\n",
        "\n",
        "    Mathematical implementation validated against metafor.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tau_method: str = 'REML'):\n",
        "        \"\"\"\n",
        "        Initialize engine.\n",
        "\n",
        "        Args:\n",
        "            tau_method: 'REML', 'DL', or 'ML'\n",
        "        \"\"\"\n",
        "        self.tau_method = tau_method\n",
        "        self.het_engine = HeterogeneityEngine()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAU\u00b2 ESTIMATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def estimate_tau2(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        effect_col: str,\n",
        "        var_col: str\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Estimate \u03c4\u00b2 using specified method.\n",
        "\n",
        "        MATH PRESERVED: Delegates to appropriate estimator\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame with effect sizes\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name\n",
        "\n",
        "        Returns:\n",
        "            \u03c4\u00b2 estimate\n",
        "        \"\"\"\n",
        "        y = df[effect_col].values\n",
        "        v = df[var_col].values\n",
        "\n",
        "        if self.tau_method == 'DL':\n",
        "            # Calculate Q from fixed-effect\n",
        "            w = 1 / v\n",
        "            mu_fe = np.sum(w * y) / np.sum(w)\n",
        "            Q, df_Q, _ = self.het_engine.calculate_Q_statistics(y, v, mu_fe)\n",
        "            return self.het_engine.calculate_tau2_DL(Q, df_Q, w)\n",
        "\n",
        "        else:\n",
        "            # Use global tau\u00b2 calculator (REML or ML)\n",
        "            try:\n",
        "                # Check if calculate_tau_squared exists in globals\n",
        "                if 'calculate_tau_squared' in globals():\n",
        "                    tau2, _ = calculate_tau_squared(\n",
        "                        df, effect_col, var_col, method=self.tau_method\n",
        "                    )\n",
        "                    return tau2\n",
        "                else:\n",
        "                    # Fallback to DL if function not available\n",
        "                    warnings.warn(\n",
        "                        f\"{self.tau_method} not available, using DL estimator\"\n",
        "                    )\n",
        "                    w = 1 / v\n",
        "                    mu_fe = np.sum(w * y) / np.sum(w)\n",
        "                    Q, df_Q, _ = self.het_engine.calculate_Q_statistics(y, v, mu_fe)\n",
        "                    return self.het_engine.calculate_tau2_DL(Q, df_Q, w)\n",
        "            except Exception as e:\n",
        "                warnings.warn(f\"\u03c4\u00b2 estimation failed: {e}, using DL\")\n",
        "                w = 1 / v\n",
        "                mu_fe = np.sum(w * y) / np.sum(w)\n",
        "                Q, df_Q, _ = self.het_engine.calculate_Q_statistics(y, v, mu_fe)\n",
        "                return self.het_engine.calculate_tau2_DL(Q, df_Q, w)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RANDOM-EFFECTS POOLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def calculate_pooled_effect(\n",
        "        self,\n",
        "        y: np.ndarray,\n",
        "        v: np.ndarray,\n",
        "        tau2: float,\n",
        "        alpha: float = 0.05,\n",
        "        dist_type: str = 't',\n",
        "        use_kh: bool = True\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate random-effects pooled estimate.\n",
        "\n",
        "        MATH PRESERVED: Original RE pooling with optional KH correction\n",
        "\n",
        "        Args:\n",
        "            y: Effect sizes\n",
        "            v: Variances\n",
        "            tau2: Between-study variance\n",
        "            alpha: Significance level\n",
        "            dist_type: 't' or 'norm'\n",
        "            use_kh: Apply Knapp-Hartung correction\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with mu, se, ci_lower, ci_upper, p_value\n",
        "        \"\"\"\n",
        "        # Random-effects weights\n",
        "        w = 1 / (v + tau2)\n",
        "        sum_w = np.sum(w)\n",
        "\n",
        "        # Pooled estimate\n",
        "        mu = np.sum(w * y) / sum_w\n",
        "        se = np.sqrt(1 / sum_w)\n",
        "\n",
        "        # Knapp-Hartung adjustment\n",
        "        if use_kh and len(y) > 1:\n",
        "            q_re = np.sum(w * (y - mu)**2)\n",
        "            df_Q = len(y) - 1\n",
        "            se = se * np.sqrt(max(1, q_re / df_Q))\n",
        "\n",
        "        # Critical value and p-value\n",
        "        df_Q = len(y) - 1\n",
        "        q = 1 - (alpha / 2)\n",
        "\n",
        "        if dist_type == 't':\n",
        "            crit_val = t.ppf(q, df_Q)\n",
        "            p_value = 2 * (1 - t.cdf(abs(mu / se), df_Q))\n",
        "        else:\n",
        "            crit_val = norm.ppf(q)\n",
        "            p_value = 2 * (1 - norm.cdf(abs(mu / se)))\n",
        "\n",
        "        # Confidence interval\n",
        "        ci_lower = mu - crit_val * se\n",
        "        ci_upper = mu + crit_val * se\n",
        "\n",
        "        return {\n",
        "            'mu': mu,\n",
        "            'se': se,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'p_value': p_value\n",
        "        }\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # LOG-LIKELIHOOD AND AIC\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def calculate_loglik_aic(\n",
        "        self,\n",
        "        y: np.ndarray,\n",
        "        v: np.ndarray,\n",
        "        tau2: float,\n",
        "        match_r: bool = False\n",
        "    ) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Calculate log-likelihood and AIC for 2-level model.\n",
        "\n",
        "        MATH PRESERVED: Original REML log-likelihood\n",
        "\n",
        "        Args:\n",
        "            y: Effect sizes\n",
        "            v: Variances\n",
        "            tau2: Between-study variance\n",
        "            match_r: Add constant term for R compatibility\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (log_likelihood, aic)\n",
        "        \"\"\"\n",
        "        k = len(y)\n",
        "        w = 1 / (v + tau2)\n",
        "        sum_w = np.sum(w)\n",
        "        mu = np.sum(w * y) / sum_w\n",
        "\n",
        "        # REML log-likelihood\n",
        "        resid_sq = np.sum(w * (y - mu)**2)\n",
        "        ll = -0.5 * (\n",
        "            np.sum(np.log(v + tau2)) +\n",
        "            np.log(sum_w) +\n",
        "            resid_sq\n",
        "        )\n",
        "\n",
        "        # Add constant term for R compatibility\n",
        "        if match_r:\n",
        "            ll += -0.5 * k * np.log(2 * np.pi)\n",
        "\n",
        "        # AIC: 2*k - 2*LL, where k=2 (mu, tau2)\n",
        "        aic = 4 - 2 * ll\n",
        "\n",
        "        return ll, aic\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# THREE-LEVEL RANDOM-EFFECTS ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "class ThreeLevelEngine:\n",
        "    \"\"\"\n",
        "    Three-level random-effects meta-analysis with robust matrix support.\n",
        "\n",
        "    Mathematical implementation validated: Handles VCV matrices and\n",
        "    nested data structures.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize engine\"\"\"\n",
        "        pass\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN OPTIMIZATION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        effect_col: str,\n",
        "        var_col: str,\n",
        "        vcv_dict: Dict[Any, np.ndarray]\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Fit three-level random-effects model using REML.\n",
        "\n",
        "        MATH PRESERVED: Your complete 3-level optimizer with matrix support\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame with effect sizes (must have 'id' column)\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name\n",
        "            vcv_dict: Dictionary of VCV matrices by study ID\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with results or None if optimization fails\n",
        "        \"\"\"\n",
        "        # 1. CRITICAL: Sort to ensure alignment with VCV construction order\n",
        "        df = df.sort_values('id').reset_index(drop=True)\n",
        "\n",
        "        grouped = df.groupby('id', sort=False)\n",
        "        y_all = [g[effect_col].values for _, g in grouped]\n",
        "\n",
        "        # --- VCV MATRIX PREPARATION ---\n",
        "        vcv_all = []\n",
        "\n",
        "        for study_id, group in grouped:\n",
        "            # Robust Key Lookup (String vs Int)\n",
        "            sid_str = str(study_id)\n",
        "\n",
        "            if sid_str in vcv_dict:\n",
        "                vcv_all.append(vcv_dict[sid_str])\n",
        "            elif study_id in vcv_dict:\n",
        "                vcv_all.append(vcv_dict[study_id])\n",
        "            else:\n",
        "                # Fallback: Create diagonal matrix\n",
        "                vi = group[var_col].values\n",
        "                # Validation: ensure non-empty and no NaN\n",
        "                if len(vi) == 0 or np.any(np.isnan(vi)):\n",
        "                    raise ValueError(f\"Invalid variance data for study {study_id}\")\n",
        "                vcv_all.append(np.diag(vi))\n",
        "\n",
        "        # Validation check\n",
        "        if len(y_all) != len(vcv_all):\n",
        "            raise ValueError(\n",
        "                f\"Data mismatch: {len(y_all)} effects vs {len(vcv_all)} matrices\"\n",
        "            )\n",
        "\n",
        "        N, M = len(df), len(y_all)\n",
        "\n",
        "        # Internal Likelihood Function (Closure captures y_all, vcv_all)\n",
        "        def nll(params):\n",
        "            \"\"\"Negative log-likelihood for REML\"\"\"\n",
        "            tau2, sigma2 = params\n",
        "            if tau2 < 0 or sigma2 < 0:\n",
        "                return 1e10\n",
        "\n",
        "            ll = 0\n",
        "            sum_S = 0\n",
        "            sum_Sy = 0\n",
        "            sum_ySy = 0\n",
        "\n",
        "            for i in range(M):\n",
        "                y = y_all[i]\n",
        "                V_i = vcv_all[i]\n",
        "                k = len(y)\n",
        "\n",
        "                # Check if diagonal (efficiency optimization)\n",
        "                is_diag = (k == 1) or np.allclose(V_i, np.diag(np.diag(V_i)))\n",
        "\n",
        "                if is_diag:\n",
        "                    # Sherman-Morrison Path (faster for diagonal)\n",
        "                    v = np.diag(V_i) if k > 1 else np.array([V_i[0, 0]])\n",
        "                    A_inv = 1.0 / (v + sigma2)\n",
        "                    sum_A_inv = np.sum(A_inv)\n",
        "                    denom = 1 + tau2 * sum_A_inv\n",
        "\n",
        "                    ll += np.sum(np.log(v + sigma2)) + np.log(denom)\n",
        "\n",
        "                    w_y = A_inv * y - (tau2 * A_inv * np.sum(A_inv * y)) / denom\n",
        "                    w_1 = A_inv - (tau2 * A_inv * sum_A_inv) / denom\n",
        "\n",
        "                    sum_S += np.sum(w_1)\n",
        "                    sum_Sy += np.sum(w_y)\n",
        "                    sum_ySy += np.dot(y, w_y)\n",
        "                else:\n",
        "                    # Matrix Path (full covariance)\n",
        "                    Sigma_i = V_i.copy()\n",
        "                    np.fill_diagonal(Sigma_i, np.diag(Sigma_i) + sigma2)\n",
        "                    Sigma_i += tau2\n",
        "\n",
        "                    try:\n",
        "                        # Cholesky for stability\n",
        "                        L = np.linalg.cholesky(Sigma_i)\n",
        "                        A_inv_mat = np.linalg.inv(Sigma_i)\n",
        "                        log_det = 2 * np.sum(np.log(np.diag(L)))\n",
        "                    except np.linalg.LinAlgError:\n",
        "                        A_inv_mat = np.linalg.pinv(Sigma_i)\n",
        "                        _, log_det = np.linalg.slogdet(Sigma_i)\n",
        "\n",
        "                    ones = np.ones(k)\n",
        "                    w_1_vec = np.dot(A_inv_mat, ones)\n",
        "                    w_y_vec = np.dot(A_inv_mat, y)\n",
        "\n",
        "                    ll += log_det\n",
        "                    sum_S += np.sum(w_1_vec)\n",
        "                    sum_Sy += np.sum(w_y_vec)\n",
        "                    sum_ySy += np.dot(y, w_y_vec)\n",
        "\n",
        "            mu = sum_Sy / sum_S\n",
        "            resid = sum_ySy - 2*mu*sum_Sy + mu**2 * sum_S\n",
        "            return 0.5 * (ll + np.log(sum_S) + resid)\n",
        "\n",
        "        # 2. Optimization Strategy (Multi-Start)\n",
        "        start_points = [\n",
        "            [0.01, 0.01], [0.1, 0.1], [0.5, 0.5],\n",
        "            [1.0, 1.0], [1.0, 0.1], [0.1, 1.0]\n",
        "        ]\n",
        "\n",
        "        best_res = None\n",
        "        best_fun = np.inf\n",
        "\n",
        "        for start in start_points:\n",
        "            try:\n",
        "                res = minimize(\n",
        "                    nll, start,\n",
        "                    bounds=[(1e-8, None)]*2,\n",
        "                    method='L-BFGS-B',\n",
        "                    options={'ftol': 1e-11}\n",
        "                )\n",
        "                if res.success and res.fun < best_fun:\n",
        "                    best_fun = res.fun\n",
        "                    best_res = res\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if not best_res:\n",
        "            return None\n",
        "\n",
        "        tau2, sigma2 = best_res.x\n",
        "        nll_val = best_res.fun\n",
        "        log_lik = -nll_val\n",
        "        aic = 6 - 2*log_lik  # 3 parameters: mu, tau2, sigma2\n",
        "\n",
        "        # Recalculate weights at optimum\n",
        "        sum_S = 0\n",
        "        sum_Sy = 0\n",
        "\n",
        "        for i in range(M):\n",
        "            y = y_all[i]\n",
        "            V_i = vcv_all[i]\n",
        "            k = len(y)\n",
        "            is_diag = (k == 1) or np.allclose(V_i, np.diag(np.diag(V_i)))\n",
        "\n",
        "            if is_diag:\n",
        "                v = np.diag(V_i) if k > 1 else np.array([V_i[0, 0]])\n",
        "                A_inv = 1.0 / (v + sigma2)\n",
        "                denom = 1 + tau2 * np.sum(A_inv)\n",
        "                w_y = A_inv * y - (tau2 * A_inv * np.sum(A_inv * y)) / denom\n",
        "                w_1 = A_inv - (tau2 * A_inv * np.sum(A_inv)) / denom\n",
        "                sum_S += np.sum(w_1)\n",
        "                sum_Sy += np.sum(w_y)\n",
        "            else:\n",
        "                Sigma_i = V_i.copy()\n",
        "                np.fill_diagonal(Sigma_i, np.diag(Sigma_i) + sigma2)\n",
        "                Sigma_i += tau2\n",
        "                try:\n",
        "                    A_inv_mat = np.linalg.inv(Sigma_i)\n",
        "                except:\n",
        "                    A_inv_mat = np.linalg.pinv(Sigma_i)\n",
        "                sum_S += np.sum(np.dot(A_inv_mat, np.ones(k)))\n",
        "                sum_Sy += np.sum(np.dot(A_inv_mat, y))\n",
        "\n",
        "        mu = sum_Sy / sum_S\n",
        "        se = np.sqrt(1.0 / sum_S)\n",
        "\n",
        "        # Calculate ICC\n",
        "        total_var = tau2 + sigma2\n",
        "        icc_l3 = (tau2 / total_var * 100) if total_var > 0 else 0\n",
        "        icc_l2 = (sigma2 / total_var * 100) if total_var > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'mu': mu,\n",
        "            'se': se,\n",
        "            'tau2': tau2,\n",
        "            'sigma2': sigma2,\n",
        "            'icc_l3': icc_l3,\n",
        "            'icc_l2': icc_l2,\n",
        "            'n': N,\n",
        "            'm': M,\n",
        "            'aic': aic,\n",
        "            'log_lik_reml': log_lik\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# OVERALL META-ANALYSIS ORCHESTRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class OverallEngine:\n",
        "    \"\"\"\n",
        "    High-level orchestrator for overall meta-analysis.\n",
        "    Coordinates fixed-effect, 2-level, and 3-level analyses.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_manager: 'OverallDataManager'):\n",
        "        \"\"\"\n",
        "        Initialize engine with data manager.\n",
        "\n",
        "        Args:\n",
        "            data_manager: OverallDataManager instance\n",
        "        \"\"\"\n",
        "        self.data_manager = data_manager\n",
        "        self.fixed_engine = FixedEffectEngine()\n",
        "        self.het_engine = HeterogeneityEngine()\n",
        "        self.two_level_engine = None  # Initialized with tau_method\n",
        "        self.three_level_engine = ThreeLevelEngine()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(\n",
        "        self,\n",
        "        alpha: float = 0.05,\n",
        "        dist_type: str = 't',\n",
        "        use_kh: bool = True,\n",
        "        tau_method: str = 'REML',\n",
        "        model_choice: str = 'Auto-Select (Best AIC)',\n",
        "        match_r_ll: bool = False,\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> Optional['OverallResult']:\n",
        "        \"\"\"\n",
        "        Execute complete overall meta-analysis workflow.\n",
        "\n",
        "        WORKFLOW:\n",
        "        1. Prepare data\n",
        "        2. Fixed-effect analysis\n",
        "        3. Heterogeneity statistics\n",
        "        4. 2-level random-effects\n",
        "        5. 3-level random-effects (if feasible)\n",
        "        6. Model selection\n",
        "\n",
        "        Args:\n",
        "            alpha: Significance level\n",
        "            dist_type: 't' or 'norm'\n",
        "            use_kh: Use Knapp-Hartung correction\n",
        "            tau_method: 'REML', 'DL', or 'ML'\n",
        "            model_choice: Model selection strategy\n",
        "            match_r_ll: Add constant term for R compatibility\n",
        "            progress_callback: Optional progress updates\n",
        "\n",
        "        Returns:\n",
        "            OverallResult object or None if analysis fails\n",
        "        \"\"\"\n",
        "        # Prepare data\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udcca Preparing data...\")\n",
        "\n",
        "        try:\n",
        "            df = self.data_manager.prepare_data()\n",
        "        except ValueError as e:\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"\u274c Data preparation failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        y = df[self.data_manager.effect_col].values\n",
        "        v = df[self.data_manager.var_col].values\n",
        "        k_obs = len(df)\n",
        "        k_studies = df['id'].nunique() if 'id' in df.columns else k_obs\n",
        "\n",
        "        # Step 1: Fixed-Effect Analysis\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udd22 Running fixed-effect analysis...\")\n",
        "\n",
        "        fe_results = self.fixed_engine.calculate(y, v, alpha, dist_type)\n",
        "\n",
        "        # Step 2: Heterogeneity Statistics\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udcca Calculating heterogeneity...\")\n",
        "\n",
        "        Q, df_Q, p_Q = self.het_engine.calculate_Q_statistics(y, v, fe_results['mu'])\n",
        "        I2 = self.het_engine.calculate_I2(Q, df_Q)\n",
        "\n",
        "        # Step 3: 2-Level Random-Effects\n",
        "        if progress_callback:\n",
        "            progress_callback(f\"\ud83c\udfb2 Running 2-level RE ({tau_method})...\")\n",
        "\n",
        "        # Initialize 2-level engine with chosen method\n",
        "        self.two_level_engine = TwoLevelEngine(tau_method=tau_method)\n",
        "\n",
        "        tau2 = self.two_level_engine.estimate_tau2(\n",
        "            df, self.data_manager.effect_col, self.data_manager.var_col\n",
        "        )\n",
        "\n",
        "        re_results = self.two_level_engine.calculate_pooled_effect(\n",
        "            y, v, tau2, alpha, dist_type, use_kh\n",
        "        )\n",
        "\n",
        "        ll_2l, aic_2l = self.two_level_engine.calculate_loglik_aic(\n",
        "            y, v, tau2, match_r_ll\n",
        "        )\n",
        "\n",
        "        # Step 4: 3-Level Random-Effects (if feasible)\n",
        "        has_3level = False\n",
        "        three_level_results = None\n",
        "\n",
        "        if self.data_manager.check_3level_feasibility(df):\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\ud83d\udd04 Running 3-level RE (nested)...\")\n",
        "\n",
        "            try:\n",
        "                three_level_results = self.three_level_engine.fit(\n",
        "                    df,\n",
        "                    self.data_manager.effect_col,\n",
        "                    self.data_manager.var_col,\n",
        "                    self.data_manager.vcv_matrices\n",
        "                )\n",
        "\n",
        "                if three_level_results:\n",
        "                    has_3level = True\n",
        "\n",
        "                    # Add R constant if needed\n",
        "                    if match_r_ll:\n",
        "                        const_term = -0.5 * k_obs * np.log(2 * np.pi)\n",
        "                        three_level_results['log_lik_reml'] += const_term\n",
        "                        three_level_results['aic'] = 6 - 2 * three_level_results['log_lik_reml']\n",
        "\n",
        "                    # Calculate CIs for 3-level\n",
        "                    mu_3l = three_level_results['mu']\n",
        "                    se_3l = three_level_results['se']\n",
        "                    df_3l = k_studies - 1\n",
        "\n",
        "                    q = 1 - (alpha / 2)\n",
        "                    if dist_type == 't':\n",
        "                        crit_val = t.ppf(q, df_3l)\n",
        "                        p_3l = 2 * (1 - t.cdf(abs(mu_3l / se_3l), df_3l))\n",
        "                    else:\n",
        "                        crit_val = norm.ppf(q)\n",
        "                        p_3l = 2 * (1 - norm.cdf(abs(mu_3l / se_3l)))\n",
        "\n",
        "                    three_level_results['ci_lower'] = mu_3l - crit_val * se_3l\n",
        "                    three_level_results['ci_upper'] = mu_3l + crit_val * se_3l\n",
        "                    three_level_results['p_value'] = p_3l\n",
        "\n",
        "            except Exception as e:\n",
        "                if progress_callback:\n",
        "                    progress_callback(f\"\u26a0\ufe0f 3-level fitting failed: {str(e)}\")\n",
        "\n",
        "        # Step 5: Model Selection\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83c\udfc6 Selecting best model...\")\n",
        "\n",
        "        best_model = self._select_model(\n",
        "            model_choice, aic_2l,\n",
        "            three_level_results['aic'] if has_3level else None\n",
        "        )\n",
        "\n",
        "        # Build result object\n",
        "        result = OverallResult(\n",
        "            # Fixed-effect\n",
        "            mu_fixed=fe_results['mu'],\n",
        "            se_fixed=fe_results['se'],\n",
        "            ci_lower_fixed=fe_results['ci_lower'],\n",
        "            ci_upper_fixed=fe_results['ci_upper'],\n",
        "\n",
        "            # 2-level random-effects\n",
        "            mu_random=re_results['mu'],\n",
        "            se_random=re_results['se'],\n",
        "            ci_lower_random=re_results['ci_lower'],\n",
        "            ci_upper_random=re_results['ci_upper'],\n",
        "            p_value_random=re_results['p_value'],\n",
        "\n",
        "            # Heterogeneity\n",
        "            Q=Q,\n",
        "            df_Q=df_Q,\n",
        "            p_Q=p_Q,\n",
        "            I2=I2,\n",
        "            tau_squared=tau2,\n",
        "\n",
        "            # Sample size\n",
        "            k_obs=k_obs,\n",
        "            k_studies=k_studies,\n",
        "\n",
        "            # Model info\n",
        "            tau_method=tau_method,\n",
        "            use_kh=use_kh,\n",
        "            dist_type=dist_type,\n",
        "            alpha=alpha,\n",
        "\n",
        "            # 2-level AIC\n",
        "            aic_2level=aic_2l,\n",
        "            ll_2level=ll_2l,\n",
        "\n",
        "            # Model selection\n",
        "            best_model=best_model\n",
        "        )\n",
        "\n",
        "        # Add 3-level results if available\n",
        "        if has_3level:\n",
        "            result.has_3level = True\n",
        "            result.mu_3level = three_level_results['mu']\n",
        "            result.se_3level = three_level_results['se']\n",
        "            result.ci_lower_3level = three_level_results['ci_lower']\n",
        "            result.ci_upper_3level = three_level_results['ci_upper']\n",
        "            result.p_value_3level = three_level_results['p_value']\n",
        "            result.tau_squared_3level = three_level_results['tau2']\n",
        "            result.sigma_squared_3level = three_level_results['sigma2']\n",
        "            result.icc_l3 = three_level_results['icc_l3']\n",
        "            result.icc_l2 = three_level_results['icc_l2']\n",
        "            result.aic_3level = three_level_results['aic']\n",
        "            result.ll_3level = three_level_results['log_lik_reml']\n",
        "\n",
        "        if progress_callback:\n",
        "            sig = \"***\" if result.p_value_random < 0.001 else \"**\" if result.p_value_random < 0.01 else \"*\" if result.p_value_random < 0.05 else \"ns\"\n",
        "            progress_callback(f\"\u2705 {best_model}: \u03bc = {result.mu_random:.3f} {sig}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MODEL SELECTION HELPER\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _select_model(\n",
        "        self,\n",
        "        model_choice: str,\n",
        "        aic_2l: float,\n",
        "        aic_3l: Optional[float]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Select best model based on user choice and AIC.\n",
        "\n",
        "        Args:\n",
        "            model_choice: User's model selection choice\n",
        "            aic_2l: 2-level AIC\n",
        "            aic_3l: 3-level AIC (None if not fitted)\n",
        "\n",
        "        Returns:\n",
        "            \"2-Level\" or \"3-Level\"\n",
        "        \"\"\"\n",
        "        if model_choice == 'Force 2-Level':\n",
        "            return \"2-Level\"\n",
        "\n",
        "        if model_choice == 'Force 3-Level':\n",
        "            return \"3-Level\" if aic_3l is not None else \"2-Level\"\n",
        "\n",
        "        # Auto-select based on AIC\n",
        "        if aic_3l is None:\n",
        "            return \"2-Level\"\n",
        "\n",
        "        # Prefer 3-level if AIC is at least 2 units better\n",
        "        if aic_3l < aic_2l - 2:\n",
        "            return \"3-Level\"\n",
        "\n",
        "        return \"2-Level\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Overall Meta-Analysis Analysis Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - FixedEffectEngine\")\n",
        "    print(\"   - HeterogeneityEngine\")\n",
        "    print(\"   - TwoLevelEngine (REML/DL/ML)\")\n",
        "    print(\"   - ThreeLevelEngine (robust matrix optimizer)\")\n",
        "    print(\"   - OverallEngine (main orchestrator)\")\n",
        "\n",
        "#@title \ud83d\udcca 7. Overall Meta-Analysis: PRESENTATION LAYER (View) - PART 1\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 3/4: PRESENTATION LAYER - OVERALL META-ANALYSIS\n",
        "# Purpose: Pure UI rendering without business logic\n",
        "# Dependencies: Data & Analysis Layers\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Any, Optional\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import sys\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HTML TEMPLATE GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class OverallHTMLTemplates:\n",
        "    \"\"\"\n",
        "    Static HTML template generators for overall meta-analysis visualizations.\n",
        "    All methods are pure functions returning HTML strings.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def gradient_card(\n",
        "        value: str,\n",
        "        subtitle: str = \"\",\n",
        "        gradient: str = \"linear-gradient(135deg, #667eea 0%, #764ba2 100%)\"\n",
        "    ) -> str:\n",
        "        \"\"\"Generate gradient card for highlighting pooled effect\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background: {gradient}; padding: 30px; border-radius: 10px; color: white;\n",
        "                    margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>\n",
        "            <h1 style='margin: 0; font-size: 3.5em; text-align: center; font-weight: 700;'>{value}</h1>\n",
        "            <p style='margin: 5px 0 0 0; text-align: center; font-size: 1.2em; opacity: 0.9;'>{subtitle}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def info_grid(items: list) -> str:\n",
        "        \"\"\"\n",
        "        Generate 2-column grid of info boxes.\n",
        "\n",
        "        Args:\n",
        "            items: List of dicts with 'label', 'value', and 'color' keys\n",
        "        \"\"\"\n",
        "        html = \"<div style='display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 20px;'>\"\n",
        "\n",
        "        for item in items:\n",
        "            color = item.get('color', '#007bff')\n",
        "            html += f\"\"\"\n",
        "            <div style='background-color: #f8f9fa; padding: 20px; border-radius: 8px;\n",
        "                        border-left: 5px solid {color}; box-shadow: 0 2px 4px rgba(0,0,0,0.05);'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em; text-transform: uppercase;\n",
        "                            letter-spacing: 1px;'>{item['label']}</div>\n",
        "                <div style='font-size: 1.6em; font-weight: bold; color: #2c3e50;'>{item['value']}</div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"</div>\"\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def model_note(model_desc: str, k_obs: int, k_studies: int) -> str:\n",
        "        \"\"\"Generate model description note\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px;\n",
        "                    color: #004085; font-size: 0.95em;'>\n",
        "            <p style='margin: 0;'><b>\u2139\ufe0f Model Note:</b> {model_desc}\n",
        "            (k = {k_obs} observations from {k_studies} studies)</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def heterogeneity_badge(I2: float) -> Tuple[str, str, str]:\n",
        "        \"\"\"\n",
        "        Get heterogeneity color, label, and description.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (color, label, description)\n",
        "        \"\"\"\n",
        "        if I2 > 75:\n",
        "            return \"#dc3545\", \"High\", \"considerable\"\n",
        "        elif I2 > 50:\n",
        "            return \"#ffc107\", \"Substantial\", \"substantial\"\n",
        "        elif I2 > 25:\n",
        "            return \"#28a745\", \"Moderate\", \"moderate\"\n",
        "        else:\n",
        "            return \"#28a745\", \"Low\", \"low\"\n",
        "\n",
        "    @staticmethod\n",
        "    def heterogeneity_display(I2: float, color: str, label: str) -> str:\n",
        "        \"\"\"Generate heterogeneity display card\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='display: flex; align-items: center; gap: 20px; margin-bottom: 25px;'>\n",
        "            <div style='background-color: {color}; padding: 20px; border-radius: 10px;\n",
        "                        color: white; min-width: 150px; text-align: center;\n",
        "                        box-shadow: 0 4px 6px rgba(0,0,0,0.1);'>\n",
        "                <h1 style='margin: 0; font-size: 2.5em;'>{I2:.1f}%</h1>\n",
        "                <p style='margin: 5px 0 0 0;'>I\u00b2 Statistic</p>\n",
        "            </div>\n",
        "            <div style='font-size: 1.1em; color: #555;'>\n",
        "                The data shows <b>{label.lower()}</b> heterogeneity.<br>\n",
        "                <span style='font-size: 0.9em; color: #888;'>This suggests that {I2:.1f}% of the\n",
        "                variance is due to real differences between studies, not just sampling error.</span>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def heterogeneity_table(\n",
        "        Q: float,\n",
        "        df_Q: int,\n",
        "        p_Q: float,\n",
        "        I2: float,\n",
        "        tau2: float,\n",
        "        tau_method: str,\n",
        "        het_label: str\n",
        "    ) -> str:\n",
        "        \"\"\"Generate heterogeneity statistics table\"\"\"\n",
        "        return f\"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse; border: 1px solid #dee2e6;'>\n",
        "            <thead style='background-color: #f1f3f5;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left; border-bottom: 2px solid #dee2e6;'>Statistic</th>\n",
        "                    <th style='padding: 12px; text-align: left; border-bottom: 2px solid #dee2e6;'>Value</th>\n",
        "                    <th style='padding: 12px; text-align: left; border-bottom: 2px solid #dee2e6;'>Interpretation</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'><b>Q-statistic</b></td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>{Q:.2f} (df = {df_Q})</td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>p = {p_Q:.4g} (Signif. if < 0.05)</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'><b>I\u00b2 (Inconsistency)</b></td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>{I2:.1f}%</td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>{het_label} Heterogeneity</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'><b>\u03c4\u00b2 (Between-Study Variance)</b></td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>{tau2:.4f}</td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>Estimated via {tau_method}</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def model_comparison_table(\n",
        "        mu_fe: float,\n",
        "        ci_lo_fe: float,\n",
        "        ci_hi_fe: float,\n",
        "        mu_re: float,\n",
        "        ci_lo_re: float,\n",
        "        ci_hi_re: float,\n",
        "        aic_2l: float,\n",
        "        mu_3l: Optional[float],\n",
        "        ci_lo_3l: Optional[float],\n",
        "        ci_hi_3l: Optional[float],\n",
        "        aic_3l: Optional[float],\n",
        "        best_model: str,\n",
        "        ci_pct: float\n",
        "    ) -> str:\n",
        "        \"\"\"Generate model comparison table\"\"\"\n",
        "        c_2l = \"#d4edda\" if best_model == \"2-Level\" else \"#fff\"\n",
        "        c_3l = \"#d4edda\" if best_model == \"3-Level\" else \"#fff\"\n",
        "        b_2l = \"\ud83c\udfc6 Best Fit\" if best_model == \"2-Level\" else \"\"\n",
        "        b_3l = \"\ud83c\udfc6 Best Fit\" if best_model == \"3-Level\" else \"\"\n",
        "\n",
        "        aic_3l_disp = f\"{aic_3l:.1f}\" if aic_3l is not None else \"N/A\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse; box-shadow: 0 2px 10px rgba(0,0,0,0.05);\n",
        "                      margin-bottom:30px;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left;'>Model</th>\n",
        "                    <th style='padding: 12px; text-align: center;'>Pooled Effect [{ci_pct:.0f}% CI]</th>\n",
        "                    <th style='padding: 12px; text-align: center;'>AIC</th>\n",
        "                    <th style='padding: 12px; text-align: center;'>Verdict</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: #f8f9fa; color: #6c757d;'>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>\n",
        "                        <i>Fixed-Effect (Baseline)</i>\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>\n",
        "                        {mu_fe:.3f} [{ci_lo_fe:.3f}, {ci_hi_fe:.3f}]\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>-</td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;\n",
        "                                font-size: 0.9em;'>\n",
        "                        <i>Assumes I\u00b2=0</i>\n",
        "                    </td>\n",
        "                </tr>\n",
        "                <tr style='background-color: {c_2l};'>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>\n",
        "                        <b>2-Level Random-Effects</b>\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>\n",
        "                        {mu_re:.3f} [{ci_lo_re:.3f}, {ci_hi_re:.3f}]\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>\n",
        "                        <b>{aic_2l:.1f}</b>\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>\n",
        "                        {b_2l}\n",
        "                    </td>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        if mu_3l is not None:\n",
        "            html += f\"\"\"\n",
        "                <tr style='background-color: {c_3l};'>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6;'>\n",
        "                        <b>3-Level REML (Nested)</b>\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>\n",
        "                        {mu_3l:.3f} [{ci_lo_3l:.3f}, {ci_hi_3l:.3f}]\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>\n",
        "                        <b>{aic_3l_disp}</b>\n",
        "                    </td>\n",
        "                    <td style='padding: 12px; border-bottom: 1px solid #dee2e6; text-align: center;'>\n",
        "                        {b_3l}\n",
        "                    </td>\n",
        "                </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def settings_info_box(\n",
        "        effect_col: str,\n",
        "        var_col: str,\n",
        "        k_obs: int,\n",
        "        k_studies: int\n",
        "    ) -> str:\n",
        "        \"\"\"Generate settings information box\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;\n",
        "                    margin-top: 20px; border: 1px solid #dee2e6;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Current Data Configuration:</h4>\n",
        "            <ul style='margin-bottom: 0; padding-left: 20px;'>\n",
        "                <li><b>Effect Size Column:</b> <code>{effect_col}</code></li>\n",
        "                <li><b>Variance Column:</b> <code>{var_col}</code></li>\n",
        "                <li><b>Total Effect Sizes (k):</b> {k_obs}</li>\n",
        "                <li><b>Unique Studies:</b> {k_studies}</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PUBLICATION TEXT GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class OverallPublicationTextGenerator:\n",
        "    \"\"\"\n",
        "    Generates publication-ready text for manuscripts.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate_methods_section(\n",
        "        self,\n",
        "        es_config: Dict[str, Any],\n",
        "        use_kh: bool\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate Materials and Methods section with dynamic citations.\n",
        "\n",
        "        PRESERVED: Original citation logic\n",
        "        \"\"\"\n",
        "        # Extract settings\n",
        "        es_label = es_config.get('effect_label', 'Effect Size')\n",
        "        es_short = es_config.get('effect_label_short', 'ES')\n",
        "\n",
        "        # Define Citation Database\n",
        "        db = {\n",
        "            'hedges': \"Hedges, L. V. (1981). Distribution theory for Glass's estimator of effect size and related estimators. <i>Journal of Educational Statistics</i>, 6(2), 107-128.\",\n",
        "            'lnRR': \"Hedges, L. V., Gurevitch, J., & Curtis, P. S. (1999). The meta-analysis of response ratios in experimental ecology. <i>Ecology</i>, 80(4), 1150-1156.\",\n",
        "            'cohen': \"Cohen, J. (1988). <i>Statistical power analysis for the behavioral sciences</i> (2nd ed.). Hillsdale, NJ: Erlbaum.\",\n",
        "            'reml': \"Viechtbauer, W. (2005). Bias and efficiency of meta-analytic variance estimators in the random-effects model. <i>Journal of Educational and Behavioral Statistics</i>, 30(3), 261-293.\",\n",
        "            'i2': \"Higgins, J. P., & Thompson, S. G. (2002). Quantifying heterogeneity in a meta-analysis. <i>Statistics in Medicine</i>, 21(11), 1539-1558.\",\n",
        "            'kh': \"Knapp, G., & Hartung, J. (2003). Improved tests for a random effects meta-regression with a single covariate. <i>Statistics in Medicine</i>, 22(17), 2693-2710.\",\n",
        "            'python': \"Virtanen, P., et al. (2020). SciPy 1.0: fundamental algorithms for scientific computing in Python. <i>Nature Methods</i>, 17(3), 261-272.\",\n",
        "            'tool': \"<b>[CITATION FOR THIS TOOL]:</b> Author, A. A. (202X). <i>Co-Meta: An Interactive Pipeline for Meta-Analysis</i>. [Repository/DOI]. (Available at: https://github.com/...)\"\n",
        "        }\n",
        "\n",
        "        # Build Dynamic Reference List\n",
        "        active_refs = []\n",
        "\n",
        "        # [1] Effect Size\n",
        "        es_key = 'hedges' if 'Hedges' in es_label else 'lnRR' if 'Ratio' in es_label else 'cohen'\n",
        "        active_refs.append(db[es_key])\n",
        "        ref_es = len(active_refs)\n",
        "\n",
        "        # [2] Model Estimator\n",
        "        active_refs.append(db['reml'])\n",
        "        ref_reml = len(active_refs)\n",
        "\n",
        "        # [3] Heterogeneity\n",
        "        active_refs.append(db['i2'])\n",
        "        ref_i2 = len(active_refs)\n",
        "\n",
        "        # [4] Knapp-Hartung (Conditional)\n",
        "        ref_kh = None\n",
        "        if use_kh:\n",
        "            active_refs.append(db['kh'])\n",
        "            ref_kh = len(active_refs)\n",
        "\n",
        "        # [Next] Python\n",
        "        active_refs.append(db['python'])\n",
        "        ref_py = len(active_refs)\n",
        "\n",
        "        # [Next] This Tool\n",
        "        active_refs.append(db['tool'])\n",
        "        ref_tool = len(active_refs)\n",
        "\n",
        "        # Build HTML Text\n",
        "        html = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;\n",
        "                    border: 1px solid #eee; margin-bottom: 20px;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;\n",
        "                   margin-top: 0;'>Materials and Methods</h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Effect Size Calculation.</b> The effect size of interest was {es_label} ({es_short}).\n",
        "        Estimates were calculated using the standard formula [{ref_es}].\n",
        "        \"\"\"\n",
        "\n",
        "        if es_key == 'hedges':\n",
        "            html += \" This metric includes a correction for small sample size bias (J-correction).\"\n",
        "        elif es_key == 'lnRR':\n",
        "            html += \" Log-transformation was applied to normalize the ratio of means.\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Meta-Analytic Model.</b> To estimate the overall pooled effect, we fitted a\n",
        "        random-effects model using the Restricted Maximum Likelihood (REML) estimator [{ref_reml}].\n",
        "        This approach accounts for both within-study sampling error and between-study heterogeneity.\n",
        "        Heterogeneity was quantified using the <i>I</i>\u00b2 statistic [{ref_i2}] and tested using\n",
        "        Cochran's <i>Q</i> test.\n",
        "        \"\"\"\n",
        "\n",
        "        if use_kh:\n",
        "            html += f\" Confidence intervals and test statistics were adjusted using the Knapp-Hartung method [{ref_kh}] to reduce Type I error rates and provide more robust inference.\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Software.</b> All analyses were conducted using the Python programming language\n",
        "        (v{sys.version.split()[0]}), utilizing the SciPy library for statistical computations [{ref_py}].\n",
        "        The complete analytical pipeline was implemented using the <b>Co-Meta</b> toolkit [{ref_tool}],\n",
        "        which integrates data processing, statistical modeling, and visualization.\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 20px; font-size: 11pt;'>References</h4>\n",
        "        <ol style='font-size: 10pt; color: #555;'>\n",
        "        \"\"\"\n",
        "\n",
        "        # Print Bibliography\n",
        "        for ref in active_refs:\n",
        "            html += f\"<li>{ref}</li>\"\n",
        "\n",
        "        html += \"</ol></div>\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    def generate_results_section(\n",
        "        self,\n",
        "        result: 'OverallResult',\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate complete Results section with interpretation.\n",
        "\n",
        "        PRESERVED: Original publication text logic with AIC justification\n",
        "        \"\"\"\n",
        "        # Extract values\n",
        "        mu_p = result.mu_random if result.best_model == \"2-Level\" else result.mu_3level\n",
        "        ci_lo_p = result.ci_lower_random if result.best_model == \"2-Level\" else result.ci_lower_3level\n",
        "        ci_hi_p = result.ci_upper_random if result.best_model == \"2-Level\" else result.ci_upper_3level\n",
        "        p_p = result.p_value_random if result.best_model == \"2-Level\" else result.p_value_3level\n",
        "\n",
        "        ci_pct = (1 - result.alpha) * 100\n",
        "\n",
        "        # Effect Size Description\n",
        "        es_type = es_config.get('type', 'effect size')\n",
        "        es_map = {\n",
        "            \"Hedges' g\": \"Effect sizes were calculated as Hedges' g, a standardized mean difference corrected for small sample bias.\",\n",
        "            'lnRR': \"Effect sizes were expressed as log response ratios (lnRR), calculated as the natural logarithm of the ratio between treatment and control group means.\",\n",
        "            'SMD': \"Effect sizes were calculated as standardized mean differences (SMD).\",\n",
        "            \"Cohen's d\": \"Effect sizes were calculated as Cohen's d.\"\n",
        "        }\n",
        "        es_description = es_map.get(es_type, f\"Effect sizes were calculated as {es_type}.\")\n",
        "\n",
        "        # Significance & formatting\n",
        "        sig_text = \"significant\" if p_p < 0.05 else \"non-significant\"\n",
        "        p_format = f\"< 0.001\" if p_p < 0.001 else f\"= {p_p:.3f}\"\n",
        "\n",
        "        # Magnitude Interpretation\n",
        "        abs_mu = abs(mu_p)\n",
        "        if abs_mu < 0.2:\n",
        "            effect_interp = \"indicating a negligible effect\"\n",
        "        elif abs_mu < 0.5:\n",
        "            effect_interp = \"indicating a small effect\"\n",
        "        elif abs_mu < 0.8:\n",
        "            effect_interp = \"indicating a moderate effect\"\n",
        "        else:\n",
        "            effect_interp = \"indicating a large effect\"\n",
        "\n",
        "        # Heterogeneity Interpretation\n",
        "        if result.I2 < 25:\n",
        "            het_interp = \"indicating low heterogeneity\"\n",
        "        elif result.I2 < 50:\n",
        "            het_interp = \"indicating moderate heterogeneity\"\n",
        "        elif result.I2 < 75:\n",
        "            het_interp = \"indicating substantial heterogeneity\"\n",
        "        else:\n",
        "            het_interp = \"indicating considerable heterogeneity\"\n",
        "\n",
        "        # Build HTML Text\n",
        "        text = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>\n",
        "            Meta-Analysis Results\n",
        "        </h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        A total of <b>{result.k_obs}</b> effect sizes from <b>{result.k_studies}</b> independent\n",
        "        studies were included in the meta-analysis. {es_description}\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        \"\"\"\n",
        "\n",
        "        # Model Selection Narrative\n",
        "        if result.has_3level:\n",
        "            delta_aic = abs(result.aic_2level - result.aic_3level)\n",
        "            if result.best_model == \"3-Level\":\n",
        "                text += f\"\"\"\n",
        "                To account for the dependency structure arising from multiple effect sizes nested\n",
        "                within studies, a three-level random-effects model was compared to a standard\n",
        "                two-level model. Model selection based on the Akaike Information Criterion (AIC)\n",
        "                favored the <b>three-level model</b> (AIC = {result.aic_3level:.1f}) over the\n",
        "                two-level model (AIC = {result.aic_2level:.1f}; \u0394AIC = {delta_aic:.1f}), indicating\n",
        "                significant clustering of effects within studies.\n",
        "                \"\"\"\n",
        "            else:\n",
        "                text += f\"\"\"\n",
        "                A three-level random-effects model was initially fitted to account for potential\n",
        "                dependency of effects within studies. However, model comparison based on the Akaike\n",
        "                Information Criterion (AIC) favored the more parsimonious <b>two-level random-effects\n",
        "                model</b> (AIC = {result.aic_2level:.1f}) over the three-level model\n",
        "                (AIC = {result.aic_3level:.1f}; \u0394AIC = {delta_aic:.1f}). Consequently, results from\n",
        "                the standard two-level model are reported below.\n",
        "                \"\"\"\n",
        "        else:\n",
        "            text += \"A standard random-effects meta-analysis was conducted. \"\n",
        "\n",
        "        # Primary Results\n",
        "        text += f\"\"\"\n",
        "        The analysis revealed a <b>{sig_text}</b> overall pooled effect of <b>{mu_p:.3f}</b>\n",
        "        ({ci_pct:.0f}% CI [{ci_lo_p:.3f}, {ci_hi_p:.3f}], <i>p</i> {p_format}), {effect_interp}.\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        # Fold Change Logic\n",
        "        if es_config.get('has_fold_change', False) or es_type == 'lnRR':\n",
        "            RR = np.exp(mu_p)\n",
        "            if mu_p >= 0:\n",
        "                fold_text = f\"{RR:.2f}\u00d7 increase\"\n",
        "                pct = (RR - 1) * 100\n",
        "                pct_text = f\"{pct:.1f}% increase\"\n",
        "            else:\n",
        "                fold_text = f\"{1/RR:.2f}\u00d7 decrease\"\n",
        "                pct = (1 - RR) * 100\n",
        "                pct_text = f\"{pct:.1f}% decrease\"\n",
        "\n",
        "            text += f\"\"\"\n",
        "            <p style='text-align: justify;'>\n",
        "            Transforming the log-ratio back to the original scale, this corresponds to a\n",
        "            <b>{fold_text}</b> in the outcome variable relative to the control group\n",
        "            (equivalent to a <b>{pct_text}</b>).\n",
        "            </p>\n",
        "            \"\"\"\n",
        "\n",
        "        # Heterogeneity Paragraph\n",
        "        text += f\"\"\"\n",
        "        <p style='text-align: justify;'>\n",
        "        {het_interp.capitalize()} was observed among the effect sizes (<i>Q</i>({result.df_Q}) =\n",
        "        {result.Q:.2f}, <i>p</i> < 0.001, <i>I</i>\u00b2 = <b>{result.I2:.1f}%</b>). The between-study\n",
        "        variance (\u03c4\u00b2) was estimated at <b>{result.tau_squared:.4f}</b> using the\n",
        "        <b>{result.tau_method}</b> estimator.\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        # Variance Decomposition (Only if 3-Level Won)\n",
        "        if result.best_model == \"3-Level\" and result.has_3level:\n",
        "            text += f\"\"\"\n",
        "            <p style='text-align: justify;'>\n",
        "            Variance decomposition in the three-level model indicated that <b>{result.icc_l3:.1f}%</b>\n",
        "            of the total heterogeneity was attributable to between-study differences\n",
        "            (\u03c4\u00b2 = {result.tau_squared_3level:.4f}), while <b>{result.icc_l2:.1f}%</b> was due to\n",
        "            within-study variance (\u03c3\u00b2 = {result.sigma_squared_3level:.4f}).\n",
        "            </p>\n",
        "            \"\"\"\n",
        "\n",
        "        # Technical Footnote\n",
        "        kh_text = f\"Confidence intervals and <i>p</i>-values were adjusted using the Knapp-Hartung correction (<i>t</i>-distribution, df = {result.df_Q}).\" if result.use_kh else \"Confidence intervals were calculated using the normal distribution.\"\n",
        "\n",
        "        text += f\"\"\"\n",
        "        <p style='color: #666; font-size: 0.9em; margin-top: 10px; border-top: 1px solid #eee;\n",
        "                  padding-top: 5px;'>\n",
        "        <i>Statistical Note: {kh_text}</i>\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        # Guidance & Tips\n",
        "        text += f\"\"\"\n",
        "        <div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db;\n",
        "                    margin-top: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "            <ul style='margin-bottom: 0; font-size: 0.95em;'>\n",
        "                <li><b>AIC Selection:</b> The text above automatically selected the statistical model\n",
        "                    that fits your data best.</li>\n",
        "                <li><b>Context:</b> Add specific biological/field context to the \"small/large effect\"\n",
        "                    interpretation.</li>\n",
        "                <li><b>Sensitivity:</b> If I\u00b2 is high (>50%), consider discussing potential sources of\n",
        "                    heterogeneity (Subgroup Analysis).</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107;\n",
        "                    margin-top: 15px;'>\n",
        "            <p style='margin: 0;'><b>\ud83d\udca1 Tip:</b> You can copy this text directly into your manuscript.\n",
        "            It includes the math, the method, and the justification.</p>\n",
        "        </div>\n",
        "\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "print(\"\u2705 Overall View Layer (Part 1) Loaded Successfully\")\n",
        "\n",
        "#@title \ud83d\udcca 7. Overall Meta-Analysis: PRESENTATION LAYER (View) - PART 2\n",
        "# =============================================================================\n",
        "# VIEW COMPONENTS (Tab Renderers)\n",
        "# =============================================================================\n",
        "\n",
        "class OverallResultsView:\n",
        "    \"\"\"\n",
        "    Manages all UI rendering for overall meta-analysis.\n",
        "    Contains zero business logic - only presentation code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize view with display settings\"\"\"\n",
        "        self.templates = OverallHTMLTemplates()\n",
        "        self.text_gen = OverallPublicationTextGenerator()\n",
        "\n",
        "        # Create tab widgets\n",
        "        self.tab_main = widgets.Output()\n",
        "        self.tab_hetero = widgets.Output()\n",
        "        self.tab_compare = widgets.Output()\n",
        "        self.tab_settings = widgets.Output()\n",
        "        self.tab_publication = widgets.Output()\n",
        "        self.tab_export = widgets.Output()\n",
        "\n",
        "        self.tabs = widgets.Tab(children=[\n",
        "            self.tab_main,\n",
        "            self.tab_hetero,\n",
        "            self.tab_compare,\n",
        "            self.tab_settings,\n",
        "            self.tab_publication,\n",
        "            self.tab_export\n",
        "        ])\n",
        "\n",
        "        self.tabs.set_title(0, '\ud83d\udcca Primary Result')\n",
        "        self.tabs.set_title(1, '\ud83d\udcc9 Heterogeneity')\n",
        "        self.tabs.set_title(2, '\u2696\ufe0f Model Selection')\n",
        "        self.tabs.set_title(3, '\u2699\ufe0f Settings')\n",
        "        self.tabs.set_title(4, '\ud83d\udcdd Publication Text')\n",
        "        self.tabs.set_title(5, '\ud83d\udcbe Export')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 1: PRIMARY RESULTS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_primary_tab(\n",
        "        self,\n",
        "        result: 'OverallResult',\n",
        "        effect_col: str,\n",
        "        var_col: str\n",
        "    ) -> None:\n",
        "        \"\"\"Render primary results tab\"\"\"\n",
        "\n",
        "        with self.tab_main:\n",
        "            self.tab_main.clear_output()\n",
        "\n",
        "            # Determine which results to show (winner model)\n",
        "            if result.best_model == \"3-Level\":\n",
        "                mu_p = result.mu_3level\n",
        "                ci_lo_p = result.ci_lower_3level\n",
        "                ci_hi_p = result.ci_upper_3level\n",
        "                p_p = result.p_value_3level\n",
        "                model_label = \"3-Level REML\"\n",
        "                model_desc = \"Adjusted for within-study dependency (AIC selected).\"\n",
        "            else:\n",
        "                mu_p = result.mu_random\n",
        "                ci_lo_p = result.ci_lower_random\n",
        "                ci_hi_p = result.ci_upper_random\n",
        "                p_p = result.p_value_random\n",
        "                model_label = f\"Random-Effects ({result.tau_method})\"\n",
        "                model_desc = f\"Standard 2-Level model using {result.tau_method} estimator.\"\n",
        "\n",
        "            # Significance indicator\n",
        "            sig = \"***\" if p_p < 0.001 else \"**\" if p_p < 0.01 else \"*\" if p_p < 0.05 else \"ns\"\n",
        "            color = \"#28a745\" if p_p < 0.05 else \"#6c757d\"\n",
        "            ci_pct = (1 - result.alpha) * 100\n",
        "\n",
        "            # Header with winner badge\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h2 style='color: #2c3e50; margin-bottom: 20px;'>{model_label}\n",
        "                <span style='font-size:0.5em; background: #28a745; color: white; padding: 4px 8px;\n",
        "                            border-radius: 4px; vertical-align: middle; margin-left: 10px;'>\n",
        "                    AIC WINNER \ud83c\udfc6\n",
        "                </span>\n",
        "            </h2>\n",
        "            \"\"\"))\n",
        "\n",
        "            # Main gradient card\n",
        "            gradient_html = self.templates.gradient_card(\n",
        "                value=f\"{mu_p:.3f}\",\n",
        "                subtitle=f\"Pooled Effect Size {sig}\"\n",
        "            )\n",
        "            display(HTML(gradient_html))\n",
        "\n",
        "            # Info grid\n",
        "            info_items = [\n",
        "                {\n",
        "                    'label': f'{ci_pct:.0f}% Confidence Interval',\n",
        "                    'value': f'[{ci_lo_p:.3f}, {ci_hi_p:.3f}]',\n",
        "                    'color': '#007bff'\n",
        "                },\n",
        "                {\n",
        "                    'label': 'P-value',\n",
        "                    'value': f'{p_p:.4g}',\n",
        "                    'color': color\n",
        "                }\n",
        "            ]\n",
        "            display(HTML(self.templates.info_grid(info_items)))\n",
        "\n",
        "            # Model note\n",
        "            model_note = self.templates.model_note(model_desc, result.k_obs, result.k_studies)\n",
        "            display(HTML(model_note + \"</div>\"))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 2: HETEROGENEITY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_heterogeneity_tab(self, result: 'OverallResult') -> None:\n",
        "        \"\"\"Render heterogeneity assessment tab\"\"\"\n",
        "\n",
        "        with self.tab_hetero:\n",
        "            self.tab_hetero.clear_output()\n",
        "\n",
        "            display(HTML(\"<div style='padding: 20px;'>\"))\n",
        "            display(HTML(\"<h2 style='color: #2c3e50;'>Heterogeneity Assessment</h2>\"))\n",
        "\n",
        "            # Get heterogeneity styling\n",
        "            het_color, het_label, het_desc = self.templates.heterogeneity_badge(result.I2)\n",
        "\n",
        "            # Display heterogeneity card\n",
        "            het_display = self.templates.heterogeneity_display(result.I2, het_color, het_label)\n",
        "            display(HTML(het_display))\n",
        "\n",
        "            # Heterogeneity table\n",
        "            het_table = self.templates.heterogeneity_table(\n",
        "                result.Q, result.df_Q, result.p_Q,\n",
        "                result.I2, result.tau_squared,\n",
        "                result.tau_method, het_label\n",
        "            )\n",
        "            display(HTML(het_table))\n",
        "            display(HTML(\"</div>\"))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 3: MODEL COMPARISON\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_comparison_tab(\n",
        "        self,\n",
        "        result: 'OverallResult',\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> None:\n",
        "        \"\"\"Render model comparison tab\"\"\"\n",
        "\n",
        "        with self.tab_compare:\n",
        "            self.tab_compare.clear_output()\n",
        "\n",
        "            display(HTML(\"<div style='padding: 20px;'>\"))\n",
        "            display(HTML(\"<h3 style='color: #2c3e50;'>Model Selection</h3>\"))\n",
        "            display(HTML(\"<p style='margin-bottom: 20px;'>We compare models using <b>AIC</b> (Akaike Information Criterion). Lower is better. The \\\"Best Fit\\\" is selected automatically.</p>\"))\n",
        "\n",
        "            # Model comparison table\n",
        "            ci_pct = (1 - result.alpha) * 100\n",
        "            comparison_table = self.templates.model_comparison_table(\n",
        "                mu_fe=result.mu_fixed,\n",
        "                ci_lo_fe=result.ci_lower_fixed,\n",
        "                ci_hi_fe=result.ci_upper_fixed,\n",
        "                mu_re=result.mu_random,\n",
        "                ci_lo_re=result.ci_lower_random,\n",
        "                ci_hi_re=result.ci_upper_random,\n",
        "                aic_2l=result.aic_2level,\n",
        "                mu_3l=result.mu_3level if result.has_3level else None,\n",
        "                ci_lo_3l=result.ci_lower_3level if result.has_3level else None,\n",
        "                ci_hi_3l=result.ci_upper_3level if result.has_3level else None,\n",
        "                aic_3l=result.aic_3level if result.has_3level else None,\n",
        "                best_model=result.best_model,\n",
        "                ci_pct=ci_pct\n",
        "            )\n",
        "            display(HTML(comparison_table))\n",
        "\n",
        "            # Visual Sensitivity Plot\n",
        "            display(HTML(\"<h4 style='color:#2E86AB; margin-left:0; margin-top:0;'>\ud83d\udcc9 Visual Sensitivity Analysis</h4>\"))\n",
        "\n",
        "            self._render_sensitivity_plot(result, es_config)\n",
        "\n",
        "            display(HTML(\"</div>\"))\n",
        "\n",
        "    def _render_sensitivity_plot(\n",
        "        self,\n",
        "        result: 'OverallResult',\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> None:\n",
        "        \"\"\"Render sensitivity analysis forest plot\"\"\"\n",
        "        try:\n",
        "            import matplotlib.pyplot as plt\n",
        "\n",
        "            models = ['Fixed-Effect', f'Random ({result.tau_method})', '3-Level (Nested)']\n",
        "            means = [result.mu_fixed, result.mu_random]\n",
        "            lowers = [result.ci_lower_fixed, result.ci_lower_random]\n",
        "            uppers = [result.ci_upper_fixed, result.ci_upper_random]\n",
        "            colors = ['#95a5a6', '#95a5a6']\n",
        "\n",
        "            if result.has_3level:\n",
        "                means.append(result.mu_3level)\n",
        "                lowers.append(result.ci_lower_3level)\n",
        "                uppers.append(result.ci_upper_3level)\n",
        "                colors.append('#95a5a6')\n",
        "            else:\n",
        "                models.pop()\n",
        "\n",
        "            winner_idx = 2 if result.best_model == \"3-Level\" and result.has_3level else 1\n",
        "            colors[winner_idx] = '#28a745'\n",
        "            labels = [f\"{m}\\n{'\u2605 Winner' if i==winner_idx else ''}\" for i, m in enumerate(models)]\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(8, 3))\n",
        "            y_pos = np.arange(len(models))\n",
        "\n",
        "            for i, (m, l, u, c) in enumerate(zip(means, lowers, uppers, colors)):\n",
        "                ax.plot([l, u], [i, i], color=c, linewidth=2.5, marker='|', markersize=10)\n",
        "                ax.plot(m, i, 'o', color=c, markersize=9, markeredgecolor='white')\n",
        "                ax.text(m, i-0.25, f\"{m:.3f}\", ha='center', va='top', color=c,\n",
        "                       fontweight='bold', fontsize=9)\n",
        "\n",
        "            ax.set_yticks(y_pos)\n",
        "            ax.set_yticklabels(labels, fontsize=10, fontweight='bold')\n",
        "            ax.set_ylim(-0.5, len(models)-0.5)\n",
        "            ax.invert_yaxis()\n",
        "\n",
        "            null_val = es_config.get('null_value', 0)\n",
        "            ax.axvline(null_val, color='black', linestyle=':', alpha=0.3)\n",
        "\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.spines['left'].set_visible(False)\n",
        "            ax.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "            ax.set_xlabel(f\"Pooled Effect Size ({es_config.get('effect_label_short', 'ES')})\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        except ImportError:\n",
        "            display(HTML(\"<p style='color: #6c757d;'><i>matplotlib not available for plotting</i></p>\"))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 4: SETTINGS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_settings_tab(\n",
        "        self,\n",
        "        effect_col: str,\n",
        "        var_col: str,\n",
        "        k_obs: int,\n",
        "        k_studies: int,\n",
        "        widgets_dict: Dict[str, Any],\n",
        "        rerun_callback: callable\n",
        "    ) -> None:\n",
        "        \"\"\"Render settings configuration tab\"\"\"\n",
        "\n",
        "        with self.tab_settings:\n",
        "            self.tab_settings.clear_output()\n",
        "\n",
        "            display(HTML(\"<h3>Analysis Settings</h3>\"))\n",
        "            display(HTML(\"<p>Configure statistical corrections:</p>\"))\n",
        "\n",
        "            # Display widgets\n",
        "            display(widgets_dict['model_selector'])\n",
        "            display(widgets_dict['tau_method'])\n",
        "            display(widgets_dict['use_kh'])\n",
        "            display(widgets_dict['ci_dist'])\n",
        "            display(widgets_dict['alpha'])\n",
        "            display(widgets_dict['match_r_ll'])\n",
        "\n",
        "            # Rerun button\n",
        "            btn = widgets.Button(\n",
        "                description=\"Re-Run Analysis\",\n",
        "                button_style='primary',\n",
        "                icon='refresh'\n",
        "            )\n",
        "            btn.on_click(rerun_callback)\n",
        "            display(btn)\n",
        "\n",
        "            # Info box\n",
        "            info_box = self.templates.settings_info_box(\n",
        "                effect_col, var_col, k_obs, k_studies\n",
        "            )\n",
        "            display(HTML(info_box))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 5: PUBLICATION TEXT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_publication_tab(\n",
        "        self,\n",
        "        result: 'OverallResult',\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Render publication text tab.\n",
        "\n",
        "        Returns:\n",
        "            Combined HTML text for saving\n",
        "        \"\"\"\n",
        "        with self.tab_publication:\n",
        "            self.tab_publication.clear_output()\n",
        "\n",
        "            # Generate both sections\n",
        "            methods_html = self.text_gen.generate_methods_section(\n",
        "                es_config, result.use_kh\n",
        "            )\n",
        "            results_html = self.text_gen.generate_results_section(\n",
        "                result, es_config\n",
        "            )\n",
        "\n",
        "            # Display\n",
        "            display(HTML(methods_html))\n",
        "            display(HTML(results_html))\n",
        "\n",
        "            # Return combined for saving\n",
        "            return methods_html + \"<br><hr><br>\" + results_html\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 6: EXPORT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_export_tab(self, export_callback: callable) -> None:\n",
        "        \"\"\"Render export tab with download button\"\"\"\n",
        "\n",
        "        with self.tab_export:\n",
        "            self.tab_export.clear_output()\n",
        "\n",
        "            display(HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcbe Download Audit Report</h3>\"))\n",
        "            display(HTML(\"<p>Generate a full Excel audit trail including model settings, heterogeneity statistics, and the exclusion log.</p>\"))\n",
        "\n",
        "            btn_export = widgets.Button(\n",
        "                description=\"\ud83d\udce5 Download Overall Analysis Report\",\n",
        "                button_style='info',\n",
        "                icon='file-excel',\n",
        "                layout=widgets.Layout(width='300px', height='40px')\n",
        "            )\n",
        "\n",
        "            btn_export.on_click(export_callback)\n",
        "            display(btn_export)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR DISPLAY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_error(self, message: str, details: Optional[str] = None) -> None:\n",
        "        \"\"\"Render error message in main tab\"\"\"\n",
        "        with self.tab_main:\n",
        "            self.tab_main.clear_output()\n",
        "            error_html = f\"<div style='color: red; background-color: #f8d7da; padding: 15px; border-radius: 5px;'>\u274c {message}</div>\"\n",
        "            if details:\n",
        "                error_html += f\"<pre style='margin-top: 10px;'>{details}</pre>\"\n",
        "            display(HTML(error_html))\n",
        "\n",
        "\n",
        "print(\"\u2705 Overall View Layer (Part 2) Loaded Successfully\")\n",
        "\n",
        "#@title \ud83d\udcca 7. Overall Meta-Analysis: CONTROLLER LAYER (Orchestration)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 4/4: CONTROLLER LAYER - OVERALL META-ANALYSIS\n",
        "# Purpose: Orchestrates data, analysis, and view components\n",
        "# Dependencies: All previous layers (Data, Analysis, View)\n",
        "# =============================================================================\n",
        "\n",
        "import traceback\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN CONTROLLER\n",
        "# =============================================================================\n",
        "\n",
        "class OverallController:\n",
        "    \"\"\"\n",
        "    Master controller that orchestrates the entire overall meta-analysis workflow.\n",
        "    Coordinates data management, statistical computation, and UI rendering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize controller with ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self.analysis_config = analysis_config\n",
        "\n",
        "        # Initialize components\n",
        "        try:\n",
        "            self.data_manager = OverallDataManager(analysis_config)\n",
        "            self.engine = OverallEngine(self.data_manager)\n",
        "            self.view = OverallResultsView()\n",
        "\n",
        "            self._initialization_error = None\n",
        "\n",
        "        except Exception as e:\n",
        "            # If initialization fails, create minimal view to show error\n",
        "            self.view = OverallResultsView()\n",
        "            self.data_manager = None\n",
        "            self.engine = None\n",
        "            self._initialization_error = e\n",
        "\n",
        "        # Create settings widgets\n",
        "        self._create_settings_widgets()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # SETTINGS WIDGETS CREATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _create_settings_widgets(self) -> None:\n",
        "        \"\"\"Create all settings widgets\"\"\"\n",
        "\n",
        "        self.alpha_widget = widgets.Dropdown(\n",
        "            options=[('95% CI (\u03b1=0.05)', 0.05),\n",
        "                     ('99% CI (\u03b1=0.01)', 0.01),\n",
        "                     ('90% CI (\u03b1=0.10)', 0.10)],\n",
        "            value=0.05,\n",
        "            description='Confidence Level:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        self.model_selector = widgets.Dropdown(\n",
        "            options=['Auto-Select (Best AIC)', 'Force 2-Level', 'Force 3-Level'],\n",
        "            value='Auto-Select (Best AIC)',\n",
        "            description='Model Selection:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        self.tau_method_widget = widgets.Dropdown(\n",
        "            options=['REML', 'DL', 'ML'],\n",
        "            value='REML',\n",
        "            description='\u03c4\u00b2 Method:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        self.use_kh_widget = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Knapp-Hartung Correction'\n",
        "        )\n",
        "\n",
        "        self.ci_dist_widget = widgets.Dropdown(\n",
        "            options=[('t-distribution (Robust/Small Sample)', 't'),\n",
        "                     ('Normal distribution (z) (Match R)', 'norm')],\n",
        "            value='t',\n",
        "            description='Inference:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        self.match_r_ll_widget = widgets.Checkbox(\n",
        "            value=False,\n",
        "            description='Use Full Log-Likelihood'\n",
        "        )\n",
        "\n",
        "        # Attach observers\n",
        "        self.alpha_widget.observe(self._handle_settings_change, 'value')\n",
        "        self.model_selector.observe(self._handle_settings_change, 'value')\n",
        "        self.tau_method_widget.observe(self._handle_settings_change, 'value')\n",
        "        self.use_kh_widget.observe(self._handle_settings_change, 'value')\n",
        "        self.ci_dist_widget.observe(self._handle_settings_change, 'value')\n",
        "        self.match_r_ll_widget.observe(self._handle_settings_change, 'value')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(self) -> None:\n",
        "        \"\"\"\n",
        "        Execute complete overall meta-analysis workflow.\n",
        "        \"\"\"\n",
        "        # Clear all tabs\n",
        "        for tab in [self.view.tab_main, self.view.tab_hetero, self.view.tab_compare,\n",
        "                    self.view.tab_settings, self.view.tab_publication]:\n",
        "            tab.clear_output()\n",
        "\n",
        "        # Check for initialization errors\n",
        "        if self._initialization_error:\n",
        "            self._handle_initialization_error()\n",
        "            return\n",
        "\n",
        "        # Validate ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            self.view.render_error(\"ANALYSIS_CONFIG not found. Run Step 1 first.\")\n",
        "            return\n",
        "\n",
        "        # Get settings from widgets\n",
        "        alpha = self.alpha_widget.value\n",
        "        dist_type = self.ci_dist_widget.value\n",
        "        use_kh = self.use_kh_widget.value\n",
        "        tau_method = self.tau_method_widget.value\n",
        "        model_choice = self.model_selector.value\n",
        "        match_r_ll = self.match_r_ll_widget.value\n",
        "\n",
        "        # Save settings to global config\n",
        "        self.data_manager.save_global_settings(\n",
        "            alpha, dist_type, tau_method, use_kh, model_choice\n",
        "        )\n",
        "\n",
        "        # Progress callback\n",
        "        def progress_callback(message: str):\n",
        "            \"\"\"Callback for progress updates\"\"\"\n",
        "            with self.view.tab_results:\n",
        "                clear_output(wait=True)\n",
        "                print(message)\n",
        "\n",
        "        try:\n",
        "            # Execute analysis engine\n",
        "            result = self.engine.run_analysis(\n",
        "                alpha=alpha,\n",
        "                dist_type=dist_type,\n",
        "                use_kh=use_kh,\n",
        "                tau_method=tau_method,\n",
        "                model_choice=model_choice,\n",
        "                match_r_ll=match_r_ll,\n",
        "                progress_callback=progress_callback\n",
        "            )\n",
        "\n",
        "            if result is None:\n",
        "                self.view.render_error(\n",
        "                    \"Analysis failed\",\n",
        "                    \"Unable to compute meta-analysis. Check your data.\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # Render all tabs\n",
        "            self._render_all_tabs(result)\n",
        "\n",
        "            # Save results\n",
        "            self._save_results(result)\n",
        "\n",
        "        except ValueError as e:\n",
        "            self.view.render_error(\"Data Error\", str(e))\n",
        "        except RuntimeError as e:\n",
        "            self.view.render_error(\"Runtime Error\", str(e))\n",
        "        except Exception as e:\n",
        "            self._handle_unexpected_error(e)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB RENDERING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _render_all_tabs(self, result: 'OverallResult') -> None:\n",
        "        \"\"\"\n",
        "        Render all tabs with results.\n",
        "\n",
        "        Args:\n",
        "            result: OverallResult object\n",
        "        \"\"\"\n",
        "        # Tab 1: Primary Results\n",
        "        self.view.render_primary_tab(\n",
        "            result,\n",
        "            self.data_manager.effect_col,\n",
        "            self.data_manager.var_col\n",
        "        )\n",
        "\n",
        "        # Tab 2: Heterogeneity\n",
        "        self.view.render_heterogeneity_tab(result)\n",
        "\n",
        "        # Tab 3: Model Comparison\n",
        "        self.view.render_comparison_tab(\n",
        "            result,\n",
        "            self.data_manager.es_config\n",
        "        )\n",
        "\n",
        "        # Tab 4: Settings\n",
        "        widgets_dict = {\n",
        "            'model_selector': self.model_selector,\n",
        "            'tau_method': self.tau_method_widget,\n",
        "            'use_kh': self.use_kh_widget,\n",
        "            'ci_dist': self.ci_dist_widget,\n",
        "            'alpha': self.alpha_widget,\n",
        "            'match_r_ll': self.match_r_ll_widget\n",
        "        }\n",
        "\n",
        "        self.view.render_settings_tab(\n",
        "            self.data_manager.effect_col,\n",
        "            self.data_manager.var_col,\n",
        "            result.k_obs,\n",
        "            result.k_studies,\n",
        "            widgets_dict,\n",
        "            self._handle_rerun_click\n",
        "        )\n",
        "\n",
        "        # Tab 5: Publication Text\n",
        "        combined_text = self.view.render_publication_tab(\n",
        "            result,\n",
        "            self.data_manager.es_config\n",
        "        )\n",
        "\n",
        "        # Save publication text\n",
        "        self.data_manager.save_publication_text(combined_text)\n",
        "\n",
        "        # Tab 6: Export\n",
        "        self.view.render_export_tab(export_callback=self._handle_export)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA PERSISTENCE\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _save_results(self, result: 'OverallResult') -> None:\n",
        "        \"\"\"\n",
        "        Save results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: OverallResult object\n",
        "        \"\"\"\n",
        "        self.data_manager.save_overall_results(result)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # EVENT HANDLERS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_settings_change(self, change) -> None:\n",
        "        \"\"\"Handle settings widget change event\"\"\"\n",
        "        self.run_analysis()\n",
        "\n",
        "    def _handle_rerun_click(self, button) -> None:\n",
        "        \"\"\"Handle rerun button click\"\"\"\n",
        "        self.run_analysis()\n",
        "\n",
        "    def _handle_export(self, button) -> None:\n",
        "        \"\"\"Handle export button click\"\"\"\n",
        "        try:\n",
        "            # Call the external export function if it exists\n",
        "            if 'export_analysis_report' in globals():\n",
        "                export_analysis_report(\n",
        "                    report_type='overall',\n",
        "                    filename_prefix='Overall_Meta_Analysis'\n",
        "                )\n",
        "            else:\n",
        "                with self.view.tab_export:\n",
        "                    print(\"\u26a0\ufe0f Export function not found. Please run the export cell first.\")\n",
        "        except Exception as e:\n",
        "            with self.view.tab_export:\n",
        "                print(f\"\u274c Export failed: {str(e)}\")\n",
        "                traceback.print_exc()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_initialization_error(self) -> None:\n",
        "        \"\"\"Handle errors during controller initialization\"\"\"\n",
        "        error = self._initialization_error\n",
        "        if error is None:\n",
        "            return\n",
        "\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "    def _handle_unexpected_error(self, error: Exception) -> None:\n",
        "        \"\"\"Handle unexpected errors during analysis\"\"\"\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION ENTRY POINT\n",
        "# =============================================================================\n",
        "\n",
        "def run_overall_meta_analysis():\n",
        "    \"\"\"\n",
        "    Main entry point for overall meta-analysis.\n",
        "    Call this function to display the UI and enable analysis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check for ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            print(\"\u274c ERROR: ANALYSIS_CONFIG not found\")\n",
        "            print(\"Please run previous analysis cells first:\")\n",
        "            print(\"  - Step 1: Data Loading\")\n",
        "            return\n",
        "\n",
        "        # Create controller\n",
        "        controller = OverallController(ANALYSIS_CONFIG)\n",
        "\n",
        "        # Display tabs\n",
        "        display(controller.view.tabs)\n",
        "\n",
        "        # Run initial analysis\n",
        "        controller.run_analysis()\n",
        "\n",
        "        # Store controller globally for access (optional)\n",
        "        globals()['_overall_controller'] = controller\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Fatal Error: {type(e).__name__}\")\n",
        "        print(f\"Message: {str(e)}\")\n",
        "        print(\"\\nFull traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STANDALONE TESTING UTILITIES (Optional)\n",
        "# =============================================================================\n",
        "\n",
        "class MockOverallConfig:\n",
        "    \"\"\"\n",
        "    Mock ANALYSIS_CONFIG for testing without running full pipeline.\n",
        "    Only for development/testing purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_sample_config():\n",
        "        \"\"\"Create a minimal valid config for testing\"\"\"\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "\n",
        "        # Sample data\n",
        "        np.random.seed(42)\n",
        "        sample_data = pd.DataFrame({\n",
        "            'id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "            'hedges_g': np.random.randn(10) * 0.3 + 0.5,\n",
        "            'Vg': np.random.uniform(0.01, 0.1, 10)\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'analysis_data': sample_data,\n",
        "            'effect_col': 'hedges_g',\n",
        "            'var_col': 'Vg',\n",
        "            'es_config': {\n",
        "                'type': \"Hedges' g\",\n",
        "                'effect_label': \"Hedges' g\",\n",
        "                'effect_label_short': 'g',\n",
        "                'null_value': 0,\n",
        "                'has_fold_change': False\n",
        "            },\n",
        "            'vcv_matrices': {},\n",
        "            'global_settings': {\n",
        "                'alpha': 0.05,\n",
        "                'dist_type': 't'\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST & INFORMATION\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Overall Meta-Analysis Controller Layer Loaded Successfully\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - OverallController\")\n",
        "    print(\"   - MockOverallConfig (for testing)\")\n",
        "    print()\n",
        "    print(\"\ud83d\ude80 Main Entry Point:\")\n",
        "    print(\"   run_overall_meta_analysis()\")\n",
        "    print()\n",
        "    print(\"\ud83d\udca1 Usage:\")\n",
        "    print(\"   Just call: run_overall_meta_analysis()\")\n",
        "    print(\"=\" * 60)\n",
        "run_overall_meta_analysis()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tGdmihvs4VH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k_UgQywyi0vh"
      },
      "outputs": [],
      "source": [
        "#@title \u2699\ufe0f 8. Subgroup Analysis: Configuration\n",
        "\n",
        "# =============================================================================\n",
        "# SUBGROUP ANALYSIS CONFIGURATION (DASHBOARD VERSION)\n",
        "# Purpose: Configure moderator variables with organized tabbed interface\n",
        "# Dependencies: Step 2 (overall_results, analysis_data)\n",
        "# Outputs: ANALYSIS_CONFIG['subgroup_config']\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import datetime\n",
        "\n",
        "# --- 1. CREATE TAB LAYOUT ---\n",
        "tab_config = widgets.VBox()\n",
        "tab_moderators = widgets.Output()\n",
        "tab_thresholds = widgets.Output()\n",
        "tab_details = widgets.Output()\n",
        "\n",
        "tabs = widgets.Tab(children=[tab_config, tab_moderators, tab_thresholds, tab_details])\n",
        "tabs.set_title(0, '\ud83d\udccb Configuration')\n",
        "tabs.set_title(1, '\ud83d\udcca Moderator Preview')\n",
        "tabs.set_title(2, '\u2699\ufe0f Thresholds')\n",
        "tabs.set_title(3, '\ud83d\udcdd Details')\n",
        "\n",
        "# --- 2. WIDGETS ---\n",
        "analysis_type_widget = widgets.RadioButtons(\n",
        "    options=[('Single-Factor Analysis', 'single'), ('Two-Factor Analysis (Interaction)', 'two_way')],\n",
        "    value='single', description='', layout=widgets.Layout(width='auto')\n",
        ")\n",
        "\n",
        "moderator1_widget = None\n",
        "moderator2_widget = None\n",
        "\n",
        "min_papers_widget = widgets.IntSlider(\n",
        "    value=3, min=1, max=10, step=1, description='Min Papers:',\n",
        "    style={'description_width': '120px'}, layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "min_obs_widget = widgets.IntSlider(\n",
        "    value=5, min=2, max=20, step=1, description='Min Observations:',\n",
        "    style={'description_width': '120px'}, layout=widgets.Layout(width='400px')\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description='\ud83d\udcbe Save Configuration & Proceed',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='400px', height='50px'),\n",
        "    style={'font_weight': 'bold'},\n",
        "    tooltip='Click to save configuration for use in the next cell'\n",
        ")\n",
        "\n",
        "run_button_output = widgets.Output()\n",
        "status_output = widgets.Output()\n",
        "\n",
        "# --- 3. INITIALIZATION ---\n",
        "def initialize_configuration():\n",
        "    global moderator1_widget, moderator2_widget\n",
        "\n",
        "    with tab_details:\n",
        "        clear_output()\n",
        "        print(\"=\"*70)\n",
        "        print(\"INITIALIZATION & VALIDATION\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            effect_col = ANALYSIS_CONFIG['effect_col']\n",
        "            var_col = ANALYSIS_CONFIG['var_col']\n",
        "            es_config = ANALYSIS_CONFIG['es_config']\n",
        "            overall_results = ANALYSIS_CONFIG['overall_results']\n",
        "\n",
        "            print(\"\u2713 Prerequisites Check:\")\n",
        "            print(f\"  \u2022 Effect: {es_config['effect_label']} ({es_config['effect_label_short']})\")\n",
        "            print(f\"  \u2022 Q: {overall_results['Qt']:.4f}, I\u00b2: {overall_results['I_squared']:.2f}%\")\n",
        "        except KeyError as e:\n",
        "            print(f\"\u274c ERROR: {e}\")\n",
        "            print(\"  Please run Step 2 first\")\n",
        "            raise\n",
        "\n",
        "        # --- DATA LOADING (FIXED PRIORITY) ---\n",
        "        # 1. Always prioritize the ANALYSIS_CONFIG (where the new data lives)\n",
        "        if 'ANALYSIS_CONFIG' in globals() and 'analysis_data' in ANALYSIS_CONFIG:\n",
        "            analysis_data = ANALYSIS_CONFIG['analysis_data']\n",
        "\n",
        "            # CRITICAL FIX: Force update the global variable so it never gets stuck\n",
        "            globals()['analysis_data'] = analysis_data\n",
        "\n",
        "        # 2. Fallback if config is missing\n",
        "        elif 'analysis_data' in globals():\n",
        "            analysis_data = globals()['analysis_data']\n",
        "\n",
        "        # 3. Last resort fallback\n",
        "        elif 'data_filtered' in globals():\n",
        "            analysis_data = globals()['data_filtered']\n",
        "\n",
        "        else:\n",
        "            print(\"\u274c ERROR: analysis_data not found\")\n",
        "            raise NameError(\"analysis_data not defined\")\n",
        "\n",
        "\n",
        "        k_total, k_papers = len(analysis_data), analysis_data['id'].nunique()\n",
        "        print(f\"\\n\u2713 Dataset: {k_total} obs, {k_papers} papers, {k_total/k_papers:.2f} avg\")\n",
        "\n",
        "        if k_total < 10:\n",
        "            print(f\"\u26a0\ufe0f  WARNING: Limited data ({k_total} obs)\")\n",
        "        elif k_total < 20:\n",
        "            print(f\"\u26a0\ufe0f  CAUTION: Moderate data ({k_total} obs)\")\n",
        "\n",
        "        excluded = ['xe', 'sde', 'ne', 'xc', 'sdc', 'nc', 'id', 'sde_imputed', 'sdc_imputed',\n",
        "                   'cv_e', 'cv_c', 'sde_was_imputed', 'sdc_was_imputed',\n",
        "                   effect_col, var_col, ANALYSIS_CONFIG.get('se_col', ''), 'w_fixed', 'w_random', 'ci_width']\n",
        "\n",
        "        if es_config.get('has_fold_change'):\n",
        "            excluded.extend(['Response_Ratio', 'RR_CI_lower', 'RR_CI_upper', 'fold_change',\n",
        "                           'Percent_Change', 'Odds_Ratio', 'OR_CI_lower', 'OR_CI_upper'])\n",
        "\n",
        "        if 'hedges_g' in effect_col or 'cohen_d' in effect_col:\n",
        "            excluded.extend(['df', 'sp', 'sp_squared', 'cohen_d', 'hedges_j'])\n",
        "\n",
        "        excluded.extend([c for c in analysis_data.columns if 'CI_' in c or 'ci_' in c])\n",
        "\n",
        "        # NEW CODE (Smart Detection)\n",
        "        available_moderators = []\n",
        "        for col in analysis_data.columns:\n",
        "            if col in excluded: continue\n",
        "\n",
        "            # Check 1: Is it text/string?\n",
        "            is_text = analysis_data[col].dtype == 'object'\n",
        "\n",
        "            # Check 2: Is it a Category? (Common in R data)\n",
        "            is_category = isinstance(analysis_data[col].dtype, pd.CategoricalDtype)\n",
        "\n",
        "            # Check 3: Is it a Number behaving like a Group? (e.g. Year, Grade)\n",
        "            is_group_like_number = False\n",
        "            if pd.api.types.is_numeric_dtype(analysis_data[col]):\n",
        "                # If it has fewer than 20 unique values, treat it as a subgroup\n",
        "                if analysis_data[col].nunique() < 20 and analysis_data[col].nunique() > 1:\n",
        "                    is_group_like_number = True\n",
        "\n",
        "            # If ANY check passes, keep it\n",
        "            if (is_text or is_category or is_group_like_number):\n",
        "                available_moderators.append(col)\n",
        "\n",
        "        print(f\"\\n\u2713 Found {len(available_moderators)} moderators:\")\n",
        "        for mod in available_moderators:\n",
        "            print(f\"  \u2022 {mod}: {analysis_data[mod].nunique()} categories\")\n",
        "\n",
        "        if not available_moderators:\n",
        "            print(\"\u274c ERROR: No moderators found\")\n",
        "            raise ValueError(\"No moderators available\")\n",
        "\n",
        "        moderator1_widget = widgets.Dropdown(\n",
        "            options=available_moderators, value=available_moderators[0],\n",
        "            description='Moderator 1:', style={'description_width': '100px'},\n",
        "            layout=widgets.Layout(width='450px')\n",
        "        )\n",
        "\n",
        "        moderator2_widget = widgets.Dropdown(\n",
        "            options=['None'] + available_moderators, value='None',\n",
        "            description='Moderator 2:', style={'description_width': '100px'},\n",
        "            layout=widgets.Layout(width='450px')\n",
        "        )\n",
        "\n",
        "        analysis_type_widget.observe(update_all_tabs, names='value')\n",
        "        moderator1_widget.observe(update_all_tabs, names='value')\n",
        "        moderator2_widget.observe(update_all_tabs, names='value')\n",
        "        min_papers_widget.observe(update_thresholds_tab, names='value')\n",
        "        min_obs_widget.observe(update_thresholds_tab, names='value')\n",
        "        run_button.on_click(save_configuration)\n",
        "\n",
        "        print(\"\\n\u2713 Initialized successfully\")\n",
        "        return available_moderators\n",
        "\n",
        "# --- 4. TAB UPDATES ---\n",
        "def update_config_tab(change=None):\n",
        "    # Clear any previous save messages\n",
        "    with status_output:\n",
        "        clear_output()\n",
        "\n",
        "    items = []\n",
        "\n",
        "    analysis_type = analysis_type_widget.value\n",
        "\n",
        "    # 1. Header & Help (Reduced margin-bottom from 15px to 5px)\n",
        "    items.append(widgets.HTML(\"<h3 style='margin-top:0; margin-bottom:5px;'>Configure Subgroup Analysis</h3>\"))\n",
        "\n",
        "    if analysis_type == 'single':\n",
        "        help_text = \"\"\"<div style='background:#e7f3ff; padding:8px; border-radius:6px; border-left:4px solid #0066cc; margin-bottom:5px;'>\n",
        "            <b>\ud83d\udcca Single-Factor Subgroup Analysis</b><br>\n",
        "            <span style='font-size:12px; color:#555;'>Test if effect varies across ONE moderator. Best for primary hypotheses (10+ obs/group).</span></div>\"\"\"\n",
        "    else:\n",
        "        help_text = \"\"\"<div style='background:#fff3cd; padding:8px; border-radius:6px; border-left:4px solid #ff9800; margin-bottom:5px;'>\n",
        "            <b>\ud83d\udcca Two-Factor Analysis (Interaction)</b><br>\n",
        "            <span style='font-size:12px; color:#555;'>Test combinations of TWO moderators. Requires 3-5 studies/combo, 20+ total obs.</span></div>\"\"\"\n",
        "    items.append(widgets.HTML(help_text))\n",
        "\n",
        "    # 2. Controls (Reduced margin-top from 20px to 10px)\n",
        "    items.append(widgets.HTML(\"<h4 style='margin-top:10px; margin-bottom:5px;'>1. Select Analysis Type</h4>\"))\n",
        "    items.append(analysis_type_widget)\n",
        "\n",
        "    items.append(widgets.HTML(\"<h4 style='margin-top:10px; margin-bottom:5px;'>2. Select Moderator(s)</h4>\"))\n",
        "    if moderator1_widget:\n",
        "        items.append(moderator1_widget)\n",
        "\n",
        "    if analysis_type == 'two_way' and moderator2_widget:\n",
        "        items.append(moderator2_widget)\n",
        "\n",
        "    # 3. Thresholds (Reduced margins)\n",
        "    items.append(widgets.HTML(\"<h4 style='margin-top:10px; margin-bottom:5px;'>3. Set Quality Thresholds</h4>\"))\n",
        "    items.append(widgets.HTML(\"<p style='color:#666; font-size:12px; margin:0 0 5px 0;'>Adjust in <b>\u2699\ufe0f Thresholds</b> tab</p>\"))\n",
        "\n",
        "    threshold_info = widgets.HBox([\n",
        "        widgets.HTML(f\"<div style='padding:5px 8px; background:#f0f0f0; border-radius:4px; margin-right:10px; font-size:13px;'>\"\n",
        "                    f\"<b>Min Papers:</b> {min_papers_widget.value}</div>\"),\n",
        "        widgets.HTML(f\"<div style='padding:5px 8px; background:#f0f0f0; border-radius:4px; font-size:13px;'>\"\n",
        "                    f\"<b>Min Obs:</b> {min_obs_widget.value}</div>\")\n",
        "    ])\n",
        "    items.append(threshold_info)\n",
        "\n",
        "    # 4. Save Section (Reduced margins)\n",
        "    items.append(widgets.HTML(\"<h4 style='margin-top:10px; margin-bottom:5px;'>4. Save Configuration</h4>\"))\n",
        "\n",
        "    items.append(run_button)\n",
        "    items.append(status_output)\n",
        "\n",
        "    # Update Children\n",
        "    tab_config.children = tuple(items)\n",
        "\n",
        "def update_moderators_tab(change=None):\n",
        "    with tab_moderators:\n",
        "        clear_output()\n",
        "\n",
        "        # --- FIX: LOAD DATA ---\n",
        "        if 'ANALYSIS_CONFIG' in globals() and 'analysis_data' in ANALYSIS_CONFIG:\n",
        "            analysis_data = ANALYSIS_CONFIG['analysis_data']\n",
        "        elif 'analysis_data' in globals():\n",
        "            analysis_data = globals()['analysis_data']\n",
        "        elif 'data_filtered' in globals():\n",
        "            analysis_data = globals()['data_filtered']\n",
        "        else:\n",
        "            return # Data not ready yet\n",
        "        if moderator1_widget is None:\n",
        "            print(\"Initializing...\")\n",
        "            return\n",
        "\n",
        "        mod1 = moderator1_widget.value\n",
        "        analysis_type = analysis_type_widget.value\n",
        "        mod2 = moderator2_widget.value if analysis_type == 'two_way' and moderator2_widget.value != 'None' else None\n",
        "\n",
        "        display(HTML(\"<h3 style='margin-top:0;'>Moderator Variable Preview</h3>\"))\n",
        "        display(HTML(f\"<h4>\ud83d\udcca {mod1}</h4>\"))\n",
        "\n",
        "        mod1_counts = analysis_data[mod1].value_counts().sort_index()\n",
        "\n",
        "        table_html = \"\"\"<table style='width:100%; border-collapse:collapse;'>\n",
        "            <tr style='background:#f0f0f0; border-bottom:2px solid #ddd;'>\n",
        "                <th style='text-align:left; padding:8px;'>Category</th>\n",
        "                <th style='text-align:right; padding:8px;'>Observations</th>\n",
        "                <th style='text-align:right; padding:8px;'>Papers</th>\n",
        "                <th style='text-align:right; padding:8px;'>Percent</th></tr>\"\"\"\n",
        "\n",
        "        for category, count in mod1_counts.items():\n",
        "            papers = analysis_data[analysis_data[mod1] == category]['id'].nunique()\n",
        "            pct = (count / len(analysis_data)) * 100\n",
        "            row_color = '#fff' if count >= 5 else '#fff3cd'\n",
        "            table_html += f\"\"\"<tr style='background:{row_color}; border-bottom:1px solid #eee;'>\n",
        "                <td style='padding:6px;'>{category}</td>\n",
        "                <td style='text-align:right; padding:6px;'><b>{count}</b></td>\n",
        "                <td style='text-align:right; padding:6px;'>{papers}</td>\n",
        "                <td style='text-align:right; padding:6px;'>{pct:.1f}%</td></tr>\"\"\"\n",
        "\n",
        "        table_html += \"</table>\"\n",
        "        display(HTML(table_html))\n",
        "\n",
        "        min_group = mod1_counts.min()\n",
        "        if min_group < 5:\n",
        "            display(HTML(f\"<div style='background:#fff3cd; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                        f\"\u26a0\ufe0f Smallest group: {min_group} obs - consider adjusting thresholds</div>\"))\n",
        "        else:\n",
        "            display(HTML(\"<div style='background:#d4edda; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                        \"\u2713 All groups have \u22655 observations</div>\"))\n",
        "\n",
        "        if mod2:\n",
        "            display(HTML(f\"<h4 style='margin-top:25px;'>\ud83d\udcca {mod2}</h4>\"))\n",
        "            mod2_counts = analysis_data[mod2].value_counts().sort_index()\n",
        "\n",
        "            table2_html = \"\"\"<table style='width:100%; border-collapse:collapse;'>\n",
        "                <tr style='background:#f0f0f0; border-bottom:2px solid #ddd;'>\n",
        "                    <th style='text-align:left; padding:8px;'>Category</th>\n",
        "                    <th style='text-align:right; padding:8px;'>Observations</th>\n",
        "                    <th style='text-align:right; padding:8px;'>Papers</th>\n",
        "                    <th style='text-align:right; padding:8px;'>Percent</th></tr>\"\"\"\n",
        "\n",
        "            for category, count in mod2_counts.items():\n",
        "                papers = analysis_data[analysis_data[mod2] == category]['id'].nunique()\n",
        "                pct = (count / len(analysis_data)) * 100\n",
        "                table2_html += f\"\"\"<tr style='border-bottom:1px solid #eee;'>\n",
        "                    <td style='padding:6px;'>{category}</td>\n",
        "                    <td style='text-align:right; padding:6px;'><b>{count}</b></td>\n",
        "                    <td style='text-align:right; padding:6px;'>{papers}</td>\n",
        "                    <td style='text-align:right; padding:6px;'>{pct:.1f}%</td></tr>\"\"\"\n",
        "\n",
        "            table2_html += \"</table>\"\n",
        "            display(HTML(table2_html))\n",
        "\n",
        "            display(HTML(f\"<h4 style='margin-top:25px;'>\ud83d\udd00 Combination Matrix: {mod1} \u00d7 {mod2}</h4>\"))\n",
        "            crosstab = pd.crosstab(analysis_data[mod1], analysis_data[mod2], margins=True, margins_name='Total')\n",
        "            display(crosstab.style.background_gradient(cmap='Blues', subset=pd.IndexSlice[crosstab.index[:-1], crosstab.columns[:-1]]))\n",
        "\n",
        "            n_empty = (crosstab.iloc[:-1, :-1] == 0).sum().sum()\n",
        "            min_cell = crosstab.iloc[:-1, :-1].min().min()\n",
        "\n",
        "            if n_empty > 0:\n",
        "                display(HTML(f\"<div style='background:#f8d7da; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            f\"\u26a0\ufe0f {n_empty} empty combinations - will be excluded</div>\"))\n",
        "            elif min_cell < 3:\n",
        "                display(HTML(f\"<div style='background:#fff3cd; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            f\"\u26a0\ufe0f Min cell: {min_cell} - results may be unstable</div>\"))\n",
        "            elif min_cell < 5:\n",
        "                display(HTML(f\"<div style='background:#fff3cd; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            f\"\u26a0\ufe0f Some combinations limited (min: {min_cell})</div>\"))\n",
        "            else:\n",
        "                display(HTML(\"<div style='background:#d4edda; padding:10px; margin-top:10px; border-radius:4px;'>\"\n",
        "                            \"\u2713 All combinations have \u22655 obs</div>\"))\n",
        "\n",
        "def update_thresholds_tab(change=None):\n",
        "    with tab_thresholds:\n",
        "        clear_output()\n",
        "        if 'ANALYSIS_CONFIG' in globals() and 'analysis_data' in ANALYSIS_CONFIG:\n",
        "            analysis_data = ANALYSIS_CONFIG['analysis_data']\n",
        "        elif 'analysis_data' in globals():\n",
        "            analysis_data = globals()['analysis_data']\n",
        "        elif 'data_filtered' in globals():\n",
        "            analysis_data = globals()['data_filtered']\n",
        "        else:\n",
        "            return\n",
        "        if moderator1_widget is None:\n",
        "            print(\"Initializing...\")\n",
        "            return\n",
        "\n",
        "        display(HTML(\"<h3 style='margin-top:0;'>Quality Thresholds & Impact Analysis</h3>\"))\n",
        "        display(HTML(\"\"\"<div style='background:#f8f9fa; padding:12px; border-radius:6px; margin-bottom:15px;'>\n",
        "            <b>Purpose:</b> Ensure sufficient data for reliable estimation<br>\n",
        "            <span style='font-size:13px; color:#555;'>Higher = more reliable but fewer subgroups</span></div>\"\"\"))\n",
        "\n",
        "        display(min_papers_widget)\n",
        "        display(min_obs_widget)\n",
        "        display(HTML(\"<h4 style='margin-top:25px;'>Impact on Data Retention</h4>\"))\n",
        "\n",
        "        mod1 = moderator1_widget.value\n",
        "        analysis_type = analysis_type_widget.value\n",
        "        mod2 = moderator2_widget.value if analysis_type == 'two_way' and moderator2_widget.value != 'None' else None\n",
        "        min_papers, min_obs = min_papers_widget.value, min_obs_widget.value\n",
        "\n",
        "        groups_meeting, groups_failing = [], []\n",
        "\n",
        "        if analysis_type == 'single':\n",
        "            for cat in analysis_data[mod1].dropna().unique():\n",
        "                group_data = analysis_data[analysis_data[mod1] == cat]\n",
        "                n_papers, n_obs = group_data['id'].nunique(), len(group_data)\n",
        "\n",
        "                if n_papers >= min_papers and n_obs >= min_obs:\n",
        "                    groups_meeting.append((cat, n_obs, n_papers))\n",
        "                else:\n",
        "                    groups_failing.append((cat, n_obs, n_papers))\n",
        "        else:\n",
        "            if mod2:\n",
        "                for cat1 in analysis_data[mod1].dropna().unique():\n",
        "                    for cat2 in analysis_data[mod2].dropna().unique():\n",
        "                        cell_data = analysis_data[(analysis_data[mod1] == cat1) & (analysis_data[mod2] == cat2)]\n",
        "                        n_papers, n_obs = cell_data['id'].nunique(), len(cell_data)\n",
        "\n",
        "                        if n_papers >= min_papers and n_obs >= min_obs:\n",
        "                            groups_meeting.append((f\"{cat1} \u00d7 {cat2}\", n_obs, n_papers))\n",
        "                        elif n_obs > 0:\n",
        "                            groups_failing.append((f\"{cat1} \u00d7 {cat2}\", n_obs, n_papers))\n",
        "\n",
        "        total_retained = sum(obs for _, obs, _ in groups_meeting)\n",
        "        retention_pct = (total_retained / len(analysis_data)) * 100\n",
        "\n",
        "        cards_html = f\"\"\"<div style='display:flex; gap:15px; margin-bottom:20px;'>\n",
        "            <div style='flex:1; background:#d4edda; padding:15px; border-radius:6px; text-align:center;'>\n",
        "                <div style='font-size:28px; font-weight:bold; color:#155724;'>{len(groups_meeting)}</div>\n",
        "                <div style='font-size:13px; color:#155724;'>Groups Meeting Criteria</div></div>\n",
        "            <div style='flex:1; background:#{'#f8d7da' if len(groups_failing) > 0 else '#e2e3e5'}; padding:15px; border-radius:6px; text-align:center;'>\n",
        "                <div style='font-size:28px; font-weight:bold; color:#{'#721c24' if len(groups_failing) > 0 else '#6c757d'};'>{len(groups_failing)}</div>\n",
        "                <div style='font-size:13px; color:#{'#721c24' if len(groups_failing) > 0 else '#6c757d'};'>Groups Excluded</div></div>\n",
        "            <div style='flex:1; background:#{'#d4edda' if retention_pct >= 75 else '#fff3cd' if retention_pct >= 50 else '#f8d7da'}; padding:15px; border-radius:6px; text-align:center;'>\n",
        "                <div style='font-size:28px; font-weight:bold;'>{retention_pct:.0f}%</div>\n",
        "                <div style='font-size:13px;'>Data Retained</div></div></div>\"\"\"\n",
        "        display(HTML(cards_html))\n",
        "\n",
        "        if groups_meeting:\n",
        "            display(HTML(\"<h4>\u2713 Groups Meeting Criteria:</h4>\"))\n",
        "            meet_html = \"<ul style='margin-top:5px;'>\"\n",
        "            for cat, obs, papers in groups_meeting:\n",
        "                meet_html += f\"<li><b>{cat}:</b> {obs} obs, {papers} papers</li>\"\n",
        "            meet_html += \"</ul>\"\n",
        "            display(HTML(meet_html))\n",
        "\n",
        "        if groups_failing:\n",
        "            display(HTML(\"<h4 style='margin-top:20px;'>\u2717 Groups Excluded:</h4>\"))\n",
        "            fail_html = \"<ul style='margin-top:5px; color:#721c24;'>\"\n",
        "            for cat, obs, papers in groups_failing:\n",
        "                reason = []\n",
        "                if papers < min_papers:\n",
        "                    reason.append(f\"papers: {papers}<{min_papers}\")\n",
        "                if obs < min_obs:\n",
        "                    reason.append(f\"obs: {obs}<{min_obs}\")\n",
        "                fail_html += f\"<li><b>{cat}:</b> {obs} obs, {papers} papers ({', '.join(reason)})</li>\"\n",
        "            fail_html += \"</ul>\"\n",
        "            display(HTML(fail_html))\n",
        "\n",
        "        if len(groups_meeting) < 2:\n",
        "            display(HTML(\"<div style='background:#f8d7da; padding:12px; border-radius:6px; margin-top:15px;'>\"\n",
        "                        \"\ud83d\udd34 <b>ERROR:</b> Need \u22652 groups. Lower thresholds.</div>\"))\n",
        "        elif retention_pct < 50:\n",
        "            display(HTML(\"<div style='background:#fff3cd; padding:12px; border-radius:6px; margin-top:15px;'>\"\n",
        "                        \"\u26a0\ufe0f <b>WARNING:</b> <50% data retained. Consider lowering thresholds.</div>\"))\n",
        "\n",
        "def update_all_tabs(change=None):\n",
        "    update_config_tab()\n",
        "    update_moderators_tab()\n",
        "    update_thresholds_tab()\n",
        "\n",
        "# --- 5. SAVE CONFIGURATION ---\n",
        "def save_configuration(button):\n",
        "    with status_output:\n",
        "        clear_output()\n",
        "\n",
        "        # --- FIX: LOAD DATA INSIDE THE FUNCTION ---\n",
        "        # We must explicitly retrieve the data again because this function\n",
        "        # runs in a different scope than the initialization.\n",
        "        if 'ANALYSIS_CONFIG' in globals() and 'analysis_data' in ANALYSIS_CONFIG:\n",
        "            analysis_data = ANALYSIS_CONFIG['analysis_data']\n",
        "        elif 'analysis_data' in globals():\n",
        "            analysis_data = globals()['analysis_data']\n",
        "        elif 'data_filtered' in globals():\n",
        "            analysis_data = globals()['data_filtered']\n",
        "        else:\n",
        "            display(HTML(\"<div style='color:red'>\u274c Error: Data not found. Please run Step 4/5 first.</div>\"))\n",
        "            return\n",
        "        analysis_type = analysis_type_widget.value\n",
        "        mod1 = moderator1_widget.value\n",
        "        mod2 = moderator2_widget.value if analysis_type == 'two_way' and moderator2_widget.value != 'None' else None\n",
        "        min_papers, min_obs = min_papers_widget.value, min_obs_widget.value\n",
        "\n",
        "        validation_errors = []\n",
        "\n",
        "        if analysis_type == 'two_way' and not mod2:\n",
        "            validation_errors.append(\"Two-way requires Moderator 2\")\n",
        "\n",
        "        if mod1 == mod2:\n",
        "            validation_errors.append(\"Moderators cannot be the same\")\n",
        "\n",
        "        valid_groups = []\n",
        "        if analysis_type == 'single':\n",
        "            for cat in analysis_data[mod1].dropna().unique():\n",
        "                group_data = analysis_data[analysis_data[mod1] == cat]\n",
        "                if group_data['id'].nunique() >= min_papers and len(group_data) >= min_obs:\n",
        "                    valid_groups.append(cat)\n",
        "        else:\n",
        "            if mod2:\n",
        "                for cat1 in analysis_data[mod1].dropna().unique():\n",
        "                    for cat2 in analysis_data[mod2].dropna().unique():\n",
        "                        cell_data = analysis_data[(analysis_data[mod1] == cat1) & (analysis_data[mod2] == cat2)]\n",
        "                        if cell_data['id'].nunique() >= min_papers and len(cell_data) >= min_obs:\n",
        "                            valid_groups.append((cat1, cat2))\n",
        "\n",
        "        if len(valid_groups) < 2:\n",
        "            validation_errors.append(f\"Only {len(valid_groups)} group(s) meet criteria. Need \u22652.\")\n",
        "\n",
        "        if validation_errors:\n",
        "            error_html = \"<div style='background:#f8d7da; padding:15px; border-radius:6px; border-left:4px solid #dc3545;'>\"\n",
        "            error_html += \"<h4 style='margin-top:0; color:#721c24;'>\u274c Validation Failed</h4><ul style='margin-bottom:0; color:#721c24;'>\"\n",
        "            for err in validation_errors:\n",
        "                error_html += f\"<li>{err}</li>\"\n",
        "            error_html += \"</ul></div>\"\n",
        "            display(HTML(error_html))\n",
        "            return\n",
        "\n",
        "        if analysis_type == 'single':\n",
        "            retained_data = analysis_data[analysis_data[mod1].isin(valid_groups)]\n",
        "        else:\n",
        "            retained_data = analysis_data[analysis_data.apply(lambda row: (row[mod1], row[mod2]) in valid_groups, axis=1)]\n",
        "\n",
        "        retention_pct = (len(retained_data) / len(analysis_data)) * 100\n",
        "\n",
        "        ANALYSIS_CONFIG['subgroup_config'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'analysis_type': analysis_type,\n",
        "            'moderator1': mod1,\n",
        "            'moderator2': mod2,\n",
        "            'min_papers': min_papers,\n",
        "            'min_obs': min_obs,\n",
        "            'expected_groups': len(valid_groups),\n",
        "            'valid_groups_list': valid_groups,\n",
        "            'data_retained': len(retained_data),\n",
        "            'retention_pct': retention_pct,\n",
        "            'has_empty_cells': analysis_type == 'two_way' and mod2 and\n",
        "                               (pd.crosstab(analysis_data[mod1], analysis_data[mod2]) == 0).sum().sum() > 0,\n",
        "            'n_empty_cells': (pd.crosstab(analysis_data[mod1], analysis_data[mod2]) == 0).sum().sum()\n",
        "                            if analysis_type == 'two_way' and mod2 else 0\n",
        "        }\n",
        "\n",
        "        ANALYSIS_CONFIG['subgroup_config']['moderator1_info'] = {\n",
        "            'name': mod1,\n",
        "            'n_categories': analysis_data[mod1].nunique(),\n",
        "            'categories': sorted(analysis_data[mod1].dropna().unique().tolist())\n",
        "        }\n",
        "\n",
        "        if mod2:\n",
        "            ANALYSIS_CONFIG['subgroup_config']['moderator2_info'] = {\n",
        "                'name': mod2,\n",
        "                'n_categories': analysis_data[mod2].nunique(),\n",
        "                'categories': sorted(analysis_data[mod2].dropna().unique().tolist())\n",
        "            }\n",
        "\n",
        "        success_html = f\"\"\"<div style='background:#d4edda; padding:15px; border-radius:6px; border-left:4px solid #28a745;'>\n",
        "            <h4 style='margin-top:0; color:#155724;'>\u2713 Configuration Saved Successfully</h4>\n",
        "            <table style='width:100%; margin-top:10px;'>\n",
        "                <tr><td><b>Analysis Type:</b></td><td>{analysis_type}</td></tr>\n",
        "                <tr><td><b>Primary Moderator:</b></td><td>{mod1}</td></tr>\n",
        "                {f'<tr><td><b>Secondary Moderator:</b></td><td>{mod2}</td></tr>' if mod2 else ''}\n",
        "                <tr><td><b>Valid Groups:</b></td><td>{len(valid_groups)}</td></tr>\n",
        "                <tr><td><b>Data Retained:</b></td><td>{len(retained_data)}/{len(analysis_data)} ({retention_pct:.1f}%)</td></tr>\n",
        "            </table>\n",
        "            <p style='margin:10px 0 0 0; color:#155724; font-size:14px;'><b>\u2705 Ready! Proceed to the next cell to run the subgroup analysis.</b></p></div>\"\"\"\n",
        "        display(HTML(success_html))\n",
        "\n",
        "        with tab_details:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"\u2713 CONFIGURATION SAVED\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            print(\"\\nConfiguration stored in ANALYSIS_CONFIG['subgroup_config']\")\n",
        "            print(\"Ready to proceed to subgroup analysis execution.\")\n",
        "\n",
        "# --- 6. INITIALIZE AND DISPLAY ---\n",
        "try:\n",
        "    available_mods = initialize_configuration()\n",
        "    update_all_tabs()\n",
        "    display(tabs)\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Initialization failed: {e}\")\n",
        "    print(\"\\nPlease ensure:\")\n",
        "    print(\"  1. Step 2 (Overall Meta-Analysis) has been run\")\n",
        "    print(\"  2. ANALYSIS_CONFIG is properly configured\")\n",
        "    print(\"  3. analysis_data is available\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udd2c 9. Subgroup Analysis: DATA LAYER (Model)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 1/4: DATA LAYER\n",
        "# Purpose: Centralized data management and validation\n",
        "# Dependencies: ANALYSIS_CONFIG global dictionary\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple, List, Union\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA CLASSES (Type-Safe Data Containers)\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class SubgroupConfig:\n",
        "    \"\"\"Configuration for subgroup analysis\"\"\"\n",
        "    analysis_type: str  # 'single' or 'two_way'\n",
        "    moderator1: str\n",
        "    moderator2: Optional[str]\n",
        "    valid_groups_list: List[Union[str, Tuple[str, str]]]\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration after initialization\"\"\"\n",
        "        if self.analysis_type not in ['single', 'two_way']:\n",
        "            raise ValueError(f\"analysis_type must be 'single' or 'two_way', got {self.analysis_type}\")\n",
        "        if self.analysis_type == 'two_way' and not self.moderator2:\n",
        "            raise ValueError(\"moderator2 required for two_way analysis\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GlobalSettings:\n",
        "    \"\"\"Global analysis settings\"\"\"\n",
        "    alpha: float = 0.05\n",
        "    dist_type: str = 'norm'  # 'norm' or 't'\n",
        "\n",
        "    @property\n",
        "    def ci_percent(self) -> float:\n",
        "        \"\"\"Calculate confidence interval percentage\"\"\"\n",
        "        return (1 - self.alpha) * 100\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate settings\"\"\"\n",
        "        if not 0 < self.alpha < 1:\n",
        "            raise ValueError(f\"alpha must be between 0 and 1, got {self.alpha}\")\n",
        "        if self.dist_type not in ['norm', 't']:\n",
        "            raise ValueError(f\"dist_type must be 'norm' or 't', got {self.dist_type}\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SubgroupResult:\n",
        "    \"\"\"Single subgroup analysis result\"\"\"\n",
        "    group: str\n",
        "    k: int\n",
        "    n_papers: int\n",
        "    pooled_effect_re: float\n",
        "    pooled_se_re: float\n",
        "    pooled_var_re: float\n",
        "    ci_lower_re: float\n",
        "    ci_upper_re: float\n",
        "    p_value_re: float\n",
        "    I_squared: float\n",
        "    tau_squared: float\n",
        "    sigma_squared: float\n",
        "    fold_change_re: float\n",
        "    Q_within: float\n",
        "    df_Q: int\n",
        "    model_type: str\n",
        "\n",
        "    # Optional fields for two-way analysis\n",
        "    moderator1_value: Optional[str] = None\n",
        "    moderator2_value: Optional[str] = None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA MANAGER CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class SubgroupDataManager:\n",
        "    \"\"\"\n",
        "    Centralized data access layer for subgroup analysis.\n",
        "    Handles all interactions with ANALYSIS_CONFIG and data validation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize data manager with configuration dictionary.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If required keys are missing\n",
        "        \"\"\"\n",
        "        self._config = analysis_config\n",
        "        self._validate_prerequisites()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # VALIDATION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _validate_prerequisites(self) -> None:\n",
        "        \"\"\"Validate that all required configuration exists\"\"\"\n",
        "        required_keys = [\n",
        "            'overall_results',\n",
        "            'three_level_results',\n",
        "            'subgroup_config',\n",
        "            'effect_col',\n",
        "            'var_col',\n",
        "            'es_config',\n",
        "            'analysis_data'\n",
        "        ]\n",
        "\n",
        "        missing = [key for key in required_keys if key not in self._config]\n",
        "\n",
        "        if missing:\n",
        "            raise ValueError(\n",
        "                f\"Missing required ANALYSIS_CONFIG keys: {', '.join(missing)}. \"\n",
        "                f\"Please run previous analysis steps first.\"\n",
        "            )\n",
        "\n",
        "    def validate_data_structure(self, df: pd.DataFrame) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Validate that dataframe has required columns and structure.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if df is None or len(df) == 0:\n",
        "            return False, \"DataFrame is empty or None\"\n",
        "\n",
        "        required_cols = [\n",
        "            self.effect_col,\n",
        "            self.var_col,\n",
        "            'id',  # study identifier\n",
        "            self.subgroup_config.moderator1\n",
        "        ]\n",
        "\n",
        "        if self.subgroup_config.moderator2:\n",
        "            required_cols.append(self.subgroup_config.moderator2)\n",
        "\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "\n",
        "        if missing_cols:\n",
        "            return False, f\"Missing required columns: {', '.join(missing_cols)}\"\n",
        "\n",
        "        # Check for invalid values\n",
        "        if df[self.effect_col].isna().any():\n",
        "            return False, f\"NaN values found in {self.effect_col}\"\n",
        "\n",
        "        if df[self.var_col].isna().any() or (df[self.var_col] <= 0).any():\n",
        "            return False, f\"Invalid variance values in {self.var_col}\"\n",
        "\n",
        "        return True, None\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROPERTY ACCESSORS (Read from ANALYSIS_CONFIG)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def analysis_data(self) -> pd.DataFrame:\n",
        "        \"\"\"Get analysis dataset\"\"\"\n",
        "        return self._config['analysis_data'].copy()\n",
        "\n",
        "    @property\n",
        "    def effect_col(self) -> str:\n",
        "        \"\"\"Get effect size column name\"\"\"\n",
        "        return self._config['effect_col']\n",
        "\n",
        "    @property\n",
        "    def var_col(self) -> str:\n",
        "        \"\"\"Get variance column name\"\"\"\n",
        "        return self._config['var_col']\n",
        "\n",
        "    @property\n",
        "    def es_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get effect size configuration\"\"\"\n",
        "        return self._config['es_config']\n",
        "\n",
        "    @property\n",
        "    def overall_results(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get overall meta-analysis results\"\"\"\n",
        "        return self._config['overall_results']\n",
        "\n",
        "    @property\n",
        "    def subgroup_config(self) -> SubgroupConfig:\n",
        "        \"\"\"Get subgroup configuration as typed object\"\"\"\n",
        "        raw_config = self._config['subgroup_config']\n",
        "        return SubgroupConfig(\n",
        "            analysis_type=raw_config['analysis_type'],\n",
        "            moderator1=raw_config['moderator1'],\n",
        "            moderator2=raw_config.get('moderator2'),\n",
        "            valid_groups_list=raw_config['valid_groups_list']\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def global_settings(self) -> GlobalSettings:\n",
        "        \"\"\"Get global settings as typed object\"\"\"\n",
        "        raw_settings = self._config.get('global_settings', {})\n",
        "        return GlobalSettings(\n",
        "            alpha=raw_settings.get('alpha', 0.05),\n",
        "            dist_type=raw_settings.get('dist_type', 'norm')\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def vcv_matrices(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Get variance-covariance matrices\"\"\"\n",
        "        return self._config.get('vcv_matrices', {})\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA EXTRACTION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def get_subgroup_data(\n",
        "        self,\n",
        "        group_identifier: Union[str, Tuple[str, str]]\n",
        "    ) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"\n",
        "        Extract data for a specific subgroup.\n",
        "\n",
        "        Args:\n",
        "            group_identifier: Either string (single moderator) or tuple (two-way)\n",
        "\n",
        "        Returns:\n",
        "            DataFrame subset for the subgroup, or None if no data\n",
        "        \"\"\"\n",
        "        df = self.analysis_data\n",
        "        config = self.subgroup_config\n",
        "\n",
        "        # Clean moderator columns\n",
        "        df[config.moderator1] = df[config.moderator1].astype(str).str.strip()\n",
        "        if config.moderator2:\n",
        "            df[config.moderator2] = df[config.moderator2].astype(str).str.strip()\n",
        "\n",
        "        # Filter based on analysis type\n",
        "        if config.analysis_type == 'single':\n",
        "            group_name = str(group_identifier)\n",
        "            subset = df[df[config.moderator1] == group_name].copy()\n",
        "        else:  # two_way\n",
        "            if not isinstance(group_identifier, tuple) or len(group_identifier) != 2:\n",
        "                raise ValueError(f\"Expected tuple for two_way analysis, got {type(group_identifier)}\")\n",
        "\n",
        "            mod1_val, mod2_val = group_identifier\n",
        "            subset = df[\n",
        "                (df[config.moderator1] == mod1_val) &\n",
        "                (df[config.moderator2] == mod2_val)\n",
        "            ].copy()\n",
        "\n",
        "        return subset if len(subset) >= 2 else None\n",
        "\n",
        "    def get_vcv_for_study(\n",
        "        self,\n",
        "        study_id: Union[str, int],\n",
        "        variance_vector: np.ndarray\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, bool]:\n",
        "        \"\"\"\n",
        "        Get variance-covariance matrices for a study (both full and diagonal).\n",
        "\n",
        "        Args:\n",
        "            study_id: Study identifier\n",
        "            variance_vector: Array of variances for this study\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (full_matrix, diagonal_matrix, has_off_diagonal)\n",
        "        \"\"\"\n",
        "        vcv_dict = self.vcv_matrices\n",
        "\n",
        "        # Default diagonal matrix\n",
        "        diag_matrix = np.diag(variance_vector)\n",
        "\n",
        "        # Try to find full matrix\n",
        "        study_id_str = str(study_id)\n",
        "\n",
        "        if study_id_str in vcv_dict:\n",
        "            full_matrix = np.asarray(vcv_dict[study_id_str], dtype=np.float64)\n",
        "        elif study_id in vcv_dict:\n",
        "            full_matrix = np.asarray(vcv_dict[study_id], dtype=np.float64)\n",
        "        else:\n",
        "            full_matrix = diag_matrix\n",
        "\n",
        "        # Check for off-diagonal elements\n",
        "        has_off_diagonal = not np.allclose(\n",
        "            full_matrix,\n",
        "            np.diag(np.diag(full_matrix))\n",
        "        )\n",
        "\n",
        "        return full_matrix, diag_matrix, has_off_diagonal\n",
        "\n",
        "    def prepare_three_level_data(\n",
        "        self,\n",
        "        subgroup_df: pd.DataFrame\n",
        "    ) -> Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], bool]:\n",
        "        \"\"\"\n",
        "        Prepare data structures for three-level meta-analysis.\n",
        "\n",
        "        Args:\n",
        "            subgroup_df: DataFrame for specific subgroup\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (y_all, vcv_full, vcv_diag, has_shared_controls)\n",
        "        \"\"\"\n",
        "        # Sort for deterministic alignment\n",
        "        subgroup_df = subgroup_df.sort_values('id').reset_index(drop=True)\n",
        "\n",
        "        grouped = subgroup_df.groupby('id', sort=False)\n",
        "\n",
        "        y_all = []\n",
        "        vcv_full = []\n",
        "        vcv_diag = []\n",
        "        has_shared_controls = False\n",
        "\n",
        "        for study_id, group in grouped:\n",
        "            # Effect sizes\n",
        "            y = np.asarray(group[self.effect_col].values, dtype=np.float64)\n",
        "            y_all.append(y)\n",
        "\n",
        "            # Variances\n",
        "            vi = np.asarray(group[self.var_col].values, dtype=np.float64)\n",
        "\n",
        "            # Get VCV matrices\n",
        "            full_mat, diag_mat, has_off_diag = self.get_vcv_for_study(study_id, vi)\n",
        "\n",
        "            vcv_full.append(full_mat)\n",
        "            vcv_diag.append(diag_mat)\n",
        "\n",
        "            if has_off_diag:\n",
        "                has_shared_controls = True\n",
        "\n",
        "        return y_all, vcv_full, vcv_diag, has_shared_controls\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RESULT PERSISTENCE METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def save_subgroup_results(\n",
        "        self,\n",
        "        results_df: pd.DataFrame,\n",
        "        metadata: Dict[str, Any]\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Save subgroup analysis results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            results_df: DataFrame containing all subgroup results\n",
        "            metadata: Dictionary with QM, R_squared, etc.\n",
        "        \"\"\"\n",
        "        import datetime\n",
        "\n",
        "        self._config['subgroup_results'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'results_df': results_df,\n",
        "            'analysis_type': self.subgroup_config.analysis_type,\n",
        "            'moderator1': self.subgroup_config.moderator1,\n",
        "            'moderator2': self.subgroup_config.moderator2,\n",
        "            **metadata  # Qt_overall, QM, Qe, df_QM, df_Qe, p_value_QM, R_squared\n",
        "        }\n",
        "\n",
        "    def save_publication_text(self, text: str) -> None:\n",
        "        \"\"\"Save publication-ready text\"\"\"\n",
        "        self._config['subgroup_text'] = text\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTILITY METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def get_group_display_name(\n",
        "        self,\n",
        "        group_identifier: Union[str, Tuple[str, str]]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Get human-readable group name.\n",
        "\n",
        "        Args:\n",
        "            group_identifier: Group identifier\n",
        "\n",
        "        Returns:\n",
        "            Formatted group name\n",
        "        \"\"\"\n",
        "        config = self.subgroup_config\n",
        "\n",
        "        if config.analysis_type == 'single':\n",
        "            return str(group_identifier)\n",
        "        else:\n",
        "            mod1_val, mod2_val = group_identifier\n",
        "            return f\"{mod1_val} \u00d7 {mod2_val}\"\n",
        "\n",
        "    def summary_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get summary of current configuration\"\"\"\n",
        "        config = self.subgroup_config\n",
        "        settings = self.global_settings\n",
        "\n",
        "        return {\n",
        "            'analysis_type': config.analysis_type,\n",
        "            'moderator1': config.moderator1,\n",
        "            'moderator2': config.moderator2,\n",
        "            'n_groups': len(config.valid_groups_list),\n",
        "            'effect_col': self.effect_col,\n",
        "            'var_col': self.var_col,\n",
        "            'alpha': settings.alpha,\n",
        "            'ci_percent': settings.ci_percent,\n",
        "            'dist_type': settings.dist_type,\n",
        "            'total_observations': len(self.analysis_data),\n",
        "            'n_studies': self.analysis_data['id'].nunique()\n",
        "        }\n",
        "\n",
        "\n",
        "#@title \ud83d\udd2c 9. Subgroup Analysis: ANALYSIS LAYER (Business Logic) - FIXED\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 2/4: ANALYSIS LAYER - CORRECTED VERSION\n",
        "# Purpose: Pure statistical computation without UI dependencies\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, chi2, t\n",
        "from scipy.optimize import minimize\n",
        "from typing import Dict, Any, Optional, Tuple, List, Union\n",
        "import warnings\n",
        "from dataclasses import asdict\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STATISTICAL COMPUTATION ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "class SubgroupAnalyzer:\n",
        "    \"\"\"\n",
        "    Pure statistical analysis engine for subgroup meta-analysis.\n",
        "    Contains no UI code - only mathematical computations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        effect_col: str,\n",
        "        var_col: str,\n",
        "        global_settings: 'GlobalSettings',\n",
        "        es_config: Dict[str, Any]\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize analyzer with configuration.\n",
        "\n",
        "        Args:\n",
        "            effect_col: Name of effect size column\n",
        "            var_col: Name of variance column\n",
        "            global_settings: GlobalSettings object with alpha, dist_type\n",
        "            es_config: Effect size configuration dictionary\n",
        "        \"\"\"\n",
        "        self.effect_col = effect_col\n",
        "        self.var_col = var_col\n",
        "        self.settings = global_settings\n",
        "        self.es_config = es_config\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # THREE-LEVEL META-ANALYSIS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_three_level_analysis(\n",
        "        self,\n",
        "        y_all: List[np.ndarray],\n",
        "        vcv_full: List[np.ndarray],\n",
        "        vcv_diag: List[np.ndarray],\n",
        "        has_shared_controls: bool,\n",
        "        n_total: int,\n",
        "        m_studies: int\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Run robust three-level meta-analysis with graceful degradation.\n",
        "\n",
        "        Execution Strategy:\n",
        "          - Plan A: 3-Level with full VCV matrices (handles shared controls)\n",
        "          - Plan B: 3-Level with diagonal VCV (independence assumption)\n",
        "          - Plan C: 2-Level model (single variance component)\n",
        "\n",
        "        Args:\n",
        "            y_all: List of effect size arrays per study\n",
        "            vcv_full: List of full VCV matrices\n",
        "            vcv_diag: List of diagonal VCV matrices\n",
        "            has_shared_controls: Whether any study has off-diagonal elements\n",
        "            n_total: Total number of observations\n",
        "            m_studies: Number of studies\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with estimates, or None if all plans fail\n",
        "        \"\"\"\n",
        "        # Minimum requirements check\n",
        "        if m_studies < 2:\n",
        "            return None\n",
        "\n",
        "        # Count multi-observation studies (needed for sigma\u00b2 identification)\n",
        "        n_multi_obs = sum(1 for y in y_all if len(y) > 1)\n",
        "\n",
        "        # Determine if 3-level is viable\n",
        "        three_level_viable = n_multi_obs >= 1 and n_total > m_studies\n",
        "\n",
        "        best_result = None\n",
        "        model_type = None\n",
        "\n",
        "        # Plan A: Full 3-Level with VCV (only if we have shared controls)\n",
        "        if three_level_viable and has_shared_controls:\n",
        "            best_result = self._optimize_three_level(\n",
        "                y_all, vcv_full, n_total, m_studies\n",
        "            )\n",
        "            if best_result is not None:\n",
        "                model_type = '3-level-vcv'\n",
        "\n",
        "        # Plan B: 3-Level with Diagonal\n",
        "        if best_result is None and three_level_viable:\n",
        "            best_result = self._optimize_three_level(\n",
        "                y_all, vcv_diag, n_total, m_studies\n",
        "            )\n",
        "            if best_result is not None:\n",
        "                model_type = '3-level-diag'\n",
        "\n",
        "        # Plan C: 2-Level Model\n",
        "        if best_result is None:\n",
        "            best_result = self._optimize_two_level(\n",
        "                y_all, vcv_diag, n_total, m_studies\n",
        "            )\n",
        "            if best_result is not None:\n",
        "                model_type = '2-level'\n",
        "\n",
        "        # All plans failed\n",
        "        if best_result is None:\n",
        "            return None\n",
        "\n",
        "        # Add metadata\n",
        "        best_result['model_type'] = model_type\n",
        "        best_result['n_studies'] = m_studies\n",
        "        best_result['n_observations'] = n_total\n",
        "        best_result['n_multi_obs_studies'] = n_multi_obs\n",
        "\n",
        "        return best_result\n",
        "\n",
        "    def _optimize_three_level(\n",
        "        self,\n",
        "        y_all: List[np.ndarray],\n",
        "        vcv_all: List[np.ndarray],\n",
        "        n_total: int,\n",
        "        m_studies: int\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Optimize 3-level model (tau\u00b2, sigma\u00b2).\n",
        "\n",
        "        Returns:\n",
        "            Estimates dictionary or None if optimization fails\n",
        "        \"\"\"\n",
        "        # Generate smart starting points\n",
        "        start_points = self._generate_start_points(y_all, vcv_all)\n",
        "\n",
        "        best_res = None\n",
        "        best_fun = np.inf\n",
        "\n",
        "        # Try multiple starting points\n",
        "        for start in start_points:\n",
        "            try:\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "                    res = minimize(\n",
        "                        _negative_log_likelihood_reml,\n",
        "                        x0=start,\n",
        "                        args=(y_all, vcv_all, n_total, m_studies),\n",
        "                        method='L-BFGS-B',\n",
        "                        bounds=[(1e-8, 50.0), (1e-8, 50.0)],\n",
        "                        options={\n",
        "                            'ftol': 1e-12,\n",
        "                            'gtol': 1e-10,\n",
        "                            'maxiter': 5000,\n",
        "                            'maxfun': 10000\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                    if res.success and np.isfinite(res.fun) and res.fun < best_fun:\n",
        "                        best_fun = res.fun\n",
        "                        best_res = res\n",
        "\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        # Fallback: BFGS with log-transformed parameters\n",
        "        if best_res is None:\n",
        "            best_res = self._optimize_log_space(y_all, vcv_all, n_total, m_studies)\n",
        "\n",
        "        # Extract estimates\n",
        "        if best_res is not None:\n",
        "            try:\n",
        "                estimates = _get_three_level_estimates(\n",
        "                    best_res.x, y_all, vcv_all, n_total, m_studies\n",
        "                )\n",
        "                estimates['optimizer_success'] = best_res.success\n",
        "                estimates['optimizer_message'] = getattr(best_res, 'message', '')\n",
        "                return estimates\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _optimize_two_level(\n",
        "        self,\n",
        "        y_all: List[np.ndarray],\n",
        "        vcv_all: List[np.ndarray],\n",
        "        n_total: int,\n",
        "        m_studies: int\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Optimize 2-level model (tau\u00b2 only, sigma\u00b2\u22480).\n",
        "\n",
        "        Returns:\n",
        "            Estimates dictionary or None if optimization fails\n",
        "        \"\"\"\n",
        "        start_points = [0.01, 0.1, 0.5, 1.0, 2.0]\n",
        "\n",
        "        # Add DL estimate if possible\n",
        "        try:\n",
        "            # Create temporary DataFrame for DL estimator\n",
        "            temp_data = []\n",
        "            for y_vec in y_all:\n",
        "                for y_val in y_vec:\n",
        "                    temp_data.append({self.effect_col: y_val})\n",
        "\n",
        "            # Get corresponding variances\n",
        "            var_data = []\n",
        "            for vcv_mat in vcv_all:\n",
        "                for var_val in np.diag(vcv_mat):\n",
        "                    var_data.append(var_val)\n",
        "\n",
        "            temp_df = pd.DataFrame(temp_data)\n",
        "            temp_df[self.var_col] = var_data\n",
        "\n",
        "            tau_sq_dl, _ = calculate_tau_squared(\n",
        "                temp_df, self.effect_col, self.var_col, method='DL'\n",
        "            )\n",
        "\n",
        "            if tau_sq_dl is not None and tau_sq_dl > 0:\n",
        "                start_points.insert(0, tau_sq_dl)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        def neg_ll_two_level(tau_sq_scalar, y_all, vcv_all, n_total, m_studies):\n",
        "            \"\"\"Wrapper that fixes sigma\u00b2\u22480\"\"\"\n",
        "            params = np.array([tau_sq_scalar[0], 1e-10])\n",
        "            return _negative_log_likelihood_reml(params, y_all, vcv_all, n_total, m_studies)\n",
        "\n",
        "        best_res = None\n",
        "        best_fun = np.inf\n",
        "\n",
        "        for start in start_points:\n",
        "            try:\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.simplefilter(\"ignore\")\n",
        "\n",
        "                    res = minimize(\n",
        "                        neg_ll_two_level,\n",
        "                        x0=[start],\n",
        "                        args=(y_all, vcv_all, n_total, m_studies),\n",
        "                        method='L-BFGS-B',\n",
        "                        bounds=[(1e-8, 50.0)],\n",
        "                        options={'ftol': 1e-11}\n",
        "                    )\n",
        "\n",
        "                    if res.success and np.isfinite(res.fun) and res.fun < best_fun:\n",
        "                        best_fun = res.fun\n",
        "                        res.x = np.array([res.x[0], 1e-10])\n",
        "                        best_res = res\n",
        "\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        if best_res is not None:\n",
        "            try:\n",
        "                estimates = _get_three_level_estimates(\n",
        "                    best_res.x, y_all, vcv_all, n_total, m_studies\n",
        "                )\n",
        "                estimates['optimizer_success'] = best_res.success\n",
        "                return estimates\n",
        "            except Exception:\n",
        "                return None\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _optimize_log_space(\n",
        "        self,\n",
        "        y_all: List[np.ndarray],\n",
        "        vcv_all: List[np.ndarray],\n",
        "        n_total: int,\n",
        "        m_studies: int\n",
        "    ) -> Optional[Any]:\n",
        "        \"\"\"\n",
        "        Fallback optimizer using log-transformed parameters.\n",
        "\n",
        "        Returns:\n",
        "            Optimization result or None\n",
        "        \"\"\"\n",
        "        try:\n",
        "            def neg_ll_log_params(log_params, *args):\n",
        "                params = np.exp(log_params)\n",
        "                return _negative_log_likelihood_reml(params, *args)\n",
        "\n",
        "            res = minimize(\n",
        "                neg_ll_log_params,\n",
        "                x0=np.log([0.1, 0.1]),\n",
        "                args=(y_all, vcv_all, n_total, m_studies),\n",
        "                method='BFGS',\n",
        "                options={'gtol': 1e-8}\n",
        "            )\n",
        "\n",
        "            if res.success and np.isfinite(res.fun):\n",
        "                res.x = np.exp(res.x)\n",
        "                return res\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _generate_start_points(\n",
        "        self,\n",
        "        y_all: List[np.ndarray],\n",
        "        vcv_all: List[np.ndarray]\n",
        "    ) -> List[List[float]]:\n",
        "        \"\"\"\n",
        "        Generate smart starting points for optimization.\n",
        "\n",
        "        Returns:\n",
        "            List of [tau\u00b2, sigma\u00b2] starting values\n",
        "        \"\"\"\n",
        "        start_points = [\n",
        "            [0.01, 0.01], [0.1, 0.1], [0.5, 0.5],\n",
        "            [1.0, 1.0], [1.0, 0.1], [0.1, 1.0]\n",
        "        ]\n",
        "\n",
        "        # Add DL-based starting point\n",
        "        try:\n",
        "            # Flatten data for DL estimator\n",
        "            all_effects = np.concatenate(y_all)\n",
        "            all_vars = np.concatenate([np.diag(vcv) for vcv in vcv_all])\n",
        "\n",
        "            temp_df = pd.DataFrame({\n",
        "                self.effect_col: all_effects,\n",
        "                self.var_col: all_vars\n",
        "            })\n",
        "\n",
        "            tau_sq_dl, _ = calculate_tau_squared(\n",
        "                temp_df, self.effect_col, self.var_col, method='DL'\n",
        "            )\n",
        "\n",
        "            if tau_sq_dl is not None and tau_sq_dl > 0:\n",
        "                start_points.insert(0, [tau_sq_dl, 0.01])\n",
        "                start_points.insert(1, [tau_sq_dl, tau_sq_dl * 0.5])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return start_points\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # CONFIDENCE INTERVALS & P-VALUES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def calculate_confidence_interval(\n",
        "        self,\n",
        "        estimate: float,\n",
        "        se: float,\n",
        "        df: int\n",
        "    ) -> Tuple[float, float, float]:\n",
        "        \"\"\"\n",
        "        Calculate confidence interval and p-value.\n",
        "\n",
        "        Args:\n",
        "            estimate: Point estimate\n",
        "            se: Standard error\n",
        "            df: Degrees of freedom (for t-distribution)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (ci_lower, ci_upper, p_value)\n",
        "        \"\"\"\n",
        "        alpha = self.settings.alpha\n",
        "        q_val = 1 - (alpha / 2)\n",
        "\n",
        "        if self.settings.dist_type == 't':\n",
        "            crit_val = t.ppf(q_val, df)\n",
        "            z_stat = estimate / se if se > 0 else 0\n",
        "            p_value = 2 * (1 - t.cdf(abs(z_stat), df))\n",
        "        else:\n",
        "            crit_val = norm.ppf(q_val)\n",
        "            z_stat = estimate / se if se > 0 else 0\n",
        "            p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "        ci_lower = estimate - crit_val * se\n",
        "        ci_upper = estimate + crit_val * se\n",
        "\n",
        "        return ci_lower, ci_upper, p_value\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # HETEROGENEITY METRICS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def calculate_i_squared(\n",
        "        self,\n",
        "        tau_squared: float,\n",
        "        sigma_squared: float,\n",
        "        mean_variance: float\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate I\u00b2 statistic.\n",
        "\n",
        "        Args:\n",
        "            tau_squared: Between-study variance\n",
        "            sigma_squared: Within-study variance\n",
        "            mean_variance: Mean sampling variance\n",
        "\n",
        "        Returns:\n",
        "            I\u00b2 as percentage\n",
        "        \"\"\"\n",
        "        total_variance = tau_squared + sigma_squared + mean_variance\n",
        "\n",
        "        if total_variance <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        between_variance = tau_squared + sigma_squared\n",
        "        i_squared = (between_variance / total_variance) * 100\n",
        "\n",
        "        return max(0.0, min(100.0, i_squared))\n",
        "\n",
        "    def calculate_q_statistic(\n",
        "        self,\n",
        "        subgroup_df: pd.DataFrame,\n",
        "        pooled_effect: float\n",
        "    ) -> Tuple[float, int]:\n",
        "        \"\"\"\n",
        "        Calculate Q statistic for within-group heterogeneity (FIXED-EFFECTS).\n",
        "\n",
        "        Args:\n",
        "            subgroup_df: DataFrame for subgroup\n",
        "            pooled_effect: Pooled effect estimate (FIXED-EFFECTS)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (Q_statistic, df)\n",
        "        \"\"\"\n",
        "        # CRITICAL FIX: Use fixed-effects pooled estimate, not random-effects\n",
        "        weights = 1 / subgroup_df[self.var_col]\n",
        "        effects = subgroup_df[self.effect_col]\n",
        "\n",
        "        # Calculate fixed-effects pooled estimate for Q calculation\n",
        "        sum_w = weights.sum()\n",
        "        pooled_fe = (weights * effects).sum() / sum_w if sum_w > 0 else 0\n",
        "\n",
        "        # Q statistic based on fixed-effects estimate\n",
        "        Q = np.sum(weights * (effects - pooled_fe)**2)\n",
        "        df = len(subgroup_df) - 1\n",
        "\n",
        "        return Q, df\n",
        "\n",
        "    def calculate_fold_change(self, log_effect: float) -> float:\n",
        "        \"\"\"\n",
        "        Calculate fold change from log effect size.\n",
        "\n",
        "        Args:\n",
        "            log_effect: Effect size on log scale\n",
        "\n",
        "        Returns:\n",
        "            Fold change (positive or negative)\n",
        "        \"\"\"\n",
        "        if not self.es_config.get('has_fold_change', False):\n",
        "            return np.nan\n",
        "\n",
        "        RR = np.exp(log_effect)\n",
        "        fold_change = RR if log_effect >= 0 else -1/RR\n",
        "\n",
        "        return fold_change\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # HETEROGENEITY PARTITIONING (FIXED)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def partition_heterogeneity(\n",
        "        self,\n",
        "        qt_overall: float,\n",
        "        q_within_sum: float,\n",
        "        n_groups: int,\n",
        "        k_overall: int\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Partition total heterogeneity into between and within components.\n",
        "\n",
        "        CRITICAL FIX: Ensure QM is non-negative and properly calculated.\n",
        "\n",
        "        Args:\n",
        "            qt_overall: Total Q from overall analysis\n",
        "            q_within_sum: Sum of within-group Q statistics\n",
        "            n_groups: Number of subgroups\n",
        "            k_overall: Total number of effect sizes\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with QM, df, p-value, R\u00b2\n",
        "        \"\"\"\n",
        "        # FIXED: Ensure proper calculation\n",
        "        QM = qt_overall - q_within_sum\n",
        "\n",
        "        # Safeguard against numerical errors\n",
        "        if QM < 0 or not np.isfinite(QM):\n",
        "            QM = 0.0\n",
        "\n",
        "        df_QM = n_groups - 1\n",
        "        df_QE = k_overall - n_groups\n",
        "\n",
        "        # Test for moderation\n",
        "        if df_QM > 0 and QM > 0:\n",
        "            p_value_QM = 1 - chi2.cdf(QM, df_QM)\n",
        "        else:\n",
        "            p_value_QM = 1.0  # Non-significant if QM = 0\n",
        "\n",
        "        # Proportion of variance explained\n",
        "        if qt_overall > 0 and QM > 0:\n",
        "            R_squared = (QM / qt_overall) * 100\n",
        "        else:\n",
        "            R_squared = 0.0\n",
        "\n",
        "        # Ensure R\u00b2 is within valid range\n",
        "        R_squared = max(0.0, min(100.0, R_squared))\n",
        "\n",
        "        return {\n",
        "            'QM': QM,\n",
        "            'df_QM': df_QM,\n",
        "            'QE': q_within_sum,\n",
        "            'df_QE': df_QE,\n",
        "            'p_value_QM': p_value_QM,\n",
        "            'R_squared': R_squared\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SUBGROUP ANALYSIS ORCHESTRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class SubgroupAnalysisEngine:\n",
        "    \"\"\"\n",
        "    High-level orchestrator that coordinates the full subgroup analysis.\n",
        "    Combines data management and statistical computation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_manager: 'SubgroupDataManager'):\n",
        "        \"\"\"\n",
        "        Initialize engine with data manager.\n",
        "\n",
        "        Args:\n",
        "            data_manager: SubgroupDataManager instance\n",
        "        \"\"\"\n",
        "        self.data_manager = data_manager\n",
        "        self.analyzer = SubgroupAnalyzer(\n",
        "            effect_col=data_manager.effect_col,\n",
        "            var_col=data_manager.var_col,\n",
        "            global_settings=data_manager.global_settings,\n",
        "            es_config=data_manager.es_config\n",
        "        )\n",
        "\n",
        "    def analyze_single_subgroup(\n",
        "        self,\n",
        "        group_identifier: Union[str, Tuple[str, str]],\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> Optional['SubgroupResult']:\n",
        "        \"\"\"\n",
        "        Analyze a single subgroup.\n",
        "\n",
        "        Args:\n",
        "            group_identifier: Group identifier (string or tuple)\n",
        "            progress_callback: Optional callback(message: str) for progress updates\n",
        "\n",
        "        Returns:\n",
        "            SubgroupResult object or None if analysis fails\n",
        "        \"\"\"\n",
        "        # Log progress\n",
        "        if progress_callback:\n",
        "            group_name = self.data_manager.get_group_display_name(group_identifier)\n",
        "            progress_callback(f\"Starting analysis: {group_name}\")\n",
        "\n",
        "        # Get subgroup data\n",
        "        subgroup_df = self.data_manager.get_subgroup_data(group_identifier)\n",
        "\n",
        "        if subgroup_df is None or len(subgroup_df) < 2:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\u274c Insufficient data\")\n",
        "            return None\n",
        "\n",
        "        k_group = len(subgroup_df)\n",
        "        n_papers = subgroup_df['id'].nunique()\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback(f\"\ud83d\udcca k={k_group}, studies={n_papers}\")\n",
        "\n",
        "        # Prepare three-level data structures\n",
        "        y_all, vcv_full, vcv_diag, has_shared = \\\n",
        "            self.data_manager.prepare_three_level_data(subgroup_df)\n",
        "\n",
        "        # Run three-level analysis\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udd04 Running optimization...\")\n",
        "\n",
        "        estimates = self.analyzer.run_three_level_analysis(\n",
        "            y_all=y_all,\n",
        "            vcv_full=vcv_full,\n",
        "            vcv_diag=vcv_diag,\n",
        "            has_shared_controls=has_shared,\n",
        "            n_total=k_group,\n",
        "            m_studies=n_papers\n",
        "        )\n",
        "\n",
        "        if estimates is None:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\u274c Optimization failed\")\n",
        "            return None\n",
        "\n",
        "        # Extract estimates\n",
        "        mu = estimates['mu']\n",
        "        se = estimates['se_mu']\n",
        "        var = estimates['var_mu']\n",
        "        tau_sq = estimates['tau_sq']\n",
        "        sigma_sq = estimates['sigma_sq']\n",
        "        model_type = estimates['model_type']\n",
        "\n",
        "        # Calculate CI and p-value\n",
        "        df = max(1, n_papers - 1)\n",
        "        ci_lower, ci_upper, p_value = self.analyzer.calculate_confidence_interval(\n",
        "            estimate=mu,\n",
        "            se=se,\n",
        "            df=df\n",
        "        )\n",
        "\n",
        "        # Calculate I\u00b2\n",
        "        mean_vi = subgroup_df[self.data_manager.var_col].mean()\n",
        "        i_squared = self.analyzer.calculate_i_squared(tau_sq, sigma_sq, mean_vi)\n",
        "\n",
        "        # Calculate Q statistic (FIXED: pass mu as pooled_effect)\n",
        "        Q_within, df_Q = self.analyzer.calculate_q_statistic(subgroup_df, mu)\n",
        "\n",
        "        # Calculate fold change\n",
        "        fold_change = self.analyzer.calculate_fold_change(mu)\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback(f\"\u2705 Effect: {mu:.3f} | Model: {model_type}\")\n",
        "\n",
        "        # Build result object\n",
        "        group_name = self.data_manager.get_group_display_name(group_identifier)\n",
        "\n",
        "        result = SubgroupResult(\n",
        "            group=group_name,\n",
        "            k=k_group,\n",
        "            n_papers=n_papers,\n",
        "            pooled_effect_re=mu,\n",
        "            pooled_se_re=se,\n",
        "            pooled_var_re=var,\n",
        "            ci_lower_re=ci_lower,\n",
        "            ci_upper_re=ci_upper,\n",
        "            p_value_re=p_value,\n",
        "            I_squared=i_squared,\n",
        "            tau_squared=tau_sq,\n",
        "            sigma_squared=sigma_sq,\n",
        "            fold_change_re=fold_change,\n",
        "            Q_within=Q_within,\n",
        "            df_Q=df_Q,\n",
        "            model_type=model_type\n",
        "        )\n",
        "\n",
        "        # Add moderator values for two-way analysis\n",
        "        if self.data_manager.subgroup_config.analysis_type == 'two_way':\n",
        "            result.moderator1_value = group_identifier[0]\n",
        "            result.moderator2_value = group_identifier[1]\n",
        "\n",
        "        return result\n",
        "\n",
        "    def analyze_all_subgroups(\n",
        "        self,\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Analyze all configured subgroups.\n",
        "\n",
        "        Args:\n",
        "            progress_callback: Optional callback for progress updates\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (results_df, heterogeneity_dict)\n",
        "        \"\"\"\n",
        "        config = self.data_manager.subgroup_config\n",
        "        valid_groups = config.valid_groups_list\n",
        "\n",
        "        results_list = []\n",
        "        total_q_within = 0.0\n",
        "\n",
        "        # Analyze each subgroup\n",
        "        for idx, group_id in enumerate(valid_groups, 1):\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"\\n{'='*60}\")\n",
        "                progress_callback(f\"Subgroup {idx}/{len(valid_groups)}\")\n",
        "                progress_callback(f\"{'='*60}\")\n",
        "\n",
        "            result = self.analyze_single_subgroup(group_id, progress_callback)\n",
        "\n",
        "            if result is not None:\n",
        "                results_list.append(asdict(result))\n",
        "                total_q_within += result.Q_within\n",
        "\n",
        "        # Create results DataFrame\n",
        "        if not results_list:\n",
        "            raise ValueError(\"No subgroups were successfully analyzed\")\n",
        "\n",
        "        results_df = pd.DataFrame(results_list)\n",
        "\n",
        "        # Calculate heterogeneity partitioning (FIXED)\n",
        "        overall = self.data_manager.overall_results\n",
        "\n",
        "        heterogeneity = self.analyzer.partition_heterogeneity(\n",
        "            qt_overall=overall['Qt'],\n",
        "            q_within_sum=total_q_within,\n",
        "            n_groups=len(results_df),\n",
        "            k_overall=overall['k']\n",
        "        )\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback(f\"\\n{'='*60}\")\n",
        "            progress_callback(\"\u2705 ANALYSIS COMPLETE\")\n",
        "            progress_callback(f\"{'='*60}\")\n",
        "\n",
        "        return results_df, heterogeneity\n",
        "\n",
        "\n",
        "\n",
        "#@title \ud83d\udd2c 9. Subgroup Analysis: PRESENTATION LAYER (View) - PART 1\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 3/4: PRESENTATION LAYER\n",
        "# Purpose: Pure UI rendering without business logic or data access\n",
        "# Dependencies:\n",
        "#   - Data Layer (SubgroupDataManager, SubgroupResult, GlobalSettings)\n",
        "#   - Analysis Layer (SubgroupAnalyzer results)\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Any, Optional, List\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HTML TEMPLATE GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class HTMLTemplates:\n",
        "    \"\"\"\n",
        "    Static HTML template generators for consistent styling.\n",
        "    All methods are pure functions that return HTML strings.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def card(content: str, bg_color: str = '#f8f9fa', border_color: str = '#dee2e6') -> str:\n",
        "        \"\"\"Generate a styled card container\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: {bg_color}; padding: 15px; border-radius: 5px;\n",
        "                    margin: 10px 0; border: 1px solid {border_color};'>\n",
        "            {content}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def header(text: str, level: int = 3, color: str = '#2c3e50') -> str:\n",
        "        \"\"\"Generate a styled header\"\"\"\n",
        "        border = \"border-bottom: 2px solid #3498db; padding-bottom: 10px;\" if level == 3 else \"\"\n",
        "        return f\"<h{level} style='color: {color}; {border}'>{text}</h{level}>\"\n",
        "\n",
        "    @staticmethod\n",
        "    def error_message(error_type: str, message: str, details: Optional[str] = None) -> str:\n",
        "        \"\"\"Generate styled error message\"\"\"\n",
        "        html = f\"\"\"\n",
        "        <div style='color: red; background-color: #f8d7da; padding: 15px;\n",
        "                    border-radius: 5px; margin: 10px 0; border: 1px solid #f5c6cb;'>\n",
        "            <b>\u274c {error_type}:</b> {message}\n",
        "        \"\"\"\n",
        "        if details:\n",
        "            html += f\"<pre style='margin-top: 10px; font-size: 0.9em;'>{details}</pre>\"\n",
        "        html += \"</div>\"\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def success_message(message: str) -> str:\n",
        "        \"\"\"Generate styled success message\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='color: #155724; background-color: #d4edda; padding: 15px;\n",
        "                    border-radius: 5px; margin: 10px 0; border: 1px solid #c3e6cb;'>\n",
        "            \u2705 {message}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def warning_message(message: str) -> str:\n",
        "        \"\"\"Generate styled warning message\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='color: #856404; background-color: #fff3cd; padding: 15px;\n",
        "                    border-radius: 5px; margin: 10px 0; border: 1px solid #ffeeba;'>\n",
        "            \u26a0\ufe0f {message}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def significance_legend() -> str:\n",
        "        \"\"\"Generate significance legend\"\"\"\n",
        "        return \"\"\"\n",
        "        <div style='font-size: 0.9em; color: #555; margin-top: 10px;\n",
        "                    background-color: #f8f9fa; padding: 10px; border-radius: 4px;'>\n",
        "            <b>Legend:</b> *** p < 0.001; ** p < 0.01; * p < 0.05\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def model_type_legend() -> str:\n",
        "        \"\"\"Generate model type explanation\"\"\"\n",
        "        return \"\"\"\n",
        "        <div style='font-size: 0.9em; color: #555; margin-top: 10px;\n",
        "                    background-color: #f8f9fa; padding: 10px; border-radius: 4px;'>\n",
        "            <b>Model Codes:</b><br>\n",
        "            \u2022 <b>3L-VCV (Plan A):</b> 3-Level model with full Variance-Covariance Matrix (Shared Controls).<br>\n",
        "            \u2022 <b>3L-Diag (Plan B):</b> 3-Level model assuming independence (fallback for stability).<br>\n",
        "            \u2022 <b>2L (Plan C):</b> 2-Level model (single variance component) used for very small subgroups.\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PUBLICATION TEXT GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class PublicationTextGenerator:\n",
        "    \"\"\"\n",
        "    Generates publication-ready text for manuscripts.\n",
        "    All methods return formatted HTML strings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ci_percent: float = 95):\n",
        "        \"\"\"\n",
        "        Initialize generator.\n",
        "\n",
        "        Args:\n",
        "            ci_percent: Confidence interval percentage (e.g., 95)\n",
        "        \"\"\"\n",
        "        self.ci_percent = ci_percent\n",
        "\n",
        "    def generate_methods_section(\n",
        "        self,\n",
        "        moderator1: str,\n",
        "        moderator2: Optional[str],\n",
        "        n_groups: int\n",
        "    ) -> str:\n",
        "        \"\"\"Generate Materials and Methods section\"\"\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;\n",
        "                    border: 1px solid #eee; margin-bottom: 20px;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db;\n",
        "                   padding-bottom: 10px; margin-top: 0;'>Materials and Methods</h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Subgroup Analysis.</b> To investigate potential sources of heterogeneity,\n",
        "        we conducted a mixed-effects subgroup analysis [1]. The categorical moderator(s)\n",
        "        tested were <b>{moderator1}</b>\"\"\"\n",
        "\n",
        "        if moderator2:\n",
        "            html += f\" and <b>{moderator2}</b>\"\n",
        "\n",
        "        html += f\"\"\". The analysis partitioned the total heterogeneity into within-group\n",
        "        variance and between-group variance.\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Statistical Tests.</b> Differences between subgroups were assessed using the\n",
        "        omnibus <i>Q</i>-test for moderation (<i>Q</i><sub>M</sub>) [2]. A significant\n",
        "        <i>Q</i><sub>M</sub> indicates that the effect sizes vary systematically across\n",
        "        the categories of the moderator. We also calculated the <i>R</i>\u00b2 statistic [3]\n",
        "        to quantify the proportion of between-study variance explained by the moderator.\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Model Specification.</b> A separate random-effects model was fitted within\n",
        "        each of the {n_groups} subgroups to estimate group-specific pooled effects and\n",
        "        heterogeneity (<i>I</i>\u00b2, \u03c4\u00b2). Common between-study variance was not assumed;\n",
        "        each subgroup was allowed to have its own heterogeneity estimate. All computations\n",
        "        were performed using the Co-Meta toolkit [4].\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 20px; font-size: 11pt;'>References</h4>\n",
        "        <ol style='font-size: 10pt; color: #555;'>\n",
        "            <li>Borenstein, M., Hedges, L. V., Higgins, J. P., & Rothstein, H. R. (2009).\n",
        "                <i>Introduction to Meta-Analysis</i>. Chichester, UK: John Wiley & Sons.</li>\n",
        "            <li>Cochran, W. G. (1954). The combination of estimates from different experiments.\n",
        "                <i>Biometrics</i>, 10(1), 101-129.</li>\n",
        "            <li>Raudenbush, S. W. (2009). Analyzing effect sizes: Random-effects models.\n",
        "                In H. Cooper, L. V. Hedges, & J. C. Valentine (Eds.),\n",
        "                <i>The Handbook of Research Synthesis and Meta-Analysis</i> (2nd ed., pp. 295-315).\n",
        "                New York: Russell Sage Foundation.</li>\n",
        "            <li><b>[CITATION FOR THIS TOOL]:</b> Author, A. A. (202X).\n",
        "                <i>Co-Meta: An Interactive Pipeline for Meta-Analysis</i>. [Repository/DOI].</li>\n",
        "        </ol>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    def generate_results_section(\n",
        "        self,\n",
        "        results_df: pd.DataFrame,\n",
        "        moderator1: str,\n",
        "        moderator2: Optional[str],\n",
        "        heterogeneity: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"Generate complete Results section with interpretation\"\"\"\n",
        "\n",
        "        QM = heterogeneity['QM']\n",
        "        df_QM = heterogeneity['df_QM']\n",
        "        p_QM = heterogeneity['p_value_QM']\n",
        "        R_sq = heterogeneity['R_squared']\n",
        "        QE = heterogeneity['QE']\n",
        "        df_QE = heterogeneity['df_QE']\n",
        "        Qt = QM + QE\n",
        "\n",
        "        M_groups = len(results_df)\n",
        "        sig_QM = \"significant\" if p_QM < 0.05 else \"non-significant\"\n",
        "        p_format = f\"< 0.001\" if p_QM < 0.001 else f\"= {p_QM:.3f}\"\n",
        "\n",
        "        # R\u00b2 interpretation\n",
        "        if R_sq < 25:\n",
        "            r2_interp = \"low R\u00b2 value suggests that this moderator explains only a small proportion of heterogeneity\"\n",
        "        elif R_sq < 50:\n",
        "            r2_interp = \"moderate R\u00b2 value indicates that this moderator partially explains the heterogeneity\"\n",
        "        else:\n",
        "            r2_interp = \"high R\u00b2 value indicates that this moderator is a substantial source of heterogeneity\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>\n",
        "            Subgroup Analysis Results\n",
        "        </h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        To explore sources of heterogeneity, we conducted a subgroup analysis based on\n",
        "        <b>{moderator1}</b>\"\"\"\n",
        "\n",
        "        if moderator2:\n",
        "            html += f\" and <b>{moderator2}</b>. We examined the interaction between these two moderators\"\n",
        "\n",
        "        html += f\"\"\". The dataset included <b>{M_groups}</b> subgroups with sufficient data\n",
        "        for analysis (minimum of 2 studies per subgroup).\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 25px;'>Overall Test for Subgroup Differences</h4>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        The test for subgroup differences was <b>{sig_QM}</b>\n",
        "        (<i>Q</i><sub>M</sub>({df_QM}) = <b>{QM:.2f}</b>, <i>p</i> {p_format}), \"\"\"\n",
        "\n",
        "        if p_QM < 0.05:\n",
        "            html += f\"\"\"indicating that the moderator variable significantly explained variation\n",
        "            in effect sizes across studies. The moderator accounted for <b>{R_sq:.1f}%</b> of\n",
        "            the total heterogeneity (<i>R</i>\u00b2 = {R_sq:.1f}%).\n",
        "            </p>\"\"\"\n",
        "        else:\n",
        "            html += f\"\"\"suggesting that the moderator variable did not significantly explain\n",
        "            variation in effect sizes across studies. The moderator accounted for only\n",
        "            <b>{R_sq:.1f}%</b> of the total heterogeneity (<i>R</i>\u00b2 = {R_sq:.1f}%).\n",
        "            </p>\"\"\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <h4 style='color: #34495e; margin-top: 25px;'>Heterogeneity Partitioning</h4>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        Heterogeneity was partitioned into between-group\n",
        "        (<i>Q</i><sub>M</sub>({df_QM}) = {QM:.2f}) and within-group components\n",
        "        (<i>Q</i><sub>E</sub>({df_QE}) = {QE:.2f}) from the total heterogeneity\n",
        "        (<i>Q</i><sub>T</sub>({int(df_QM + df_QE)}) = {Qt:.2f}). The {r2_interp}.\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 25px;'>Individual Subgroup Results</h4>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        Results by subgroup were as follows (Table 1):\n",
        "        </p>\n",
        "\n",
        "        <ul style='line-height: 2.0;'>\n",
        "        \"\"\"\n",
        "\n",
        "        # Individual subgroup summaries\n",
        "        for _, row in results_df.iterrows():\n",
        "            sig = \"significant\" if row['p_value_re'] < 0.05 else \"non-significant\"\n",
        "            p_fmt = f\"< 0.001\" if row['p_value_re'] < 0.001 else f\"= {row['p_value_re']:.3f}\"\n",
        "            het = \"with\" if row['I_squared'] >= 50 else \"without\"\n",
        "\n",
        "            html += f\"\"\"\n",
        "            <li><b>{row['group']}:</b> Based on {int(row['k'])} effect sizes from\n",
        "            {int(row['n_papers'])} studies, the pooled effect was <b>{row['pooled_effect_re']:.3f}</b>\n",
        "            ({self.ci_percent:.0f}% CI [{row['ci_lower_re']:.3f}, {row['ci_upper_re']:.3f}],\n",
        "            <i>p</i> {p_fmt}), {het} substantial heterogeneity\n",
        "            (<i>I</i>\u00b2 = {row['I_squared']:.1f}%, \u03c4\u00b2 = {row['tau_squared']:.4f},\n",
        "            \u03c3\u00b2 = {row['sigma_squared']:.4f}).</li>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"</ul>\"\n",
        "\n",
        "        # Comparative interpretation\n",
        "        max_row = results_df.loc[results_df['pooled_effect_re'].idxmax()]\n",
        "        min_row = results_df.loc[results_df['pooled_effect_re'].idxmin()]\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <h4 style='color: #34495e; margin-top: 25px;'>Comparative Interpretation</h4>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        The largest effect was observed for <b>{max_row['group']}</b>\n",
        "        ({max_row['pooled_effect_re']:.3f}, {self.ci_percent:.0f}% CI\n",
        "        [{max_row['ci_lower_re']:.3f}, {max_row['ci_upper_re']:.3f}])\"\"\"\n",
        "\n",
        "        if M_groups > 1:\n",
        "            html += f\"\"\", while <b>{min_row['group']}</b> showed the\n",
        "            {'smallest' if min_row['pooled_effect_re'] > 0 else 'most negative'} effect\n",
        "            ({min_row['pooled_effect_re']:.3f}, {self.ci_percent:.0f}% CI\n",
        "            [{min_row['ci_lower_re']:.3f}, {min_row['ci_upper_re']:.3f}])\"\"\"\n",
        "\n",
        "        html += \".</p>\"\n",
        "\n",
        "        # Interpretation guidance\n",
        "        if p_QM < 0.05:\n",
        "            html += f\"\"\"\n",
        "            <p style='text-align: justify;'>\n",
        "            These results demonstrate that <b>{moderator1}</b>\"\"\"\n",
        "            if moderator2:\n",
        "                html += f\" and <b>{moderator2}</b>\"\n",
        "            html += \"\"\" is an important moderator of the outcome, with differential effects\n",
        "            observed across subgroups. [<i>Add mechanistic explanation or theoretical context\n",
        "            specific to your research domain</i>]\n",
        "            </p>\"\"\"\n",
        "        else:\n",
        "            html += f\"\"\"\n",
        "            <p style='text-align: justify;'>\n",
        "            Although numerical differences were observed among subgroups, these differences\n",
        "            were not statistically significant. This suggests that <b>{moderator1}</b>\"\"\"\n",
        "            if moderator2:\n",
        "                html += f\" and <b>{moderator2}</b>\"\n",
        "            html += \"\"\" may not be a primary driver of heterogeneity in this meta-analysis,\n",
        "            or that insufficient statistical power limits our ability to detect subgroup\n",
        "            differences. [<i>Consider discussing alternative explanations or limitations</i>]\n",
        "            </p>\"\"\"\n",
        "\n",
        "        # Summary table\n",
        "        html += self._generate_results_table(results_df)\n",
        "\n",
        "        # Guidance box\n",
        "        html += \"\"\"\n",
        "        <hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "        <div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db;\n",
        "                    margin-top: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "            <ul style='margin-bottom: 0;'>\n",
        "                <li>Customize subgroup descriptions based on your specific moderator variables</li>\n",
        "                <li>Add domain-specific interpretations of why certain subgroups show different effects</li>\n",
        "                <li>Include relevant post-hoc pairwise comparisons if appropriate</li>\n",
        "                <li>Discuss potential confounding factors or limitations</li>\n",
        "                <li>Link findings to your theoretical framework</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107;\n",
        "                    margin-top: 15px;'>\n",
        "            <p style='margin: 0;'><b>\ud83d\udca1 Tip:</b> Select all text (Ctrl+A / Cmd+A),\n",
        "            copy (Ctrl+C / Cmd+C), and paste into your word processor.\n",
        "            Edit the [<i>bracketed notes</i>] to add your specific interpretations.</p>\n",
        "        </div>\n",
        "\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    def _generate_results_table(self, results_df: pd.DataFrame) -> str:\n",
        "        \"\"\"Generate formatted results table for publication text\"\"\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "        <div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db;\n",
        "                    margin-top: 25px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>\ud83d\udcca Table 1. Summary of Subgroup Analysis Results</h4>\n",
        "            <table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "                <thead style='background-color: #34495e; color: white;'>\n",
        "                    <tr>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Subgroup</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>k</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Studies</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Effect</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>{self.ci_percent:.0f}% CI</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>p</i>-value</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>I</i>\u00b2</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "        \"\"\"\n",
        "\n",
        "        for idx, row in results_df.iterrows():\n",
        "            bg = \"#f8f9fa\" if idx % 2 == 0 else \"white\"\n",
        "            bold = \"font-weight: bold;\" if row['p_value_re'] < 0.05 else \"\"\n",
        "\n",
        "            html += f\"\"\"\n",
        "                    <tr style='background-color: {bg};'>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px;'>{row['group']}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{int(row['k'])}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{int(row['n_papers'])}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center; {bold}'>{row['pooled_effect_re']:.3f}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{row['ci_lower_re']:.3f}, {row['ci_upper_re']:.3f}]</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{row['p_value_re']:.3g}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{row['I_squared']:.1f}%</td>\n",
        "                    </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "                </tbody>\n",
        "            </table>\n",
        "            <p style='margin-top: 10px; font-size: 0.9em; color: #6c757d;'>\n",
        "                <i>Note:</i> k = number of effect sizes; Studies = number of independent studies;\n",
        "                CI = confidence interval; <i>I</i>\u00b2 = heterogeneity statistic.\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "\n",
        "class SubgroupResultsView:\n",
        "    \"\"\"\n",
        "    Manages all UI rendering for subgroup analysis.\n",
        "    Contains zero business logic - only presentation code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ci_percent: float = 95):\n",
        "        \"\"\"\n",
        "        Initialize view with display settings.\n",
        "\n",
        "        Args:\n",
        "            ci_percent: Confidence interval percentage\n",
        "        \"\"\"\n",
        "        self.ci_percent = ci_percent\n",
        "        self.templates = HTMLTemplates()\n",
        "        self.text_gen = PublicationTextGenerator(ci_percent)\n",
        "\n",
        "        # Create tab widgets\n",
        "        self.tab_results = widgets.Output()\n",
        "        self.tab_hetero = widgets.Output()\n",
        "        self.tab_details = widgets.Output()\n",
        "        self.tab_config = widgets.Output()\n",
        "        self.tab_publication = widgets.Output()\n",
        "        self.tab_export = widgets.Output()\n",
        "\n",
        "        self.tabs = widgets.Tab(children=[\n",
        "            self.tab_results,\n",
        "            self.tab_hetero,\n",
        "            self.tab_details,\n",
        "            self.tab_config,\n",
        "            self.tab_publication,\n",
        "            self.tab_export\n",
        "        ])\n",
        "\n",
        "        self.tabs.set_title(0, '\ud83d\udcca Results Summary')\n",
        "        self.tabs.set_title(1, '\ud83d\udcc9 Heterogeneity')\n",
        "        self.tabs.set_title(2, '\ud83d\udd0d Subgroup Details')\n",
        "        self.tabs.set_title(3, '\u2699\ufe0f Configuration')\n",
        "        self.tabs.set_title(4, '\ud83d\udcdd Publication Text')\n",
        "        self.tabs.set_title(5, '\ud83d\udcbe Export')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 1: RESULTS SUMMARY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_results_tab(\n",
        "        self,\n",
        "        results_df: pd.DataFrame,\n",
        "        heterogeneity: Dict[str, Any],\n",
        "        moderator1: str,\n",
        "        moderator2: Optional[str]\n",
        "    ) -> None:\n",
        "        \"\"\"Render results summary tab\"\"\"\n",
        "\n",
        "        with self.tab_results:\n",
        "            self.tab_results.clear_output()\n",
        "\n",
        "            display(HTML(self.templates.header(\"\ud83d\udcca Subgroup Analysis Results\")))\n",
        "\n",
        "            # Summary card\n",
        "            summary = f\"<b>Moderator:</b> {moderator1}\"\n",
        "            if moderator2:\n",
        "                summary += f\" \u00d7 {moderator2}\"\n",
        "            summary += f\"<br><b>Subgroups Analyzed:</b> {len(results_df)}\"\n",
        "            summary += f\"<br><b>Test for Subgroup Differences:</b> Q<sub>M</sub> = {heterogeneity['QM']:.2f} \"\n",
        "            summary += f\"(df={heterogeneity['df_QM']}, p = {heterogeneity['p_value_QM']:.4g})\"\n",
        "            summary += f\"<br><b>Variance Explained (R\u00b2):</b> {heterogeneity['R_squared']:.1f}%\"\n",
        "\n",
        "            display(HTML(self.templates.card(summary, bg_color='#e7f3ff')))\n",
        "\n",
        "            # Results table\n",
        "            self._render_results_table(results_df)\n",
        "\n",
        "            # Legends\n",
        "            display(HTML(self.templates.significance_legend()))\n",
        "            display(HTML(self.templates.model_type_legend()))\n",
        "\n",
        "    def _render_results_table(self, results_df: pd.DataFrame) -> None:\n",
        "        \"\"\"Render main results table - CORRECTED VERSION\"\"\"\n",
        "\n",
        "        # Format significance stars\n",
        "        def add_stars(p_val):\n",
        "            if p_val < 0.001:\n",
        "                return \"***\"\n",
        "            elif p_val < 0.01:\n",
        "                return \"**\"\n",
        "            elif p_val < 0.05:\n",
        "                return \"*\"\n",
        "            return \"\"\n",
        "\n",
        "        # Format model type\n",
        "        def format_model(model):\n",
        "            if '3-level-vcv' in str(model):\n",
        "                return \"3L-VCV\"\n",
        "            elif '3-level-diag' in str(model):\n",
        "                return \"3L-Diag\"\n",
        "            elif '2-level' in str(model):\n",
        "                return \"2L\"\n",
        "            return str(model)\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 13px;'>\n",
        "        <thead style='background-color: #f8f9fa;'><tr>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: left;'>Subgroup</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>k</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>Studies</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>Effect</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{self.ci_percent:.0f}% CI</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>p-value</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>I\u00b2</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>Model*</th>\n",
        "        </tr></thead><tbody>\n",
        "        \"\"\"\n",
        "\n",
        "        for idx, row in results_df.iterrows():\n",
        "            stars = add_stars(row['p_value_re'])\n",
        "            style = \"font-weight: bold; color: #28a745;\" if stars else \"\"\n",
        "            model = format_model(row['model_type'])\n",
        "\n",
        "            html += f\"\"\"\n",
        "            <tr>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px;'>{row['group']}</td>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{int(row['k'])}</td>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{int(row['n_papers'])}</td>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center; {style}'>{row['pooled_effect_re']:.3f} {stars}</td>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>[{row['ci_lower_re']:.3f}, {row['ci_upper_re']:.3f}]</td>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{row['p_value_re']:.4g}</td>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{row['I_squared']:.1f}%</td>\n",
        "                <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center; color: #666; font-size: 11px;'>{model}</td>\n",
        "            </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"</tbody></table>\"\n",
        "        display(HTML(html))\n",
        "  # -------------------------------------------------------------------------\n",
        "    # TAB 2: HETEROGENEITY (CONTINUATION)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_heterogeneity_tab(\n",
        "        self,\n",
        "        heterogeneity: Dict[str, Any],\n",
        "        results_df: pd.DataFrame,\n",
        "        moderator1: str,\n",
        "        moderator2: Optional[str]\n",
        "    ) -> None:\n",
        "        \"\"\"Render heterogeneity partitioning tab\"\"\"\n",
        "\n",
        "        with self.tab_hetero:\n",
        "            self.tab_hetero.clear_output()\n",
        "\n",
        "            display(HTML(self.templates.header(\"\ud83d\udcc9 Heterogeneity Partitioning\")))\n",
        "\n",
        "            # Explanation\n",
        "            explanation = \"\"\"\n",
        "            <p><b>Understanding Heterogeneity Decomposition:</b></p>\n",
        "            <ul>\n",
        "                <li><b>Q<sub>T</sub> (Total):</b> Overall heterogeneity across all studies</li>\n",
        "                <li><b>Q<sub>M</sub> (Between-Groups):</b> Heterogeneity explained by the moderator</li>\n",
        "                <li><b>Q<sub>E</sub> (Within-Groups):</b> Residual heterogeneity within subgroups</li>\n",
        "                <li><b>R\u00b2:</b> Proportion of total heterogeneity explained by the moderator</li>\n",
        "            </ul>\n",
        "            \"\"\"\n",
        "            display(HTML(self.templates.card(explanation)))\n",
        "\n",
        "            # Q-statistics table\n",
        "            self._render_q_statistics_table(heterogeneity)\n",
        "\n",
        "            # R\u00b2 interpretation\n",
        "            self._render_r_squared_interpretation(\n",
        "                heterogeneity['R_squared'],\n",
        "                moderator1,\n",
        "                moderator2\n",
        "            )\n",
        "\n",
        "    def _render_q_statistics_table(self, het: Dict[str, Any]) -> None:\n",
        "        \"\"\"Render Q-statistics breakdown table\"\"\"\n",
        "\n",
        "        Qt = het['QM'] + het['QE']\n",
        "        df_total = het['df_QM'] + het['df_QE']\n",
        "\n",
        "        sig_qm = \"\"\n",
        "        if het['p_value_QM'] < 0.001:\n",
        "            sig_qm = \"***\"\n",
        "        elif het['p_value_QM'] < 0.01:\n",
        "            sig_qm = \"**\"\n",
        "        elif het['p_value_QM'] < 0.05:\n",
        "            sig_qm = \"*\"\n",
        "        else:\n",
        "            sig_qm = \"ns\"\n",
        "\n",
        "        style_qm = \"font-weight: bold; color: #28a745;\" if sig_qm != \"ns\" else \"\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "        <thead style='background-color: #f8f9fa;'><tr>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: left;'>Component</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>Q</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>df</th>\n",
        "            <th style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>p-value</th>\n",
        "        </tr></thead><tbody>\n",
        "        <tr>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px;'><b>Total (Q<sub>T</sub>)</b></td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{Qt:.2f}</td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{df_total}</td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>\u2014</td>\n",
        "        </tr>\n",
        "        <tr style='background-color: #e7f3ff;'>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px;'><b>Between-Groups (Q<sub>M</sub>)</b></td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center; {style_qm}'>{het['QM']:.2f}</td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{het['df_QM']}</td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center; {style_qm}'>{het['p_value_QM']:.4g} {sig_qm}</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px;'><b>Within-Groups (Q<sub>E</sub>)</b></td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{het['QE']:.2f}</td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>{het['df_QE']}</td>\n",
        "            <td style='border: 1px solid #dee2e6; padding: 8px; text-align: center;'>\u2014</td>\n",
        "        </tr>\n",
        "        </tbody></table>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(html))\n",
        "\n",
        "    def _render_r_squared_interpretation(\n",
        "        self,\n",
        "        r_squared: float,\n",
        "        moderator1: str,\n",
        "        moderator2: Optional[str]\n",
        "    ) -> None:\n",
        "        \"\"\"Render R\u00b2 interpretation\"\"\"\n",
        "\n",
        "        mod_text = f\"<b>{moderator1}</b>\"\n",
        "        if moderator2:\n",
        "            mod_text += f\" \u00d7 <b>{moderator2}</b>\"\n",
        "\n",
        "        if r_squared < 25:\n",
        "            color = \"#856404\"\n",
        "            label = \"(Low explanatory power)\"\n",
        "        elif r_squared < 50:\n",
        "            color = \"#856404\"\n",
        "            label = \"(Moderate explanatory power)\"\n",
        "        else:\n",
        "            color = \"#155724\"\n",
        "            label = \"(High explanatory power)\"\n",
        "\n",
        "        content = f\"\"\"\n",
        "        <p style='margin: 0; font-size: 1.1em;'><b>Variance Explained (R\u00b2): {r_squared:.1f}%</b></p>\n",
        "        <p style='margin: 5px 0 0 0;'>\n",
        "            The moderator {mod_text} explains {r_squared:.1f}% of the total heterogeneity.\n",
        "            <span style='color: {color};'>{label}</span>\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(self.templates.card(content, bg_color='#fff3cd')))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 3: DETAILS (Progress Stream)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_details_tab(self) -> widgets.Output:\n",
        "        \"\"\"\n",
        "        Render details tab and return the output widget for streaming.\n",
        "\n",
        "        Returns:\n",
        "            Output widget where progress messages should be written\n",
        "        \"\"\"\n",
        "        with self.tab_details:\n",
        "            self.tab_details.clear_output()\n",
        "            display(HTML(self.templates.header(\"\ud83d\udd0d Subgroup Analysis Progress\")))\n",
        "\n",
        "        return self.tab_details\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 4: CONFIGURATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_config_tab(self, config_summary: Dict[str, Any]) -> None:\n",
        "        \"\"\"Render configuration tab\"\"\"\n",
        "\n",
        "        with self.tab_config:\n",
        "            self.tab_config.clear_output()\n",
        "\n",
        "            display(HTML(self.templates.header(\"\u2699\ufe0f Analysis Configuration\")))\n",
        "\n",
        "            # Configuration details\n",
        "            content = f\"<b>Timestamp:</b> {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>\"\n",
        "            content += f\"<b>Analysis Type:</b> {config_summary['analysis_type']}<br>\"\n",
        "            content += f\"<b>Moderator 1:</b> {config_summary['moderator1']}<br>\"\n",
        "\n",
        "            if config_summary['moderator2']:\n",
        "                content += f\"<b>Moderator 2:</b> {config_summary['moderator2']}<br>\"\n",
        "\n",
        "            content += f\"<b>Number of Subgroups:</b> {config_summary['n_groups']}<br>\"\n",
        "            content += f\"<b>Effect Column:</b> {config_summary['effect_col']}<br>\"\n",
        "            content += f\"<b>Variance Column:</b> {config_summary['var_col']}<br>\"\n",
        "            content += f\"<b>Alpha Level:</b> {config_summary['alpha']}<br>\"\n",
        "            content += f\"<b>Confidence Interval:</b> {config_summary['ci_percent']:.0f}%<br>\"\n",
        "            content += f\"<b>Distribution:</b> {config_summary['dist_type']}<br>\"\n",
        "            content += f\"<b>Total Observations:</b> {config_summary['total_observations']}<br>\"\n",
        "            content += f\"<b>Total Studies:</b> {config_summary['n_studies']}\"\n",
        "\n",
        "            display(HTML(self.templates.card(content)))\n",
        "            display(HTML(self.templates.success_message(\"All prerequisites met\")))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 5: PUBLICATION TEXT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_publication_tab(\n",
        "        self,\n",
        "        results_df: pd.DataFrame,\n",
        "        heterogeneity: Dict[str, Any],\n",
        "        moderator1: str,\n",
        "        moderator2: Optional[str],\n",
        "        n_groups: int\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Render publication text tab.\n",
        "\n",
        "        Returns:\n",
        "            Combined HTML text for saving\n",
        "        \"\"\"\n",
        "        with self.tab_publication:\n",
        "            self.tab_publication.clear_output()\n",
        "\n",
        "            display(HTML(self.templates.header(\"\ud83d\udcdd Publication-Ready Results Text\", level=3)))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "            # Generate both sections\n",
        "            methods_html = self.text_gen.generate_methods_section(\n",
        "                moderator1, moderator2, n_groups\n",
        "            )\n",
        "            results_html = self.text_gen.generate_results_section(\n",
        "                results_df, moderator1, moderator2, heterogeneity\n",
        "            )\n",
        "\n",
        "            # Display\n",
        "            display(HTML(methods_html))\n",
        "            display(HTML(results_html))\n",
        "\n",
        "            # Return combined for saving\n",
        "            return methods_html + \"<br><hr><br>\" + results_html\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 6: EXPORT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_export_tab(self, export_callback: callable) -> None:\n",
        "        \"\"\"Render export tab with download button\"\"\"\n",
        "\n",
        "        with self.tab_export:\n",
        "            self.tab_export.clear_output()\n",
        "\n",
        "            display(HTML(self.templates.header(\"\ud83d\udcbe Download Audit Report\", level=3)))\n",
        "            display(HTML(\"<p>Generate an Excel file containing the subgroup table, heterogeneity breakdown, and specific group data.</p>\"))\n",
        "\n",
        "            btn_export = widgets.Button(\n",
        "                description=\"\ud83d\udce5 Download Subgroup Report\",\n",
        "                button_style='info',\n",
        "                icon='file-excel',\n",
        "                layout=widgets.Layout(width='300px', height='40px')\n",
        "            )\n",
        "\n",
        "            btn_export.on_click(export_callback)\n",
        "            display(btn_export)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR DISPLAY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_error(self, error_type: str, message: str, details: Optional[str] = None) -> None:\n",
        "        \"\"\"Render error message in results tab\"\"\"\n",
        "        with self.tab_results:\n",
        "            self.tab_results.clear_output()\n",
        "            display(HTML(self.templates.error_message(error_type, message, details)))\n",
        "\n",
        "    def render_prerequisite_error(self, missing_keys: List[str]) -> None:\n",
        "        \"\"\"Render prerequisite check failure\"\"\"\n",
        "        with self.tab_config:\n",
        "            self.tab_config.clear_output()\n",
        "            display(HTML(self.templates.header(\"\u2699\ufe0f Configuration Check\")))\n",
        "\n",
        "            message = f\"Missing required ANALYSIS_CONFIG keys: {', '.join(missing_keys)}\"\n",
        "            display(HTML(self.templates.error_message(\"Configuration Error\", message)))\n",
        "\n",
        "            display(HTML(\"<p>Please run:</p><ul><li>Step 2: Overall Meta-Analysis</li><li>Step 3a: Subgroup Configuration</li></ul>\"))\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 4/4: CONTROLLER LAYER\n",
        "# Purpose: Orchestrates data, analysis, and view components\n",
        "# Dependencies: All previous layers (Data, Analysis, View)\n",
        "# =============================================================================\n",
        "\n",
        "import traceback\n",
        "import sys\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN CONTROLLER\n",
        "# =============================================================================\n",
        "\n",
        "class SubgroupController:\n",
        "    \"\"\"\n",
        "    Master controller that orchestrates the entire subgroup analysis workflow.\n",
        "    Coordinates data management, statistical computation, and UI rendering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize controller with ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self.analysis_config = analysis_config\n",
        "\n",
        "        # Initialize components\n",
        "        try:\n",
        "            self.data_manager = SubgroupDataManager(analysis_config)\n",
        "            self.engine = SubgroupAnalysisEngine(self.data_manager)\n",
        "\n",
        "            # Get CI percentage from settings\n",
        "            ci_percent = self.data_manager.global_settings.ci_percent\n",
        "            self.view = SubgroupResultsView(ci_percent=ci_percent)\n",
        "\n",
        "        except Exception as e:\n",
        "            # If initialization fails, create minimal view to show error\n",
        "            self.view = SubgroupResultsView()\n",
        "            self.data_manager = None\n",
        "            self.engine = None\n",
        "            self._initialization_error = e\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(self) -> None:\n",
        "        \"\"\"\n",
        "        Execute complete subgroup analysis workflow.\n",
        "        This is the main entry point that orchestrates everything.\n",
        "        \"\"\"\n",
        "        # Display tabs immediately\n",
        "        display(self.view.tabs)\n",
        "\n",
        "        # Check for initialization errors\n",
        "        if self.data_manager is None or self.engine is None:\n",
        "            self._handle_initialization_error()\n",
        "            return\n",
        "\n",
        "        # Render configuration tab first\n",
        "        try:\n",
        "            self._render_configuration()\n",
        "        except Exception as e:\n",
        "            self._handle_error(\"Configuration Error\", e)\n",
        "            return\n",
        "\n",
        "        # Run main analysis\n",
        "        try:\n",
        "            self._execute_analysis()\n",
        "        except Exception as e:\n",
        "            self._handle_error(\"Analysis Error\", e)\n",
        "            return\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # WORKFLOW STEPS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _render_configuration(self) -> None:\n",
        "        \"\"\"Render configuration tab\"\"\"\n",
        "        config_summary = self.data_manager.summary_dict()\n",
        "        self.view.render_config_tab(config_summary)\n",
        "\n",
        "    def _execute_analysis(self) -> None:\n",
        "        \"\"\"Execute statistical analysis with progress streaming\"\"\"\n",
        "\n",
        "        # Setup progress callback for details tab\n",
        "        details_tab = self.view.render_details_tab()\n",
        "\n",
        "        def progress_callback(message: str):\n",
        "            \"\"\"Callback to stream progress to details tab\"\"\"\n",
        "            with details_tab:\n",
        "                print(message)\n",
        "\n",
        "        # Run analysis engine\n",
        "        progress_callback(\"\ud83d\ude80 Starting subgroup analysis...\")\n",
        "        progress_callback(\"=\" * 60)\n",
        "\n",
        "        results_df, heterogeneity = self.engine.analyze_all_subgroups(\n",
        "            progress_callback=progress_callback\n",
        "        )\n",
        "\n",
        "        # Extract metadata\n",
        "        config = self.data_manager.subgroup_config\n",
        "        moderator1 = config.moderator1\n",
        "        moderator2 = config.moderator2\n",
        "        n_groups = len(results_df)\n",
        "\n",
        "        # Render all tabs\n",
        "        self._render_results_tab(results_df, heterogeneity, moderator1, moderator2)\n",
        "        self._render_heterogeneity_tab(results_df, heterogeneity, moderator1, moderator2)\n",
        "        self._render_publication_tab(results_df, heterogeneity, moderator1, moderator2, n_groups)\n",
        "        self._render_export_tab()\n",
        "\n",
        "        # Save results to ANALYSIS_CONFIG\n",
        "        self._save_results(results_df, heterogeneity)\n",
        "\n",
        "        # Final progress message\n",
        "        with details_tab:\n",
        "            print(\"=\" * 60)\n",
        "            print(\"\u2705 ANALYSIS COMPLETE\")\n",
        "            print(\"=\" * 60)\n",
        "            print(\"Results saved to ANALYSIS_CONFIG['subgroup_results']\")\n",
        "            print(\"\u25b6\ufe0f  Ready for next step: Forest Plot visualization\")\n",
        "\n",
        "    def _render_results_tab(\n",
        "        self,\n",
        "        results_df,\n",
        "        heterogeneity,\n",
        "        moderator1,\n",
        "        moderator2\n",
        "    ) -> None:\n",
        "        \"\"\"Render results summary tab\"\"\"\n",
        "        self.view.render_results_tab(\n",
        "            results_df=results_df,\n",
        "            heterogeneity=heterogeneity,\n",
        "            moderator1=moderator1,\n",
        "            moderator2=moderator2\n",
        "        )\n",
        "\n",
        "    def _render_heterogeneity_tab(\n",
        "        self,\n",
        "        results_df,\n",
        "        heterogeneity,\n",
        "        moderator1,\n",
        "        moderator2\n",
        "    ) -> None:\n",
        "        \"\"\"Render heterogeneity partitioning tab\"\"\"\n",
        "        self.view.render_heterogeneity_tab(\n",
        "            heterogeneity=heterogeneity,\n",
        "            results_df=results_df,\n",
        "            moderator1=moderator1,\n",
        "            moderator2=moderator2\n",
        "        )\n",
        "\n",
        "    def _render_publication_tab(\n",
        "        self,\n",
        "        results_df,\n",
        "        heterogeneity,\n",
        "        moderator1,\n",
        "        moderator2,\n",
        "        n_groups\n",
        "    ) -> None:\n",
        "        \"\"\"Render publication text tab\"\"\"\n",
        "        combined_text = self.view.render_publication_tab(\n",
        "            results_df=results_df,\n",
        "            heterogeneity=heterogeneity,\n",
        "            moderator1=moderator1,\n",
        "            moderator2=moderator2,\n",
        "            n_groups=n_groups\n",
        "        )\n",
        "\n",
        "        # Save to ANALYSIS_CONFIG\n",
        "        self.data_manager.save_publication_text(combined_text)\n",
        "\n",
        "    def _render_export_tab(self) -> None:\n",
        "        \"\"\"Render export tab with callback\"\"\"\n",
        "        self.view.render_export_tab(export_callback=self._handle_export)\n",
        "\n",
        "    def _save_results(self, results_df, heterogeneity) -> None:\n",
        "        \"\"\"Save results to ANALYSIS_CONFIG\"\"\"\n",
        "        metadata = {\n",
        "            'Qt_overall': self.data_manager.overall_results['Qt'],\n",
        "            'QM': heterogeneity['QM'],\n",
        "            'Qe': heterogeneity['QE'],\n",
        "            'df_QM': heterogeneity['df_QM'],\n",
        "            'df_Qe': heterogeneity['df_QE'],\n",
        "            'p_value_QM': heterogeneity['p_value_QM'],\n",
        "            'R_squared': heterogeneity['R_squared']\n",
        "        }\n",
        "\n",
        "        self.data_manager.save_subgroup_results(results_df, metadata)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # EVENT HANDLERS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_export(self, button) -> None:\n",
        "        \"\"\"Handle export button click\"\"\"\n",
        "        try:\n",
        "            # Call the external export function if it exists\n",
        "            if 'export_analysis_report' in globals():\n",
        "                export_analysis_report(\n",
        "                    report_type='subgroup',\n",
        "                    filename_prefix='Subgroup_Analysis'\n",
        "                )\n",
        "            else:\n",
        "                with self.view.tab_export:\n",
        "                    print(\"\u26a0\ufe0f Export function not found. Please run the export cell first.\")\n",
        "        except Exception as e:\n",
        "            with self.view.tab_export:\n",
        "                print(f\"\u274c Export failed: {str(e)}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_initialization_error(self) -> None:\n",
        "        \"\"\"Handle errors during controller initialization\"\"\"\n",
        "        error = getattr(self, '_initialization_error', None)\n",
        "\n",
        "        if error is None:\n",
        "            return\n",
        "\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "\n",
        "        if isinstance(error, ValueError):\n",
        "            # Missing prerequisites\n",
        "            if 'Missing required ANALYSIS_CONFIG keys' in error_msg:\n",
        "                missing = error_msg.split(': ')[1].split('.')[0]\n",
        "                self.view.render_prerequisite_error(missing.split(', '))\n",
        "            else:\n",
        "                self.view.render_error(error_type, error_msg)\n",
        "        else:\n",
        "            # Unexpected error\n",
        "            details = traceback.format_exc()\n",
        "            self.view.render_error(error_type, error_msg, details)\n",
        "\n",
        "    def _handle_error(self, error_type: str, error: Exception) -> None:\n",
        "        \"\"\"Handle errors during analysis execution\"\"\"\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(error_type, error_msg, details)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION ENTRY POINT\n",
        "# =============================================================================\n",
        "\n",
        "def run_subgroup_analysis():\n",
        "    \"\"\"\n",
        "    Main entry point for subgroup analysis.\n",
        "    Call this function to execute the complete workflow.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check for ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            print(\"\u274c ERROR: ANALYSIS_CONFIG not found\")\n",
        "            print(\"Please run previous analysis cells first:\")\n",
        "            print(\"  - Step 2: Overall Meta-Analysis\")\n",
        "            print(\"  - Step 3a: Subgroup Configuration\")\n",
        "            return\n",
        "\n",
        "        # Create controller and run\n",
        "        controller = SubgroupController(ANALYSIS_CONFIG)\n",
        "        controller.run_analysis()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Fatal Error: {type(e).__name__}\")\n",
        "        print(f\"Message: {str(e)}\")\n",
        "        print(\"\\nFull traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STANDALONE TESTING UTILITIES (Optional)\n",
        "# =============================================================================\n",
        "\n",
        "class MockAnalysisConfig:\n",
        "    \"\"\"\n",
        "    Mock ANALYSIS_CONFIG for testing without running full pipeline.\n",
        "    Only for development/testing purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_sample_config():\n",
        "        \"\"\"Create a minimal valid config for testing\"\"\"\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "\n",
        "        # Sample data\n",
        "        sample_data = pd.DataFrame({\n",
        "            'id': [1, 1, 2, 2, 3, 3, 4, 4],\n",
        "            'effect': np.random.randn(8),\n",
        "            'variance': np.random.uniform(0.01, 0.1, 8),\n",
        "            'moderator1': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B']\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'analysis_data': sample_data,\n",
        "            'effect_col': 'effect',\n",
        "            'var_col': 'variance',\n",
        "            'es_config': {'has_fold_change': False},\n",
        "            'overall_results': {\n",
        "                'Qt': 15.5,\n",
        "                'k': 8,\n",
        "                'mu': 0.25\n",
        "            },\n",
        "            'three_level_results': {},\n",
        "            'subgroup_config': {\n",
        "                'analysis_type': 'single',\n",
        "                'moderator1': 'moderator1',\n",
        "                'moderator2': None,\n",
        "                'valid_groups_list': ['A', 'B']\n",
        "            },\n",
        "            'vcv_matrices': {},\n",
        "            'global_settings': {\n",
        "                'alpha': 0.05,\n",
        "                'dist_type': 'norm'\n",
        "            }\n",
        "        }\n",
        "\n",
        "run_subgroup_analysis()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wE0-PPueInpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 10. Forest Plot\n",
        "# =============================================================================\n",
        "# CELL 9: PUBLICATION-READY FOREST PLOT\n",
        "# Purpose: Create customizable forest plots for meta-analysis results\n",
        "# Fix: Updated result keys to match the robust Cell 6 output.\n",
        "# =============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import datetime\n",
        "from matplotlib.patches import Patch, Rectangle\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "# --- 1. LOAD CONFIGURATION ---\n",
        "print(\"=\"*70)\n",
        "print(\"FOREST PLOT CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in locals() and 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"ANALYSIS_CONFIG not found.\")\n",
        "\n",
        "    subgroup_results = ANALYSIS_CONFIG.get('subgroup_results', {})\n",
        "    overall_results = ANALYSIS_CONFIG['overall_results']\n",
        "    es_config = ANALYSIS_CONFIG['es_config']\n",
        "\n",
        "    # Determine if we have subgroup analysis\n",
        "    has_subgroups = bool(subgroup_results) and 'results_df' in subgroup_results\n",
        "\n",
        "    if has_subgroups:\n",
        "        analysis_type = subgroup_results['analysis_type']\n",
        "        moderator1 = subgroup_results['moderator1']\n",
        "        moderator2 = subgroup_results.get('moderator2', None)\n",
        "        results_df = subgroup_results['results_df']\n",
        "\n",
        "        # Set dynamic defaults\n",
        "        if analysis_type == 'two_way':\n",
        "            default_title = f'Forest Plot: {moderator1} \u00d7 {moderator2}'\n",
        "            default_y_label = moderator2\n",
        "        else:\n",
        "            default_title = f'Forest Plot: {moderator1}'\n",
        "            default_y_label = moderator1\n",
        "    else:\n",
        "        # Overall only (no subgroups)\n",
        "        analysis_type = 'overall_only'\n",
        "        default_title = 'Forest Plot: Overall Effect'\n",
        "        default_y_label = 'Study'\n",
        "        moderator1 = None\n",
        "        moderator2 = None\n",
        "\n",
        "    default_x_label = es_config.get('effect_label', \"Effect Size\")\n",
        "\n",
        "    print(f\"\u2713 Analysis type: {analysis_type}\")\n",
        "    print(f\"\u2713 Has subgroups: {has_subgroups}\")\n",
        "    print(f\"\u2713 Configuration loaded successfully\")\n",
        "\n",
        "except (KeyError, NameError) as e:\n",
        "    print(f\"\u274c ERROR: Failed to load configuration: {e}\")\n",
        "    print(\"   Please run Cell 6 (overall analysis) first\")\n",
        "    raise\n",
        "\n",
        "# --- 2. DEFINE CUSTOMIZATION WIDGETS ---\n",
        "\n",
        "# ========== TAB 1: PLOT STYLE ==========\n",
        "style_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Plot Style & Layout</h3>\")\n",
        "\n",
        "model_widget = widgets.Dropdown(\n",
        "    options=[('Random-Effects', 'RE'), ('Fixed-Effects', 'FE')],\n",
        "    value='RE',\n",
        "    description='Model:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "width_widget = widgets.FloatSlider(\n",
        "    value=8.0, min=6.0, max=14.0, step=0.5,\n",
        "    description='Plot Width (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "height_widget = widgets.FloatSlider(\n",
        "    value=0.4, min=0.2, max=1.0, step=0.05,\n",
        "    description='Height per Row (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "title_fontsize_widget = widgets.IntSlider(\n",
        "    value=12, min=8, max=18, step=1,\n",
        "    description='Title Font Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "label_fontsize_widget = widgets.IntSlider(\n",
        "    value=11, min=8, max=16, step=1,\n",
        "    description='Axis Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "tick_fontsize_widget = widgets.IntSlider(\n",
        "    value=9, min=6, max=14, step=1,\n",
        "    description='Tick Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_fontsize_widget = widgets.IntSlider(\n",
        "    value=8, min=6, max=12, step=1,\n",
        "    description='Annotation Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "color_scheme_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Grayscale (Publication)', 'gray'),\n",
        "        ('Color (Presentation)', 'color'),\n",
        "        ('Black & White Only', 'bw')\n",
        "    ],\n",
        "    value='gray',\n",
        "    description='Color Scheme:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "marker_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Circle/Diamond (\u25cf/\u25c6)', 'circle_diamond'),\n",
        "        ('Square/Diamond (\u25a0/\u25c6)', 'square_diamond'),\n",
        "        ('Circle/Star (\u25cf/\u2605)', 'circle_star')\n",
        "    ],\n",
        "    value='circle_diamond',\n",
        "    description='Marker Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "ci_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Solid Line', 'solid'),\n",
        "        ('Dashed Line', 'dashed'),\n",
        "        ('Solid with Caps', 'caps')\n",
        "    ],\n",
        "    value='solid',\n",
        "    description='CI Line Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    style_header,\n",
        "    preset_widget,\n",
        "    model_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Dimensions:</b>\"),\n",
        "    width_widget,\n",
        "    height_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Typography:</b>\"),\n",
        "    title_fontsize_widget,\n",
        "    label_fontsize_widget,\n",
        "    tick_fontsize_widget,\n",
        "    annot_fontsize_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Visual Style:</b>\"),\n",
        "    color_scheme_widget,\n",
        "    marker_style_widget,\n",
        "    ci_style_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 2: TEXT & LABELS ==========\n",
        "text_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Text & Labels</h3>\")\n",
        "\n",
        "show_title_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Plot Title',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "title_widget = widgets.Text(\n",
        "    value=default_title,\n",
        "    description='Plot Title:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "xlabel_widget = widgets.Text(\n",
        "    value=default_x_label,\n",
        "    description='X-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "ylabel_widget = widgets.Text(\n",
        "    value=default_y_label,\n",
        "    description='Y-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "show_ylabel_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Y-Axis Label',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "text_tab = widgets.VBox([\n",
        "    text_header,\n",
        "    show_title_widget,\n",
        "    title_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    xlabel_widget,\n",
        "    show_ylabel_widget,\n",
        "    ylabel_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 3: ANNOTATIONS ==========\n",
        "annot_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Annotations</h3>\")\n",
        "\n",
        "show_k_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show k (observations)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_papers_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show paper count',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_fold_change_widget = widgets.Checkbox(\n",
        "    value=es_config.get('has_fold_change', False),\n",
        "    description='Show Fold-Change',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_pos_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Right of CI', 'right'),\n",
        "        ('Above Marker', 'above'),\n",
        "        ('Below Marker', 'below')\n",
        "    ],\n",
        "    value='right',\n",
        "    description='Position:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-1.0, max=1.0, step=0.05,\n",
        "    description='H-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    readout_format='.2f'\n",
        ")\n",
        "\n",
        "group_label_box = widgets.VBox()\n",
        "# Group label widgets (always defined, conditionally displayed)\n",
        "group_label_h_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-2.0, max=2.0, step=0.1,\n",
        "    description='Group H-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "group_label_v_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-5.0, max=5.0, step=0.5,\n",
        "    description='Group V-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "group_label_fontsize_widget = widgets.IntSlider(\n",
        "    value=10, min=6, max=20, step=1,\n",
        "    description='Group Fontsize:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Only display group label widgets for two-way analysis\n",
        "if has_subgroups and analysis_type == 'two_way':\n",
        "    group_label_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h4>Group Label Positioning (Two-Way Only)</h4>\"),\n",
        "        group_label_h_offset_widget,\n",
        "        group_label_v_offset_widget,\n",
        "        group_label_fontsize_widget\n",
        "    ])\n",
        "else:\n",
        "    group_label_box = widgets.VBox()\n",
        "\n",
        "\n",
        "annot_tab = widgets.VBox([\n",
        "    annot_header,\n",
        "    widgets.HTML(\"<b>Show in Annotations:</b>\"),\n",
        "    show_k_widget,\n",
        "    show_papers_widget,\n",
        "    show_fold_change_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Position:</b>\"),\n",
        "    annot_pos_widget,\n",
        "    annot_offset_widget,\n",
        "    group_label_box\n",
        "])\n",
        "\n",
        "# ========== TAB 4: AXES & SCALE ==========\n",
        "axes_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Axes & Scaling</h3>\")\n",
        "\n",
        "auto_scale_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Auto-Scale X-Axis',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "x_min_widget = widgets.FloatText(\n",
        "    value=-2.0,\n",
        "    description='X-Min:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "x_max_widget = widgets.FloatText(\n",
        "    value=2.0,\n",
        "    description='X-Max:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "manual_scale_box = widgets.HBox([x_min_widget, x_max_widget])\n",
        "\n",
        "def toggle_manual_scale(change):\n",
        "    if change['new']:\n",
        "        x_min_widget.layout.visibility = 'hidden'\n",
        "        x_max_widget.layout.visibility = 'hidden'\n",
        "    else:\n",
        "        x_min_widget.layout.visibility = 'visible'\n",
        "        x_max_widget.layout.visibility = 'visible'\n",
        "\n",
        "auto_scale_widget.observe(toggle_manual_scale, names='value')\n",
        "\n",
        "show_grid_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Grid',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "grid_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Dashed (Light)', 'dashed_light'),\n",
        "        ('Dotted (Light)', 'dotted_light'),\n",
        "        ('Solid (Light)', 'solid_light')\n",
        "    ],\n",
        "    value='dashed_light',\n",
        "    description='Grid Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_null_line_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Null Effect Line',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_fold_axis_widget = widgets.Checkbox(\n",
        "    value=es_config.get('has_fold_change', False) and show_fold_change_widget.value,\n",
        "    description='Show Fold-Change Axis (Top)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "axes_tab = widgets.VBox([\n",
        "    axes_header,\n",
        "    auto_scale_widget,\n",
        "    manual_scale_box,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Grid & Reference Lines:</b>\"),\n",
        "    show_grid_widget,\n",
        "    grid_style_widget,\n",
        "    show_null_line_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    show_fold_axis_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 5: EXPORT OPTIONS ==========\n",
        "export_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Export Options</h3>\")\n",
        "\n",
        "save_pdf_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PDF',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "save_png_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PNG',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "png_dpi_widget = widgets.IntSlider(\n",
        "    value=300, min=150, max=600, step=50,\n",
        "    description='PNG DPI:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "filename_prefix_widget = widgets.Text(\n",
        "    value='ForestPlot',\n",
        "    description='Filename Prefix:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "transparent_bg_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Transparent Background',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    export_header,\n",
        "    save_pdf_widget,\n",
        "    save_png_widget,\n",
        "    png_dpi_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    filename_prefix_widget,\n",
        "    transparent_bg_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 6: LABEL EDITOR ==========\n",
        "label_editor_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Label Editor</h3>\")\n",
        "label_editor_desc = widgets.HTML(\n",
        "    \"<p style='color: #666;'><i>Customize display names for all groups and subgroups in the plot</i></p>\"\n",
        ")\n",
        "\n",
        "print(f\"\\n\ud83d\udd0d Identifying labels for editor...\")\n",
        "\n",
        "unique_labels = set()\n",
        "label_widgets_dict = {}\n",
        "\n",
        "try:\n",
        "    if has_subgroups:\n",
        "        if analysis_type == 'single':\n",
        "            unique_labels.update(results_df['group'].astype(str).unique())\n",
        "        else:  # two_way\n",
        "            unique_labels.update(results_df[moderator1].astype(str).unique())\n",
        "            unique_labels.update(results_df[moderator2].astype(str).unique())\n",
        "\n",
        "    unique_labels.add('Overall')\n",
        "    sorted_labels = sorted(list(unique_labels))\n",
        "\n",
        "    print(f\"  \u2713 Found {len(sorted_labels)} unique labels\")\n",
        "\n",
        "    label_editor_widgets = []\n",
        "    for label in sorted_labels:\n",
        "        widget_label = f\"Overall Effect:\" if label == 'Overall' else f\"{label}:\"\n",
        "        text_widget = widgets.Text(\n",
        "            value=str(label),\n",
        "            description=widget_label,\n",
        "            layout=widgets.Layout(width='500px'),\n",
        "            style={'description_width': '200px'}\n",
        "        )\n",
        "        label_editor_widgets.append(text_widget)\n",
        "        label_widgets_dict[str(label)] = text_widget\n",
        "\n",
        "    label_editor_tab = widgets.VBox([\n",
        "        label_editor_header,\n",
        "        label_editor_desc,\n",
        "        widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "        widgets.HTML(\n",
        "            \"<p><b>Instructions:</b> Edit the text on the right to change how labels appear in the plot. \"\n",
        "            \"The original coded names are shown on the left.</p>\"\n",
        "        ),\n",
        "        widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "        *label_editor_widgets\n",
        "    ])\n",
        "\n",
        "    print(f\"  \u2713 Label editor created\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  \u26a0\ufe0f  Error creating label editor: {e}\")\n",
        "    label_editor_tab = widgets.VBox([\n",
        "        label_editor_header,\n",
        "        widgets.HTML(\"<p style='color: red;'>Error creating label editor.</p>\")\n",
        "    ])\n",
        "    label_widgets_dict = {}\n",
        "\n",
        "# ========== CREATE TAB WIDGET ==========\n",
        "tab_children = [style_tab, text_tab, annot_tab, axes_tab, export_tab, label_editor_tab]\n",
        "tab = widgets.Tab(children=tab_children)\n",
        "tab.set_title(0, '\ud83c\udfa8 Style')\n",
        "tab.set_title(1, '\ud83d\udcdd Text')\n",
        "tab.set_title(2, '\ud83c\udff7\ufe0f Annotations')\n",
        "tab.set_title(3, '\ud83d\udccf Axes')\n",
        "tab.set_title(4, '\ud83d\udcbe Export')\n",
        "tab.set_title(5, '\u270f\ufe0f Labels')\n",
        "\n",
        "# --- 3. DEFINE PLOT GENERATION FUNCTION ---\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "def generate_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING FOREST PLOT\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            # --- GET WIDGET VALUES ---\n",
        "            plot_model = model_widget.value\n",
        "            plot_width = width_widget.value\n",
        "            height_per_row = height_widget.value\n",
        "            title_fontsize = title_fontsize_widget.value\n",
        "            label_fontsize = label_fontsize_widget.value\n",
        "            tick_fontsize = tick_fontsize_widget.value\n",
        "            annot_fontsize = annot_fontsize_widget.value\n",
        "            color_scheme = color_scheme_widget.value\n",
        "            marker_style = marker_style_widget.value\n",
        "            ci_style = ci_style_widget.value\n",
        "\n",
        "            show_title = show_title_widget.value\n",
        "            graph_title = title_widget.value\n",
        "            x_label = xlabel_widget.value\n",
        "            show_ylabel = show_ylabel_widget.value\n",
        "            y_label = ylabel_widget.value\n",
        "\n",
        "            show_k = show_k_widget.value\n",
        "            show_papers = show_papers_widget.value\n",
        "            show_fold_change = show_fold_change_widget.value\n",
        "            annot_pos = annot_pos_widget.value\n",
        "            annot_offset = annot_offset_widget.value\n",
        "\n",
        "            auto_scale = auto_scale_widget.value\n",
        "            x_min_manual = x_min_widget.value\n",
        "            x_max_manual = x_max_widget.value\n",
        "            show_grid = show_grid_widget.value\n",
        "            grid_style = grid_style_widget.value\n",
        "            show_null_line = show_null_line_widget.value\n",
        "            show_fold_axis = show_fold_axis_widget.value\n",
        "\n",
        "            save_pdf = save_pdf_widget.value\n",
        "            save_png = save_png_widget.value\n",
        "            png_dpi = png_dpi_widget.value\n",
        "            filename_prefix = filename_prefix_widget.value\n",
        "            transparent_bg = transparent_bg_widget.value\n",
        "\n",
        "            # Group label offsets (two-way only)\n",
        "            if has_subgroups and analysis_type == 'two_way':\n",
        "                group_label_h_offset = group_label_h_offset_widget.value\n",
        "                group_label_v_offset = group_label_v_offset_widget.value\n",
        "                group_label_fontsize = group_label_fontsize_widget.value\n",
        "            else:\n",
        "                group_label_h_offset = 0\n",
        "                group_label_v_offset = 0\n",
        "                group_label_fontsize = 10\n",
        "\n",
        "            # --- BUILD LABEL MAPPING FROM EDITOR ---\n",
        "            label_mapping = {}\n",
        "            for original_label, widget in label_widgets_dict.items():\n",
        "                custom_label = widget.value\n",
        "                label_mapping[original_label] = custom_label\n",
        "                label_mapping[str(original_label)] = custom_label\n",
        "\n",
        "            print(f\"\ud83d\udcca Configuration:\")\n",
        "            print(f\"  Model: {plot_model}\")\n",
        "            print(f\"  Dimensions: {plot_width}\\\" \u00d7 auto\")\n",
        "            print(f\"  Color scheme: {color_scheme}\")\n",
        "            print(f\"  Has subgroups: {has_subgroups}\")\n",
        "\n",
        "            # Show custom labels if any were changed\n",
        "            changed_labels = {k: v for k, v in label_mapping.items() if k != v}\n",
        "            if changed_labels:\n",
        "                print(f\"\\n\ud83d\udcdd Custom labels ({len(changed_labels)} changed):\")\n",
        "                for orig, custom in list(changed_labels.items())[:5]:\n",
        "                    print(f\"  '{orig}' \u2192 '{custom}'\")\n",
        "                if len(changed_labels) > 5:\n",
        "                    print(f\"  ... and {len(changed_labels)-5} more\")\n",
        "\n",
        "            overall_label_text = label_mapping.get('Overall', 'Overall Effect')\n",
        "\n",
        "            # --- DETERMINE COLUMN NAMES BASED ON MODEL ---\n",
        "            if plot_model == 'FE':\n",
        "                effect_col = 'pooled_effect_fe'\n",
        "                se_col = 'pooled_se_fe'\n",
        "                ci_lower_col = 'ci_lower_fe'\n",
        "                ci_upper_col = 'ci_upper_fe'\n",
        "                fold_col = 'fold_change_fe'\n",
        "\n",
        "                overall_effect_key = 'pooled_effect_fixed'\n",
        "                overall_se_key = 'pooled_SE_fixed'\n",
        "                overall_ci_lower_key = 'ci_lower_fixed'\n",
        "                overall_ci_upper_key = 'ci_upper_fixed'\n",
        "                overall_fold_key = 'pooled_fold_fixed' # Assuming this exists\n",
        "            else:  # RE\n",
        "                effect_col = 'pooled_effect_re'\n",
        "                se_col = 'pooled_se_re'\n",
        "                ci_lower_col = 'ci_lower_re'\n",
        "                ci_upper_col = 'ci_upper_re'\n",
        "                fold_col = 'fold_change_re'\n",
        "\n",
        "                overall_effect_key = 'pooled_effect_random'\n",
        "                # FIX: Use keys that exist in Cell 6 output\n",
        "                overall_se_key = 'pooled_SE_random_reported'\n",
        "                overall_ci_lower_key = 'ci_lower_random_reported'\n",
        "                overall_ci_upper_key = 'ci_upper_random_reported'\n",
        "                overall_fold_key = 'pooled_fold_random'\n",
        "\n",
        "            # --- PREPARE DATA ---\n",
        "            if has_subgroups:\n",
        "                plot_df_subgroups = results_df.copy()\n",
        "\n",
        "                plot_df_subgroups = plot_df_subgroups.rename(columns={\n",
        "                    effect_col: 'EffectSize',\n",
        "                    se_col: 'SE',\n",
        "                    ci_lower_col: 'CI_Lower',\n",
        "                    ci_upper_col: 'CI_Upper',\n",
        "                    fold_col: 'FoldChange',\n",
        "                    'k': 'k',\n",
        "                    'n_papers': 'nPapers'\n",
        "                })\n",
        "\n",
        "                if analysis_type == 'two_way':\n",
        "                    plot_df_subgroups['GroupVar'] = plot_df_subgroups[moderator1].astype(str)\n",
        "                    plot_df_subgroups['LabelVar'] = plot_df_subgroups[moderator2].astype(str)\n",
        "                else:  # single\n",
        "                    plot_df_subgroups['GroupVar'] = 'Subgroup'\n",
        "                    plot_df_subgroups['LabelVar'] = plot_df_subgroups['group'].astype(str)\n",
        "\n",
        "                required_cols = ['GroupVar', 'LabelVar', 'k', 'nPapers',\n",
        "                               'EffectSize', 'SE', 'CI_Lower', 'CI_Upper', 'FoldChange']\n",
        "                plot_df_subgroups = plot_df_subgroups[required_cols]\n",
        "                plot_df_subgroups.dropna(subset=['EffectSize', 'SE'], inplace=True)\n",
        "\n",
        "                print(f\"  Subgroups: {len(plot_df_subgroups)}\")\n",
        "            else:\n",
        "                plot_df_subgroups = pd.DataFrame(columns=[\n",
        "                    'GroupVar', 'LabelVar', 'k', 'nPapers',\n",
        "                    'EffectSize', 'SE', 'CI_Lower', 'CI_Upper', 'FoldChange'\n",
        "                ])\n",
        "\n",
        "            # --- ADD OVERALL EFFECT ---\n",
        "            overall_effect_val = overall_results[overall_effect_key]\n",
        "            # FIX: Safely get values or default to Z-test version if reported missing\n",
        "            overall_se_val = overall_results.get(overall_se_key, overall_results.get('pooled_SE_random_Z'))\n",
        "            overall_ci_lower_val = overall_results.get(overall_ci_lower_key, overall_results.get('ci_lower_random_Z'))\n",
        "            overall_ci_upper_val = overall_results.get(overall_ci_upper_key, overall_results.get('ci_upper_random_Z'))\n",
        "\n",
        "            overall_k_val = overall_results['k']\n",
        "            overall_papers_val = overall_results['k_papers']\n",
        "            overall_fold_val = overall_results.get(overall_fold_key, np.nan)\n",
        "\n",
        "            overall_row = pd.DataFrame([{\n",
        "                'GroupVar': 'Overall',\n",
        "                'LabelVar': 'Overall',\n",
        "                'k': overall_k_val,\n",
        "                'nPapers': overall_papers_val,\n",
        "                'EffectSize': overall_effect_val,\n",
        "                'SE': overall_se_val,\n",
        "                'CI_Lower': overall_ci_lower_val,\n",
        "                'CI_Upper': overall_ci_upper_val,\n",
        "                'FoldChange': overall_fold_val\n",
        "            }])\n",
        "\n",
        "            print(f\"  Overall: k={overall_k_val}, papers={overall_papers_val}\")\n",
        "\n",
        "            # --- COMBINE DATA (OVERALL ON TOP) ---\n",
        "            plot_df = pd.concat([overall_row, plot_df_subgroups], ignore_index=True)\n",
        "\n",
        "            plot_df['SortKey_Group'] = plot_df['GroupVar'].apply(\n",
        "                lambda x: 'AAAAA' if x == 'Overall' else str(x)\n",
        "            )\n",
        "            plot_df['SortKey_Label'] = plot_df['LabelVar'].apply(\n",
        "                lambda x: 'AAAAA' if x == 'Overall' else str(x)\n",
        "            )\n",
        "            plot_df.sort_values(by=['SortKey_Group', 'SortKey_Label'], inplace=True)\n",
        "            plot_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "            if plot_df.empty:\n",
        "                print(\"\u274c ERROR: No data to plot\")\n",
        "                return\n",
        "\n",
        "            print(f\"  Total rows: {len(plot_df)}\")\n",
        "\n",
        "            # --- CALCULATE PLOT DIMENSIONS ---\n",
        "            num_rows = len(plot_df)\n",
        "            y_positions = np.arange(num_rows)\n",
        "\n",
        "            base_height = 2.5\n",
        "            plot_height = max(base_height, num_rows * height_per_row + 1.5)\n",
        "\n",
        "            y_margin_top = 0.75\n",
        "            y_margin_bottom = 0.75\n",
        "            y_lim_bottom = y_positions[0] - y_margin_bottom\n",
        "            y_lim_top = y_positions[-1] + y_margin_top\n",
        "\n",
        "            # --- Y-TICK LABELS (USE CUSTOM MAPPING) ---\n",
        "            y_tick_labels = []\n",
        "            for i, row in plot_df.iterrows():\n",
        "                if row['GroupVar'] == 'Overall':\n",
        "                    y_tick_labels.append(overall_label_text)\n",
        "                else:\n",
        "                    original_label = str(row['LabelVar'])\n",
        "                    display_label = label_mapping.get(original_label, original_label)\n",
        "                    y_tick_labels.append(display_label)\n",
        "\n",
        "            # --- CALCULATE X-AXIS LIMITS (FIXED - USE ALL DATA) ---\n",
        "            min_ci = plot_df['CI_Lower'].min()\n",
        "            max_ci = plot_df['CI_Upper'].max()\n",
        "            min_effect = plot_df['EffectSize'].min()\n",
        "            max_effect = plot_df['EffectSize'].max()\n",
        "\n",
        "            plot_min = min(min_ci, 0)\n",
        "            plot_max = max(max_ci, 0)\n",
        "            x_range = plot_max - plot_min\n",
        "\n",
        "            if x_range == 0:\n",
        "                x_range = 1\n",
        "\n",
        "            print(f\"\\n\ud83d\udccf Data range:\")\n",
        "            print(f\"  Effect sizes: [{min_effect:.3f}, {max_effect:.3f}]\")\n",
        "            print(f\"  CI range: [{min_ci:.3f}, {max_ci:.3f}]\")\n",
        "            print(f\"  Plot range: [{plot_min:.3f}, {plot_max:.3f}]\")\n",
        "\n",
        "            # --- ESTIMATE ANNOTATION SPACE NEEDED ---\n",
        "            max_k = int(plot_df['k'].max())\n",
        "            max_np = int(plot_df['nPapers'].max()) if 'nPapers' in plot_df.columns else 0\n",
        "\n",
        "            annot_parts = []\n",
        "            if show_k:\n",
        "                annot_parts.append(f\"k={max_k}\")\n",
        "            if show_papers:\n",
        "                annot_parts.append(f\"({max_np})\")\n",
        "            if show_fold_change and es_config.get('has_fold_change', False):\n",
        "                max_fold = plot_df['FoldChange'].abs().max() if 'FoldChange' in plot_df.columns else 10\n",
        "                annot_parts.append(f\"[-{max_fold:.2f}\u00d7]\")\n",
        "\n",
        "            example_annot = \" \".join(annot_parts) if annot_parts else \"k=100 (10)\"\n",
        "\n",
        "            char_width_fraction = (annot_fontsize / 8.0) * 0.006\n",
        "            annot_space_fraction = len(example_annot) * char_width_fraction\n",
        "\n",
        "            print(f\"  Annotation example: '{example_annot}' ({len(example_annot)} chars)\")\n",
        "\n",
        "            # --- CALCULATE SPACE FOR GROUP LABELS (TWO-WAY) ---\n",
        "            group_label_space = 0\n",
        "            if has_subgroups and analysis_type == 'two_way':\n",
        "                max_group_len = 0\n",
        "                for group_val in plot_df[plot_df['GroupVar'] != 'Overall']['GroupVar'].unique():\n",
        "                    custom_label = label_mapping.get(str(group_val), str(group_val))\n",
        "                    max_group_len = max(max_group_len, len(custom_label))\n",
        "\n",
        "                char_width_group = (group_label_fontsize / 8.0) * 0.006\n",
        "                group_label_space = max_group_len * char_width_group\n",
        "\n",
        "                print(f\"  Group label max: {max_group_len} chars\")\n",
        "\n",
        "            # --- AUTO-SCALE CALCULATION ---\n",
        "            if auto_scale:\n",
        "                left_padding = 0.05\n",
        "                annot_distance = 0.015\n",
        "                right_padding = 0.03\n",
        "\n",
        "                total_right_fraction = (annot_distance +\n",
        "                                       annot_space_fraction +\n",
        "                                       group_label_space +\n",
        "                                       right_padding)\n",
        "\n",
        "                x_min_auto = plot_min - x_range * left_padding\n",
        "                x_max_auto = plot_max + x_range * (total_right_fraction / (1 - total_right_fraction))\n",
        "\n",
        "                x_limits = (x_min_auto, x_max_auto)\n",
        "                print(f\"  X-axis (auto): [{x_min_auto:.3f}, {x_max_auto:.3f}]\")\n",
        "            else:\n",
        "                x_limits = (x_min_manual, x_max_manual)\n",
        "                print(f\"  X-axis (manual): [{x_min_manual:.3f}, {x_max_manual:.3f}]\")\n",
        "\n",
        "            # --- DETERMINE COLORS AND MARKERS ---\n",
        "            if color_scheme == 'gray':\n",
        "                subgroup_color = 'dimgray'\n",
        "                overall_color = 'black'\n",
        "                ci_color_subgroup = 'gray'\n",
        "                ci_color_overall = 'black'\n",
        "            elif color_scheme == 'color':\n",
        "                subgroup_color = '#4A90E2'\n",
        "                overall_color = '#E74C3C'\n",
        "                ci_color_subgroup = '#4A90E2'\n",
        "                ci_color_overall = '#E74C3C'\n",
        "            else:  # bw\n",
        "                subgroup_color = 'black'\n",
        "                overall_color = 'black'\n",
        "                ci_color_subgroup = 'black'\n",
        "                ci_color_overall = 'black'\n",
        "\n",
        "            if marker_style == 'circle_diamond':\n",
        "                subgroup_marker = 'o'\n",
        "                overall_marker = 'D'\n",
        "            elif marker_style == 'square_diamond':\n",
        "                subgroup_marker = 's'\n",
        "                overall_marker = 'D'\n",
        "            else:  # circle_star\n",
        "                subgroup_marker = 'o'\n",
        "                overall_marker = '*'\n",
        "\n",
        "            subgroup_marker_size = 6\n",
        "            overall_marker_size = 8\n",
        "            subgroup_ci_width = 1.5\n",
        "            overall_ci_width = 2.0\n",
        "\n",
        "            if ci_style == 'solid':\n",
        "                capsize = 0\n",
        "            elif ci_style == 'dashed':\n",
        "                capsize = 0\n",
        "            else:  # caps\n",
        "                capsize = 4\n",
        "\n",
        "            # --- CREATE FIGURE ---\n",
        "            fig, ax = plt.subplots(figsize=(plot_width, plot_height))\n",
        "\n",
        "            if transparent_bg:\n",
        "                fig.patch.set_alpha(0)\n",
        "                ax.patch.set_alpha(0)\n",
        "\n",
        "            print(f\"\\n\ud83c\udfa8 Plotting {num_rows} rows...\")\n",
        "\n",
        "            # --- PLOT DATA POINTS AND ERROR BARS ---\n",
        "            for i, row in plot_df.iterrows():\n",
        "                is_overall = (row['GroupVar'] == 'Overall')\n",
        "\n",
        "                marker = overall_marker if is_overall else subgroup_marker\n",
        "                msize = overall_marker_size if is_overall else subgroup_marker_size\n",
        "                color = overall_color if is_overall else subgroup_color\n",
        "                ci_color = ci_color_overall if is_overall else ci_color_subgroup\n",
        "                ci_width = overall_ci_width if is_overall else subgroup_ci_width\n",
        "                zorder = 5 if is_overall else 3\n",
        "\n",
        "                linestyle = '-' if ci_style != 'dashed' else '--'\n",
        "\n",
        "                ax.errorbar(\n",
        "                    x=row['EffectSize'],\n",
        "                    y=y_positions[i],\n",
        "                    xerr=[[row['EffectSize'] - row['CI_Lower']],\n",
        "                          [row['CI_Upper'] - row['EffectSize']]],\n",
        "                    fmt='none',\n",
        "                    capsize=capsize,\n",
        "                    color=ci_color,\n",
        "                    linewidth=ci_width,\n",
        "                    linestyle=linestyle,\n",
        "                    alpha=0.9,\n",
        "                    zorder=zorder-1\n",
        "                )\n",
        "\n",
        "                ax.plot(\n",
        "                    row['EffectSize'],\n",
        "                    y_positions[i],\n",
        "                    marker=marker,\n",
        "                    markersize=msize,\n",
        "                    markerfacecolor=color,\n",
        "                    markeredgecolor='black' if color_scheme != 'bw' else 'black',\n",
        "                    markeredgewidth=1.0,\n",
        "                    linestyle='none',\n",
        "                    zorder=zorder\n",
        "                )\n",
        "\n",
        "            # --- SET AXIS LIMITS FIRST ---\n",
        "            ax.set_xlim(x_limits[0], x_limits[1])\n",
        "            ax.set_ylim(y_lim_top, y_lim_bottom)  # Inverted\n",
        "\n",
        "            final_xlims = ax.get_xlim()\n",
        "            final_xrange = final_xlims[1] - final_xlims[0]\n",
        "\n",
        "            print(f\"  Final X-axis: [{final_xlims[0]:.3f}, {final_xlims[1]:.3f}]\")\n",
        "\n",
        "            # --- ADD ANNOTATIONS ---\n",
        "            print(f\"  Adding annotations...\")\n",
        "\n",
        "            annot_x_offset = annot_distance * final_xrange\n",
        "\n",
        "            for i, row in plot_df.iterrows():\n",
        "                is_overall = (row['GroupVar'] == 'Overall')\n",
        "                font_weight = 'bold' if is_overall else 'normal'\n",
        "\n",
        "                annot_parts = []\n",
        "                if show_k:\n",
        "                    annot_parts.append(f\"k={int(row['k'])}\")\n",
        "                if show_papers and pd.notna(row['nPapers']):\n",
        "                    annot_parts.append(f\"({int(row['nPapers'])})\")\n",
        "                if show_fold_change and pd.notna(row['FoldChange']) and es_config.get('has_fold_change', False):\n",
        "                    fold_sign = \"+\" if row['FoldChange'] > 0 else \"\"\n",
        "                    annot_parts.append(f\"[{fold_sign}{row['FoldChange']:.2f}\u00d7]\")\n",
        "\n",
        "                annotation_text = \" \".join(annot_parts) if annot_parts else \"\"\n",
        "\n",
        "                if annotation_text:\n",
        "                    if annot_pos == 'right':\n",
        "                        x_pos = row['CI_Upper'] + annot_x_offset + (annot_offset * final_xrange * 0.1)\n",
        "                        y_pos = y_positions[i]\n",
        "                        va = 'center'\n",
        "                        ha = 'left'\n",
        "                    elif annot_pos == 'above':\n",
        "                        x_pos = row['EffectSize'] + (annot_offset * final_xrange * 0.1)\n",
        "                        y_pos = y_positions[i] - 0.2\n",
        "                        va = 'bottom'\n",
        "                        ha = 'center'\n",
        "                    else:  # below\n",
        "                        x_pos = row['EffectSize'] + (annot_offset * final_xrange * 0.1)\n",
        "                        y_pos = y_positions[i] + 0.2\n",
        "                        va = 'top'\n",
        "                        ha = 'center'\n",
        "\n",
        "                    ax.text(\n",
        "                        x_pos, y_pos,\n",
        "                        annotation_text,\n",
        "                        va=va, ha=ha,\n",
        "                        fontsize=annot_fontsize,\n",
        "                        fontweight=font_weight,\n",
        "                        clip_on=False\n",
        "                    )\n",
        "\n",
        "            # --- ADD GROUP LABELS (TWO-WAY) ---\n",
        "            if has_subgroups and analysis_type == 'two_way':\n",
        "                print(f\"  Adding group labels...\")\n",
        "\n",
        "                current_group = None\n",
        "                first_subgroup_idx = 1 if 'Overall' in plot_df['GroupVar'].values else 0\n",
        "                group_label_x_base = final_xlims[1] - (right_padding * final_xrange)\n",
        "\n",
        "                for i, row in plot_df.iterrows():\n",
        "                    group_val = str(row['GroupVar'])\n",
        "\n",
        "                    if group_val != 'Overall' and group_val != current_group:\n",
        "                        if i > first_subgroup_idx:\n",
        "                            ax.axhline(\n",
        "                                y=y_positions[i] - 0.5,\n",
        "                                color='darkgray',\n",
        "                                linewidth=0.8,\n",
        "                                linestyle='-',\n",
        "                                xmin=0.01,\n",
        "                                xmax=0.99,\n",
        "                                zorder=1\n",
        "                            )\n",
        "\n",
        "                        group_indices = plot_df[plot_df['GroupVar'] == group_val].index\n",
        "                        label_y = (y_positions[group_indices[0]] + y_positions[group_indices[-1]]) / 2.0\n",
        "\n",
        "                        label_x = group_label_x_base + (group_label_h_offset * final_xrange * 0.05)\n",
        "                        label_y = label_y + group_label_v_offset\n",
        "\n",
        "                        display_group_label = label_mapping.get(group_val, group_val)\n",
        "\n",
        "                        ax.text(\n",
        "                            label_x, label_y,\n",
        "                            display_group_label,\n",
        "                            va='center',\n",
        "                            ha='right',\n",
        "                            fontweight='bold',\n",
        "                            fontsize=group_label_fontsize,\n",
        "                            color='black',\n",
        "                            clip_on=False\n",
        "                        )\n",
        "\n",
        "                        current_group = group_val\n",
        "\n",
        "            # --- ADD SEPARATOR LINE BELOW OVERALL ---\n",
        "            if len(plot_df) > 1:\n",
        "                separator_y = y_positions[0] + 0.5\n",
        "                ax.axhline(\n",
        "                    y=separator_y,\n",
        "                    color='black',\n",
        "                    linewidth=1.5,\n",
        "                    linestyle='-'\n",
        "                )\n",
        "\n",
        "            # --- CUSTOMIZE AXES ---\n",
        "            print(f\"  Customizing axes...\")\n",
        "\n",
        "            if show_null_line:\n",
        "                ax.axvline(\n",
        "                    x=0,\n",
        "                    color='black',\n",
        "                    linestyle='-',\n",
        "                    linewidth=1.5,\n",
        "                    alpha=0.8,\n",
        "                    zorder=1\n",
        "                )\n",
        "\n",
        "            ax.set_xlabel(x_label, fontsize=label_fontsize, fontweight='bold')\n",
        "            if show_ylabel:\n",
        "                ax.set_ylabel(y_label, fontsize=label_fontsize, fontweight='bold')\n",
        "\n",
        "            if show_title:\n",
        "                ax.set_title(graph_title, fontweight='bold', fontsize=title_fontsize, pad=15)\n",
        "\n",
        "            ax.set_yticks(y_positions)\n",
        "            ax.set_yticklabels(y_tick_labels, fontsize=tick_fontsize)\n",
        "            ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
        "\n",
        "            if show_grid:\n",
        "                if grid_style == 'dashed_light':\n",
        "                    ax.grid(axis='x', alpha=0.3, linestyle='--', linewidth=0.5)\n",
        "                elif grid_style == 'dotted_light':\n",
        "                    ax.grid(axis='x', alpha=0.3, linestyle=':', linewidth=0.5)\n",
        "                else:  # solid_light\n",
        "                    ax.grid(axis='x', alpha=0.2, linestyle='-', linewidth=0.5)\n",
        "\n",
        "            # --- ADD FOLD-CHANGE AXIS (TOP) ---\n",
        "            if show_fold_axis and es_config.get('has_fold_change', False):\n",
        "                print(f\"  Adding fold-change axis...\")\n",
        "\n",
        "                ax2 = ax.twiny()\n",
        "\n",
        "                fold_ticks_lnRR = np.array([-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2])\n",
        "                fold_ticks_RR = np.exp(fold_ticks_lnRR)\n",
        "\n",
        "                valid_mask = ((fold_ticks_lnRR >= final_xlims[0]) &\n",
        "                             (fold_ticks_lnRR <= final_xlims[1]))\n",
        "                fold_ticks_lnRR = fold_ticks_lnRR[valid_mask]\n",
        "                fold_ticks_RR = fold_ticks_RR[valid_mask]\n",
        "\n",
        "                ax2.set_xlim(final_xlims[0], final_xlims[1])\n",
        "                ax2.set_xticks(fold_ticks_lnRR)\n",
        "\n",
        "                fold_labels = []\n",
        "                for rr in fold_ticks_RR:\n",
        "                    if rr < 1:\n",
        "                        fold_labels.append(f\"{1/rr:.1f}\u00d7 \u2193\")\n",
        "                    elif rr > 1:\n",
        "                        fold_labels.append(f\"{rr:.1f}\u00d7 \u2191\")\n",
        "                    else:\n",
        "                        fold_labels.append(\"1\u00d7\")\n",
        "\n",
        "                ax2.set_xticklabels(fold_labels, fontsize=tick_fontsize)\n",
        "                ax2.set_xlabel(\"Fold-Change\", fontsize=label_fontsize, fontweight='bold')\n",
        "\n",
        "            # --- FINALIZE PLOT ---\n",
        "            fig.tight_layout()\n",
        "\n",
        "            # --- SAVE FILES ---\n",
        "            print(f\"\\n\ud83d\udcbe Saving files...\")\n",
        "\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            base_filename = f\"{filename_prefix}_{plot_model}_{timestamp}\"\n",
        "\n",
        "            saved_files = []\n",
        "\n",
        "            if save_pdf:\n",
        "                pdf_filename = f\"{base_filename}.pdf\"\n",
        "                fig.savefig(pdf_filename, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(pdf_filename)\n",
        "                print(f\"  \u2713 {pdf_filename}\")\n",
        "\n",
        "            if save_png:\n",
        "                png_filename = f\"{base_filename}.png\"\n",
        "                fig.savefig(png_filename, dpi=png_dpi, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(png_filename)\n",
        "                print(f\"  \u2713 {png_filename} (DPI: {png_dpi})\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"\\n\" + \"=\"*70)\n",
        "            print(\"\u2705 FOREST PLOT COMPLETE\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Files: {', '.join(saved_files)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n\u274c ERROR: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# --- 4. CREATE BUTTON AND DISPLAY ---\n",
        "plot_button = widgets.Button(\n",
        "    description='\ud83d\udcca Generate Forest Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold', 'font_size': '14px'}\n",
        ")\n",
        "\n",
        "plot_button.on_click(generate_plot)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 FOREST PLOT INTERFACE READY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udc46 Customize your plot using the tabs above, then click Generate\")\n",
        "print(\"\\n\ud83d\udcdd Tips:\")\n",
        "print(\"  \u2022 Use the 'Labels' tab to rename coded variables\")\n",
        "print(\"  \u2022 Auto-scale considers ALL data points for proper spacing\")\n",
        "print(\"  \u2022 Annotations and group labels will fit within the plot\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcca Forest Plot Generator</h3>\"),\n",
        "    widgets.HTML(\"<p style='color: #666;'>Create publication-ready forest plots with full customization</p>\"),\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    tab,\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    plot_button,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-XXpDWLFt-s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PQQCAwh5C8A6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title \ud83c\udf4e 11. Orchard Plot\n",
        "# =============================================================================\n",
        "# CELL 15: PUBLICATION-READY ORCHARD PLOT\n",
        "# Purpose: Create customizable orchard plots for meta-analysis results\n",
        "# Enhanced: Full GUI matching Dynamic Forest Plot functionality\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import datetime\n",
        "from scipy.stats import t, norm\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "print(\"=\"*70)\n",
        "print(\"ORCHARD PLOT CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"ANALYSIS_CONFIG not found. Run previous cells first.\")\n",
        "\n",
        "    # Load Raw Data\n",
        "    if 'analysis_data' in globals():\n",
        "        df_orchard = analysis_data.copy()\n",
        "    elif 'data_filtered' in globals():\n",
        "        df_orchard = data_filtered.copy()\n",
        "    else:\n",
        "        df_orchard = ANALYSIS_CONFIG.get('cleaned_data', ANALYSIS_CONFIG.get('data'))\n",
        "\n",
        "    if df_orchard is None:\n",
        "        raise ValueError(\"Analysis data not found.\")\n",
        "\n",
        "    # Load Results & Config\n",
        "    overall_res = ANALYSIS_CONFIG['overall_results']\n",
        "    es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "\n",
        "    if 'subgroup_results' in ANALYSIS_CONFIG and 'results_df' in ANALYSIS_CONFIG['subgroup_results']:\n",
        "        subgroup_config = ANALYSIS_CONFIG['subgroup_results']\n",
        "        res_orchard = subgroup_config['results_df'].copy()\n",
        "\n",
        "        analysis_type = subgroup_config.get('analysis_type', 'single')\n",
        "        mod1_name = subgroup_config.get('moderator1', 'Subgroup')\n",
        "        mod2_name = subgroup_config.get('moderator2', None)\n",
        "        has_subgroups = True\n",
        "\n",
        "        # Sort Subgroups\n",
        "        if analysis_type == 'two_way' and mod2_name:\n",
        "            if mod1_name in res_orchard.columns and mod2_name in res_orchard.columns:\n",
        "                res_orchard = res_orchard.sort_values([mod1_name, mod2_name]).reset_index(drop=True)\n",
        "            default_title = f\"Orchard Plot: {mod1_name} \u00d7 {mod2_name}\"\n",
        "            default_y_label = mod2_name\n",
        "        else:\n",
        "            res_orchard = res_orchard.sort_values('group').reset_index(drop=True)\n",
        "            default_title = f\"Orchard Plot: {mod1_name}\"\n",
        "            default_y_label = mod1_name\n",
        "    else:\n",
        "        # No subgroups\n",
        "        res_orchard = pd.DataFrame()\n",
        "        mod1_name = 'Subgroup'\n",
        "        mod2_name = None\n",
        "        has_subgroups = False\n",
        "        analysis_type = 'single'\n",
        "        default_title = \"Orchard Plot: Overall Effect\"\n",
        "        default_y_label = \"Groups\"\n",
        "\n",
        "    default_x_label = es_config.get('effect_label', \"Effect Size\")\n",
        "\n",
        "    # --- ADD OVERALL ROW ---\n",
        "    overall_row = pd.DataFrame([{\n",
        "        'group': 'Overall',\n",
        "        'pooled_effect_re': overall_res['pooled_effect_random'],\n",
        "        'pooled_se_re': overall_res.get('pooled_SE_random_reported', 0.1),\n",
        "        'tau_squared': overall_res.get('tau_squared', 0),\n",
        "        'sigma_squared': overall_res.get('sigma_squared', 0),\n",
        "        'k': overall_res['k'],\n",
        "        'n_papers': overall_res.get('k_papers', overall_res['k']),\n",
        "        mod1_name: 'Overall',\n",
        "        mod2_name: 'Overall' if mod2_name else None\n",
        "    }])\n",
        "\n",
        "    # Combine: Overall first, then subgroups\n",
        "    plot_df_final = pd.concat([overall_row, res_orchard], ignore_index=True)\n",
        "\n",
        "    # Setup Columns for Raw Data\n",
        "    effect_col = es_config.get('es_col', 'hedges_g')\n",
        "    var_col = es_config.get('var_col', 'Vg')\n",
        "    df_orchard = df_orchard.dropna(subset=[effect_col, var_col])\n",
        "\n",
        "    # --- UPDATED: Dynamic Inference (Row-by-Row) ---\n",
        "    # 1. Get Global Settings\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        gs = ANALYSIS_CONFIG.get('global_settings', {})\n",
        "        alpha = gs.get('alpha', 0.05)\n",
        "        dist_type = gs.get('dist_type', 'norm')\n",
        "    else:\n",
        "        alpha = 0.05\n",
        "        dist_type = 'norm'\n",
        "\n",
        "    q_val = 1 - (alpha / 2)\n",
        "\n",
        "    # 2. Define helper to get critical value per subgroup\n",
        "    def get_critical_value(row):\n",
        "        if dist_type == 't':\n",
        "            # Degrees of Freedom = Number of Papers - 1 (Conservative for 3-Level)\n",
        "            # Fallback to 'k' if 'n_papers' is missing\n",
        "            n = row.get('n_papers', row.get('k', 2))\n",
        "            df = max(1, int(n) - 1)\n",
        "            return t.ppf(q_val, df)\n",
        "        else:\n",
        "            # Normal Distribution (Z)\n",
        "            return norm.ppf(q_val)\n",
        "\n",
        "    # 3. Apply to create a dynamic 'crit_val' column\n",
        "    plot_df_final['crit_val'] = plot_df_final.apply(get_critical_value, axis=1)\n",
        "\n",
        "    # 4. Calculate PIs and CIs using the dynamic critical value\n",
        "    sigma_sq = plot_df_final.get('sigma_squared', plot_df_final.get('sigma_2', 0)).fillna(0)\n",
        "    plot_df_final['PI_SD'] = np.sqrt(plot_df_final['pooled_se_re']**2 + plot_df_final['tau_squared'] + sigma_sq)\n",
        "\n",
        "    # Use the dynamic 'crit_val' instead of 1.96\n",
        "    plot_df_final['PI_Lower'] = plot_df_final['pooled_effect_re'] - plot_df_final['crit_val'] * plot_df_final['PI_SD']\n",
        "    plot_df_final['PI_Upper'] = plot_df_final['pooled_effect_re'] + plot_df_final['crit_val'] * plot_df_final['PI_SD']\n",
        "\n",
        "    plot_df_final['CI_Lower'] = plot_df_final['pooled_effect_re'] - plot_df_final['crit_val'] * plot_df_final['pooled_se_re']\n",
        "    plot_df_final['CI_Upper'] = plot_df_final['pooled_effect_re'] + plot_df_final['crit_val'] * plot_df_final['pooled_se_re']\n",
        "    # -----------------------------------------------\n",
        "    print(f\"\u2713 Analysis type: {analysis_type}\")\n",
        "    print(f\"\u2713 Has subgroups: {has_subgroups}\")\n",
        "    print(f\"\u2713 Total groups: {len(plot_df_final)}\")\n",
        "    print(f\"\u2713 Configuration loaded successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Initialization Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    plot_df_final = None\n",
        "\n",
        "# --- 2. DEFINE CUSTOMIZATION WIDGETS ---\n",
        "\n",
        "# ========== TAB 1: STYLE & LAYOUT ==========\n",
        "style_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83c\udfa8 Style & Layout</h3>\")\n",
        "\n",
        "# Dimensions Section\n",
        "width_widget = widgets.FloatSlider(\n",
        "    value=10.0, min=6.0, max=16.0, step=0.5,\n",
        "    description='Plot Width (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "height_widget = widgets.FloatSlider(\n",
        "    value=max(6.0, len(plot_df_final)*0.6 if plot_df_final is not None else 6.0),\n",
        "    min=4.0, max=30.0, step=0.5,\n",
        "    description='Plot Height (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Typography Section\n",
        "title_fontsize_widget = widgets.IntSlider(\n",
        "    value=14, min=8, max=24, step=1,\n",
        "    description='Title Font Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "label_fontsize_widget = widgets.IntSlider(\n",
        "    value=12, min=8, max=18, step=1,\n",
        "    description='Axis Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "tick_fontsize_widget = widgets.IntSlider(\n",
        "    value=10, min=6, max=16, step=1,\n",
        "    description='Tick Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_fontsize_widget = widgets.IntSlider(\n",
        "    value=9, min=6, max=14, step=1,\n",
        "    description='Annotation Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Visual Style Section\n",
        "color_scheme_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Viridis (Default)', 'viridis'),\n",
        "        ('Plasma', 'plasma'),\n",
        "        ('Coolwarm', 'coolwarm'),\n",
        "        ('Grayscale (Publication)', 'gray'),\n",
        "        ('Color Palette (Tab10)', 'tab10'),\n",
        "        ('Color Palette (Set2)', 'Set2'),\n",
        "        ('Black & White Only', 'bw')\n",
        "    ],\n",
        "    value='viridis',\n",
        "    description='Color Scheme:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "marker_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Circle/Diamond (\u25cf/\u25c6)', 'circle_diamond'),\n",
        "        ('Square/Diamond (\u25a0/\u25c6)', 'square_diamond'),\n",
        "        ('Circle/Star (\u25cf/\u2605)', 'circle_star')\n",
        "    ],\n",
        "    value='circle_diamond',\n",
        "    description='Marker Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "ci_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Solid Line', 'solid'),\n",
        "        ('Dashed Line', 'dashed'),\n",
        "        ('Solid with Caps', 'caps')\n",
        "    ],\n",
        "    value='solid',\n",
        "    description='CI Line Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Orientation Section\n",
        "orientation_widget = widgets.Dropdown(\n",
        "    options=[('Horizontal', 'h'), ('Vertical', 'v')],\n",
        "    value='h',\n",
        "    description='Orientation:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    style_header,\n",
        "    widgets.HTML(\"<b>Dimensions:</b>\"),\n",
        "    width_widget,\n",
        "    height_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Typography:</b>\"),\n",
        "    title_fontsize_widget,\n",
        "    label_fontsize_widget,\n",
        "    tick_fontsize_widget,\n",
        "    annot_fontsize_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Visual Style:</b>\"),\n",
        "    color_scheme_widget,\n",
        "    marker_style_widget,\n",
        "    ci_style_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Orientation:</b>\"),\n",
        "    orientation_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 2: TEXT & LABELS ==========\n",
        "text_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcdd Text & Labels</h3>\")\n",
        "\n",
        "show_title_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Plot Title',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "title_widget = widgets.Text(\n",
        "    value=default_title,\n",
        "    description='Plot Title:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "xlabel_widget = widgets.Text(\n",
        "    value=default_x_label,\n",
        "    description='X-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "show_ylabel_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Y-Axis Label',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "ylabel_widget = widgets.Text(\n",
        "    value=default_y_label,\n",
        "    description='Y-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "text_tab = widgets.VBox([\n",
        "    text_header,\n",
        "    widgets.HTML(\"<b>Title:</b>\"),\n",
        "    show_title_widget,\n",
        "    title_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Axis Labels:</b>\"),\n",
        "    xlabel_widget,\n",
        "    show_ylabel_widget,\n",
        "    ylabel_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 3: ORCHARD ELEMENTS ==========\n",
        "orchard_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83c\udf4e Orchard Elements</h3>\")\n",
        "\n",
        "# Raw Data Points Section\n",
        "point_alpha_widget = widgets.FloatSlider(\n",
        "    value=0.5, min=0.1, max=1.0, step=0.05,\n",
        "    description='Point Alpha:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "point_size_widget = widgets.IntSlider(\n",
        "    value=50, min=10, max=200, step=5,\n",
        "    description='Point Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "jitter_widget = widgets.FloatSlider(\n",
        "    value=0.10, min=0.01, max=0.4, step=0.01,\n",
        "    description='Jitter Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "scale_points_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Scale Points by Weight',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Pooled Effects Visualization Section\n",
        "show_pi_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show PI - Prediction Interval (Trunk)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "pi_linewidth_widget = widgets.FloatSlider(\n",
        "    value=4.0, min=1.0, max=8.0, step=0.5,\n",
        "    description='PI Line Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "pi_alpha_widget = widgets.FloatSlider(\n",
        "    value=0.3, min=0.1, max=1.0, step=0.05,\n",
        "    description='PI Alpha:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_ci_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show CI - Confidence Interval (Fruit)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "ci_linewidth_widget = widgets.FloatSlider(\n",
        "    value=2.0, min=1.0, max=5.0, step=0.5,\n",
        "    description='CI Line Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Annotations Section\n",
        "show_k_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show k (observations)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_papers_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Paper Count',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_effect_value_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Show Effect Size Value',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_pos_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Right of Interval', 'right'),\n",
        "        ('Above Marker', 'above'),\n",
        "        ('Below Marker', 'below')\n",
        "    ],\n",
        "    value='right',\n",
        "    description='Position:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "annot_h_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-1.0, max=1.0, step=0.05,\n",
        "    description='H-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    readout_format='.2f'\n",
        ")\n",
        "\n",
        "annot_v_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-1.0, max=1.0, step=0.05,\n",
        "    description='V-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    readout_format='.2f'\n",
        ")\n",
        "\n",
        "# Group Organization Section\n",
        "group_gap_widget = widgets.FloatSlider(\n",
        "    value=1.0, min=0.0, max=3.0, step=0.25,\n",
        "    description='Group Gap:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_inner_labels_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Inner Group Labels',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "group_label_h_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-2.0, max=2.0, step=0.1,\n",
        "    description='Group H-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "group_label_v_offset_widget = widgets.FloatSlider(\n",
        "    value=0.0, min=-2.0, max=2.0, step=0.1,\n",
        "    description='Group V-Offset:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "group_label_fontsize_widget = widgets.IntSlider(\n",
        "    value=12, min=6, max=20, step=1,\n",
        "    description='Group Fontsize:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "orchard_tab = widgets.VBox([\n",
        "    orchard_header,\n",
        "    widgets.HTML(\"<b>Raw Data Points (Leaves):</b>\"),\n",
        "    point_alpha_widget,\n",
        "    point_size_widget,\n",
        "    jitter_widget,\n",
        "    scale_points_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Pooled Effects Visualization:</b>\"),\n",
        "    show_pi_widget,\n",
        "    pi_linewidth_widget,\n",
        "    pi_alpha_widget,\n",
        "    show_ci_widget,\n",
        "    ci_linewidth_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Annotations:</b>\"),\n",
        "    show_k_widget,\n",
        "    show_papers_widget,\n",
        "    show_effect_value_widget,\n",
        "    annot_pos_widget,\n",
        "    annot_h_offset_widget,\n",
        "    annot_v_offset_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Group Organization:</b>\"),\n",
        "    group_gap_widget,\n",
        "    show_inner_labels_widget,\n",
        "    group_label_h_offset_widget,\n",
        "    group_label_v_offset_widget,\n",
        "    group_label_fontsize_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 4: AXES & GRID ==========\n",
        "axes_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udccf Axes & Grid</h3>\")\n",
        "\n",
        "# Axis Scaling Section\n",
        "auto_scale_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Auto-Scale Axis',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "axis_min_widget = widgets.FloatText(\n",
        "    value=-2.0,\n",
        "    description='Axis Min:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "axis_max_widget = widgets.FloatText(\n",
        "    value=2.0,\n",
        "    description='Axis Max:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "manual_scale_box = widgets.HBox([axis_min_widget, axis_max_widget])\n",
        "\n",
        "def toggle_manual_scale(change):\n",
        "    if change['new']:\n",
        "        axis_min_widget.layout.visibility = 'hidden'\n",
        "        axis_max_widget.layout.visibility = 'hidden'\n",
        "    else:\n",
        "        axis_min_widget.layout.visibility = 'visible'\n",
        "        axis_max_widget.layout.visibility = 'visible'\n",
        "\n",
        "auto_scale_widget.observe(toggle_manual_scale, names='value')\n",
        "\n",
        "# Grid & Reference Lines Section\n",
        "show_grid_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Grid',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "grid_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Dashed (Light)', 'dashed'),\n",
        "        ('Dotted (Light)', 'dotted'),\n",
        "        ('Solid (Light)', 'solid')\n",
        "    ],\n",
        "    value='dashed',\n",
        "    description='Grid Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "show_null_line_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Null Effect Line',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "null_line_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Solid', 'solid'),\n",
        "        ('Dashed', 'dashed')\n",
        "    ],\n",
        "    value='solid',\n",
        "    description='Null Line Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "null_line_width_widget = widgets.FloatSlider(\n",
        "    value=1.5, min=0.5, max=3.0, step=0.25,\n",
        "    description='Null Line Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Separator Lines Section\n",
        "show_separators_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Group Separators',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "separator_width_widget = widgets.FloatSlider(\n",
        "    value=0.8, min=0.5, max=2.0, step=0.1,\n",
        "    description='Separator Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "separator_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Solid', 'solid'),\n",
        "        ('Dashed', 'dashed')\n",
        "    ],\n",
        "    value='solid',\n",
        "    description='Separator Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "axes_tab = widgets.VBox([\n",
        "    axes_header,\n",
        "    widgets.HTML(\"<b>Axis Scaling:</b>\"),\n",
        "    auto_scale_widget,\n",
        "    manual_scale_box,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Grid & Reference Lines:</b>\"),\n",
        "    show_grid_widget,\n",
        "    grid_style_widget,\n",
        "    show_null_line_widget,\n",
        "    null_line_style_widget,\n",
        "    null_line_width_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Separator Lines:</b>\"),\n",
        "    show_separators_widget,\n",
        "    separator_width_widget,\n",
        "    separator_style_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 5: EXPORT OPTIONS ==========\n",
        "export_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcbe Export Options</h3>\")\n",
        "\n",
        "save_pdf_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PDF',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "save_png_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PNG',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "png_dpi_widget = widgets.IntSlider(\n",
        "    value=300, min=150, max=600, step=50,\n",
        "    description='PNG DPI:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "filename_widget = widgets.Text(\n",
        "    value='OrchardPlot',\n",
        "    description='Filename Prefix:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "transparent_bg_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Transparent Background',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "include_timestamp_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Include Timestamp',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    export_header,\n",
        "    widgets.HTML(\"<b>File Formats:</b>\"),\n",
        "    save_pdf_widget,\n",
        "    save_png_widget,\n",
        "    png_dpi_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>File Settings:</b>\"),\n",
        "    filename_widget,\n",
        "    transparent_bg_widget,\n",
        "    include_timestamp_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 6: LABEL EDITOR ==========\n",
        "label_editor_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\u270f\ufe0f Label Editor</h3>\")\n",
        "label_editor_desc = widgets.HTML(\n",
        "    \"<p style='color: #666;'><i>Customize display names for all groups and subgroups in the plot</i></p>\"\n",
        ")\n",
        "\n",
        "print(f\"\\n\ud83d\udd0d Identifying labels for editor...\")\n",
        "\n",
        "unique_labels = set()\n",
        "label_widgets_dict = {}\n",
        "\n",
        "try:\n",
        "    if has_subgroups and plot_df_final is not None:\n",
        "        if analysis_type == 'single':\n",
        "            unique_labels.update(res_orchard['group'].astype(str).unique())\n",
        "        else:  # two_way\n",
        "            unique_labels.update(plot_df_final[mod1_name].astype(str).unique())\n",
        "            unique_labels.update(plot_df_final[mod2_name].astype(str).unique())\n",
        "\n",
        "    unique_labels.add('Overall')\n",
        "    sorted_labels = sorted(list(unique_labels))\n",
        "\n",
        "    print(f\"  \u2713 Found {len(sorted_labels)} unique labels\")\n",
        "\n",
        "    label_editor_widgets = []\n",
        "    for label in sorted_labels:\n",
        "        widget_label = f\"Overall Effect:\" if label == 'Overall' else f\"{label}:\"\n",
        "        text_widget = widgets.Text(\n",
        "            value=str(label),\n",
        "            description=widget_label,\n",
        "            layout=widgets.Layout(width='500px'),\n",
        "            style={'description_width': '200px'}\n",
        "        )\n",
        "        label_editor_widgets.append(text_widget)\n",
        "        label_widgets_dict[str(label)] = text_widget\n",
        "\n",
        "    label_editor_tab = widgets.VBox([\n",
        "        label_editor_header,\n",
        "        label_editor_desc,\n",
        "        widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "        widgets.HTML(\n",
        "            \"<p><b>Instructions:</b> Edit the text on the right to change how labels appear in the plot. \"\n",
        "            \"The original coded names are shown on the left.</p>\"\n",
        "        ),\n",
        "        widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "        *label_editor_widgets\n",
        "    ])\n",
        "\n",
        "    print(f\"  \u2713 Label editor created\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  \u26a0\ufe0f  Error creating label editor: {e}\")\n",
        "    label_editor_tab = widgets.VBox([\n",
        "        label_editor_header,\n",
        "        widgets.HTML(\"<p style='color: red;'>Error creating label editor.</p>\")\n",
        "    ])\n",
        "    label_widgets_dict = {}\n",
        "\n",
        "# ========== CREATE TAB WIDGET ==========\n",
        "tab_children = [style_tab, text_tab, orchard_tab, axes_tab, export_tab, label_editor_tab]\n",
        "tab = widgets.Tab(children=tab_children)\n",
        "tab.set_title(0, '\ud83c\udfa8 Style')\n",
        "tab.set_title(1, '\ud83d\udcdd Text')\n",
        "tab.set_title(2, '\ud83c\udf4e Orchard')\n",
        "tab.set_title(3, '\ud83d\udccf Axes')\n",
        "tab.set_title(4, '\ud83d\udcbe Export')\n",
        "tab.set_title(5, '\u270f\ufe0f Labels')\n",
        "\n",
        "# --- 3. DEFINE PLOT GENERATION FUNCTION ---\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "def generate_orchard_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING ORCHARD PLOT\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        if plot_df_final is None:\n",
        "            print(\"\u274c ERROR: No data available\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # --- GET WIDGET VALUES ---\n",
        "            plot_width = width_widget.value\n",
        "            plot_height = height_widget.value\n",
        "            title_fontsize = title_fontsize_widget.value\n",
        "            label_fontsize = label_fontsize_widget.value\n",
        "            tick_fontsize = tick_fontsize_widget.value\n",
        "            annot_fontsize = annot_fontsize_widget.value\n",
        "            color_scheme = color_scheme_widget.value\n",
        "            marker_style = marker_style_widget.value\n",
        "            ci_style = ci_style_widget.value\n",
        "            orientation = orientation_widget.value\n",
        "\n",
        "            show_title = show_title_widget.value\n",
        "            graph_title = title_widget.value\n",
        "            x_label = xlabel_widget.value\n",
        "            show_ylabel = show_ylabel_widget.value\n",
        "            y_label = ylabel_widget.value\n",
        "\n",
        "            point_alpha = point_alpha_widget.value\n",
        "            point_size = point_size_widget.value\n",
        "            jitter_amount = jitter_widget.value\n",
        "            scale_points = scale_points_widget.value\n",
        "\n",
        "            show_pi = show_pi_widget.value\n",
        "            pi_linewidth = pi_linewidth_widget.value\n",
        "            pi_alpha = pi_alpha_widget.value\n",
        "            show_ci = show_ci_widget.value\n",
        "            ci_linewidth = ci_linewidth_widget.value\n",
        "\n",
        "            show_k = show_k_widget.value\n",
        "            show_papers = show_papers_widget.value\n",
        "            show_effect_value = show_effect_value_widget.value\n",
        "            annot_pos = annot_pos_widget.value\n",
        "            annot_h_offset = annot_h_offset_widget.value\n",
        "            annot_v_offset = annot_v_offset_widget.value\n",
        "\n",
        "            group_gap = group_gap_widget.value\n",
        "            show_inner_labels = show_inner_labels_widget.value\n",
        "            group_label_h_offset = group_label_h_offset_widget.value\n",
        "            group_label_v_offset = group_label_v_offset_widget.value\n",
        "            group_label_fontsize = group_label_fontsize_widget.value\n",
        "\n",
        "            auto_scale = auto_scale_widget.value\n",
        "            axis_min_manual = axis_min_widget.value\n",
        "            axis_max_manual = axis_max_widget.value\n",
        "            show_grid = show_grid_widget.value\n",
        "            grid_style = grid_style_widget.value\n",
        "            show_null_line = show_null_line_widget.value\n",
        "            null_line_style = null_line_style_widget.value\n",
        "            null_line_width = null_line_width_widget.value\n",
        "\n",
        "            show_separators = show_separators_widget.value\n",
        "            separator_width = separator_width_widget.value\n",
        "            separator_style = separator_style_widget.value\n",
        "\n",
        "            save_pdf = save_pdf_widget.value\n",
        "            save_png = save_png_widget.value\n",
        "            png_dpi = png_dpi_widget.value\n",
        "            filename_prefix = filename_widget.value\n",
        "            transparent_bg = transparent_bg_widget.value\n",
        "            include_timestamp = include_timestamp_widget.value\n",
        "\n",
        "            # --- BUILD LABEL MAPPING ---\n",
        "            label_mapping = {}\n",
        "            for original_label, widget in label_widgets_dict.items():\n",
        "                custom_label = widget.value\n",
        "                label_mapping[original_label] = custom_label\n",
        "                label_mapping[str(original_label)] = custom_label\n",
        "\n",
        "            print(f\"\ud83d\udcca Configuration:\")\n",
        "            print(f\"  Dimensions: {plot_width}\\\" \u00d7 {plot_height}\\\"\")\n",
        "            print(f\"  Orientation: {orientation}\")\n",
        "            print(f\"  Color scheme: {color_scheme}\")\n",
        "            print(f\"  Has subgroups: {has_subgroups}\")\n",
        "\n",
        "            # Show custom labels if any were changed\n",
        "            changed_labels = {k: v for k, v in label_mapping.items() if k != v}\n",
        "            if changed_labels:\n",
        "                print(f\"\\n\ud83d\udcdd Custom labels ({len(changed_labels)} changed):\")\n",
        "                for orig, custom in list(changed_labels.items())[:5]:\n",
        "                    print(f\"  '{orig}' \u2192 '{custom}'\")\n",
        "                if len(changed_labels) > 5:\n",
        "                    print(f\"  ... and {len(changed_labels)-5} more\")\n",
        "\n",
        "            # --- PREPARE DATA ---\n",
        "            plot_df = plot_df_final.copy()\n",
        "            raw_df = df_orchard.copy()\n",
        "\n",
        "            # --- PREPARE MATCH KEYS ---\n",
        "            if has_subgroups:\n",
        "                if analysis_type == 'two_way' and mod2_name:\n",
        "                    raw_df['MatchKey'] = raw_df[mod1_name].astype(str) + \" x \" + raw_df[mod2_name].astype(str)\n",
        "                    if len(set(raw_df['MatchKey']).intersection(set(plot_df['group']))) == 0:\n",
        "                        raw_df['MatchKey'] = raw_df[mod1_name].astype(str) + \" \u00d7 \" + raw_df[mod2_name].astype(str)\n",
        "                else:\n",
        "                    raw_df['MatchKey'] = raw_df[mod1_name].astype(str)\n",
        "            else:\n",
        "                raw_df['MatchKey'] = 'Overall'\n",
        "\n",
        "            # --- CALCULATE POSITIONS & GAPS ---\n",
        "            is_horiz = (orientation == 'h')\n",
        "            groups = plot_df['group'].tolist()\n",
        "\n",
        "            if is_horiz:\n",
        "                groups = groups[::-1]\n",
        "\n",
        "            y_locs = []\n",
        "            display_labels = []\n",
        "            group_centers = {}\n",
        "\n",
        "            cursor = 0\n",
        "            last_mod1 = None\n",
        "            separators = []\n",
        "            current_group_locs = []\n",
        "\n",
        "            for grp in groups:\n",
        "                is_overall = (grp == 'Overall')\n",
        "\n",
        "                # Identify Mod1 and Mod2\n",
        "                if is_overall:\n",
        "                    curr_mod1 = \"Overall\"\n",
        "                    curr_mod2 = \"Overall\"\n",
        "                elif analysis_type == 'two_way' and mod1_name in plot_df.columns:\n",
        "                    row = plot_df[plot_df['group'] == grp].iloc[0]\n",
        "                    curr_mod1 = str(row[mod1_name])\n",
        "                    curr_mod2 = str(row[mod2_name])\n",
        "                else:\n",
        "                    curr_mod1 = \"Subgroups\"\n",
        "                    curr_mod2 = grp\n",
        "\n",
        "                # Gap Logic\n",
        "                if last_mod1 is not None and curr_mod1 != last_mod1:\n",
        "                    if last_mod1 not in group_centers and current_group_locs:\n",
        "                        group_centers[last_mod1] = np.mean(current_group_locs)\n",
        "                    current_group_locs = []\n",
        "\n",
        "                    cursor += group_gap\n",
        "                    sep_pos = cursor - (group_gap/2) - 0.5\n",
        "                    separators.append(sep_pos)\n",
        "\n",
        "                y_locs.append(cursor)\n",
        "                current_group_locs.append(cursor)\n",
        "\n",
        "                # Apply label mapping\n",
        "                display_label = label_mapping.get(str(curr_mod2), curr_mod2)\n",
        "                display_labels.append(display_label)\n",
        "\n",
        "                last_mod1 = curr_mod1\n",
        "                cursor += 1\n",
        "\n",
        "            # Catch last group center\n",
        "            if last_mod1 not in group_centers and current_group_locs:\n",
        "                group_centers[last_mod1] = np.mean(current_group_locs)\n",
        "\n",
        "            print(f\"  Total groups: {len(groups)}\")\n",
        "            print(f\"  Separators: {len(separators)}\")\n",
        "\n",
        "            # --- DETERMINE COLOR SCHEME ---\n",
        "            if color_scheme == 'gray':\n",
        "                cmap = plt.cm.gray\n",
        "            elif color_scheme == 'bw':\n",
        "                cmap = plt.cm.binary\n",
        "            else:\n",
        "                cmap = plt.get_cmap(color_scheme)\n",
        "\n",
        "            # --- DETERMINE MARKER STYLES ---\n",
        "            if marker_style == 'circle_diamond':\n",
        "                subgroup_marker = 'o'\n",
        "                overall_marker = 'D'\n",
        "            elif marker_style == 'square_diamond':\n",
        "                subgroup_marker = 's'\n",
        "                overall_marker = 'D'\n",
        "            else:  # circle_star\n",
        "                subgroup_marker = 'o'\n",
        "                overall_marker = '*'\n",
        "\n",
        "            # --- CREATE FIGURE ---\n",
        "            fig, ax = plt.subplots(figsize=(plot_width, plot_height))\n",
        "\n",
        "            if transparent_bg:\n",
        "                fig.patch.set_alpha(0)\n",
        "                ax.patch.set_alpha(0)\n",
        "\n",
        "            print(f\"\\n\ud83c\udfa8 Plotting {len(groups)} groups...\")\n",
        "\n",
        "            # --- PLOT DATA ---\n",
        "            for i, (grp, pos) in enumerate(zip(groups, y_locs)):\n",
        "                row = plot_df[plot_df['group'] == grp].iloc[0]\n",
        "                is_overall = (grp == 'Overall')\n",
        "\n",
        "                # Color\n",
        "                if is_overall:\n",
        "                    if color_scheme == 'bw' or color_scheme == 'gray':\n",
        "                        col = 'black'\n",
        "                    else:\n",
        "                        col = 'black'\n",
        "                    marker = overall_marker\n",
        "                    alpha_trunk = 1.0\n",
        "                elif analysis_type == 'two_way' and mod1_name in plot_df.columns:\n",
        "                    unique_mod1 = sorted(plot_df[plot_df['group']!='Overall'][mod1_name].unique().astype(str).tolist())\n",
        "                    if is_horiz:\n",
        "                        unique_mod1 = unique_mod1[::-1]\n",
        "                    try:\n",
        "                        c_idx = unique_mod1.index(str(row[mod1_name]))\n",
        "                    except:\n",
        "                        c_idx = 0\n",
        "                    col = cmap(c_idx / max(1, len(unique_mod1)-1))\n",
        "                    marker = subgroup_marker\n",
        "                    alpha_trunk = pi_alpha\n",
        "                else:\n",
        "                    col = cmap(i/max(1, len(groups)-1))\n",
        "                    marker = subgroup_marker\n",
        "                    alpha_trunk = pi_alpha\n",
        "\n",
        "                # Trunk (PI)\n",
        "                if show_pi:\n",
        "                    trunk_lw = pi_linewidth if not is_overall else pi_linewidth * 1.2\n",
        "                    if is_horiz:\n",
        "                        ax.plot([row['PI_Lower'], row['PI_Upper']], [pos, pos],\n",
        "                               color=col, alpha=alpha_trunk, lw=trunk_lw,\n",
        "                               solid_capstyle='round', zorder=1)\n",
        "                    else:\n",
        "                        ax.plot([pos, pos], [row['PI_Lower'], row['PI_Upper']],\n",
        "                               color=col, alpha=alpha_trunk, lw=trunk_lw,\n",
        "                               solid_capstyle='round', zorder=1)\n",
        "\n",
        "                # Leaves (Raw Data)\n",
        "                if is_overall:\n",
        "                    sub_data = raw_df\n",
        "                else:\n",
        "                    sub_data = raw_df[raw_df['MatchKey'] == grp]\n",
        "\n",
        "                if not sub_data.empty:\n",
        "                    rng = np.random.default_rng(42+i)\n",
        "                    jitter = rng.uniform(-jitter_amount, jitter_amount, size=len(sub_data))\n",
        "                    sizes = point_size\n",
        "                    if scale_points:\n",
        "                        w = 1 / sub_data[var_col]\n",
        "                        sizes = point_size * (w / w.mean())\n",
        "                        sizes = sizes.clip(10, point_size*3)\n",
        "\n",
        "                    pt_col = 'gray' if is_overall else col\n",
        "                    pt_alpha = point_alpha * 0.5 if is_overall else point_alpha\n",
        "\n",
        "                    if is_horiz:\n",
        "                        ax.scatter(sub_data[effect_col], np.full(len(sub_data), pos)+jitter,\n",
        "                                 s=sizes, color=pt_col, alpha=pt_alpha, edgecolor='none', zorder=2)\n",
        "                    else:\n",
        "                        ax.scatter(np.full(len(sub_data), pos)+jitter, sub_data[effect_col],\n",
        "                                 s=sizes, color=pt_col, alpha=pt_alpha, edgecolor='none', zorder=2)\n",
        "\n",
        "                # Fruit (CI and Mean)\n",
        "                msize = point_size * 2.5 if is_overall else point_size * 2\n",
        "\n",
        "                if show_ci:\n",
        "                    ci_lw = ci_linewidth if not is_overall else ci_linewidth * 1.2\n",
        "                    ci_ls = '-' if ci_style == 'solid' else '--'\n",
        "                    ci_capsize = 4 if ci_style == 'caps' else 0\n",
        "\n",
        "                    if is_horiz:\n",
        "                        ax.plot([row['CI_Lower'], row['CI_Upper']], [pos, pos],\n",
        "                               color='black', lw=ci_lw, linestyle=ci_ls, zorder=3)\n",
        "                        if ci_capsize > 0:\n",
        "                            ax.plot([row['CI_Lower'], row['CI_Lower']], [pos-0.1, pos+0.1],\n",
        "                                   color='black', lw=ci_lw, zorder=3)\n",
        "                            ax.plot([row['CI_Upper'], row['CI_Upper']], [pos-0.1, pos+0.1],\n",
        "                                   color='black', lw=ci_lw, zorder=3)\n",
        "                    else:\n",
        "                        ax.plot([pos, pos], [row['CI_Lower'], row['CI_Upper']],\n",
        "                               color='black', lw=ci_lw, linestyle=ci_ls, zorder=3)\n",
        "                        if ci_capsize > 0:\n",
        "                            ax.plot([pos-0.1, pos+0.1], [row['CI_Lower'], row['CI_Lower']],\n",
        "                                   color='black', lw=ci_lw, zorder=3)\n",
        "                            ax.plot([pos-0.1, pos+0.1], [row['CI_Upper'], row['CI_Upper']],\n",
        "                                   color='black', lw=ci_lw, zorder=3)\n",
        "\n",
        "                # Plot mean marker\n",
        "                if is_horiz:\n",
        "                    ax.plot(row['pooled_effect_re'], pos, marker=marker,\n",
        "                           markersize=np.sqrt(msize)*1.5, color=col,\n",
        "                           markeredgecolor='black', markeredgewidth=1.5, zorder=4)\n",
        "                else:\n",
        "                    ax.plot(pos, row['pooled_effect_re'], marker=marker,\n",
        "                           markersize=np.sqrt(msize)*1.5, color=col,\n",
        "                           markeredgecolor='black', markeredgewidth=1.5, zorder=4)\n",
        "\n",
        "                # Annotations\n",
        "                if show_k or show_papers or show_effect_value:\n",
        "                    annot_parts = []\n",
        "                    if show_k:\n",
        "                        annot_parts.append(f\"k={int(row['k'])}\")\n",
        "                    if show_papers and pd.notna(row.get('n_papers')):\n",
        "                        annot_parts.append(f\"({int(row['n_papers'])})\")\n",
        "                    if show_effect_value:\n",
        "                        annot_parts.append(f\"ES={row['pooled_effect_re']:.2f}\")\n",
        "\n",
        "                    annotation_text = \" \".join(annot_parts)\n",
        "                    font_w = 'bold' if is_overall else 'normal'\n",
        "\n",
        "                    if is_horiz:\n",
        "                        if annot_pos == 'right':\n",
        "                            label_x = (row['PI_Upper'] if show_pi else row['CI_Upper']) + annot_h_offset\n",
        "                            label_y = pos + annot_v_offset\n",
        "                            ha, va = 'left', 'center'\n",
        "                        elif annot_pos == 'above':\n",
        "                            label_x = row['pooled_effect_re'] + annot_h_offset\n",
        "                            label_y = pos - 0.2 + annot_v_offset\n",
        "                            ha, va = 'center', 'bottom'\n",
        "                        else:  # below\n",
        "                            label_x = row['pooled_effect_re'] + annot_h_offset\n",
        "                            label_y = pos + 0.2 + annot_v_offset\n",
        "                            ha, va = 'center', 'top'\n",
        "\n",
        "                        ax.text(label_x, label_y, annotation_text,\n",
        "                               fontsize=annot_fontsize, fontweight=font_w,\n",
        "                               ha=ha, va=va, clip_on=False)\n",
        "                    else:\n",
        "                        if annot_pos == 'right':\n",
        "                            label_x = pos + annot_h_offset\n",
        "                            label_y = (row['PI_Upper'] if show_pi else row['CI_Upper']) + annot_v_offset\n",
        "                            ha, va = 'center', 'bottom'\n",
        "                        else:\n",
        "                            label_x = pos + annot_h_offset\n",
        "                            label_y = row['pooled_effect_re'] + annot_v_offset\n",
        "                            ha, va = 'center', 'center'\n",
        "\n",
        "                        ax.text(label_x, label_y, annotation_text,\n",
        "                               fontsize=annot_fontsize, fontweight=font_w,\n",
        "                               ha=ha, va=va, clip_on=False)\n",
        "\n",
        "            # --- ADD SEPARATORS ---\n",
        "            if show_separators:\n",
        "                sep_ls = '-' if separator_style == 'solid' else '--'\n",
        "                for sep in separators:\n",
        "                    if is_horiz:\n",
        "                        ax.axhline(sep, color='black', linestyle=sep_ls,\n",
        "                                  lw=separator_width, alpha=1.0)\n",
        "                    else:\n",
        "                        ax.axvline(sep, color='black', linestyle=sep_ls,\n",
        "                                  lw=separator_width, alpha=1.0)\n",
        "\n",
        "            # --- ADD INNER LABELS ---\n",
        "            if show_inner_labels:\n",
        "                for mod1_label, center_pos in group_centers.items():\n",
        "                    if mod1_label == 'Overall':\n",
        "                        continue\n",
        "\n",
        "                    # Apply label mapping\n",
        "                    display_mod1_label = label_mapping.get(str(mod1_label), mod1_label)\n",
        "\n",
        "                    if is_horiz:\n",
        "                        label_x = 0.98 + group_label_h_offset * 0.01\n",
        "                        label_y = center_pos + group_label_v_offset\n",
        "                        ax.text(label_x, label_y, display_mod1_label,\n",
        "                               transform=ax.get_yaxis_transform(),\n",
        "                               ha='right', va='center', fontweight='bold',\n",
        "                               fontsize=group_label_fontsize)\n",
        "                    else:\n",
        "                        label_x = center_pos + group_label_h_offset\n",
        "                        label_y = 0.98 + group_label_v_offset * 0.01\n",
        "                        ax.text(label_x, label_y, display_mod1_label,\n",
        "                               transform=ax.get_xaxis_transform(),\n",
        "                               ha='center', va='top', fontweight='bold',\n",
        "                               fontsize=group_label_fontsize)\n",
        "\n",
        "            # --- AXIS SETTINGS ---\n",
        "            if is_horiz:\n",
        "                ax.set_yticks(y_locs)\n",
        "                # Bold the 'Overall' label\n",
        "                labels_formatted = [\n",
        "                    r\"$\\bf{\" + l.replace(' ', r'\\ ') + \"}$\" if l == label_mapping.get('Overall', 'Overall') else l\n",
        "                    for l in display_labels\n",
        "                ]\n",
        "                ax.set_yticklabels(labels_formatted, fontsize=tick_fontsize)\n",
        "                ax.set_xlabel(x_label, fontweight='bold', fontsize=label_fontsize)\n",
        "                if show_ylabel:\n",
        "                    ax.set_ylabel(y_label, fontweight='bold', fontsize=label_fontsize)\n",
        "\n",
        "                # Null line\n",
        "                if show_null_line:\n",
        "                    null_ls = '-' if null_line_style == 'solid' else '--'\n",
        "                    ax.axvline(0, color='black', lw=null_line_width, linestyle=null_ls)\n",
        "\n",
        "                # Grid\n",
        "                if show_grid:\n",
        "                    grid_ls = '--' if grid_style == 'dashed' else (':' if grid_style == 'dotted' else '-')\n",
        "                    ax.grid(axis='x', linestyle=grid_ls, alpha=0.3)\n",
        "\n",
        "                # Axis limits\n",
        "                if auto_scale:\n",
        "                    # Auto scale\n",
        "                    pass\n",
        "                else:\n",
        "                    ax.set_xlim(axis_min_manual, axis_max_manual)\n",
        "\n",
        "            else:  # Vertical\n",
        "                ax.set_xticks(y_locs)\n",
        "                ax.set_xticklabels(display_labels, fontsize=tick_fontsize, rotation=45, ha='right')\n",
        "                ax.set_ylabel(x_label, fontweight='bold', fontsize=label_fontsize)\n",
        "\n",
        "                # Null line\n",
        "                if show_null_line:\n",
        "                    null_ls = '-' if null_line_style == 'solid' else '--'\n",
        "                    ax.axhline(0, color='black', lw=null_line_width, linestyle=null_ls)\n",
        "\n",
        "                # Grid\n",
        "                if show_grid:\n",
        "                    grid_ls = '--' if grid_style == 'dashed' else (':' if grid_style == 'dotted' else '-')\n",
        "                    ax.grid(axis='y', linestyle=grid_ls, alpha=0.3)\n",
        "\n",
        "                # Axis limits\n",
        "                if auto_scale:\n",
        "                    pass\n",
        "                else:\n",
        "                    ax.set_ylim(axis_min_manual, axis_max_manual)\n",
        "\n",
        "            # Title\n",
        "            if show_title:\n",
        "                ax.set_title(graph_title, fontweight='bold', fontsize=title_fontsize, pad=15)\n",
        "\n",
        "            ax.tick_params(labelsize=tick_fontsize)\n",
        "            sns.despine(trim=True)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- SAVE FILES ---\n",
        "            print(f\"\\n\ud83d\udcbe Saving files...\")\n",
        "\n",
        "            saved_files = []\n",
        "\n",
        "            if include_timestamp:\n",
        "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                base_filename = f\"{filename_prefix}_{timestamp}\"\n",
        "            else:\n",
        "                base_filename = filename_prefix\n",
        "\n",
        "            if save_pdf:\n",
        "                pdf_filename = f\"{base_filename}.pdf\"\n",
        "                fig.savefig(pdf_filename, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(pdf_filename)\n",
        "                print(f\"  \u2713 {pdf_filename}\")\n",
        "\n",
        "            if save_png:\n",
        "                png_filename = f\"{base_filename}.png\"\n",
        "                fig.savefig(png_filename, dpi=png_dpi, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(png_filename)\n",
        "                print(f\"  \u2713 {png_filename} (DPI: {png_dpi})\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"\\n\" + \"=\"*70)\n",
        "            print(\"\u2705 ORCHARD PLOT COMPLETE\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Files: {', '.join(saved_files)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n\u274c ERROR: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# --- 4. CREATE BUTTON AND DISPLAY ---\n",
        "plot_button = widgets.Button(\n",
        "    description='\ud83c\udf33 Generate Orchard Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "\n",
        "plot_button.on_click(generate_orchard_plot)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 ORCHARD PLOT INTERFACE READY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udc46 Customize your plot using the tabs above, then click Generate\")\n",
        "print(\"\\n\ud83d\udcdd Tips:\")\n",
        "print(\"  \u2022 Use the 'Labels' tab to rename coded variables\")\n",
        "print(\"  \u2022 Adjust point size and jitter for optimal data visibility\")\n",
        "print(\"  \u2022 PI (Trunk) shows prediction interval, CI (Fruit) shows pooled effect\")\n",
        "print(\"  \u2022 Auto-scale considers all data for proper spacing\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83c\udf4e Orchard Plot Generator (Enhanced)</h3>\"),\n",
        "    widgets.HTML(\"<p style='color: #666;'>Create publication-ready orchard plots with full customization</p>\"),\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    tab,\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    plot_button,\n",
        "    plot_output\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 12. Linear Meta-Regression: DATA LAYER (WORKING)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 1/2: DATA & LOGIC LAYER\n",
        "# Purpose: Core mathematics for Linear Meta-Regression (Fixed/Random/Mixed)\n",
        "# Architecture: MVC Pattern (Model)\n",
        "# Dependencies: ANALYSIS_CONFIG, statsmodels, scipy\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Any, Optional\n",
        "\n",
        "# --- 1. RESULT CONTAINER ---\n",
        "@dataclass\n",
        "class RegressionResult:\n",
        "    \"\"\"Data Transfer Object for regression results\"\"\"\n",
        "    beta0: float\n",
        "    beta1: float\n",
        "    se0: float\n",
        "    se1: float\n",
        "    p0: float\n",
        "    p1: float\n",
        "    ci0: Tuple[float, float]\n",
        "    ci1: Tuple[float, float]\n",
        "    df_resid: int\n",
        "    n_obs: int\n",
        "    k_studies: int\n",
        "    tau_sq: float\n",
        "    sigma_sq: float\n",
        "    R_squared_adj: float\n",
        "    model_type: str\n",
        "    reg_df: pd.DataFrame\n",
        "    moderator_col_name: str\n",
        "    var_betas_robust: np.ndarray\n",
        "    resid: np.ndarray\n",
        "    fitted: np.ndarray\n",
        "\n",
        "# --- 2. DATA MANAGER ---\n",
        "class RegressionDataManager:\n",
        "    \"\"\"\n",
        "    Handles data retrieval, cleaning, and preparation for the regression engine.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: dict):\n",
        "        self.config = config\n",
        "        self.global_settings = config.get('global_settings', {'alpha': 0.05, 'dist_type': 't'})\n",
        "\n",
        "        # Pull main dataset safely\n",
        "        if 'analysis_data' in config:\n",
        "            self.df = config['analysis_data'].copy()\n",
        "        elif 'clean_dataframe' in config:\n",
        "            self.df = config['clean_dataframe'].copy()\n",
        "        else:\n",
        "            print(\"\u26a0\ufe0f Warning: No analysis data found in config. Using empty DataFrame.\")\n",
        "            self.df = pd.DataFrame()\n",
        "\n",
        "        self.effect_col = config.get('effect_col', 'yi')\n",
        "        self.var_col = config.get('var_col', 'vi')\n",
        "\n",
        "    def get_potential_moderators(self) -> list:\n",
        "        \"\"\"Identify valid numeric columns for regression\"\"\"\n",
        "        if self.df.empty: return []\n",
        "\n",
        "        exclude = ['id', 'w_fixed', 'w_random', 'w_3level', 'shared_group_id',\n",
        "                   self.effect_col, self.var_col]\n",
        "\n",
        "        # Get numeric columns\n",
        "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Filter: Must not be excluded and must have variance\n",
        "        candidates = [c for c in numeric_cols if c not in exclude]\n",
        "        valid = [c for c in candidates if self.df[c].nunique() > 1]\n",
        "\n",
        "        return sorted(valid)\n",
        "\n",
        "    def get_regression_data(self, moderator_col: str) -> pd.DataFrame:\n",
        "        \"\"\"Prepare clean dataframe for a specific moderator\"\"\"\n",
        "        if moderator_col not in self.df.columns:\n",
        "            raise ValueError(f\"Moderator '{moderator_col}' not found in dataset.\")\n",
        "\n",
        "        # Select relevant columns\n",
        "        cols = ['id', self.effect_col, self.var_col, moderator_col]\n",
        "        temp_df = self.df[cols].copy()\n",
        "\n",
        "        # Force numeric and drop NaNs\n",
        "        temp_df[moderator_col] = pd.to_numeric(temp_df[moderator_col], errors='coerce')\n",
        "        temp_df = temp_df.dropna()\n",
        "\n",
        "        # Sort for consistency\n",
        "        temp_df = temp_df.sort_values(moderator_col)\n",
        "\n",
        "        return temp_df\n",
        "\n",
        "# --- 3. REGRESSION ENGINE (LOGIC) ---\n",
        "class RegressionEngine:\n",
        "    \"\"\"\n",
        "    Performs the statistical calculations (WLS, RVE/Cluster-Robust).\n",
        "    \"\"\"\n",
        "    def __init__(self, data_manager: RegressionDataManager):\n",
        "        self.dm = data_manager\n",
        "\n",
        "    def run_meta_regression(self, moderator_col: str, progress_callback=None) -> Tuple[RegressionResult, pd.DataFrame]:\n",
        "        \"\"\"\n",
        "        Main execution method.\n",
        "        Automatically detects if Cluster-Robust (RVE) inference is needed.\n",
        "        \"\"\"\n",
        "        # 1. Get Data\n",
        "        df = self.dm.get_regression_data(moderator_col)\n",
        "        n_obs = len(df)\n",
        "        k_studies = df['id'].nunique()\n",
        "\n",
        "        if n_obs < 3:\n",
        "            raise ValueError(f\"Insufficient data (n={n_obs}). Need at least 3 points.\")\n",
        "\n",
        "        # 2. Logic Check: Dependencies?\n",
        "        # If multiple rows share the same 'id', we have dependencies -> Use Cluster Robust\n",
        "        has_dependencies = (df.groupby('id').size() > 1).any()\n",
        "\n",
        "        y = df[self.dm.effect_col].values\n",
        "        v = df[self.dm.var_col].values\n",
        "        X = sm.add_constant(df[moderator_col].values)\n",
        "\n",
        "        # 3. Estimate Tau2 (Method of Moments / DL approximation)\n",
        "        # Iterative WLS to find tau2\n",
        "        tau2 = 0.0\n",
        "        for _ in range(5): # Simple iteration\n",
        "            w = 1 / (v + tau2)\n",
        "            try:\n",
        "                mod_pre = sm.WLS(y, X, weights=w).fit()\n",
        "                # Update tau2 estimate (DL-like logic)\n",
        "                resid_sq = (y - mod_pre.fittedvalues)**2\n",
        "                Q = np.sum(w * resid_sq)\n",
        "                df_res = n_obs - 2\n",
        "                C = np.sum(w) - np.sum(w**2)/np.sum(w)\n",
        "                if C > 0:\n",
        "                    tau2_new = max(0, (Q - df_res) / C)\n",
        "                    tau2 = (tau2 + tau2_new)/2 # Dampen update\n",
        "                else:\n",
        "                    break\n",
        "            except:\n",
        "                break # Fallback to tau2=0 if fail\n",
        "\n",
        "        # 4. Final Fit\n",
        "        weights_final = 1 / (v + tau2)\n",
        "\n",
        "        if has_dependencies:\n",
        "            # Cluster-Robust Variance Estimation (RVE)\n",
        "            # This handles the dependency within 'id'\n",
        "            model = sm.WLS(y, X, weights=weights_final).fit(\n",
        "                cov_type='cluster',\n",
        "                cov_kwds={'groups': df['id']}\n",
        "            )\n",
        "            model_type = \"Cluster-Robust (RVE) Random-Effects\"\n",
        "        else:\n",
        "            # Standard WLS\n",
        "            model = sm.WLS(y, X, weights=weights_final).fit()\n",
        "            model_type = \"Standard Random-Effects (2-Level)\"\n",
        "\n",
        "        # 5. Extract Statistics\n",
        "        alpha = self.dm.global_settings.get('alpha', 0.05)\n",
        "        params = model.params\n",
        "        bse = model.bse\n",
        "\n",
        "        # Confidence Intervals\n",
        "        t_crit = stats.t.ppf(1 - alpha/2, df=model.df_resid)\n",
        "        ci0 = (params[0] - t_crit*bse[0], params[0] + t_crit*bse[0])\n",
        "        ci1 = (params[1] - t_crit*bse[1], params[1] + t_crit*bse[1])\n",
        "\n",
        "        # 6. Package Results\n",
        "        result = RegressionResult(\n",
        "            beta0=params[0],\n",
        "            beta1=params[1],\n",
        "            se0=bse[0],\n",
        "            se1=bse[1],\n",
        "            p0=model.pvalues[0],\n",
        "            p1=model.pvalues[1],\n",
        "            ci0=ci0,\n",
        "            ci1=ci1,\n",
        "            df_resid=int(model.df_resid),\n",
        "            n_obs=n_obs,\n",
        "            k_studies=k_studies,\n",
        "            tau_sq=tau2,\n",
        "            sigma_sq=0.0, # Not explicitly separated in this simplified WLS approach\n",
        "            R_squared_adj=model.rsquared_adj,\n",
        "            model_type=model_type,\n",
        "            reg_df=df,\n",
        "            moderator_col_name=moderator_col,\n",
        "            var_betas_robust=model.cov_params(),\n",
        "            resid=model.resid,\n",
        "            fitted=model.fittedvalues\n",
        "        )\n",
        "\n",
        "        return result, df\n",
        "\n",
        "print(\"\u2705 Linear Meta-Regression Data Layer Loaded (Classes: RegressionDataManager, RegressionEngine)\")"
      ],
      "metadata": {
        "id": "zi0W3PuAuftL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcc8 12. Meta-Regression: DATA LAYER (WORKING)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 1/4: DATA LAYER - META-REGRESSION\n",
        "# Purpose: Centralized data management for meta-regression analysis\n",
        "# Dependencies: ANALYSIS_CONFIG global dictionary\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA CLASSES\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class RegressionConfig:\n",
        "    \"\"\"Configuration for meta-regression analysis\"\"\"\n",
        "    moderator_col: str\n",
        "    effect_col: str\n",
        "    var_col: str\n",
        "    se_col: Optional[str] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration\"\"\"\n",
        "        if not self.moderator_col:\n",
        "            raise ValueError(\"moderator_col cannot be empty\")\n",
        "        if not self.effect_col:\n",
        "            raise ValueError(\"effect_col cannot be empty\")\n",
        "        if not self.var_col:\n",
        "            raise ValueError(\"var_col cannot be empty\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RegressionResult:\n",
        "    \"\"\"Complete meta-regression result\"\"\"\n",
        "    # Coefficients\n",
        "    beta0: float  # Intercept\n",
        "    beta1: float  # Slope\n",
        "    se0: float    # SE of intercept\n",
        "    se1: float    # SE of slope\n",
        "    p0: float     # p-value intercept\n",
        "    p1: float     # p-value slope\n",
        "    ci0: Tuple[float, float]  # CI for intercept\n",
        "    ci1: Tuple[float, float]  # CI for slope\n",
        "\n",
        "    # Variance components\n",
        "    tau_sq: float\n",
        "    sigma_sq: float\n",
        "\n",
        "    # Model info\n",
        "    model_type: str\n",
        "    k_studies: int\n",
        "    n_obs: int\n",
        "    df_resid: int\n",
        "\n",
        "    # Heterogeneity\n",
        "    r_squared: float\n",
        "    resid_i2: float\n",
        "\n",
        "    # Diagnostics\n",
        "    fitted: np.ndarray\n",
        "    resid: np.ndarray\n",
        "    var_betas_robust: np.ndarray\n",
        "\n",
        "    # Additional metadata\n",
        "    moderator_col_name: str\n",
        "    has_influential: bool = False\n",
        "    cooks_d: Optional[np.ndarray] = None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA MANAGER CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class RegressionDataManager:\n",
        "    \"\"\"\n",
        "    Centralized data access layer for meta-regression.\n",
        "    Handles all interactions with ANALYSIS_CONFIG and data validation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize data manager.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self._config = analysis_config\n",
        "        self._validate_prerequisites()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # VALIDATION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _validate_prerequisites(self) -> None:\n",
        "        \"\"\"Validate that required configuration exists\"\"\"\n",
        "        # Meta-regression doesn't require as many prerequisites as subgroup analysis\n",
        "        # but we still need basic effect size configuration\n",
        "        if 'effect_col' not in self._config:\n",
        "            warnings.warn(\"effect_col not in ANALYSIS_CONFIG, using default 'hedges_g'\")\n",
        "        if 'var_col' not in self._config:\n",
        "            warnings.warn(\"var_col not in ANALYSIS_CONFIG, using default 'Vg'\")\n",
        "\n",
        "    def validate_moderator(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        moderator_col: str\n",
        "    ) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Validate that moderator column is suitable for regression.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "            moderator_col: Moderator column name\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if moderator_col not in df.columns:\n",
        "            return False, f\"Column '{moderator_col}' not found in data\"\n",
        "\n",
        "        # Try to convert to numeric\n",
        "        try:\n",
        "            numeric_vals = pd.to_numeric(df[moderator_col], errors='coerce')\n",
        "        except Exception as e:\n",
        "            return False, f\"Cannot convert '{moderator_col}' to numeric: {str(e)}\"\n",
        "\n",
        "        # Check for sufficient non-missing values\n",
        "        n_valid = numeric_vals.notna().sum()\n",
        "        if n_valid < 3:\n",
        "            return False, f\"Insufficient data: only {n_valid} valid numeric values\"\n",
        "\n",
        "        # Check for variation\n",
        "        if numeric_vals.nunique() <= 1:\n",
        "            return False, f\"No variation in '{moderator_col}'\"\n",
        "\n",
        "        return True, None\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROPERTY ACCESSORS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def analysis_data(self) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Get analysis dataset\"\"\"\n",
        "        if 'analysis_data' in self._config:\n",
        "            return self._config['analysis_data'].copy()\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def effect_col(self) -> str:\n",
        "        \"\"\"Get effect size column name\"\"\"\n",
        "        return self._config.get('effect_col', 'hedges_g')\n",
        "\n",
        "    @property\n",
        "    def var_col(self) -> str:\n",
        "        \"\"\"Get variance column name\"\"\"\n",
        "        return self._config.get('var_col', 'Vg')\n",
        "\n",
        "    @property\n",
        "    def se_col(self) -> Optional[str]:\n",
        "        \"\"\"Get standard error column name\"\"\"\n",
        "        return self._config.get('se_col')\n",
        "\n",
        "    @property\n",
        "    def global_settings(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get global settings\"\"\"\n",
        "        return self._config.get('global_settings', {\n",
        "            'alpha': 0.05,\n",
        "            'dist_type': 't'\n",
        "        })\n",
        "\n",
        "    @property\n",
        "    def overall_results(self) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Get overall meta-analysis results (for R\u00b2 calculation)\"\"\"\n",
        "        return self._config.get('overall_results')\n",
        "\n",
        "    @property\n",
        "    def es_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get effect size configuration\"\"\"\n",
        "        return self._config.get('es_config', {})\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA EXTRACTION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def get_potential_moderators(\n",
        "        self,\n",
        "        df: Optional[pd.DataFrame] = None\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Get list of valid numeric moderator columns.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to search (uses analysis_data if None)\n",
        "\n",
        "        Returns:\n",
        "            List of valid moderator column names\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            df = self.analysis_data\n",
        "\n",
        "        if df is None:\n",
        "            return []\n",
        "\n",
        "        valid_mods = []\n",
        "        exclude = ['id', 'w_fixed', 'w_random', self.effect_col, self.var_col]\n",
        "        if self.se_col:\n",
        "            exclude.append(self.se_col)\n",
        "\n",
        "        for col in df.columns:\n",
        "            if col in exclude or col is None:\n",
        "                continue\n",
        "\n",
        "            # Check numeric columns\n",
        "            if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                if df[col].nunique() > 1:\n",
        "                    valid_mods.append(col)\n",
        "            # Check string columns that can be converted to numeric\n",
        "            elif df[col].dtype == 'object':\n",
        "                try:\n",
        "                    nums = pd.to_numeric(df[col], errors='coerce')\n",
        "                    if nums.notna().sum() >= 3 and nums.nunique() > 1:\n",
        "                        valid_mods.append(col)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        return sorted(list(set(valid_mods)))\n",
        "\n",
        "    def prepare_regression_data(\n",
        "        self,\n",
        "        moderator_col: str,\n",
        "        df: Optional[pd.DataFrame] = None\n",
        "    ) -> Tuple[pd.DataFrame, RegressionConfig]:\n",
        "        \"\"\"\n",
        "        Prepare and clean data for regression analysis.\n",
        "\n",
        "        Args:\n",
        "            moderator_col: Name of moderator column\n",
        "            df: DataFrame to prepare (uses analysis_data if None)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (cleaned_df, config)\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If data cannot be prepared\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            df = self.analysis_data\n",
        "\n",
        "        if df is None:\n",
        "            raise ValueError(\"No data available for analysis\")\n",
        "\n",
        "        # Validate moderator\n",
        "        is_valid, error_msg = self.validate_moderator(df, moderator_col)\n",
        "        if not is_valid:\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        # Create working copy\n",
        "        reg_df = df.copy()\n",
        "\n",
        "        # Convert moderator to numeric\n",
        "        reg_df[moderator_col] = pd.to_numeric(reg_df[moderator_col], errors='coerce')\n",
        "\n",
        "        # Remove missing values\n",
        "        reg_df = reg_df.dropna(subset=[\n",
        "            moderator_col,\n",
        "            self.effect_col,\n",
        "            self.var_col\n",
        "        ]).copy()\n",
        "\n",
        "        # Remove zero or negative variances\n",
        "        reg_df = reg_df[reg_df[self.var_col] > 0].copy()\n",
        "\n",
        "        # Final check\n",
        "        if len(reg_df) < 3:\n",
        "            raise ValueError(\n",
        "                f\"Insufficient data after cleaning: {len(reg_df)} observations. \"\n",
        "                f\"Need at least 3.\"\n",
        "            )\n",
        "\n",
        "        # Create configuration\n",
        "        config = RegressionConfig(\n",
        "            moderator_col=moderator_col,\n",
        "            effect_col=self.effect_col,\n",
        "            var_col=self.var_col,\n",
        "            se_col=self.se_col\n",
        "        )\n",
        "\n",
        "        return reg_df, config\n",
        "\n",
        "    def check_within_study_variation(\n",
        "        self,\n",
        "        reg_df: pd.DataFrame,\n",
        "        moderator_col: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Check if moderator varies within studies.\n",
        "\n",
        "        This determines whether we need 3-level (varying) or\n",
        "        2-level aggregated (constant) model.\n",
        "\n",
        "        Args:\n",
        "            reg_df: Prepared regression DataFrame\n",
        "            moderator_col: Moderator column name\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with variation statistics\n",
        "        \"\"\"\n",
        "        studies_with_variation = reg_df.groupby('id')[moderator_col].nunique()\n",
        "        varying_studies = (studies_with_variation > 1).sum()\n",
        "        k_studies = reg_df['id'].nunique()\n",
        "        n_obs = len(reg_df)\n",
        "        has_multiple_effects = (reg_df.groupby('id').size() > 1).any()\n",
        "\n",
        "        return {\n",
        "            'varying_studies': varying_studies,\n",
        "            'k_studies': k_studies,\n",
        "            'n_obs': n_obs,\n",
        "            'has_multiple_effects': has_multiple_effects,\n",
        "            'needs_3level': has_multiple_effects,\n",
        "            'moderator_constant_within_study': varying_studies == 0\n",
        "        }\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RESULT PERSISTENCE METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def save_regression_results(\n",
        "        self,\n",
        "        result: RegressionResult,\n",
        "        reg_df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Save regression results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: RegressionResult object\n",
        "            reg_df: DataFrame used in analysis\n",
        "        \"\"\"\n",
        "        import datetime\n",
        "\n",
        "        self._config['meta_regression_RVE_results'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'reg_df': reg_df,\n",
        "            'moderator_col_name': result.moderator_col_name,\n",
        "            'effect_col': self.effect_col,\n",
        "            'betas': [result.beta0, result.beta1],\n",
        "            'var_betas_robust': result.var_betas_robust,\n",
        "            'std_errors_robust': [result.se0, result.se1],\n",
        "            'p_slope': result.p1,\n",
        "            'p_intercept': result.p0,\n",
        "            'R_squared_adj': result.r_squared,\n",
        "            'df_robust': result.df_resid,\n",
        "            'fitted': result.fitted,\n",
        "            'resid': result.resid,\n",
        "            'tau_sq': result.tau_sq,\n",
        "            'sigma_sq': result.sigma_sq,\n",
        "            'model_type': result.model_type,\n",
        "            'k_studies': result.k_studies,\n",
        "            'n_obs': result.n_obs,\n",
        "            'ci0': result.ci0,\n",
        "            'ci1': result.ci1,\n",
        "            'resid_i2': result.resid_i2,\n",
        "            'has_influential': result.has_influential,\n",
        "            'cooks_d': result.cooks_d\n",
        "        }\n",
        "\n",
        "        # Also save var_col for compatibility\n",
        "        self._config['var_col'] = self.var_col\n",
        "\n",
        "    def save_publication_text(self, text: str) -> None:\n",
        "        \"\"\"Save publication-ready text\"\"\"\n",
        "        self._config['regression_text'] = text\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTILITY METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def summary_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get summary of current configuration\"\"\"\n",
        "        settings = self.global_settings\n",
        "\n",
        "        return {\n",
        "            'effect_col': self.effect_col,\n",
        "            'var_col': self.var_col,\n",
        "            'se_col': self.se_col,\n",
        "            'alpha': settings.get('alpha', 0.05),\n",
        "            'dist_type': settings.get('dist_type', 't'),\n",
        "            'has_overall_results': self.overall_results is not None,\n",
        "            'n_potential_moderators': len(self.get_potential_moderators())\n",
        "        }\n",
        "#@title \ud83d\udcc8 12. Meta-Regression: ANALYSIS LAYER (Business Logic)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 2/4: ANALYSIS LAYER - META-REGRESSION\n",
        "# Purpose: Pure statistical computation without UI dependencies\n",
        "# Dependencies:\n",
        "#   - Data Layer (RegressionDataManager, RegressionResult)\n",
        "#   - External functions: calculate_tau_squared (if used),\n",
        "#     _run_three_level_reml_regression_v2 (from Cell 9.5)\n",
        "# Math validated against metafor and Monte Carlo simulations\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, chi2, t\n",
        "from scipy.optimize import minimize, minimize_scalar\n",
        "import statsmodels.api as sm\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CORE REGRESSION ENGINES (MATHEMATICAL IMPLEMENTATIONS)\n",
        "# =============================================================================\n",
        "\n",
        "class TwoLevelRegressionEngine:\n",
        "    \"\"\"\n",
        "    Standard 2-Level Random-Effects Meta-Regression.\n",
        "    Used when moderator is constant within studies (aggregated data).\n",
        "\n",
        "    Mathematical implementation validated against metafor.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def run_aggregated_regression(\n",
        "        agg_df: pd.DataFrame,\n",
        "        moderator_col: str,\n",
        "        effect_col: str,\n",
        "        var_col: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Run 2-level random-effects meta-regression.\n",
        "\n",
        "        MATH PRESERVED: This is your original _run_aggregated_re_regression\n",
        "\n",
        "        Args:\n",
        "            agg_df: Aggregated DataFrame (one row per study)\n",
        "            moderator_col: Moderator column name\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with regression results\n",
        "        \"\"\"\n",
        "        y = agg_df[effect_col].values\n",
        "        v = agg_df[var_col].values\n",
        "        X = sm.add_constant(agg_df[moderator_col].values)\n",
        "\n",
        "        def re_nll(tau2):\n",
        "            \"\"\"Negative log-likelihood for REML estimation\"\"\"\n",
        "            if tau2 < 0:\n",
        "                tau2 = 0\n",
        "            weights = 1.0 / (v + tau2)\n",
        "            try:\n",
        "                wls = sm.WLS(y, X, weights=weights).fit()\n",
        "                betas = wls.params\n",
        "                resid = y - wls.fittedvalues\n",
        "                ll = -0.5 * (\n",
        "                    np.sum(np.log(v + tau2)) +\n",
        "                    np.log(np.linalg.det(X.T @ np.diag(weights) @ X)) +\n",
        "                    np.sum((resid**2) * weights)\n",
        "                )\n",
        "                return -ll\n",
        "            except:\n",
        "                return np.inf\n",
        "\n",
        "        # REML optimization\n",
        "        res = minimize_scalar(re_nll, bounds=(0, 100), method='bounded')\n",
        "        tau2_est = res.x\n",
        "\n",
        "        # Final weighted regression\n",
        "        weights_final = 1.0 / (v + tau2_est)\n",
        "        final_model = sm.WLS(y, X, weights=weights_final).fit()\n",
        "\n",
        "        return {\n",
        "            'betas': final_model.params,\n",
        "            'se_betas': final_model.bse,\n",
        "            'p_values': final_model.pvalues,\n",
        "            'tau_sq': tau2_est,\n",
        "            'sigma_sq': 0.0,  # No within-study variance in 2-level\n",
        "            'model_type': 'Aggregated Random-Effects (2-Level)',\n",
        "            'n_obs': len(agg_df),\n",
        "            'resid_df': final_model.df_resid,\n",
        "            'fitted': final_model.fittedvalues,\n",
        "            'resid': final_model.resid_pearson,\n",
        "            'model': final_model,\n",
        "            'var_betas_robust': np.diag([final_model.bse[0]**2, final_model.bse[1]**2])\n",
        "        }\n",
        "\n",
        "\n",
        "class ThreeLevelRegressionEngine:\n",
        "    \"\"\"\n",
        "    3-Level Random-Effects Meta-Regression with RVE.\n",
        "    Used when moderator varies within studies.\n",
        "\n",
        "    Mathematical implementation validated against metafor/robumeta.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def run_three_level_regression(\n",
        "        reg_df: pd.DataFrame,\n",
        "        moderator_col: str,\n",
        "        effect_col: str,\n",
        "        var_col: str\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Run 3-level meta-regression with cluster-robust variance estimation.\n",
        "\n",
        "        MATH PRESERVED: Calls your original _run_three_level_reml_regression_v2\n",
        "\n",
        "        Args:\n",
        "            reg_df: Full regression DataFrame (multiple effects per study)\n",
        "            moderator_col: Moderator column name\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with regression results, or None if optimization fails\n",
        "        \"\"\"\n",
        "        # Check if external function exists\n",
        "        if '_run_three_level_reml_regression_v2' not in globals():\n",
        "            raise RuntimeError(\n",
        "                \"Required function '_run_three_level_reml_regression_v2' not found. \"\n",
        "                \"Please run Cell 9.5 (High-Precision Regression Engine) first.\"\n",
        "            )\n",
        "\n",
        "        # Call your validated 3-level implementation\n",
        "        est, info, opt_result = _run_three_level_reml_regression_v2(\n",
        "            reg_df, moderator_col, effect_col, var_col\n",
        "        )\n",
        "\n",
        "        if est is None:\n",
        "            return None\n",
        "\n",
        "        # Safety check: ensure we got 2 coefficients (intercept + slope)\n",
        "        if 'betas' not in est or len(est['betas']) != 2:\n",
        "            return None\n",
        "\n",
        "        # Extract results\n",
        "        beta0, beta1 = est['betas']\n",
        "        se0, se1 = est['se_betas']\n",
        "        tau_sq = est['tau_sq']\n",
        "        sigma_sq = est['sigma_sq']\n",
        "        var_betas_robust = est.get('var_betas_robust', est.get('cov_beta'))\n",
        "\n",
        "        # Get model type (may indicate Plan A/B/C)\n",
        "        model_type = est.get('model_type', '3-Level REML with Cluster-Robust SE')\n",
        "\n",
        "        # Degrees of freedom and p-values\n",
        "        if 'df' in est and 'p_values' in est:\n",
        "            df_resid = est['df']\n",
        "            p0, p1 = est['p_values']\n",
        "        else:\n",
        "            # Fallback calculation\n",
        "            k_studies = reg_df['id'].nunique()\n",
        "            df_resid = max(1, k_studies - 2)\n",
        "            t_stat0 = beta0 / se0\n",
        "            t_stat1 = beta1 / se1\n",
        "            p0 = 2 * (1 - t.cdf(abs(t_stat0), df_resid))\n",
        "            p1 = 2 * (1 - t.cdf(abs(t_stat1), df_resid))\n",
        "\n",
        "        # Calculate fitted values and residuals\n",
        "        X_mod = reg_df[moderator_col].values\n",
        "        fitted = beta0 + beta1 * X_mod\n",
        "        resid = reg_df[effect_col].values - fitted\n",
        "\n",
        "        return {\n",
        "            'betas': np.array([beta0, beta1]),\n",
        "            'se_betas': np.array([se0, se1]),\n",
        "            'p_values': np.array([p0, p1]),\n",
        "            'tau_sq': tau_sq,\n",
        "            'sigma_sq': sigma_sq,\n",
        "            'model_type': model_type,\n",
        "            'n_obs': len(reg_df),\n",
        "            'resid_df': df_resid,\n",
        "            'fitted': fitted,\n",
        "            'resid': resid,\n",
        "            'var_betas_robust': var_betas_robust\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# REGRESSION ANALYZER (STATISTICAL COMPUTATIONS)\n",
        "# =============================================================================\n",
        "\n",
        "class RegressionAnalyzer:\n",
        "    \"\"\"\n",
        "    Statistical analysis engine for meta-regression.\n",
        "    Handles model selection, diagnostics, and heterogeneity calculations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        effect_col: str,\n",
        "        var_col: str,\n",
        "        global_settings: Dict[str, Any]\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize analyzer.\n",
        "\n",
        "        Args:\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name\n",
        "            global_settings: Dict with 'alpha' and 'dist_type'\n",
        "        \"\"\"\n",
        "        self.effect_col = effect_col\n",
        "        self.var_col = var_col\n",
        "        self.alpha = global_settings.get('alpha', 0.05)\n",
        "        self.dist_type = global_settings.get('dist_type', 't')\n",
        "        self.ci_level = (1 - self.alpha) * 100\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MODEL SELECTION & AGGREGATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def aggregate_to_study_level(\n",
        "        self,\n",
        "        reg_df: pd.DataFrame,\n",
        "        moderator_col: str\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Aggregate effect sizes to study level using inverse-variance weights.\n",
        "\n",
        "        MATH PRESERVED: Original aggregation logic\n",
        "\n",
        "        Args:\n",
        "            reg_df: Regression DataFrame\n",
        "            moderator_col: Moderator column name\n",
        "\n",
        "        Returns:\n",
        "            Aggregated DataFrame (one row per study)\n",
        "        \"\"\"\n",
        "        reg_df['wi'] = 1 / reg_df[self.var_col]\n",
        "\n",
        "        def agg_func(x):\n",
        "            return pd.Series({\n",
        "                self.effect_col: np.average(x[self.effect_col], weights=x['wi']),\n",
        "                self.var_col: 1 / np.sum(x['wi']),\n",
        "                moderator_col: x[moderator_col].iloc[0]\n",
        "            })\n",
        "\n",
        "        try:\n",
        "            agg_df = reg_df.groupby('id').apply(agg_func, include_groups=False).reset_index()\n",
        "        except TypeError:\n",
        "            # Fallback for older pandas versions\n",
        "            agg_df = reg_df.groupby('id').apply(agg_func).reset_index()\n",
        "\n",
        "        return agg_df\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # CONFIDENCE INTERVALS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def calculate_confidence_intervals(\n",
        "        self,\n",
        "        betas: np.ndarray,\n",
        "        se_betas: np.ndarray,\n",
        "        df: int\n",
        "    ) -> Tuple[Tuple[float, float], Tuple[float, float]]:\n",
        "        \"\"\"\n",
        "        Calculate confidence intervals for regression coefficients.\n",
        "\n",
        "        Args:\n",
        "            betas: Array of [beta0, beta1]\n",
        "            se_betas: Array of [se0, se1]\n",
        "            df: Degrees of freedom\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (ci0, ci1) where each ci is (lower, upper)\n",
        "        \"\"\"\n",
        "        q_val = 1 - (self.alpha / 2)\n",
        "\n",
        "        if self.dist_type == 't':\n",
        "            crit_val = t.ppf(q_val, df)\n",
        "        else:\n",
        "            crit_val = norm.ppf(q_val)\n",
        "\n",
        "        ci0 = (\n",
        "            betas[0] - crit_val * se_betas[0],\n",
        "            betas[0] + crit_val * se_betas[0]\n",
        "        )\n",
        "        ci1 = (\n",
        "            betas[1] - crit_val * se_betas[1],\n",
        "            betas[1] + crit_val * se_betas[1]\n",
        "        )\n",
        "\n",
        "        return ci0, ci1\n",
        "\n",
        "    def recalculate_p_values(\n",
        "        self,\n",
        "        betas: np.ndarray,\n",
        "        se_betas: np.ndarray,\n",
        "        df: int\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Recalculate p-values using specified distribution.\n",
        "\n",
        "        Args:\n",
        "            betas: Coefficient estimates\n",
        "            se_betas: Standard errors\n",
        "            df: Degrees of freedom\n",
        "\n",
        "        Returns:\n",
        "            Array of p-values\n",
        "        \"\"\"\n",
        "        if self.dist_type == 't':\n",
        "            t_stats = betas / se_betas\n",
        "            p_values = 2 * (1 - t.cdf(np.abs(t_stats), df))\n",
        "        else:\n",
        "            z_stats = betas / se_betas\n",
        "            p_values = 2 * (1 - norm.cdf(np.abs(z_stats)))\n",
        "\n",
        "        return p_values\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # HETEROGENEITY METRICS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def calculate_r_squared(\n",
        "        self,\n",
        "        tau2_null: float,\n",
        "        tau2_model: float\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate pseudo R\u00b2 (proportion of variance explained).\n",
        "\n",
        "        MATH PRESERVED: Original R\u00b2 calculation\n",
        "\n",
        "        Args:\n",
        "            tau2_null: Between-study variance from null model\n",
        "            tau2_model: Between-study variance from regression model\n",
        "\n",
        "        Returns:\n",
        "            R\u00b2 as percentage (0-100)\n",
        "        \"\"\"\n",
        "        if tau2_null <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        r2 = max(0, (tau2_null - tau2_model) / tau2_null * 100)\n",
        "        return r2\n",
        "\n",
        "    def calculate_residual_heterogeneity(\n",
        "        self,\n",
        "        tau_sq: float,\n",
        "        sigma_sq: float,\n",
        "        mean_variance: float\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate residual I\u00b2 statistic.\n",
        "\n",
        "        Args:\n",
        "            tau_sq: Between-study variance\n",
        "            sigma_sq: Within-study variance\n",
        "            mean_variance: Mean sampling variance\n",
        "\n",
        "        Returns:\n",
        "            Residual I\u00b2 as percentage\n",
        "        \"\"\"\n",
        "        if tau_sq <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        total_var = tau_sq + sigma_sq + mean_variance\n",
        "        if total_var <= 0:\n",
        "            return 0.0\n",
        "\n",
        "        resid_i2 = ((tau_sq + sigma_sq) / total_var) * 100\n",
        "        return max(0.0, min(100.0, resid_i2))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # INFLUENCE DIAGNOSTICS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def calculate_influence_diagnostics(\n",
        "        self,\n",
        "        model_results: Dict[str, Any],\n",
        "        reg_df: pd.DataFrame,\n",
        "        moderator_col: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate Cook's distance and influence metrics.\n",
        "\n",
        "        MATH PRESERVED: Original influence calculation\n",
        "\n",
        "        Args:\n",
        "            model_results: Results dictionary from regression\n",
        "            reg_df: Regression DataFrame\n",
        "            moderator_col: Moderator column name\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with influence metrics\n",
        "        \"\"\"\n",
        "        try:\n",
        "            n = len(reg_df)\n",
        "\n",
        "            # For 2-level aggregated models, use statsmodels diagnostics\n",
        "            if 'model' in model_results:\n",
        "                from statsmodels.stats.outliers_influence import OLSInfluence\n",
        "                influence = OLSInfluence(model_results['model'])\n",
        "                cooks_d = influence.cooks_distance[0]\n",
        "\n",
        "                return {\n",
        "                    'cooks_d': cooks_d,\n",
        "                    'has_influential': np.any(cooks_d > 4/n)\n",
        "                }\n",
        "            else:\n",
        "                # For 3-level, calculate manually (or return zeros as placeholder)\n",
        "                # This matches original behavior\n",
        "                return {\n",
        "                    'cooks_d': np.zeros(n),\n",
        "                    'has_influential': False\n",
        "                }\n",
        "        except:\n",
        "            return {\n",
        "                'cooks_d': np.zeros(len(reg_df)),\n",
        "                'has_influential': False\n",
        "            }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# REGRESSION ORCHESTRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class RegressionEngine:\n",
        "    \"\"\"\n",
        "    High-level orchestrator for meta-regression analysis.\n",
        "    Coordinates model selection, estimation, and diagnostics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_manager: 'RegressionDataManager'):\n",
        "        \"\"\"\n",
        "        Initialize engine with data manager.\n",
        "\n",
        "        Args:\n",
        "            data_manager: RegressionDataManager instance\n",
        "        \"\"\"\n",
        "        self.data_manager = data_manager\n",
        "        self.analyzer = RegressionAnalyzer(\n",
        "            effect_col=data_manager.effect_col,\n",
        "            var_col=data_manager.var_col,\n",
        "            global_settings=data_manager.global_settings\n",
        "        )\n",
        "        self.two_level = TwoLevelRegressionEngine()\n",
        "        self.three_level = ThreeLevelRegressionEngine()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_meta_regression(\n",
        "        self,\n",
        "        moderator_col: str,\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> Optional['RegressionResult']:\n",
        "        \"\"\"\n",
        "        Execute complete meta-regression analysis.\n",
        "\n",
        "        DECISION LOGIC PRESERVED: Original model selection strategy\n",
        "\n",
        "        Args:\n",
        "            moderator_col: Name of moderator variable\n",
        "            progress_callback: Optional callback for progress updates\n",
        "\n",
        "        Returns:\n",
        "            RegressionResult object or None if analysis fails\n",
        "        \"\"\"\n",
        "        # Prepare data\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udcca Preparing data...\")\n",
        "\n",
        "        try:\n",
        "            reg_df, config = self.data_manager.prepare_regression_data(moderator_col)\n",
        "        except ValueError as e:\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"\u274c Data preparation failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        # Check data structure\n",
        "        variation_info = self.data_manager.check_within_study_variation(\n",
        "            reg_df, moderator_col\n",
        "        )\n",
        "\n",
        "        k_studies = variation_info['k_studies']\n",
        "        n_obs = variation_info['n_obs']\n",
        "        has_multiple_effects = variation_info['has_multiple_effects']\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback(f\"\ud83d\udcc8 k = {k_studies} studies, n = {n_obs} observations\")\n",
        "\n",
        "        # =================================================================\n",
        "        # DECISION LOGIC (PRESERVED FROM ORIGINAL)\n",
        "        # =================================================================\n",
        "\n",
        "        if not has_multiple_effects:\n",
        "            # Only 1 effect per study \u2192 2-level structure\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\ud83d\udd04 Running 2-level aggregated regression...\")\n",
        "\n",
        "            # Aggregate data\n",
        "            agg_df = self.analyzer.aggregate_to_study_level(reg_df, moderator_col)\n",
        "\n",
        "            # Run 2-level regression\n",
        "            model_results = self.two_level.run_aggregated_regression(\n",
        "                agg_df, moderator_col, config.effect_col, config.var_col\n",
        "            )\n",
        "\n",
        "            reg_df_for_plot = agg_df\n",
        "\n",
        "        else:\n",
        "            # Multiple effects per study \u2192 3-level model\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\ud83d\udd04 Running 3-level regression with RVE...\")\n",
        "\n",
        "            model_results = self.three_level.run_three_level_regression(\n",
        "                reg_df, moderator_col, config.effect_col, config.var_col\n",
        "            )\n",
        "\n",
        "            if model_results is None:\n",
        "                if progress_callback:\n",
        "                    progress_callback(\"\u274c Optimization failed\")\n",
        "                return None\n",
        "\n",
        "            reg_df_for_plot = reg_df\n",
        "\n",
        "        # =================================================================\n",
        "        # POST-PROCESSING (PRESERVED FROM ORIGINAL)\n",
        "        # =================================================================\n",
        "\n",
        "        # Extract coefficients\n",
        "        beta0, beta1 = model_results['betas']\n",
        "        se0, se1 = model_results['se_betas']\n",
        "        p0, p1 = model_results['p_values']\n",
        "        tau_sq = model_results['tau_sq']\n",
        "        sigma_sq = model_results['sigma_sq']\n",
        "        df_resid = model_results['resid_df']\n",
        "        model_type = model_results['model_type']\n",
        "        fitted = model_results['fitted']\n",
        "        resid = model_results['resid']\n",
        "        var_betas_robust = model_results['var_betas_robust']\n",
        "\n",
        "        # Recalculate inference if needed (for dynamic dist_type)\n",
        "        if self.analyzer.dist_type != 't' or True:  # Always recalculate for consistency\n",
        "            p_values_new = self.analyzer.recalculate_p_values(\n",
        "                np.array([beta0, beta1]),\n",
        "                np.array([se0, se1]),\n",
        "                df_resid\n",
        "            )\n",
        "            p0, p1 = p_values_new\n",
        "\n",
        "        # Calculate confidence intervals\n",
        "        ci0, ci1 = self.analyzer.calculate_confidence_intervals(\n",
        "            np.array([beta0, beta1]),\n",
        "            np.array([se0, se1]),\n",
        "            df_resid\n",
        "        )\n",
        "\n",
        "        # Calculate R\u00b2\n",
        "        if self.data_manager.overall_results:\n",
        "            tau2_null = self.data_manager.overall_results.get('tau_squared', tau_sq)\n",
        "        else:\n",
        "            tau2_null = tau_sq\n",
        "\n",
        "        r2 = self.analyzer.calculate_r_squared(tau2_null, tau_sq)\n",
        "\n",
        "        # Calculate residual heterogeneity\n",
        "        mean_v = np.mean(reg_df_for_plot[config.var_col])\n",
        "        resid_i2 = self.analyzer.calculate_residual_heterogeneity(\n",
        "            tau_sq, sigma_sq, mean_v\n",
        "        )\n",
        "\n",
        "        # Calculate influence diagnostics\n",
        "        influence_metrics = self.analyzer.calculate_influence_diagnostics(\n",
        "            model_results, reg_df_for_plot, moderator_col\n",
        "        )\n",
        "\n",
        "        # Build result object\n",
        "        result = RegressionResult(\n",
        "            beta0=beta0,\n",
        "            beta1=beta1,\n",
        "            se0=se0,\n",
        "            se1=se1,\n",
        "            p0=p0,\n",
        "            p1=p1,\n",
        "            ci0=ci0,\n",
        "            ci1=ci1,\n",
        "            tau_sq=tau_sq,\n",
        "            sigma_sq=sigma_sq,\n",
        "            model_type=model_type,\n",
        "            k_studies=k_studies,\n",
        "            n_obs=n_obs,\n",
        "            df_resid=df_resid,\n",
        "            r_squared=r2,\n",
        "            resid_i2=resid_i2,\n",
        "            fitted=fitted,\n",
        "            resid=resid,\n",
        "            var_betas_robust=var_betas_robust,\n",
        "            moderator_col_name=moderator_col,\n",
        "            has_influential=influence_metrics['has_influential'],\n",
        "            cooks_d=influence_metrics['cooks_d']\n",
        "        )\n",
        "\n",
        "        if progress_callback:\n",
        "            sig = \"***\" if p1 < 0.001 else \"**\" if p1 < 0.01 else \"*\" if p1 < 0.05 else \"ns\"\n",
        "            progress_callback(f\"\u2705 \u03b2\u2081 = {beta1:.4f} {sig}, R\u00b2 = {r2:.1f}%\")\n",
        "\n",
        "        return result, reg_df_for_plot\n",
        "\n",
        "#@title \ud83d\udcc8 12. Meta-Regression: PRESENTATION LAYER (View) - PART 1\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 3/4: PRESENTATION LAYER - META-REGRESSION\n",
        "# Purpose: Pure UI rendering without business logic\n",
        "# Dependencies: Data & Analysis Layers\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Any, Optional\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HTML TEMPLATE GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class RegressionHTMLTemplates:\n",
        "    \"\"\"\n",
        "    Static HTML template generators for meta-regression visualizations.\n",
        "    All methods are pure functions returning HTML strings.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def gradient_card(\n",
        "        title: str,\n",
        "        value: str,\n",
        "        subtitle: str = \"\",\n",
        "        gradient: str = \"linear-gradient(135deg, #667eea 0%, #764ba2 100%)\"\n",
        "    ) -> str:\n",
        "        \"\"\"Generate gradient card for highlighting key statistics\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background: {gradient}; padding: 30px; border-radius: 10px;\n",
        "                    color: white; margin-bottom: 20px;'>\n",
        "            <div style='text-align: center;'>\n",
        "                <div style='font-size: 0.9em; margin-bottom: 10px;'>{title}</div>\n",
        "                <h1 style='margin: 0; font-size: 3em;'>{value}</h1>\n",
        "                <p style='margin: 10px 0 0 0; font-size: 1.2em;'>{subtitle}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def info_grid(items: list) -> str:\n",
        "        \"\"\"\n",
        "        Generate 2-column grid of info boxes.\n",
        "\n",
        "        Args:\n",
        "            items: List of dicts with 'label' and 'value' keys\n",
        "        \"\"\"\n",
        "        html = \"<div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-bottom: 20px;'>\"\n",
        "\n",
        "        for item in items:\n",
        "            color = item.get('color', '#007bff')\n",
        "            html += f\"\"\"\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;\n",
        "                        border-left: 4px solid {color};'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>{item['label']}</div>\n",
        "                <div style='font-size: 1.3em; font-weight: bold;'>{item['value']}</div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"</div>\"\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def interpretation_box(content: str, is_significant: bool = False) -> str:\n",
        "        \"\"\"Generate interpretation box with appropriate styling\"\"\"\n",
        "        bg_color = \"#e7f3ff\" if is_significant else \"#f8f9fa\"\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: {bg_color}; padding: 20px; border-radius: 5px;\n",
        "                    margin-bottom: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "            <p style='margin: 0; font-size: 1.05em;'>{content}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def coefficient_table(\n",
        "        beta0: float, beta1: float,\n",
        "        se0: float, se1: float,\n",
        "        p0: float, p1: float,\n",
        "        ci0: tuple, ci1: tuple,\n",
        "        df: int,\n",
        "        moderator_name: str,\n",
        "        ci_level: float = 95\n",
        "    ) -> str:\n",
        "        \"\"\"Generate styled coefficient table\"\"\"\n",
        "\n",
        "        def format_p(p):\n",
        "            return \"<0.001\" if p < 0.001 else f\"{p:.4g}\"\n",
        "\n",
        "        sig_style_slope = \"font-weight: bold; color: #28a745;\" if p1 < 0.05 else \"\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Term</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Estimate (\u03b2)</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>SE</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>t-value</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>p-value</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>{ci_level:.0f}% CI</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Intercept</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{beta0:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{se0:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{beta0/se0:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{format_p(p0)}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{ci0[0]:.4f}, {ci0[1]:.4f}]</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>{moderator_name}</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6; {sig_style_slope}'>{beta1:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{se1:.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{beta1/se1:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6; {sig_style_slope}'>{format_p(p1)}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{ci1[0]:.4f}, {ci1[1]:.4f}]</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def model_summary_box(\n",
        "        model_type: str,\n",
        "        k_studies: int,\n",
        "        n_obs: int,\n",
        "        df: int,\n",
        "        tau_sq: float,\n",
        "        sigma_sq: float,\n",
        "        r2: float,\n",
        "        resid_i2: float\n",
        "    ) -> str:\n",
        "        \"\"\"Generate model summary information box\"\"\"\n",
        "        html = f\"\"\"\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "            <p style='margin: 5px 0;'><b>Model Type:</b> {model_type}</p>\n",
        "            <p style='margin: 5px 0;'><b>Studies (k):</b> {k_studies}</p>\n",
        "            <p style='margin: 5px 0;'><b>Observations (n):</b> {n_obs}</p>\n",
        "            <p style='margin: 5px 0;'><b>Degrees of Freedom:</b> {df}</p>\n",
        "            <p style='margin: 5px 0;'><b>Between-Study Variance (\u03c4\u00b2):</b> {tau_sq:.4f}</p>\n",
        "        \"\"\"\n",
        "\n",
        "        if sigma_sq > 0:\n",
        "            html += f\"<p style='margin: 5px 0;'><b>Within-Study Variance (\u03c3\u00b2):</b> {sigma_sq:.4f}</p>\"\n",
        "\n",
        "        if r2 > 0:\n",
        "            html += f\"<p style='margin: 5px 0;'><b>Variance Explained (R\u00b2):</b> {r2:.1f}%</p>\"\n",
        "\n",
        "        html += f\"<p style='margin: 5px 0;'><b>Residual I\u00b2:</b> {resid_i2:.1f}%</p></div>\"\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def assumption_table(sigma_sq: float) -> str:\n",
        "        \"\"\"Generate model assumptions checklist\"\"\"\n",
        "        return f\"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse;'>\n",
        "            <thead style='background-color: #f8f9fa;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Assumption</th>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Assessment</th>\n",
        "                    <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Status</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Linearity</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Check scatter plot in dedicated plot cell</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>\u26a0\ufe0f Visual check needed</td>\n",
        "                </tr>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Independence</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>{'Cluster-robust SE used' if sigma_sq > 0 else 'Aggregated to study level'}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>\u2713 Accounted for</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Normality</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Residuals approximately normal (t-distribution)</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>\u2713 Assumed</td>\n",
        "                </tr>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Homoscedasticity</b></td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>Weighted by inverse variance</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>\u2713 Weighted regression</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def variance_covariance_matrix(var_betas: np.ndarray) -> str:\n",
        "        \"\"\"Generate styled variance-covariance matrix display\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <table style='margin: 10px auto; border-collapse: collapse;'>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas[0,0]:.6f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas[0,1]:.6f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas[1,0]:.6f}</td>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6; text-align: center;'>{var_betas[1,1]:.6f}</td>\n",
        "                </tr>\n",
        "            </table>\n",
        "            <p style='margin: 10px 0 0 0; text-align: center; font-size: 0.9em;'>\n",
        "                <i>Var(\u03b2\u2080) and Var(\u03b2\u2081) on diagonal; Cov(\u03b2\u2080,\u03b2\u2081) on off-diagonal</i>\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def card(content: str, bg_color: str = '#f8f9fa') -> str:\n",
        "        \"\"\"Generate simple card container\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: {bg_color}; padding: 15px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            {content}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def header(text: str, level: int = 3) -> str:\n",
        "        \"\"\"Generate styled header\"\"\"\n",
        "        return f\"<h{level} style='color: #2c3e50;'>{text}</h{level}>\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PUBLICATION TEXT GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class RegressionPublicationTextGenerator:\n",
        "    \"\"\"\n",
        "    Generates publication-ready text for manuscripts.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ci_level: float = 95):\n",
        "        self.ci_level = ci_level\n",
        "\n",
        "    def generate_methods_section(\n",
        "        self,\n",
        "        moderator_col: str,\n",
        "        model_type: str,\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate Materials and Methods section.\n",
        "\n",
        "        PRESERVED: Original citation logic based on model type\n",
        "        \"\"\"\n",
        "        # Citation database\n",
        "        db = {\n",
        "            'thompson': \"Thompson, S. G., & Higgins, J. P. (2002). How should meta-regression analyses be undertaken and interpreted? <i>Statistics in Medicine</i>, 21(11), 1559-1573.\",\n",
        "            'rve': \"Hedges, L. V., Tipton, E., & Johnson, M. C. (2010). Robust variance estimation in meta-regression with dependent effect size estimates. <i>Research Synthesis Methods</i>, 1(1), 39-65.\",\n",
        "            '3level': \"Van den Noortgate, W., L\u00f3pez-L\u00f3pez, J. A., Mar\u00edn-Mart\u00ednez, F., & S\u00e1nchez-Meca, J. (2013). Three-level meta-analysis of dependent effect sizes. <i>Behavior Research Methods</i>, 45(2), 576-594.\",\n",
        "            'knapp': \"Knapp, G., & Hartung, J. (2003). Improved tests for a random effects meta-regression with a single covariate. <i>Statistics in Medicine</i>, 22(17), 2693-2710.\",\n",
        "            'tool': \"<b>[CITATION FOR THIS TOOL]:</b> Author, A. A. (202X). <i>Co-Meta: An Interactive Pipeline for Meta-Analysis</i>. [Repository/DOI].\"\n",
        "        }\n",
        "\n",
        "        # Determine citations based on model type\n",
        "        active_refs = []\n",
        "\n",
        "        if \"Cluster-Robust\" in model_type or \"3-Level\" in model_type:\n",
        "            model_desc = \"To account for the nested structure of the data (multiple effect sizes per study), we employed a multi-level meta-regression model [1].\"\n",
        "            active_refs.append(db['3level'])\n",
        "\n",
        "            model_desc += \" Standard errors and hypothesis tests were computed using Cluster-Robust Variance Estimation (RVE) to handle dependencies [2].\"\n",
        "            active_refs.append(db['rve'])\n",
        "        else:\n",
        "            model_desc = \"We examined the relationship between effect size and the moderator using a mixed-effects meta-regression model [1].\"\n",
        "            active_refs.append(db['thompson'])\n",
        "\n",
        "            model_desc += \" The Knapp-Hartung adjustment was used for hypothesis testing to improve the accuracy of significance levels [2].\"\n",
        "            active_refs.append(db['knapp'])\n",
        "\n",
        "        # Add tool citation\n",
        "        active_refs.append(db['tool'])\n",
        "        ref_tool = len(active_refs)\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;\n",
        "                    border: 1px solid #eee; margin-bottom: 20px;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db;\n",
        "                   padding-bottom: 10px; margin-top: 0;'>Materials and Methods</h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Meta-Regression.</b> We conducted a meta-regression analysis to investigate whether\n",
        "        the variation in effect sizes could be explained by the continuous moderator <b>{moderator_col}</b>.\n",
        "        {model_desc}\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Model Specification.</b> The model estimated the intercept (\u03b2\u2080, expected effect when\n",
        "        {moderator_col} is zero) and the slope (\u03b2\u2081, the change in effect size per unit increase in\n",
        "        {moderator_col}). Between-study heterogeneity was quantified using the residual <i>I</i>\u00b2 statistic,\n",
        "        representing the proportion of variance not explained by the moderator. All analyses were performed\n",
        "        using the Co-Meta toolkit [{ref_tool}].\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 20px; font-size: 11pt;'>References</h4>\n",
        "        <ol style='font-size: 10pt; color: #555;'>\n",
        "        \"\"\"\n",
        "\n",
        "        for ref in active_refs:\n",
        "            html += f\"<li>{ref}</li>\"\n",
        "\n",
        "        html += \"</ol></div>\"\n",
        "        return html\n",
        "\n",
        "    def generate_results_section(\n",
        "        self,\n",
        "        result: 'RegressionResult',\n",
        "        moderator_col: str\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate complete Results section with interpretation.\n",
        "\n",
        "        PRESERVED: Original publication text logic\n",
        "        \"\"\"\n",
        "        # Extract values\n",
        "        beta0, beta1 = result.beta0, result.beta1\n",
        "        se0, se1 = result.se0, result.se1\n",
        "        p0, p1 = result.p0, result.p1\n",
        "        ci0, ci1 = result.ci0, result.ci1\n",
        "        tau_sq = result.tau_sq\n",
        "        sigma_sq = result.sigma_sq\n",
        "        k_studies = result.k_studies\n",
        "        n_obs = result.n_obs\n",
        "        model_type = result.model_type\n",
        "        r2 = result.r_squared\n",
        "        resid_i2 = result.resid_i2\n",
        "        df_resid = result.df_resid\n",
        "\n",
        "        sig_text = \"significantly predicted\" if p1 < 0.05 else \"did not significantly predict\"\n",
        "        p_format = f\"< 0.001\" if p1 < 0.001 else f\"= {p1:.3f}\"\n",
        "        direction = \"increased\" if beta1 > 0 else \"decreased\"\n",
        "\n",
        "        # Model type description\n",
        "        if \"2-Level\" in model_type or \"Aggregated\" in model_type:\n",
        "            model_desc = \"two-level aggregated random-effects meta-regression\"\n",
        "            variance_note = f\"Between-study variance (\u03c4\u00b2) was estimated at {tau_sq:.4f}.\"\n",
        "            cluster_note = \"\"\n",
        "        else:\n",
        "            model_desc = \"three-level random-effects meta-regression with cluster-robust variance estimation\"\n",
        "            variance_note = f\"Between-study variance (\u03c4\u00b2) was {tau_sq:.4f} and within-study variance (\u03c3\u00b2) was {sigma_sq:.4f}.\"\n",
        "            cluster_note = \" Cluster-robust standard errors were computed to account for the nested structure of effect sizes within studies.\"\n",
        "\n",
        "        # Residual heterogeneity interpretation\n",
        "        if resid_i2 < 25:\n",
        "            het_text = \"low\"\n",
        "            het_interp = \"suggesting that the moderator successfully captured most of the systematic variation in effect sizes\"\n",
        "        elif resid_i2 < 50:\n",
        "            het_text = \"moderate\"\n",
        "            het_interp = \"suggesting that additional unmeasured factors may contribute to the variation in effect sizes\"\n",
        "        else:\n",
        "            het_text = \"substantial\"\n",
        "            het_interp = \"indicating that additional moderators not examined in this analysis likely contribute to variation in effect sizes\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>\n",
        "            Meta-Regression Results\n",
        "        </h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        We conducted a meta-regression to examine whether <b>{moderator_col}</b> moderated the effect sizes.\n",
        "        A {model_desc} was employed to account for dependencies in the data.{cluster_note} The analysis\n",
        "        included <b>k = {k_studies}</b> studies with <b>n = {n_obs}</b> effect sizes.\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        The moderator <b>{sig_text}</b> effect sizes (\u03b2\u2081 = <b>{beta1:.3f}</b>, SE = {se1:.3f},\n",
        "        <i>t</i>({df_resid}) = {beta1/se1:.2f}, <i>p</i> {p_format}, {self.ci_level:.0f}% CI\n",
        "        [{ci1[0]:.3f}, {ci1[1]:.3f}]). \"\"\"\n",
        "\n",
        "        if p1 < 0.05:\n",
        "            html += f\"\"\"For every one-unit increase in {moderator_col}, the effect size {direction} by\n",
        "            <b>{abs(beta1):.3f}</b> units on average.\n",
        "            </p>\n",
        "\n",
        "            <p style='text-align: justify;'>\n",
        "            This finding suggests that <b>{moderator_col}</b> is an important moderator of the outcome. \"\"\"\n",
        "            if r2 > 0:\n",
        "                html += f\"\"\"The moderator explained <b>{r2:.1f}%</b> of the between-study heterogeneity. \"\"\"\n",
        "            html += f\"\"\"[<i>Add domain-specific interpretation: Why might {moderator_col} influence the effect?\n",
        "            Link to theory or prior research.</i>]\n",
        "            </p>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            html += f\"\"\"The relationship between {moderator_col} and effect sizes was not statistically significant.\n",
        "            </p>\n",
        "\n",
        "            <p style='text-align: justify;'>\n",
        "            No significant linear relationship was detected between <b>{moderator_col}</b> and effect sizes,\n",
        "            suggesting that {moderator_col} may not be a primary source of heterogeneity in this meta-analysis. \"\"\"\n",
        "            if k_studies < 10:\n",
        "                html += f\"\"\"However, the small number of studies (k = {k_studies}) may have limited statistical\n",
        "                power to detect a relationship. \"\"\"\n",
        "            html += f\"\"\"[<i>Discuss alternative explanations: Could the relationship be non-linear? Are there\n",
        "            confounding factors? Should subgroup analysis be considered?</i>]\n",
        "            </p>\n",
        "            \"\"\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <p style='text-align: justify;'>\n",
        "        {variance_note} Residual heterogeneity remained <b>{het_text}</b> (\u03c4\u00b2<sub>residual</sub> = {tau_sq:.4f}\"\"\"\n",
        "\n",
        "        if resid_i2 > 0:\n",
        "            html += f\"\"\", <i>I</i>\u00b2<sub>residual</sub> = {resid_i2:.1f}%\"\"\"\n",
        "\n",
        "        html += f\"\"\"), {het_interp}.\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 25px;'>Statistical Methods</h4>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        All meta-regression analyses were conducted using {model_desc}. Restricted maximum likelihood (REML)\n",
        "        was used to estimate variance components. The intercept (\u03b2\u2080 = {beta0:.3f}, {self.ci_level:.0f}% CI\n",
        "        [{ci0[0]:.3f}, {ci0[1]:.3f}]) represents the expected effect size when {moderator_col} equals zero.\n",
        "        Confidence intervals and <i>p</i>-values were based on a <i>t</i>-distribution with {df_resid} degrees\n",
        "        of freedom.\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        # Add summary table\n",
        "        html += self._generate_coefficient_table(result, moderator_col)\n",
        "\n",
        "        # Guidance\n",
        "        html += \"\"\"\n",
        "        <hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "        <div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; margin-top: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "            <ul style='margin-bottom: 0;'>\n",
        "                <li>Customize the interpretation based on your specific research domain and theoretical framework</li>\n",
        "                <li>Add context about why the moderator might theoretically influence the effect sizes</li>\n",
        "                <li>Discuss the practical significance of the slope magnitude (not just statistical significance)</li>\n",
        "                <li>Consider whether the relationship might be non-linear (quadratic, threshold effects, etc.)</li>\n",
        "                <li>Link findings to prior research or meta-analyses in your field</li>\n",
        "                <li>If non-significant, discuss statistical power and whether a larger sample might detect an effect</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "            <p style='margin: 0;'><b>\ud83d\udca1 Tip:</b> Select all text (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C),\n",
        "            and paste into your word processor. Edit the [<i>bracketed notes</i>] to add your domain-specific\n",
        "            interpretations. Delete sections not relevant to your journal's requirements.</p>\n",
        "        </div>\n",
        "\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "#@title \ud83d\udcc8 12. Meta-Regression: PRESENTATION LAYER (View) - PART 2\n",
        "# =============================================================================\n",
        "# Continuation: Complete _generate_coefficient_table and Tab Renderers\n",
        "# =============================================================================\n",
        "\n",
        "    def _generate_coefficient_table(\n",
        "        self,\n",
        "        result: 'RegressionResult',\n",
        "        moderator_col: str\n",
        "    ) -> str:\n",
        "        \"\"\"Generate formatted coefficient table for publication\"\"\"\n",
        "\n",
        "        beta0, beta1 = result.beta0, result.beta1\n",
        "        se0, se1 = result.se0, result.se1\n",
        "        p0, p1 = result.p0, result.p1\n",
        "        ci0, ci1 = result.ci0, result.ci1\n",
        "        df = result.df_resid\n",
        "        sigma_sq = result.sigma_sq\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "        <div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 25px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>\ud83d\udcca Table 1. Meta-Regression Coefficients</h4>\n",
        "            <table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "                <thead style='background-color: #34495e; color: white;'>\n",
        "                    <tr>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Predictor</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>\u03b2</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>SE</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>t</i></th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>df</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'><i>p</i>-value</th>\n",
        "                        <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>{self.ci_level:.0f}% CI</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr style='background-color: #f8f9fa;'>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px;'>Intercept</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{beta0:.3f}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{se0:.3f}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{beta0/se0:.2f}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{df}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{\"<0.001\" if p0 < 0.001 else f\"{p0:.3f}\"}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{ci0[0]:.3f}, {ci0[1]:.3f}]</td>\n",
        "                    </tr>\n",
        "                    <tr style='background-color: white;'>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px;'><b>{moderator_col}</b></td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center; {\"font-weight: bold;\" if p1 < 0.05 else \"\"}'>{beta1:.3f}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{se1:.3f}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{beta1/se1:.2f}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{df}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center; {\"font-weight: bold;\" if p1 < 0.05 else \"\"}'>{\"<0.001\" if p1 < 0.001 else f\"{p1:.3f}\"}</td>\n",
        "                        <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{ci1[0]:.3f}, {ci1[1]:.3f}]</td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "            <p style='margin-top: 10px; font-size: 0.9em; color: #6c757d;'>\n",
        "                <i>Note:</i> Results from {'two-level aggregated random-effects' if sigma_sq == 0 else 'three-level'}\n",
        "                meta-regression. k = number of studies; n = number of effect sizes; \u03c4\u00b2 = between-study variance\"\"\"\n",
        "\n",
        "        if sigma_sq > 0:\n",
        "            html += \"\"\"; \u03c3\u00b2 = within-study variance\"\"\"\n",
        "\n",
        "        html += \"\"\".</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# VIEW COMPONENTS (Tab Renderers)\n",
        "# =============================================================================\n",
        "\n",
        "class RegressionResultsView:\n",
        "    \"\"\"\n",
        "    Manages all UI rendering for meta-regression.\n",
        "    Contains zero business logic - only presentation code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ci_level: float = 95):\n",
        "        \"\"\"\n",
        "        Initialize view with display settings.\n",
        "\n",
        "        Args:\n",
        "            ci_level: Confidence interval percentage\n",
        "        \"\"\"\n",
        "        self.ci_level = ci_level\n",
        "        self.templates = RegressionHTMLTemplates()\n",
        "        self.text_gen = RegressionPublicationTextGenerator(ci_level)\n",
        "\n",
        "        # Create tab widgets\n",
        "        self.tab_results = widgets.Output()\n",
        "        self.tab_diagnostics = widgets.Output()\n",
        "        self.tab_details = widgets.Output()\n",
        "        self.tab_publication = widgets.Output()\n",
        "        self.tab_export = widgets.Output()\n",
        "\n",
        "        self.tabs = widgets.Tab(children=[\n",
        "            self.tab_results,\n",
        "            self.tab_diagnostics,\n",
        "            self.tab_details,\n",
        "            self.tab_publication,\n",
        "            self.tab_export\n",
        "        ])\n",
        "\n",
        "        self.tabs.set_title(0, '\ud83d\udcca Results')\n",
        "        self.tabs.set_title(1, '\ud83d\udd0d Diagnostics')\n",
        "        self.tabs.set_title(2, '\u2699\ufe0f Model Details')\n",
        "        self.tabs.set_title(3, '\ud83d\udcdd Publication Text')\n",
        "        self.tabs.set_title(4, '\ud83d\udcbe Export')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 1: RESULTS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_results_tab(\n",
        "        self,\n",
        "        result: 'RegressionResult',\n",
        "        moderator_col: str\n",
        "    ) -> None:\n",
        "        \"\"\"Render results summary tab\"\"\"\n",
        "\n",
        "        with self.tab_results:\n",
        "            self.tab_results.clear_output()\n",
        "\n",
        "            # Header\n",
        "            display(HTML(f\"<div style='padding: 20px;'><h2 style='color: #2c3e50; margin-bottom: 20px;'>Meta-Regression: {moderator_col}</h2>\"))\n",
        "\n",
        "            # Significance indicator\n",
        "            sig = \"***\" if result.p1 < 0.001 else \"**\" if result.p1 < 0.01 else \"*\" if result.p1 < 0.05 else \"ns\"\n",
        "\n",
        "            # Main gradient card\n",
        "            gradient_html = self.templates.gradient_card(\n",
        "                title=\"SLOPE COEFFICIENT (\u03b2\u2081)\",\n",
        "                value=f\"{result.beta1:.4f}\",\n",
        "                subtitle=sig\n",
        "            )\n",
        "            display(HTML(gradient_html))\n",
        "\n",
        "            # Info grid\n",
        "            color = \"#28a745\" if result.p1 < 0.05 else \"#6c757d\"\n",
        "            info_items = [\n",
        "                {\n",
        "                    'label': f'{self.ci_level:.0f}% Confidence Interval',\n",
        "                    'value': f'[{result.ci1[0]:.4f}, {result.ci1[1]:.4f}]',\n",
        "                    'color': '#007bff'\n",
        "                },\n",
        "                {\n",
        "                    'label': 'P-value',\n",
        "                    'value': f'{result.p1:.4g}',\n",
        "                    'color': color\n",
        "                }\n",
        "            ]\n",
        "            display(HTML(self.templates.info_grid(info_items)))\n",
        "\n",
        "            # Interpretation box\n",
        "            direction_text = '<b>increases</b>' if result.beta1 > 0 else '<b>decreases</b>'\n",
        "            sig_text = 'This relationship is <b style=\"color: #28a745;\">statistically significant</b>.' if result.p1 < 0.05 else 'This relationship is <b>not statistically significant</b>.'\n",
        "\n",
        "            interp_content = f\"\"\"\n",
        "            For every 1-unit increase in <b>{moderator_col}</b>, the effect size {direction_text} by\n",
        "            <b>{abs(result.beta1):.4f}</b> units. {sig_text}\n",
        "            \"\"\"\n",
        "            display(HTML(self.templates.interpretation_box(interp_content, result.p1 < 0.05)))\n",
        "\n",
        "            # Coefficient table\n",
        "            display(HTML(self.templates.header(\"Coefficient Table\")))\n",
        "            coef_table = self.templates.coefficient_table(\n",
        "                result.beta0, result.beta1,\n",
        "                result.se0, result.se1,\n",
        "                result.p0, result.p1,\n",
        "                result.ci0, result.ci1,\n",
        "                result.df_resid,\n",
        "                moderator_col,\n",
        "                self.ci_level\n",
        "            )\n",
        "            display(HTML(coef_table))\n",
        "\n",
        "            # Model summary\n",
        "            display(HTML(self.templates.header(\"Model Summary\")))\n",
        "            summary_html = self.templates.model_summary_box(\n",
        "                result.model_type,\n",
        "                result.k_studies,\n",
        "                result.n_obs,\n",
        "                result.df_resid,\n",
        "                result.tau_sq,\n",
        "                result.sigma_sq,\n",
        "                result.r_squared,\n",
        "                result.resid_i2\n",
        "            )\n",
        "            display(HTML(summary_html))\n",
        "\n",
        "            # Next step tip\n",
        "            tip_html = \"\"\"\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px;\n",
        "                        border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "                <p style='margin: 0;'><b>\ud83d\udcca Next Step:</b> Use the dedicated plot cell to visualize\n",
        "                this regression relationship with full customization options.</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(tip_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 2: DIAGNOSTICS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_diagnostics_tab(self, result: 'RegressionResult') -> None:\n",
        "        \"\"\"Render diagnostics tab\"\"\"\n",
        "\n",
        "        with self.tab_diagnostics:\n",
        "            self.tab_diagnostics.clear_output()\n",
        "\n",
        "            display(HTML(\"<div style='padding: 20px;'>\"))\n",
        "            display(HTML(self.templates.header(\"\ud83d\udd0d Model Diagnostics\")))\n",
        "\n",
        "            # Residual analysis\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Residual Analysis</h4>\"))\n",
        "\n",
        "            resid_content = f\"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Residual Range:</b> [{np.min(result.resid):.4f}, {np.max(result.resid):.4f}]</p>\n",
        "            <p style='margin: 5px 0;'><b>Mean Residual:</b> {np.mean(result.resid):.4f} (should be \u2248 0)</p>\n",
        "            <p style='margin: 5px 0;'><b>SD of Residuals:</b> {np.std(result.resid):.4f}</p>\n",
        "            \"\"\"\n",
        "            display(HTML(self.templates.card(resid_content)))\n",
        "\n",
        "            # Influence diagnostics\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Influence Diagnostics</h4>\"))\n",
        "\n",
        "            if result.has_influential:\n",
        "                if result.cooks_d is not None:\n",
        "                    threshold = 4 / result.n_obs\n",
        "                    influential_indices = np.where(result.cooks_d > threshold)[0]\n",
        "                    influence_html = f\"\"\"\n",
        "                    <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px;\n",
        "                                border-left: 4px solid #ffc107; margin-bottom: 20px;'>\n",
        "                        <p style='margin: 0;'><b>\u26a0\ufe0f Warning:</b> {len(influential_indices)} potentially\n",
        "                        influential observation(s) detected (Cook's D > {threshold:.4f}).</p>\n",
        "                        <p style='margin: 10px 0 0 0;'>Influential points: {', '.join(map(str, influential_indices))}</p>\n",
        "                    </div>\n",
        "                    \"\"\"\n",
        "                else:\n",
        "                    influence_html = \"\"\"\n",
        "                    <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px;\n",
        "                                border-left: 4px solid #ffc107; margin-bottom: 20px;'>\n",
        "                        <p style='margin: 0;'><b>\u26a0\ufe0f Note:</b> Influence diagnostics indicated potential issues.</p>\n",
        "                    </div>\n",
        "                    \"\"\"\n",
        "            else:\n",
        "                influence_html = \"\"\"\n",
        "                <div style='background-color: #d4edda; padding: 15px; border-radius: 5px;\n",
        "                            border-left: 4px solid #28a745; margin-bottom: 20px;'>\n",
        "                    <p style='margin: 0;'><b>\u2713 Good:</b> No highly influential observations detected.</p>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "            display(HTML(influence_html))\n",
        "\n",
        "            # Heterogeneity assessment\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Heterogeneity Assessment</h4>\"))\n",
        "\n",
        "            het_content = f\"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Residual Heterogeneity (I\u00b2):</b> {result.resid_i2:.1f}%</p>\n",
        "            \"\"\"\n",
        "            if result.r_squared > 0:\n",
        "                het_content += f\"<p style='margin: 5px 0;'><b>Heterogeneity Explained (R\u00b2):</b> {result.r_squared:.1f}%</p>\"\n",
        "\n",
        "            het_content += \"<p style='margin: 10px 0 0 0;'><i>Lower residual heterogeneity suggests the moderator explains variation well.</i></p>\"\n",
        "\n",
        "            display(HTML(self.templates.card(het_content)))\n",
        "\n",
        "            # Model assumptions\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Model Assumptions</h4>\"))\n",
        "            display(HTML(self.templates.assumption_table(result.sigma_sq)))\n",
        "\n",
        "            # Recommendation\n",
        "            rec_html = \"\"\"\n",
        "            <div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px; margin-top: 20px;'>\n",
        "                <p style='margin: 0;'><b>\ud83d\udca1 Recommendation:</b> Use the dedicated plot cell to create\n",
        "                residual plots and visually assess linearity and homoscedasticity assumptions.</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(rec_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 3: MODEL DETAILS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_details_tab(\n",
        "        self,\n",
        "        result: 'RegressionResult',\n",
        "        moderator_col: str,\n",
        "        reg_df: pd.DataFrame,\n",
        "        effect_col: str,\n",
        "        var_col: str\n",
        "    ) -> None:\n",
        "        \"\"\"Render model details tab\"\"\"\n",
        "\n",
        "        with self.tab_details:\n",
        "            self.tab_details.clear_output()\n",
        "\n",
        "            display(HTML(\"<div style='padding: 20px;'>\"))\n",
        "            display(HTML(self.templates.header(\"\u2699\ufe0f Model Details & Specifications\")))\n",
        "\n",
        "            # Model specification\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Model Specification</h4>\"))\n",
        "\n",
        "            if result.sigma_sq > 0:\n",
        "                spec_html = \"\"\"\n",
        "                <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;\n",
        "                            margin-bottom: 20px; font-family: monospace;'>\n",
        "                    <p style='margin: 5px 0;'><b>Three-Level Model:</b></p>\n",
        "                    <p style='margin: 5px 0; padding-left: 20px;'>y<sub>ij</sub> = \u03b2\u2080 + \u03b2\u2081X<sub>i</sub> + u<sub>i</sub> + e<sub>ij</sub></p>\n",
        "                    <p style='margin: 5px 0; padding-left: 20px;'>where:</p>\n",
        "                    <p style='margin: 5px 0; padding-left: 40px;'>\u2022 y<sub>ij</sub> = effect size j in study i</p>\n",
        "                    <p style='margin: 5px 0; padding-left: 40px;'>\u2022 X<sub>i</sub> = moderator value for study i</p>\n",
        "                    <p style='margin: 5px 0; padding-left: 40px;'>\u2022 u<sub>i</sub> ~ N(0, \u03c4\u00b2) = between-study random effect</p>\n",
        "                    <p style='margin: 5px 0; padding-left: 40px;'>\u2022 e<sub>ij</sub> ~ N(0, \u03c3\u00b2) = within-study random effect</p>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "            else:\n",
        "                spec_html = f\"\"\"\n",
        "                <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;\n",
        "                            margin-bottom: 20px; font-family: monospace;'>\n",
        "                    <p style='margin: 5px 0;'><b>Two-Level Aggregated Model:</b></p>\n",
        "                    <p style='margin: 5px 0; padding-left: 20px;'>y<sub>i</sub> = \u03b2\u2080 + \u03b2\u2081X<sub>i</sub> + u<sub>i</sub></p>\n",
        "                    <p style='margin: 5px 0; padding-left: 20px;'>where:</p>\n",
        "                    <p style='margin: 5px 0; padding-left: 40px;'>\u2022 y<sub>i</sub> = aggregated effect size for study i</p>\n",
        "                    <p style='margin: 5px 0; padding-left: 40px;'>\u2022 X<sub>i</sub> = moderator value for study i</p>\n",
        "                    <p style='margin: 5px 0; padding-left: 40px;'>\u2022 u<sub>i</sub> ~ N(0, \u03c4\u00b2) = between-study random effect</p>\n",
        "                    <p style='margin: 10px 0 0 0;'><i>Note: Data aggregated to study level because moderator was constant within studies.</i></p>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "            display(HTML(spec_html))\n",
        "\n",
        "            # Variance-covariance matrix\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Variance-Covariance Matrix</h4>\"))\n",
        "            display(HTML(self.templates.variance_covariance_matrix(result.var_betas_robust)))\n",
        "\n",
        "            # Variance components\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Variance Components</h4>\"))\n",
        "\n",
        "            var_table = f\"\"\"\n",
        "            <table style='width: 100%; border-collapse: collapse; margin-bottom: 20px;'>\n",
        "                <thead style='background-color: #f8f9fa;'>\n",
        "                    <tr>\n",
        "                        <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Component</th>\n",
        "                        <th style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>Value</th>\n",
        "                        <th style='padding: 10px; text-align: left; border: 1px solid #dee2e6;'>Description</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>\u03c4\u00b2</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{result.tau_sq:.4f}</td>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'>Between-study variance (residual)</td>\n",
        "                    </tr>\n",
        "            \"\"\"\n",
        "\n",
        "            if result.sigma_sq > 0:\n",
        "                var_table += f\"\"\"\n",
        "                    <tr style='background-color: #f8f9fa;'>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>\u03c3\u00b2</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{result.sigma_sq:.4f}</td>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'>Within-study variance</td>\n",
        "                    </tr>\n",
        "                \"\"\"\n",
        "\n",
        "            var_table += \"</tbody></table>\"\n",
        "            display(HTML(var_table))\n",
        "\n",
        "            # Degrees of freedom\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Degrees of Freedom</h4>\"))\n",
        "\n",
        "            if result.sigma_sq > 0:\n",
        "                df_calc = f\"Number of studies (k = {result.k_studies}) - Number of parameters (2) = {result.df_resid}\"\n",
        "            else:\n",
        "                df_calc = f\"Number of observations (n = {result.n_obs}) - Number of parameters (2) = {result.df_resid}\"\n",
        "\n",
        "            df_content = f\"\"\"\n",
        "            <p style='margin: 5px 0;'><b>df:</b> {result.df_resid}</p>\n",
        "            <p style='margin: 5px 0;'><b>Calculation:</b> {df_calc}</p>\n",
        "            <p style='margin: 10px 0 0 0;'><i>Used for t-distribution in hypothesis testing and confidence intervals</i></p>\n",
        "            \"\"\"\n",
        "            display(HTML(self.templates.card(df_content)))\n",
        "\n",
        "            # Standard error details\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Standard Error Details</h4>\"))\n",
        "\n",
        "            if result.sigma_sq > 0:\n",
        "                se_content = \"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Cluster-Robust Standard Errors</b></p>\n",
        "                <p style='margin: 5px 0;'>Standard errors account for clustering of effect sizes within studies,\n",
        "                providing more conservative estimates when multiple effect sizes come from the same study.</p>\n",
        "                \"\"\"\n",
        "            else:\n",
        "                se_content = \"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Standard Random-Effects Standard Errors</b></p>\n",
        "                <p style='margin: 5px 0;'>Standard errors from aggregated two-level model. Data was aggregated\n",
        "                to study level because the moderator was constant within each study.</p>\n",
        "                \"\"\"\n",
        "\n",
        "            display(HTML(self.templates.card(se_content)))\n",
        "\n",
        "            # Data summary\n",
        "            display(HTML(\"<h4 style='color: #34495e;'>Data Summary</h4>\"))\n",
        "\n",
        "            data_content = f\"\"\"\n",
        "            <p style='margin: 5px 0;'><b>Used in analysis:</b> {result.n_obs} {'studies' if result.sigma_sq == 0 else 'observations'}</p>\n",
        "            <p style='margin: 5px 0;'><b>Moderator range:</b> [{reg_df[moderator_col].min():.3f}, {reg_df[moderator_col].max():.3f}]</p>\n",
        "            <p style='margin: 5px 0;'><b>Effect size range:</b> [{reg_df[effect_col].min():.3f}, {reg_df[effect_col].max():.3f}]</p>\n",
        "            \"\"\"\n",
        "            display(HTML(self.templates.card(data_content)))\n",
        "\n",
        "            display(HTML(\"</div>\"))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 4: PUBLICATION TEXT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_publication_tab(\n",
        "        self,\n",
        "        result: 'RegressionResult',\n",
        "        moderator_col: str,\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Render publication text tab.\n",
        "\n",
        "        Returns:\n",
        "            Combined HTML text for saving\n",
        "        \"\"\"\n",
        "        with self.tab_publication:\n",
        "            self.tab_publication.clear_output()\n",
        "\n",
        "            display(HTML(self.templates.header(\"\ud83d\udcdd Publication-Ready Results Text\", level=3)))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "            # Generate both sections\n",
        "            methods_html = self.text_gen.generate_methods_section(\n",
        "                moderator_col, result.model_type, es_config\n",
        "            )\n",
        "            results_html = self.text_gen.generate_results_section(\n",
        "                result, moderator_col\n",
        "            )\n",
        "\n",
        "            # Display\n",
        "            display(HTML(methods_html))\n",
        "            display(HTML(results_html))\n",
        "\n",
        "            # Return combined for saving\n",
        "            return methods_html + \"<br><hr><br>\" + results_html\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 5: EXPORT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_export_tab(self, export_callback: callable) -> None:\n",
        "        \"\"\"Render export tab with download button\"\"\"\n",
        "\n",
        "        with self.tab_export:\n",
        "            self.tab_export.clear_output()\n",
        "\n",
        "            display(HTML(self.templates.header(\"\ud83d\udcbe Download Audit Report\", level=3)))\n",
        "            display(HTML(\"<p>Generate a full Excel audit trail including regression coefficients, diagnostics, and model settings.</p>\"))\n",
        "\n",
        "            btn_export = widgets.Button(\n",
        "                description=\"\ud83d\udce5 Download Regression Report\",\n",
        "                button_style='info',\n",
        "                icon='file-excel',\n",
        "                layout=widgets.Layout(width='300px', height='40px')\n",
        "            )\n",
        "\n",
        "            btn_export.on_click(export_callback)\n",
        "            display(btn_export)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR DISPLAY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_error(self, message: str, details: Optional[str] = None) -> None:\n",
        "        \"\"\"Render error message in results tab\"\"\"\n",
        "        with self.tab_results:\n",
        "            self.tab_results.clear_output()\n",
        "            error_html = f\"<div style='color: red; background-color: #f8d7da; padding: 15px; border-radius: 5px;'>\u274c {message}</div>\"\n",
        "            if details:\n",
        "                error_html += f\"<pre style='margin-top: 10px;'>{details}</pre>\"\n",
        "            display(HTML(error_html))\n",
        "\n",
        "\n",
        "print(\"\u2705 Meta-Regression View Layer (Part 2) Loaded Successfully\")\n",
        "\n",
        "#@title \ud83d\udcc8 12. Meta-Regression: CONTROLLER LAYER (Orchestration)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 4/4: CONTROLLER LAYER - META-REGRESSION\n",
        "# Purpose: Orchestrates data, analysis, and view components\n",
        "# Dependencies: All previous layers (Data, Analysis, View)\n",
        "# =============================================================================\n",
        "\n",
        "import traceback\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN CONTROLLER\n",
        "# =============================================================================\n",
        "\n",
        "class RegressionController:\n",
        "    \"\"\"\n",
        "    Master controller that orchestrates the entire meta-regression workflow.\n",
        "    Coordinates data management, statistical computation, and UI rendering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize controller with ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self.analysis_config = analysis_config\n",
        "\n",
        "        # Initialize components\n",
        "        try:\n",
        "            self.data_manager = RegressionDataManager(analysis_config)\n",
        "            self.engine = RegressionEngine(self.data_manager)\n",
        "\n",
        "            # Get CI level from settings\n",
        "            global_settings = self.data_manager.global_settings\n",
        "            ci_level = (1 - global_settings.get('alpha', 0.05)) * 100\n",
        "            self.view = RegressionResultsView(ci_level=ci_level)\n",
        "\n",
        "            self._initialization_error = None\n",
        "\n",
        "        except Exception as e:\n",
        "            # If initialization fails, create minimal view to show error\n",
        "            self.view = RegressionResultsView()\n",
        "            self.data_manager = None\n",
        "            self.engine = None\n",
        "            self._initialization_error = e\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UI SETUP\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def create_ui(self) -> widgets.VBox:\n",
        "        \"\"\"\n",
        "        Create the user interface with moderator selector and run button.\n",
        "\n",
        "        Returns:\n",
        "            VBox widget containing the UI\n",
        "        \"\"\"\n",
        "        # Get potential moderators\n",
        "        if self.data_manager:\n",
        "            moderators = self.data_manager.get_potential_moderators()\n",
        "            if not moderators:\n",
        "                moderators = ['No numeric moderators found']\n",
        "        else:\n",
        "            moderators = ['Data not loaded']\n",
        "\n",
        "        # Create widgets\n",
        "        self.moderator_widget = widgets.Dropdown(\n",
        "            options=moderators,\n",
        "            description='Moderator:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        self.run_button = widgets.Button(\n",
        "            description=\"\u25b6 Run Meta-Regression\",\n",
        "            button_style='success',\n",
        "            icon='play'\n",
        "        )\n",
        "\n",
        "        # Attach event handler\n",
        "        self.run_button.on_click(self._handle_run_click)\n",
        "\n",
        "        # Create UI layout\n",
        "        ui = widgets.VBox([\n",
        "            widgets.HTML(\"<h3>\ud83d\udcca Meta-Regression Analysis (V2)</h3>\"),\n",
        "            widgets.HTML(\"<p style='color: #6c757d;'>Select a moderator variable and run the analysis. Results will appear in organized tabs below.</p>\"),\n",
        "            self.moderator_widget,\n",
        "            self.run_button\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(self, moderator_col: str) -> None:\n",
        "        \"\"\"\n",
        "        Execute complete meta-regression workflow.\n",
        "\n",
        "        Args:\n",
        "            moderator_col: Name of moderator variable\n",
        "        \"\"\"\n",
        "        # Display tabs immediately\n",
        "        display(self.view.tabs)\n",
        "\n",
        "        # Check for initialization errors\n",
        "        if self._initialization_error:\n",
        "            self._handle_initialization_error()\n",
        "            return\n",
        "\n",
        "        # Validate moderator selection\n",
        "        if moderator_col in ['No numeric moderators found', 'Data not loaded', None, '']:\n",
        "            self.view.render_error(\"No valid moderator selected\")\n",
        "            return\n",
        "\n",
        "        # Run analysis with progress callback\n",
        "        def progress_callback(message: str):\n",
        "            \"\"\"Callback for progress updates (currently just prints)\"\"\"\n",
        "            # Could be enhanced to update a progress widget\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            # Execute regression engine\n",
        "            result_tuple = self.engine.run_meta_regression(\n",
        "                moderator_col=moderator_col,\n",
        "                progress_callback=progress_callback\n",
        "            )\n",
        "\n",
        "            if result_tuple is None:\n",
        "                self.view.render_error(\n",
        "                    \"Analysis failed\",\n",
        "                    \"Optimization did not converge. Try a different moderator or check your data.\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            result, reg_df_for_plot = result_tuple\n",
        "\n",
        "            # Render all tabs\n",
        "            self._render_all_tabs(result, moderator_col, reg_df_for_plot)\n",
        "\n",
        "            # Save results\n",
        "            self._save_results(result, reg_df_for_plot)\n",
        "\n",
        "        except ValueError as e:\n",
        "            self.view.render_error(\"Data Error\", str(e))\n",
        "        except RuntimeError as e:\n",
        "            self.view.render_error(\"Runtime Error\", str(e))\n",
        "        except Exception as e:\n",
        "            self._handle_unexpected_error(e)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB RENDERING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _render_all_tabs(\n",
        "        self,\n",
        "        result: 'RegressionResult',\n",
        "        moderator_col: str,\n",
        "        reg_df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Render all tabs with results.\n",
        "\n",
        "        Args:\n",
        "            result: RegressionResult object\n",
        "            moderator_col: Moderator column name\n",
        "            reg_df: DataFrame used for regression\n",
        "        \"\"\"\n",
        "        # Tab 1: Results\n",
        "        self.view.render_results_tab(result, moderator_col)\n",
        "\n",
        "        # Tab 2: Diagnostics\n",
        "        self.view.render_diagnostics_tab(result)\n",
        "\n",
        "        # Tab 3: Model Details\n",
        "        self.view.render_details_tab(\n",
        "            result=result,\n",
        "            moderator_col=moderator_col,\n",
        "            reg_df=reg_df,\n",
        "            effect_col=self.data_manager.effect_col,\n",
        "            var_col=self.data_manager.var_col\n",
        "        )\n",
        "\n",
        "        # Tab 4: Publication Text\n",
        "        combined_text = self.view.render_publication_tab(\n",
        "            result=result,\n",
        "            moderator_col=moderator_col,\n",
        "            es_config=self.data_manager.es_config\n",
        "        )\n",
        "\n",
        "        # Save publication text\n",
        "        self.data_manager.save_publication_text(combined_text)\n",
        "\n",
        "        # Tab 5: Export\n",
        "        self.view.render_export_tab(export_callback=self._handle_export)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA PERSISTENCE\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _save_results(\n",
        "        self,\n",
        "        result: 'RegressionResult',\n",
        "        reg_df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Save results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: RegressionResult object\n",
        "            reg_df: DataFrame used for regression\n",
        "        \"\"\"\n",
        "        self.data_manager.save_regression_results(result, reg_df)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # EVENT HANDLERS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_run_click(self, button) -> None:\n",
        "        \"\"\"Handle run button click event\"\"\"\n",
        "        moderator_col = self.moderator_widget.value\n",
        "        self.run_analysis(moderator_col)\n",
        "\n",
        "    def _handle_export(self, button) -> None:\n",
        "        \"\"\"Handle export button click\"\"\"\n",
        "        try:\n",
        "            # Call the external export function if it exists\n",
        "            if 'export_analysis_report' in globals():\n",
        "                export_analysis_report(\n",
        "                    report_type='regression',\n",
        "                    filename_prefix='Meta_Regression_Audit'\n",
        "                )\n",
        "            else:\n",
        "                with self.view.tab_export:\n",
        "                    print(\"\u26a0\ufe0f Export function not found. Please run the export cell first.\")\n",
        "        except Exception as e:\n",
        "            with self.view.tab_export:\n",
        "                print(f\"\u274c Export failed: {str(e)}\")\n",
        "                traceback.print_exc()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_initialization_error(self) -> None:\n",
        "        \"\"\"Handle errors during controller initialization\"\"\"\n",
        "        error = self._initialization_error\n",
        "        if error is None:\n",
        "            return\n",
        "\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "    def _handle_unexpected_error(self, error: Exception) -> None:\n",
        "        \"\"\"Handle unexpected errors during analysis\"\"\"\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION ENTRY POINT\n",
        "# =============================================================================\n",
        "\n",
        "def run_meta_regression_analysis():\n",
        "    \"\"\"\n",
        "    Main entry point for meta-regression analysis.\n",
        "    Call this function to display the UI and enable analysis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check for ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            print(\"\u274c ERROR: ANALYSIS_CONFIG not found\")\n",
        "            print(\"Please run previous analysis cells first:\")\n",
        "            print(\"  - Step 1: Data Loading\")\n",
        "            print(\"  - Step 2: Overall Meta-Analysis (for R\u00b2 calculation)\")\n",
        "            return\n",
        "\n",
        "        # Create controller\n",
        "        controller = RegressionController(ANALYSIS_CONFIG)\n",
        "\n",
        "        # Display UI\n",
        "        ui = controller.create_ui()\n",
        "        display(ui)\n",
        "\n",
        "        # Store controller globally for access (optional)\n",
        "        globals()['_regression_controller'] = controller\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Fatal Error: {type(e).__name__}\")\n",
        "        print(f\"Message: {str(e)}\")\n",
        "        print(\"\\nFull traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STANDALONE TESTING UTILITIES (Optional)\n",
        "# =============================================================================\n",
        "\n",
        "class MockRegressionConfig:\n",
        "    \"\"\"\n",
        "    Mock ANALYSIS_CONFIG for testing without running full pipeline.\n",
        "    Only for development/testing purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_sample_config():\n",
        "        \"\"\"Create a minimal valid config for testing\"\"\"\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "\n",
        "        # Sample data with moderator\n",
        "        np.random.seed(42)\n",
        "        sample_data = pd.DataFrame({\n",
        "            'id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "            'hedges_g': np.random.randn(10) * 0.5 + 0.3,\n",
        "            'Vg': np.random.uniform(0.01, 0.1, 10),\n",
        "            'year': [2010, 2010, 2012, 2012, 2015, 2015, 2018, 2018, 2020, 2020],\n",
        "            'sample_size': np.random.randint(50, 200, 10)\n",
        "        })\n",
        "\n",
        "        # Add linear relationship for testing\n",
        "        sample_data['hedges_g'] = sample_data['hedges_g'] + 0.01 * sample_data['year']\n",
        "\n",
        "        return {\n",
        "            'analysis_data': sample_data,\n",
        "            'effect_col': 'hedges_g',\n",
        "            'var_col': 'Vg',\n",
        "            'es_config': {'has_fold_change': False},\n",
        "            'overall_results': {\n",
        "                'tau_squared': 0.15,\n",
        "                'mu': 0.3\n",
        "            },\n",
        "            'global_settings': {\n",
        "                'alpha': 0.05,\n",
        "                'dist_type': 't'\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BACKWARD COMPATIBILITY WRAPPER\n",
        "# =============================================================================\n",
        "\n",
        "def create_legacy_widgets():\n",
        "    \"\"\"\n",
        "    Create widgets in the original style for backward compatibility.\n",
        "    This allows the new MVC code to work with existing notebook structure.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (moderator_widget, run_button)\n",
        "    \"\"\"\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        print(\"\u26a0\ufe0f Warning: ANALYSIS_CONFIG not found\")\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        controller = RegressionController(ANALYSIS_CONFIG)\n",
        "        ui = controller.create_ui()\n",
        "\n",
        "        # Store controller globally\n",
        "        globals()['_regression_controller'] = controller\n",
        "\n",
        "        return controller.moderator_widget, controller.run_button\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Error creating widgets: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST & INFORMATION\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Meta-Regression Controller Layer Loaded Successfully\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - RegressionController\")\n",
        "    print(\"   - MockRegressionConfig (for testing)\")\n",
        "    print()\n",
        "    print(\"\ud83d\ude80 Main Entry Point:\")\n",
        "    print(\"   run_meta_regression_analysis()\")\n",
        "    print()\n",
        "    print(\"\ud83d\udca1 Usage:\")\n",
        "    print(\"   Just call: run_meta_regression_analysis()\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "run_meta_regression_analysis()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lbyNDxZiUjEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcc8 13. Meta-Regression Plot\n",
        "\n",
        "# =============================================================================\n",
        "# CELL 11 (REPLACEMENT): META-REGRESSION PLOT\n",
        "# Purpose: Visualize the meta-regression results from Cell 10\n",
        "# Method: Creates a bubble plot with cluster-robust confidence bands\n",
        "# Dependencies: Cell 10 (meta_regression_RVE_results)\n",
        "# Outputs: Publication-ready plot (PDF/PNG)\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import t\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import sys\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# --- 1. WIDGET DEFINITIONS ---\n",
        "# Initialize lists\n",
        "available_color_moderators = ['None']\n",
        "analysis_data_init = None\n",
        "default_x_label = \"Moderator\"\n",
        "default_y_label = \"Effect Size\"\n",
        "default_title = \"Meta-Regression Plot\"\n",
        "label_widgets_dict = {} # Dictionary to store label widgets\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        raise NameError(\"ANALYSIS_CONFIG not found\")\n",
        "\n",
        "    if 'analysis_data' in globals():\n",
        "        analysis_data_init = analysis_data.copy()\n",
        "    elif 'data_filtered' in globals():\n",
        "        analysis_data_init = data_filtered.copy()\n",
        "    else:\n",
        "        raise ValueError(\"No data found\")\n",
        "\n",
        "    if 'meta_regression_RVE_results' in ANALYSIS_CONFIG:\n",
        "        reg_results = ANALYSIS_CONFIG['meta_regression_RVE_results']\n",
        "        es_config = ANALYSIS_CONFIG['es_config']\n",
        "        default_x_label = reg_results['moderator_col_name']\n",
        "        default_y_label = es_config['effect_label']\n",
        "        default_title = f\"Meta-Regression: {default_y_label} vs. {default_x_label}\"\n",
        "\n",
        "    # Find categorical moderators for color AND labels\n",
        "    excluded_cols = [\n",
        "        ANALYSIS_CONFIG.get('effect_col'), ANALYSIS_CONFIG.get('var_col'),\n",
        "        ANALYSIS_CONFIG.get('se_col'), 'w_fixed', 'w_random', 'id',\n",
        "        'xe', 'sde', 'ne', 'xc', 'sdc', 'nc',\n",
        "        ANALYSIS_CONFIG.get('ci_lower_col'), ANALYSIS_CONFIG.get('ci_upper_col')\n",
        "    ]\n",
        "    excluded_cols = [col for col in excluded_cols if col is not None]\n",
        "\n",
        "    categorical_cols = analysis_data_init.select_dtypes(include=['object', 'category']).columns\n",
        "    available_color_moderators.extend([\n",
        "        col for col in categorical_cols\n",
        "        if col not in excluded_cols and analysis_data_init[col].nunique() <= 10\n",
        "    ])\n",
        "\n",
        "    # *** NEW: Find all unique labels for the Label Editor ***\n",
        "    all_categorical_labels = set()\n",
        "    for col in available_color_moderators:\n",
        "        if col != 'None' and col in analysis_data_init.columns:\n",
        "            # Add the column name itself (e.g., \"Crop\")\n",
        "            all_categorical_labels.add(col)\n",
        "            # Add all unique values in that column (e.g., \"B\", \"C\", \"R\", \"W\")\n",
        "            all_categorical_labels.update(analysis_data_init[col].astype(str).str.strip().unique())\n",
        "\n",
        "    # Remove any empty strings\n",
        "    all_categorical_labels.discard('')\n",
        "    all_categorical_labels.discard('nan')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u26a0\ufe0f  Initialization Error: {e}. Please run previous cells.\")\n",
        "\n",
        "\n",
        "# --- Widget Interface ---\n",
        "header = widgets.HTML(\n",
        "    \"<h3 style='color: #2E86AB;'>Meta-Regression Plot Setup</h3>\"\n",
        "    \"<p style='color: #666;'><i>Visualize the relationship between moderator and effect size</i></p>\"\n",
        ")\n",
        "\n",
        "# ========== TAB 1: PLOT STYLE ==========\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Plot Title:',\n",
        "                            layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "xlabel_widget = widgets.Text(value=default_x_label, description='X-Axis Label:',\n",
        "                             layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "ylabel_widget = widgets.Text(value=default_y_label, description='Y-Axis Label:',\n",
        "                             layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "width_widget = widgets.FloatSlider(value=8.0, min=5.0, max=14.0, step=0.5, description='Plot Width (in):',\n",
        "                                   continuous_update=False, style={'description_width': '120px'},\n",
        "                                   layout=widgets.Layout(width='450px'))\n",
        "height_widget = widgets.FloatSlider(value=6.0, min=4.0, max=12.0, step=0.5, description='Plot Height (in):',\n",
        "                                    continuous_update=False, style={'description_width': '120px'},\n",
        "                                    layout=widgets.Layout(width='450px'))\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Size</h4>\"),\n",
        "    show_title_widget, title_widget, xlabel_widget, ylabel_widget, width_widget, height_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 2: DATA POINTS ==========\n",
        "color_mod_widget = widgets.Dropdown(options=available_color_moderators, value='None', description='Color By:',\n",
        "                                    style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "point_color_widget = widgets.Dropdown(options=['gray', 'blue', 'red', 'green', 'purple', 'orange'], value='gray',\n",
        "                                      description='Point Color:', style={'description_width': '120px'},\n",
        "                                      layout=widgets.Layout(width='450px'))\n",
        "bubble_base_widget = widgets.IntSlider(value=20, min=0, max=200, step=10, description='Min Bubble Size:',\n",
        "                                       continuous_update=False, style={'description_width': '120px'},\n",
        "                                       layout=widgets.Layout(width='450px'))\n",
        "bubble_range_widget = widgets.IntSlider(value=800, min=100, max=2000, step=100, description='Max Bubble Size:',\n",
        "                                        continuous_update=False, style={'description_width': '120px'},\n",
        "                                        layout=widgets.Layout(width='450px'))\n",
        "bubble_alpha_widget = widgets.FloatSlider(value=0.6, min=0.1, max=1.0, step=0.1, description='Transparency:',\n",
        "                                          continuous_update=False, style={'description_width': '120px'},\n",
        "                                          layout=widgets.Layout(width='450px'))\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Points</h4>\"),\n",
        "    color_mod_widget, point_color_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Bubble Size (by precision):</b>\"),\n",
        "    bubble_base_widget, bubble_range_widget, bubble_alpha_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 3: REGRESSION LINE ==========\n",
        "show_ci_widget = widgets.Checkbox(value=True, description='Show 95% Confidence Band', indent=False)\n",
        "line_color_widget = widgets.Dropdown(options=['red', 'blue', 'black', 'green', 'purple'], value='red',\n",
        "                                     description='Line Color:', style={'description_width': '120px'},\n",
        "                                     layout=widgets.Layout(width='450px'))\n",
        "line_width_widget = widgets.FloatSlider(value=2.0, min=0.5, max=5.0, step=0.5, description='Line Width:',\n",
        "                                        continuous_update=False, style={'description_width': '120px'},\n",
        "                                        layout=widgets.Layout(width='450px'))\n",
        "ci_alpha_widget = widgets.FloatSlider(value=0.3, min=0.1, max=0.8, step=0.1, description='CI Transparency:',\n",
        "                                      continuous_update=False, style={'description_width': '120px'},\n",
        "                                      layout=widgets.Layout(width='450px'))\n",
        "show_equation_widget = widgets.Checkbox(value=True, description='Show Regression Equation & P-value', indent=False)\n",
        "show_r2_widget = widgets.Checkbox(value=True, description='Show R\u00b2 Value', indent=False)\n",
        "\n",
        "regline_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Regression Line</h4>\"),\n",
        "    line_color_widget, line_width_widget, show_ci_widget, ci_alpha_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    show_equation_widget, show_r2_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 4: LAYOUT & EXPORT ==========\n",
        "show_grid_widget = widgets.Checkbox(value=True, description='Show Grid', indent=False)\n",
        "show_null_line_widget = widgets.Checkbox(value=True, description='Show Null Effect Line (y=0)', indent=False)\n",
        "legend_loc_widget = widgets.Dropdown(options=['best', 'upper right', 'upper left', 'lower left', 'lower right'],\n",
        "                                     value='best', description='Legend Position:',\n",
        "                                     style={'description_width': '120px'}, layout=widgets.Layout(width='450px'))\n",
        "legend_fontsize_widget = widgets.IntSlider(value=10, min=6, max=14, step=1, description='Legend Font:',\n",
        "                                           continuous_update=False, style={'description_width': '120px'},\n",
        "                                           layout=widgets.Layout(width='450px'))\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "png_dpi_widget = widgets.IntSlider(value=300, min=150, max=600, step=50, description='PNG DPI:',\n",
        "                                   continuous_update=False, style={'description_width': '120px'},\n",
        "                                   layout=widgets.Layout(width='450px'))\n",
        "filename_prefix_widget = widgets.Text(value='MetaRegression_Plot', description='Filename Prefix:',\n",
        "                                      layout=widgets.Layout(width='450px'), style={'description_width': '120px'})\n",
        "transparent_bg_widget = widgets.Checkbox(value=False, description='Transparent Background', indent=False)\n",
        "\n",
        "layout_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Layout & Legend</h4>\"),\n",
        "    show_grid_widget, show_null_line_widget, legend_loc_widget, legend_fontsize_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Export</h4>\"),\n",
        "    save_pdf_widget, save_png_widget, png_dpi_widget, filename_prefix_widget, transparent_bg_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 5: LABELS (NEW) ==========\n",
        "label_editor_widgets = []\n",
        "for label in sorted(list(all_categorical_labels)):\n",
        "    text_widget = widgets.Text(\n",
        "        value=str(label),\n",
        "        description=f\"{label}:\",\n",
        "        layout=widgets.Layout(width='500px'),\n",
        "        style={'description_width': '200px'}\n",
        "    )\n",
        "    label_editor_widgets.append(text_widget)\n",
        "    label_widgets_dict[str(label)] = text_widget # Store widget by its original name\n",
        "\n",
        "label_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Edit Plot Labels</h4>\"),\n",
        "    widgets.HTML(\"<p style='color: #666;'><i>Rename raw data values (e.g., 'W') to publication-ready labels (e.g., 'Wheat').</i></p>\"),\n",
        "    *label_editor_widgets\n",
        "])\n",
        "\n",
        "\n",
        "# --- Assemble Tabs ---\n",
        "tab = widgets.Tab(children=[style_tab, points_tab, regline_tab, layout_tab, label_tab])\n",
        "tab.set_title(0, '\ud83c\udfa8 Style'); tab.set_title(1, '\u26ab Points'); tab.set_title(2, '\ud83d\udcc8 Regression')\n",
        "tab.set_title(3, '\ud83d\udcbe Layout/Export'); tab.set_title(4, '\u270f\ufe0f Labels')\n",
        "\n",
        "run_plot_button = widgets.Button(\n",
        "    description='\ud83d\udcca Generate Regression Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# --- 2. PLOTTING FUNCTION ---\n",
        "@run_plot_button.on_click\n",
        "def generate_regression_plot(b):\n",
        "    \"\"\"Generate meta-regression scatter plot with regression line\"\"\"\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(\"=\"*70)\n",
        "        print(\"GENERATING CLUSTER-ROBUST META-REGRESSION PLOT\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            # --- Get Global Settings ---\n",
        "            gs = ANALYSIS_CONFIG.get('global_settings', {})\n",
        "            alpha = gs.get('alpha', 0.05)\n",
        "            dist_type = gs.get('dist_type', 't')\n",
        "            ci_pct = (1 - alpha) * 100\n",
        "\n",
        "            # --- 1. Load Data & Config ---\n",
        "            print(\"STEP 1: LOADING RESULTS FROM CELL 10\")\n",
        "            print(\"---------------------------------\")\n",
        "            if 'meta_regression_RVE_results' not in ANALYSIS_CONFIG:\n",
        "                raise ValueError(\"No meta-regression results found. Please re-run Cell 10.\")\n",
        "\n",
        "            reg_results = ANALYSIS_CONFIG['meta_regression_RVE_results']\n",
        "            es_config = ANALYSIS_CONFIG['es_config']\n",
        "\n",
        "            plot_data = reg_results['reg_df'].copy()\n",
        "            moderator_col = reg_results['moderator_col_name']\n",
        "            effect_col = reg_results['effect_col']\n",
        "            var_col = ANALYSIS_CONFIG['var_col']\n",
        "\n",
        "            b0, b1 = reg_results['betas']\n",
        "            var_betas_robust = reg_results['var_betas_robust']\n",
        "            R_sq = reg_results['R_squared_adj']\n",
        "            p_slope = reg_results['p_slope']\n",
        "            df_robust = reg_results['df_robust']\n",
        "\n",
        "            print(f\"  \u2713 Loaded results for moderator: {moderator_col}\")\n",
        "            print(f\"  \u2713 Found {len(plot_data)} data points to plot.\")\n",
        "\n",
        "            # --- 2. Get Widget Values (*** FIX: ADDED .value TO ALL ***) ---\n",
        "            show_title = show_title_widget.value\n",
        "            graph_title = title_widget.value\n",
        "            x_label = xlabel_widget.value\n",
        "            y_label = ylabel_widget.value\n",
        "            plot_width = width_widget.value\n",
        "            plot_height = height_widget.value\n",
        "\n",
        "            color_mod_name = color_mod_widget.value\n",
        "            point_color = point_color_widget.value\n",
        "            bubble_base = bubble_base_widget.value\n",
        "            bubble_range = bubble_range_widget.value\n",
        "            bubble_alpha = bubble_alpha_widget.value\n",
        "\n",
        "            show_ci = show_ci_widget.value\n",
        "            line_color = line_color_widget.value\n",
        "            line_width = line_width_widget.value\n",
        "            ci_alpha = ci_alpha_widget.value\n",
        "            show_equation = show_equation_widget.value\n",
        "            show_r2 = show_r2_widget.value\n",
        "\n",
        "            show_grid = show_grid_widget.value\n",
        "            show_null_line = show_null_line_widget.value\n",
        "            legend_loc = legend_loc_widget.value\n",
        "            legend_fontsize = legend_fontsize_widget.value\n",
        "\n",
        "            save_pdf = save_pdf_widget.value\n",
        "            save_png = save_png_widget.value\n",
        "            png_dpi = png_dpi_widget.value\n",
        "            filename_prefix = filename_prefix_widget.value\n",
        "            transparent_bg = transparent_bg_widget.value\n",
        "            # *** END FIX ***\n",
        "\n",
        "            print(f\"\\n\ud83d\udcca Configuration:\")\n",
        "            print(f\"  Plot size: {plot_width}\\\\\\\" \u00d7 {plot_height}\\\\\\\"\")\n",
        "            print(f\"  Color by: {color_mod_name}\")\n",
        "\n",
        "            # --- 2b. Build Label Mapping ---\n",
        "            label_mapping = {orig: w.value for orig, w in label_widgets_dict.items()}\n",
        "\n",
        "            # --- 3. Prepare Data for Plotting ---\n",
        "            print(\"\\nSTEP 2: PREPARING PLOT DATA\")\n",
        "            print(\"---------------------------------\")\n",
        "\n",
        "            if 'weights' not in plot_data.columns:\n",
        "                tau_sq_overall = ANALYSIS_CONFIG['overall_results']['tau_squared']\n",
        "                plot_data['weights'] = 1 / (plot_data[var_col] + tau_sq_overall)\n",
        "\n",
        "            min_w = plot_data['weights'].min()\n",
        "            max_w = plot_data['weights'].max()\n",
        "\n",
        "            if max_w > min_w:\n",
        "                plot_data['BubbleSize'] = bubble_base + (\n",
        "                    ((plot_data['weights'] - min_w) / (max_w - min_w)) * bubble_range\n",
        "                )\n",
        "            else:\n",
        "                plot_data['BubbleSize'] = bubble_base + bubble_range / 2\n",
        "\n",
        "            print(f\"  \u2713 Bubble sizes calculated (Range: {plot_data['BubbleSize'].min():.0f} to {plot_data['BubbleSize'].max():.0f})\")\n",
        "\n",
        "            # --- Handle Color Coding (*** FIX: Corrected logic ***) ---\n",
        "            c_values = point_color\n",
        "            cmap = None\n",
        "            norm = None\n",
        "            unique_cats = []\n",
        "\n",
        "            if color_mod_name != 'None':\n",
        "                if color_mod_name in analysis_data_init.columns:\n",
        "                    # Merge color data from the original dataframe based on index\n",
        "                    color_data = analysis_data_init[[color_mod_name]].copy()\n",
        "                    plot_data = plot_data.merge(color_data, left_index=True, right_index=True, how='left',\n",
        "                                                suffixes=('', '_color'))\n",
        "\n",
        "                    # Use the merged column\n",
        "                    color_col_merged = f\"{color_mod_name}\"\n",
        "                    plot_data[color_col_merged] = plot_data[color_col_merged].fillna('N/A').astype(str).str.strip()\n",
        "                    plot_data['color_codes'], unique_cats = pd.factorize(plot_data[color_col_merged])\n",
        "                    c_values = plot_data['color_codes']\n",
        "                    cmap = 'tab10' # A good categorical colormap\n",
        "                    norm = plt.Normalize(vmin=0, vmax=len(unique_cats)-1)\n",
        "                    print(f\"  \u2713 Applying color based on '{color_mod_name}' ({len(unique_cats)} categories)\")\n",
        "                else:\n",
        "                    print(f\"  \u26a0\ufe0f  Color moderator '{color_mod_name}' not found, using default.\")\n",
        "                    color_mod_name = 'None'\n",
        "            # *** END COLOR FIX ***\n",
        "\n",
        "            # --- 4. Create Figure ---\n",
        "            print(\"\\nSTEP 3: GENERATING PLOT\")\n",
        "            print(\"---------------------------------\")\n",
        "            fig, ax = plt.subplots(figsize=(plot_width, plot_height))\n",
        "            if transparent_bg:\n",
        "                fig.patch.set_alpha(0)\n",
        "                ax.patch.set_alpha(0)\n",
        "\n",
        "            # --- Plot Data Points ---\n",
        "            ax.scatter(\n",
        "                x=plot_data[moderator_col],\n",
        "                y=plot_data[effect_col],\n",
        "                s=plot_data['BubbleSize'],\n",
        "                c=c_values,\n",
        "                cmap=cmap,\n",
        "                norm=norm,\n",
        "                alpha=bubble_alpha,\n",
        "                edgecolors='black',\n",
        "                linewidths=0.5,\n",
        "                zorder=3\n",
        "            )\n",
        "\n",
        "            # --- Plot Regression Line & Confidence Band ---\n",
        "            x_min = plot_data[moderator_col].min()\n",
        "            x_max = plot_data[moderator_col].max()\n",
        "            x_range_val = x_max - x_min\n",
        "            x_padding = x_range_val * 0.05 if x_range_val > 0 else 1\n",
        "\n",
        "            x_line = np.linspace(x_min - x_padding, x_max + x_padding, 100)\n",
        "            y_line = b0 + b1 * x_line\n",
        "\n",
        "            ax.plot(x_line, y_line, color=line_color, linewidth=line_width, zorder=2, label=\"Regression Line\")\n",
        "\n",
        "            if show_ci:\n",
        "                X_line_pred = sm.add_constant(x_line, prepend=True)\n",
        "                se_line = np.array([\n",
        "                    np.sqrt(np.array([1, x]) @ var_betas_robust @ np.array([1, x]).T)\n",
        "                    for x in x_line\n",
        "                ])\n",
        "                # --- Dynamic Critical Value ---\n",
        "                q_val = 1 - (alpha / 2)\n",
        "                if dist_type == 't':\n",
        "                    crit_val = t.ppf(q_val, df=df_robust)\n",
        "                else:\n",
        "                    crit_val = norm.ppf(q_val)\n",
        "                # ---------------------------------------\n",
        "\n",
        "                y_ci_upper = y_line + crit_val * se_line\n",
        "                y_ci_lower = y_line - crit_val * se_line\n",
        "                ax.fill_between(x_line, y_ci_lower, y_ci_upper,\n",
        "                                color=line_color, alpha=ci_alpha, zorder=1, label=f\"95% CI (Robust, df={df_robust})\")\n",
        "                print(\"  \u2713 Plotted regression line and robust confidence band.\")\n",
        "\n",
        "            # --- Customize Axes ---\n",
        "            if show_null_line:\n",
        "                ax.axhline(es_config.get('null_value', 0), color='gray', linestyle='--', linewidth=1.0, zorder=0)\n",
        "\n",
        "            ax.set_xlabel(x_label, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(y_label, fontsize=12, fontweight='bold')\n",
        "            if show_title:\n",
        "                ax.set_title(graph_title, fontsize=14, fontweight='bold', pad=15)\n",
        "            if show_grid:\n",
        "                ax.grid(True, linestyle=':', alpha=0.4, zorder=0)\n",
        "\n",
        "            # --- Add Equation and R\u00b2 ---\n",
        "            if show_equation or show_r2:\n",
        "                text_lines = []\n",
        "                if show_equation:\n",
        "                    sign = \"+\" if b1 >= 0 else \"\"\n",
        "                    sig_marker = \"***\" if p_slope < 0.001 else \"**\" if p_slope < 0.01 else \"*\" if p_slope < 0.05 else \"ns\"\n",
        "                    eq_text = f\"y = {b0:.3f} {sign} {b1:.3f}x\"\n",
        "                    p_text = f\"p (slope) = {p_slope:.3g} {sig_marker}\"\n",
        "                    text_lines.append(eq_text)\n",
        "                    text_lines.append(p_text)\n",
        "                if show_r2:\n",
        "                    r2_text = f\"R\u00b2 (adj) \u2248 {R_sq:.1f}%\"\n",
        "                    text_lines.append(r2_text)\n",
        "\n",
        "                ax.text(\n",
        "                    0.05, 0.95, \"\\n\".join(text_lines),\n",
        "                    transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='gray'),\n",
        "                    zorder=10\n",
        "                )\n",
        "\n",
        "            # --- Create Legend ---\n",
        "            handles, labels = ax.get_legend_handles_labels()\n",
        "\n",
        "            # *** FIX: Use Label Mapping ***\n",
        "            if color_mod_name != 'None':\n",
        "                for i, cat in enumerate(unique_cats):\n",
        "                    display_label = label_mapping.get(cat, cat) # Get new label\n",
        "                    color_val = plt.get_cmap(cmap)(norm(i))\n",
        "                    handles.append(mpatches.Patch(color=color_val, label=display_label, alpha=bubble_alpha, ec='black', lw=0.5))\n",
        "                    labels.append(display_label)\n",
        "\n",
        "            handles.append(plt.scatter([], [], s=bubble_base + bubble_range/2, c='gray' if color_mod_name == 'None' else 'lightgray',\n",
        "                                       alpha=bubble_alpha, ec='black', lw=0.5))\n",
        "            labels.append(\"Weight (1 / (v\u1d62 + \u03c4\u00b2))\")\n",
        "\n",
        "            display_legend_title = label_mapping.get(color_mod_name, color_mod_name)\n",
        "\n",
        "            ax.legend(handles=handles, labels=labels, loc=legend_loc,\n",
        "                      fontsize=legend_fontsize, framealpha=0.9,\n",
        "                      title=display_legend_title if color_mod_name != 'None' else None)\n",
        "            # *** END FIX ***\n",
        "\n",
        "            fig.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # --- 5. Save Files ---\n",
        "            print(f\"\\nSTEP 4: SAVING FILES\")\n",
        "            print(\"---------------------------------\")\n",
        "\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            base_filename = f\"{filename_prefix}_{moderator_col.replace(' ','_')}_{timestamp}\"\n",
        "\n",
        "            saved_files = []\n",
        "            if save_pdf:\n",
        "                pdf_filename = f\"{base_filename}.pdf\"\n",
        "                fig.savefig(pdf_filename, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(pdf_filename)\n",
        "                print(f\"  \u2713 {pdf_filename}\")\n",
        "            if save_png:\n",
        "                png_filename = f\"{base_filename}.png\"\n",
        "                fig.savefig(png_filename, dpi=png_dpi, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(png_filename)\n",
        "                print(f\"  \u2713 {png_filename} (DPI: {png_dpi})\")\n",
        "\n",
        "            print(f\"\\n\" + \"=\"*70)\n",
        "            print(\"\u2705 PLOT GENERATION COMPLETE\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n\u274c AN ERROR OCCURRED:\\n\")\n",
        "            print(f\"  Type: {type(e).__name__}\")\n",
        "            print(f\"  Message: {e}\")\n",
        "            print(\"\\n  Traceback:\")\n",
        "            traceback.print_exc(file=sys.stdout)\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(\"ANALYSIS FAILED. See error message above.\")\n",
        "            print(\"Please check your data and configuration.\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "\n",
        "# --- 6. DISPLAY WIDGETS ---\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals() or 'meta_regression_RVE_results' not in ANALYSIS_CONFIG:\n",
        "        print(\"=\"*70)\n",
        "        print(\"\u26a0\ufe0f  PREREQUISITE NOT MET\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"Please run Cell 10 (Meta-Regression) successfully before running this cell.\")\n",
        "    else:\n",
        "        print(\"=\"*70)\n",
        "        print(\"\u2705 ROBUST META-REGRESSION PLOTTER READY\")\n",
        "        print(\"=\"*70)\n",
        "        print(\"  \u2713 Results from Cell 10 are loaded.\")\n",
        "        print(\"  \u2713 Customize your plot using the tabs below and click 'Generate'.\")\n",
        "\n",
        "        # Hook up widget events\n",
        "        def on_color_mod_change(change):\n",
        "            point_color_widget.layout.display = 'none' if change['new'] != 'None' else 'flex'\n",
        "        color_mod_widget.observe(on_color_mod_change, names='value')\n",
        "\n",
        "        display(widgets.VBox([\n",
        "            header,\n",
        "            widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "            widgets.HTML(\"<b>Plot Options:</b>\"),\n",
        "            tab,\n",
        "            widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "            run_plot_button,\n",
        "            plot_output\n",
        "        ]))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u274c An error occurred during initialization: {e}\")\n",
        "    print(\"Please ensure the notebook has been run in order.\")"
      ],
      "metadata": {
        "id": "3QSIWqR7P5an",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83c\udf0a 14. Meta-Regression: Non-Linear Spline Models REFACTORED\n",
        "# =============================================================================\n",
        "# CELL: SPLINE ANALYSIS WITH DASHBOARD (MVC REFACTORED)\n",
        "# Purpose: Non-linear meta-regression using natural cubic splines.\n",
        "# Architecture: Model-View-Controller pattern for maintainability.\n",
        "# Note: Drop-in replacement - preserves all original math and logic.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import t, chi2, norm\n",
        "from scipy.optimize import minimize_scalar\n",
        "import statsmodels.api as sm\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import warnings\n",
        "\n",
        "# Check for patsy\n",
        "try:\n",
        "    import patsy\n",
        "    PATSY_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PATSY_AVAILABLE = False\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 1: MODEL (Logic, Math, Data Access)\n",
        "# =============================================================================\n",
        "\n",
        "class SplineMetaRegressionModel:\n",
        "    \"\"\"\n",
        "    Handles all data processing, statistical calculations, and business logic\n",
        "    for spline meta-regression analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = None\n",
        "        self.linear_results = None\n",
        "        self.error = None\n",
        "        self.data = None\n",
        "        self.config = None\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Data Access Methods\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def get_analysis_data(self):\n",
        "        \"\"\"Retrieve analysis data from global context.\"\"\"\n",
        "        if 'analysis_data' in globals():\n",
        "            return globals()['analysis_data']\n",
        "        elif 'data_filtered' in globals():\n",
        "            return globals()['data_filtered']\n",
        "        return None\n",
        "\n",
        "    def get_analysis_config(self):\n",
        "        \"\"\"Retrieve analysis configuration from global context.\"\"\"\n",
        "        if 'ANALYSIS_CONFIG' in globals():\n",
        "            return globals()['ANALYSIS_CONFIG']\n",
        "        return {}\n",
        "\n",
        "    def set_analysis_config(self, key, value):\n",
        "        \"\"\"Set a value in the global ANALYSIS_CONFIG.\"\"\"\n",
        "        global ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            ANALYSIS_CONFIG = {}\n",
        "        ANALYSIS_CONFIG[key] = value\n",
        "\n",
        "    def get_numeric_moderators(self, df):\n",
        "        \"\"\"Get list of valid numeric moderator columns.\"\"\"\n",
        "        if df is None:\n",
        "            return []\n",
        "\n",
        "        valid_mods = []\n",
        "        technical_cols = [\n",
        "            'id', 'xe', 'xc', 'ne', 'nc', 'sde', 'sdc', 'w_fixed', 'w_random',\n",
        "            'df', 'sp', 'sp_squared', 'hedges_j', 'weights', 'wi'\n",
        "        ]\n",
        "\n",
        "        config = self.get_analysis_config()\n",
        "        if config:\n",
        "            technical_cols.extend([\n",
        "                config.get('effect_col'),\n",
        "                config.get('var_col'),\n",
        "                config.get('se_col')\n",
        "            ])\n",
        "\n",
        "        for col in df.columns:\n",
        "            if col in technical_cols or col is None:\n",
        "                continue\n",
        "            if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                valid_mods.append(col)\n",
        "            elif df[col].dtype == 'object':\n",
        "                try:\n",
        "                    if pd.to_numeric(df[col], errors='coerce').notna().sum() >= 3:\n",
        "                        valid_mods.append(col)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        return sorted(list(set(valid_mods)))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Core Statistical Methods (Preserved from Original)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def estimate_linear_tau2(self, agg_df, moderator_col, effect_col, var_col):\n",
        "        \"\"\"\n",
        "        Estimate tau\u00b2 from linear model for plug-in approach.\n",
        "        Preserves exact original math.\n",
        "        \"\"\"\n",
        "        X_lin = sm.add_constant(agg_df[moderator_col])\n",
        "        y_agg = agg_df[effect_col].values\n",
        "        v_agg = agg_df[var_col].values\n",
        "\n",
        "        def lin_nll(t2):\n",
        "            if t2 < 0:\n",
        "                t2 = 0\n",
        "            w = 1 / (v_agg + t2)\n",
        "            try:\n",
        "                res = sm.WLS(y_agg, X_lin, weights=w).fit()\n",
        "                ll = -0.5 * (\n",
        "                    np.sum(np.log(v_agg + t2)) +\n",
        "                    np.log(np.linalg.det(X_lin.T @ np.diag(w) @ X_lin)) +\n",
        "                    np.sum(res.resid**2 * w)\n",
        "                )\n",
        "                return -ll\n",
        "            except:\n",
        "                return np.inf\n",
        "\n",
        "        opt_lin = minimize_scalar(lin_nll, bounds=(0, 100), method='bounded')\n",
        "\n",
        "        # Fit linear model for comparison\n",
        "        w_opt = 1 / (v_agg + opt_lin.x)\n",
        "        lin_model = sm.WLS(y_agg, X_lin, weights=w_opt).fit()\n",
        "        lin_ll = -lin_nll(opt_lin.x)\n",
        "\n",
        "        return opt_lin.x, lin_ll, lin_model\n",
        "\n",
        "    def run_aggregated_spline_re(self, agg_df, moderator_col, effect_col, var_col,\n",
        "                                  df_spline, mod_mean, mod_std, fixed_tau2):\n",
        "        \"\"\"\n",
        "        Runs a Random-Effects Spline Model using a FIXED Tau^2.\n",
        "        Prevents optimizer crashes on flat likelihood surfaces.\n",
        "        Preserves exact original math.\n",
        "        \"\"\"\n",
        "        agg_df = agg_df.reset_index(drop=True)\n",
        "        mod_z = (agg_df[moderator_col] - mod_mean) / mod_std\n",
        "        formula = f\"cr(x, df={df_spline}) - 1\"\n",
        "\n",
        "        try:\n",
        "            basis_matrix = patsy.dmatrix(formula, {\"x\": mod_z}, return_type='dataframe')\n",
        "        except Exception as e:\n",
        "            return None, f\"Basis Error: {e}\"\n",
        "\n",
        "        y = agg_df[effect_col].values\n",
        "        v = agg_df[var_col].values\n",
        "        basis_matrix.index = agg_df.index\n",
        "        X = sm.add_constant(basis_matrix)\n",
        "        weights = 1.0 / (v + fixed_tau2 + 1e-8)\n",
        "\n",
        "        try:\n",
        "            final_model = sm.WLS(y, X, weights=weights).fit()\n",
        "            resid = y - final_model.fittedvalues\n",
        "\n",
        "            XTWX = X.T @ np.diag(weights) @ X\n",
        "            sign, logdet = np.linalg.slogdet(XTWX)\n",
        "            if sign <= 0:\n",
        "                logdet = 0\n",
        "\n",
        "            ll = -0.5 * (\n",
        "                np.sum(np.log(v + fixed_tau2 + 1e-8)) +\n",
        "                logdet +\n",
        "                np.sum((resid**2) * weights)\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'betas': final_model.params.values,\n",
        "                'var_betas': final_model.cov_params().values,\n",
        "                'tau_sq': fixed_tau2,\n",
        "                'sigma_sq': 0.0,\n",
        "                'log_lik_reml': ll,\n",
        "                'mod_mean': mod_mean,\n",
        "                'mod_std': mod_std,\n",
        "                'formula': formula,\n",
        "                'model_type': 'Spline Model (Plug-in Tau\u00b2)',\n",
        "                'X_design': X,\n",
        "                'fitted': final_model.fittedvalues,\n",
        "                'resid': resid,\n",
        "                'model': final_model\n",
        "            }, None\n",
        "        except Exception as e:\n",
        "            return None, f\"Final Fit Error: {e}\"\n",
        "\n",
        "    def run_analysis(self, moderator_col, df_spline):\n",
        "        \"\"\"\n",
        "        Main analysis orchestrator. Runs the complete spline analysis.\n",
        "        \"\"\"\n",
        "        self.error = None\n",
        "        self.results = None\n",
        "\n",
        "        # Check patsy availability\n",
        "        if not PATSY_AVAILABLE:\n",
        "            self.error = \"\u274c Error: 'patsy' package not installed. Install with: pip install patsy\"\n",
        "            return False\n",
        "\n",
        "        # Get data\n",
        "        df_working = self.get_analysis_data()\n",
        "        if df_working is None:\n",
        "            self.error = \"\u274c Error: Data not found. Run Step 1 first.\"\n",
        "            return False\n",
        "\n",
        "        # Get config\n",
        "        config = self.get_analysis_config()\n",
        "        if not config:\n",
        "            self.error = \"\u274c Error: Config not found. Run Step 1 first.\"\n",
        "            return False\n",
        "\n",
        "        eff_col = config.get('effect_col', 'hedges_g')\n",
        "        var_col = config.get('var_col', 'Vg')\n",
        "\n",
        "        # Prepare data\n",
        "        df = df_working.copy()\n",
        "        df[moderator_col] = pd.to_numeric(df[moderator_col], errors='coerce')\n",
        "        df = df.dropna(subset=[moderator_col, eff_col, var_col])\n",
        "        df = df[df[var_col] > 0]\n",
        "\n",
        "        if len(df) < 3:\n",
        "            self.error = f\"\u274c Error: Insufficient data (n={len(df)}). Need at least 3 observations.\"\n",
        "            return False\n",
        "\n",
        "        self.data = df\n",
        "\n",
        "        # Run robust spline analysis (calls external function)\n",
        "        # Must use globals() to find functions defined in other cells\n",
        "        if '_run_robust_spline_analysis' in globals():\n",
        "            est, err = globals()['_run_robust_spline_analysis'](\n",
        "                df, moderator_col, eff_col, var_col, df_spline=df_spline\n",
        "            )\n",
        "        else:\n",
        "            # Fallback: run internal implementation\n",
        "            est, err = self._run_internal_spline_analysis(\n",
        "                df, moderator_col, eff_col, var_col, df_spline\n",
        "            )\n",
        "\n",
        "        if err:\n",
        "            self.error = f\"\u274c {err}\"\n",
        "            return False\n",
        "\n",
        "        self.results = est\n",
        "        self.results['moderator_col'] = moderator_col\n",
        "        self.results['df_spline'] = df_spline\n",
        "\n",
        "        # Get linear model stats for comparison\n",
        "        # Must use globals() to find functions defined in other cells\n",
        "        if '_run_three_level_reml_regression_v2' in globals():\n",
        "            lin_est, _, _ = globals()['_run_three_level_reml_regression_v2'](\n",
        "                df, moderator_col, eff_col, var_col\n",
        "            )\n",
        "        else:\n",
        "            lin_est = self._run_internal_linear_analysis(\n",
        "                df, moderator_col, eff_col, var_col\n",
        "            )\n",
        "\n",
        "        if lin_est:\n",
        "            self.linear_results = {\n",
        "                'log_lik_reml': lin_est['log_lik_reml'],\n",
        "                'aic': 2 * 2 - 2 * lin_est['log_lik_reml']\n",
        "            }\n",
        "        else:\n",
        "            self.linear_results = {'log_lik_reml': np.nan, 'aic': np.nan}\n",
        "\n",
        "        # Calculate spline AIC\n",
        "        n_params = len(self.results['betas'])\n",
        "        self.results['aic'] = 2 * n_params - 2 * self.results['log_lik_reml']\n",
        "        self.results['ll_linear'] = self.linear_results['log_lik_reml']\n",
        "\n",
        "        # Save to global config\n",
        "        self.set_analysis_config('spline_model_results', self.results)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _run_internal_spline_analysis(self, df, mod_col, eff_col, var_col, df_spline):\n",
        "        \"\"\"\n",
        "        Internal spline analysis when external function not available.\n",
        "        \"\"\"\n",
        "        # First estimate tau\u00b2 from linear model\n",
        "        fixed_tau2, _, _ = self.estimate_linear_tau2(df, mod_col, eff_col, var_col)\n",
        "\n",
        "        mod_mean = df[mod_col].mean()\n",
        "        mod_std = df[mod_col].std()\n",
        "        if mod_std == 0:\n",
        "            mod_std = 1.0\n",
        "\n",
        "        # Run spline model\n",
        "        est, err = self.run_aggregated_spline_re(\n",
        "            df, mod_col, eff_col, var_col,\n",
        "            df_spline, mod_mean, mod_std, fixed_tau2\n",
        "        )\n",
        "\n",
        "        if err:\n",
        "            return None, err\n",
        "\n",
        "        # Calculate omnibus test\n",
        "        betas = est['betas']\n",
        "        cov = est['var_betas']\n",
        "\n",
        "        # Test non-intercept coefficients\n",
        "        if len(betas) > 1:\n",
        "            beta_nl = betas[1:]\n",
        "            cov_nl = cov[1:, 1:]\n",
        "            try:\n",
        "                chi2_stat = beta_nl @ np.linalg.inv(cov_nl) @ beta_nl\n",
        "                df_test = len(beta_nl)\n",
        "                p_omnibus = 1 - chi2.cdf(chi2_stat, df_test)\n",
        "            except:\n",
        "                chi2_stat = 0\n",
        "                df_test = len(beta_nl)\n",
        "                p_omnibus = 1.0\n",
        "        else:\n",
        "            chi2_stat = 0\n",
        "            df_test = 0\n",
        "            p_omnibus = 1.0\n",
        "\n",
        "        est['omnibus_chi2'] = chi2_stat\n",
        "        est['omnibus_df'] = df_test\n",
        "        est['omnibus_p'] = p_omnibus\n",
        "        est['reg_df'] = df\n",
        "\n",
        "        return est, None\n",
        "\n",
        "    def _run_internal_linear_analysis(self, df, mod_col, eff_col, var_col):\n",
        "        \"\"\"\n",
        "        Internal linear analysis when external function not available.\n",
        "        \"\"\"\n",
        "        tau2, ll, model = self.estimate_linear_tau2(df, mod_col, eff_col, var_col)\n",
        "        return {'log_lik_reml': ll, 'tau_sq': tau2}\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Computed Properties\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def get_summary_stats(self):\n",
        "        \"\"\"Return key summary statistics for display.\"\"\"\n",
        "        if not self.results:\n",
        "            return None\n",
        "\n",
        "        r = self.results\n",
        "        lr = self.linear_results\n",
        "\n",
        "        preferred = \"Spline\" if (\n",
        "            not np.isnan(lr['aic']) and r['aic'] < lr['aic']\n",
        "        ) else \"Linear\"\n",
        "\n",
        "        return {\n",
        "            'chi2_stat': r.get('omnibus_chi2', 0),\n",
        "            'df_test': r.get('omnibus_df', 0),\n",
        "            'p_omnibus': r.get('omnibus_p', 1.0),\n",
        "            'tau_sq': r.get('tau_sq', 0),\n",
        "            'n_studies': r.get('reg_df', pd.DataFrame()).shape[0] if isinstance(r.get('reg_df'), pd.DataFrame) else r.get('n_studies', 0),\n",
        "            'n_coefs': len(r.get('betas', [])),\n",
        "            'll_spline': r.get('log_lik_reml', np.nan),\n",
        "            'll_linear': lr['log_lik_reml'],\n",
        "            'aic_spline': r.get('aic', np.nan),\n",
        "            'aic_linear': lr['aic'],\n",
        "            'preferred_model': preferred,\n",
        "            'moderator_col': r.get('moderator_col', 'Unknown'),\n",
        "            'df_spline': r.get('df_spline', 3),\n",
        "            'model_type': r.get('model_type', 'Spline'),\n",
        "            'resid': r.get('resid', np.array([])),\n",
        "            'betas': r.get('betas', np.array([]))\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 2: VIEW (Widgets, HTML Generation, Layout)\n",
        "# =============================================================================\n",
        "\n",
        "class SplineMetaRegressionView:\n",
        "    \"\"\"\n",
        "    Handles all UI components, widget creation, and HTML generation.\n",
        "    No business logic - purely presentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._create_widgets()\n",
        "        self._create_tabs()\n",
        "        self._build_layout()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Widget Creation\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _create_widgets(self):\n",
        "        \"\"\"Create all input widgets.\"\"\"\n",
        "        self.mod_dropdown = widgets.Dropdown(\n",
        "            options=['Data not loaded'],\n",
        "            description='Moderator:',\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "        self.df_slider = widgets.IntSlider(\n",
        "            value=3,\n",
        "            min=3,\n",
        "            max=6,\n",
        "            description='Spline df:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        self.run_button = widgets.Button(\n",
        "            description='\u25b6 Run Spline Analysis',\n",
        "            button_style='success',\n",
        "            icon='play'\n",
        "        )\n",
        "\n",
        "        self.export_button = widgets.Button(\n",
        "            description=\"\ud83d\udce5 Download Spline Report\",\n",
        "            button_style='info',\n",
        "            icon='file-excel',\n",
        "            layout=widgets.Layout(width='300px', height='40px')\n",
        "        )\n",
        "\n",
        "    def _create_tabs(self):\n",
        "        \"\"\"Create output tabs.\"\"\"\n",
        "        self.tab_results = widgets.Output()\n",
        "        self.tab_diagnostics = widgets.Output()\n",
        "        self.tab_details = widgets.Output()\n",
        "        self.tab_publication = widgets.Output()\n",
        "        self.tab_export = widgets.Output()\n",
        "\n",
        "        self.tabs = widgets.Tab(children=[\n",
        "            self.tab_results,\n",
        "            self.tab_diagnostics,\n",
        "            self.tab_details,\n",
        "            self.tab_publication,\n",
        "            self.tab_export\n",
        "        ])\n",
        "\n",
        "        self.tabs.set_title(0, '\ud83d\udcca Results')\n",
        "        self.tabs.set_title(1, '\ud83d\udd0d Diagnostics')\n",
        "        self.tabs.set_title(2, '\u2699\ufe0f Model Details')\n",
        "        self.tabs.set_title(3, '\ud83d\udcdd Publication Text')\n",
        "        self.tabs.set_title(4, '\ud83d\udcbe Export')\n",
        "\n",
        "    def _build_layout(self):\n",
        "        \"\"\"Build the main layout container.\"\"\"\n",
        "        self.controls = widgets.VBox([\n",
        "            self.mod_dropdown,\n",
        "            self.df_slider,\n",
        "            self.run_button\n",
        "        ])\n",
        "\n",
        "        self.header = HTML(\"\"\"\n",
        "            <h3>\ud83c\udf0a Spline Meta-Regression Analysis (V2)</h3>\n",
        "            <p style='color: #6c757d;'>Test for non-linear relationships using\n",
        "            natural cubic splines. Results appear in organized tabs below.</p>\n",
        "        \"\"\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Update Methods\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def update_moderator_options(self, options):\n",
        "        \"\"\"Update moderator dropdown options.\"\"\"\n",
        "        self.mod_dropdown.options = options if options else ['Data not loaded']\n",
        "\n",
        "    def clear_all_tabs(self):\n",
        "        \"\"\"Clear all tab outputs.\"\"\"\n",
        "        for tab in [self.tab_results, self.tab_diagnostics,\n",
        "                    self.tab_details, self.tab_publication]:\n",
        "            tab.clear_output()\n",
        "\n",
        "    def show_loading(self):\n",
        "        \"\"\"Show loading message in results tab.\"\"\"\n",
        "        with self.tab_results:\n",
        "            print(\"\u23f3 Running Robust Spline Analysis...\")\n",
        "\n",
        "    def show_error(self, error_msg):\n",
        "        \"\"\"Display error message in results tab.\"\"\"\n",
        "        with self.tab_results:\n",
        "            clear_output()\n",
        "            display(HTML(f\"<div style='color: red;'>{error_msg}</div>\"))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # HTML Generation Methods (No Logic - Pure Presentation)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_results(self, stats):\n",
        "        \"\"\"Render the main results tab.\"\"\"\n",
        "        sig = \"***\" if stats['p_omnibus'] < 0.001 else \\\n",
        "              \"**\" if stats['p_omnibus'] < 0.01 else \\\n",
        "              \"*\" if stats['p_omnibus'] < 0.05 else \"ns\"\n",
        "        color = \"#28a745\" if stats['p_omnibus'] < 0.05 else \"#6c757d\"\n",
        "\n",
        "        html = self._generate_results_html(stats, sig, color)\n",
        "\n",
        "        with self.tab_results:\n",
        "            clear_output()\n",
        "            display(HTML(html))\n",
        "\n",
        "    def _generate_results_html(self, s, sig, color):\n",
        "        \"\"\"Generate HTML for results display.\"\"\"\n",
        "        is_sig = s['p_omnibus'] < 0.05\n",
        "\n",
        "        interpretation = (\n",
        "            f\"The relationship between <b>{s['moderator_col']}</b> and effect sizes \"\n",
        "            f\"exhibits <b style='color: #28a745;'>significant non-linear patterns</b>. \"\n",
        "            \"A flexible spline model fits the data better than a simple linear relationship. \"\n",
        "            \"Examine the spline plot to understand the nature of this non-linearity.\"\n",
        "        ) if is_sig else (\n",
        "            \"No significant evidence of non-linearity was detected. \"\n",
        "            f\"A simple linear relationship may adequately describe the association between \"\n",
        "            f\"<b>{s['moderator_col']}</b> and effect sizes. \"\n",
        "            \"The added complexity of the spline model does not significantly improve fit.\"\n",
        "        )\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h2 style='color: #2c3e50; margin-bottom: 20px;'>Spline Meta-Regression: {s['moderator_col']}</h2>\n",
        "\n",
        "        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "             padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "            <div style='text-align: center;'>\n",
        "                <div style='font-size: 0.9em; margin-bottom: 10px;'>OMNIBUS TEST FOR NON-LINEARITY</div>\n",
        "                <h1 style='margin: 0; font-size: 2.5em;'>{\"Significant\" if is_sig else \"Not Significant\"}</h1>\n",
        "                <p style='margin: 10px 0 0 0; font-size: 1.2em;'>p {s['p_omnibus']:.4g} {sig}</p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-bottom: 20px;'>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;\n",
        "                 border-left: 4px solid #007bff;'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>Chi-Square Statistic</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold;'>\u03c7\u00b2({s['df_test']}) = {s['chi2_stat']:.2f}</div>\n",
        "            </div>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;\n",
        "                 border-left: 4px solid {color};'>\n",
        "                <div style='color: #6c757d; font-size: 0.9em;'>P-value</div>\n",
        "                <div style='font-size: 1.5em; font-weight: bold; color: {color};'>{s['p_omnibus']:.4g}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "            <p style='margin: 0; font-size: 1.05em;'>{interpretation}</p>\n",
        "        </div>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>\n",
        "            Model Comparison\n",
        "        </h3>\n",
        "        <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Model</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Parameters</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Log-Likelihood</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>AIC</th>\n",
        "                    <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Preferred</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Linear</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>2</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{s['ll_linear']:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{s['aic_linear']:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>\n",
        "                        {\"\u2713\" if s['preferred_model'] == \"Linear\" else \"\"}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'>\n",
        "                        <b>Spline (df={s['df_spline']})</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{s['n_coefs']}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{s['ll_spline']:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{s['aic_spline']:.2f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>\n",
        "                        {\"\u2713\" if s['preferred_model'] == \"Spline\" else \"\"}</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>\n",
        "            Model Summary\n",
        "        </h3>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "            <p style='margin: 5px 0;'><b>Model Type:</b> {s['model_type']}</p>\n",
        "            <p style='margin: 5px 0;'><b>Studies (k):</b> {s['n_studies']}</p>\n",
        "            <p style='margin: 5px 0;'><b>Spline Degrees of Freedom:</b> {s['df_spline']}</p>\n",
        "            <p style='margin: 5px 0;'><b>Number of Coefficients:</b> {s['n_coefs']}\n",
        "                (1 intercept + {s['n_coefs']-1} spline terms)</p>\n",
        "            <p style='margin: 5px 0;'><b>Between-Study Variance (\u03c4\u00b2):</b> {s['tau_sq']:.4f}\n",
        "                (fixed from linear model)</p>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px;\n",
        "             border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "            <p style='margin: 0;'><b>\ud83d\udcca Next Step:</b> Use the dedicated spline plot cell to\n",
        "            visualize the non-linear relationship and identify key features\n",
        "            (thresholds, plateaus, etc.).</p>\n",
        "        </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    def render_diagnostics(self, resid):\n",
        "        \"\"\"Render diagnostics tab.\"\"\"\n",
        "        if resid is None or len(resid) == 0:\n",
        "            html = \"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h4 style='color: #34495e;'>Residual Analysis</h4>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                <p><i>Residual data not available from external analysis function.</i></p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            html = f\"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h4 style='color: #34495e;'>Residual Analysis</h4>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                <p><b>Mean Residual:</b> {np.mean(resid):.4f}</p>\n",
        "                <p><b>SD Residual:</b> {np.std(resid):.4f}</p>\n",
        "                <p><b>Range:</b> [{np.min(resid):.3f}, {np.max(resid):.3f}]</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        with self.tab_diagnostics:\n",
        "            clear_output()\n",
        "            display(HTML(html))\n",
        "\n",
        "    def render_details(self):\n",
        "        \"\"\"Render model details tab.\"\"\"\n",
        "        html = \"\"\"\n",
        "        <div style='padding: 20px;'>\n",
        "        <h4 style='color: #34495e;'>Coefficient Estimates</h4>\n",
        "        <p><i>See Results tab for Omnibus Test</i></p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        with self.tab_details:\n",
        "            clear_output()\n",
        "            display(HTML(html))\n",
        "\n",
        "    def render_publication(self, stats, config):\n",
        "        \"\"\"Render publication text tab.\"\"\"\n",
        "        with self.tab_publication:\n",
        "            clear_output()\n",
        "            display(HTML(\"<h3 style='color: #2c3e50;'>\ud83d\udcdd Publication-Ready Results Text</h3>\"))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "            methods_html = self._generate_methods_text(stats, config)\n",
        "            results_html = self._generate_publication_results_text(stats)\n",
        "\n",
        "            display(HTML(methods_html))\n",
        "            display(HTML(results_html))\n",
        "\n",
        "            return methods_html + \"<br><hr><br>\" + results_html\n",
        "\n",
        "    def _generate_methods_text(self, stats, config):\n",
        "        \"\"\"Generate methods section HTML.\"\"\"\n",
        "        db = {\n",
        "            'splines': \"Durrleman, S., & Simon, R. (1989). Flexible regression models with cubic splines. <i>Statistics in Medicine</i>, 8(5), 551-561.\",\n",
        "            'harrell': \"Harrell, F. E. (2001). <i>Regression Modeling Strategies</i>. New York: Springer.\",\n",
        "            'aic': \"Burnham, K. P., & Anderson, D. R. (2002). <i>Model Selection and Multimodel Inference</i> (2nd ed.). New York: Springer-Verlag.\",\n",
        "            'plugin': \"Jackson, D., White, I. R., & Thompson, S. G. (2010). Extending DerSimonian and Laird's methodology. <i>Statistics in Medicine</i>, 29(12), 1282-1297.\",\n",
        "            'tool': \"<b>[CITATION FOR THIS TOOL]:</b> Author, A. A. (202X). <i>Co-Meta: An Interactive Pipeline for Meta-Analysis</i>. [Repository/DOI].\"\n",
        "        }\n",
        "\n",
        "        return f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff; border: 1px solid #eee;'>\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>\n",
        "            Materials and Methods</h3>\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Spline Meta-Regression.</b> To detect potential non-linear relationships between the\n",
        "        effect size and <b>{stats['moderator_col']}</b>, we fitted a Restricted Cubic Spline model [1].\n",
        "        Restricted (natural) cubic splines are linear beyond boundary knots [2].\n",
        "        The model was specified with {stats['df_spline']} degrees of freedom.\n",
        "        </p>\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Variance Estimation.</b> We employed a \"plug-in\" approach for between-study variance\n",
        "        (\u03c4\u00b2 = <b>{stats['tau_sq']:.4f}</b>), estimated from the linear model and held fixed [3].\n",
        "        </p>\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Hypothesis Testing.</b> Non-linearity was assessed using an omnibus Wald-type \u03c7\u00b2 test.\n",
        "        Model fit was compared using AIC [4]. Analyses performed using Co-Meta [5].\n",
        "        </p>\n",
        "        <h4 style='color: #34495e; margin-top: 20px; font-size: 11pt;'>References</h4>\n",
        "        <ol style='font-size: 10pt; color: #555;'>\n",
        "            <li>{db['splines']}</li><li>{db['harrell']}</li>\n",
        "            <li>{db['plugin']}</li><li>{db['aic']}</li><li>{db['tool']}</li>\n",
        "        </ol>\n",
        "        </div>\"\"\"\n",
        "\n",
        "    def _generate_publication_results_text(self, s):\n",
        "        \"\"\"Generate publication results section HTML.\"\"\"\n",
        "        sig_text = \"significant\" if s['p_omnibus'] < 0.05 else \"non-significant\"\n",
        "        p_format = f\"< 0.001\" if s['p_omnibus'] < 0.001 else f\"= {s['p_omnibus']:.3f}\"\n",
        "\n",
        "        # Calculate BIC for completeness\n",
        "        k = s['n_studies']\n",
        "        bic_linear = -2 * s['ll_linear'] + np.log(k) * 2\n",
        "        bic_spline = -2 * s['ll_spline'] + np.log(k) * s['n_coefs']\n",
        "\n",
        "        interpretation = \"\"\n",
        "        if s['p_omnibus'] < 0.05:\n",
        "            interpretation = f\"\"\"This indicates that the relationship between {s['moderator_col']}\n",
        "            and effect sizes exhibits <b>significant non-linear patterns</b>.\"\"\"\n",
        "        else:\n",
        "            interpretation = f\"\"\"This suggests that a simple linear relationship may adequately\n",
        "            describe the association between {s['moderator_col']} and effect sizes.\"\"\"\n",
        "\n",
        "        return f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>\n",
        "            Spline Meta-Regression Results</h3>\n",
        "        <h4 style='color: #34495e; margin-top: 25px;'>Non-Linearity Test</h4>\n",
        "        <p style='text-align: justify;'>\n",
        "        The omnibus test for non-linearity was <b>{sig_text}</b>\n",
        "        (\u03c7\u00b2({s['df_test']}) = <b>{s['chi2_stat']:.2f}</b>, <i>p</i> {p_format}). {interpretation}\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 25px;'>Model Comparison</h4>\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 15px 0;'>\n",
        "            <p style='margin: 5px 0;'><b>Linear Model:</b> AIC = {s['aic_linear']:.2f}, BIC = {bic_linear:.2f}</p>\n",
        "            <p style='margin: 5px 0;'><b>Spline Model:</b> AIC = {s['aic_spline']:.2f}, BIC = {bic_spline:.2f}</p>\n",
        "            <p style='margin: 5px 0;'><b>Preferred Model:</b> {s['preferred_model']} (lower AIC)</p>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 25px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>\ud83d\udcca Table 1. Spline Model Summary</h4>\n",
        "            <table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "            <thead style='background-color: #34495e; color: white;'>\n",
        "                <tr>\n",
        "                    <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Statistic</th>\n",
        "                    <th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Value</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px;'>Number of studies (k)</td>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{s['n_studies']}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px;'>Spline degrees of freedom</td>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{s['df_spline']}</td>\n",
        "                </tr>\n",
        "                <tr style='background-color: #f8f9fa;'>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px;'>Between-study variance (\u03c4\u00b2)</td>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{s['tau_sq']:.4f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px;'>Omnibus test for non-linearity</td>\n",
        "                    <td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>\n",
        "                        \u03c7\u00b2({s['df_test']}) = {s['chi2_stat']:.2f}, <i>p</i> {p_format}</td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "            </table>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "            <p style='margin: 0;'><b>\ud83d\udca1 Tip:</b> Select all text (Ctrl+A), copy (Ctrl+C), and paste\n",
        "            into your word processor.</p>\n",
        "        </div>\n",
        "        </div>\"\"\"\n",
        "\n",
        "    def render_export_tab(self):\n",
        "        \"\"\"Render the export tab with download button.\"\"\"\n",
        "        with self.tab_export:\n",
        "            clear_output()\n",
        "            display(HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcbe Download Audit Report</h3>\"))\n",
        "            display(HTML(\"<p>Download the Spline analysis results, including the non-linearity \"\n",
        "                        \"test and model comparison statistics.</p>\"))\n",
        "            display(self.export_button)\n",
        "\n",
        "    def display(self):\n",
        "        \"\"\"Display the complete UI.\"\"\"\n",
        "        display(self.header)\n",
        "        display(self.controls)\n",
        "        display(self.tabs)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3: CONTROLLER (Event Handling, Linking Model & View)\n",
        "# =============================================================================\n",
        "\n",
        "class SplineMetaRegressionController:\n",
        "    \"\"\"\n",
        "    Handles user interactions and coordinates between Model and View.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, view):\n",
        "        self.model = model\n",
        "        self.view = view\n",
        "        self._bind_events()\n",
        "        self._initialize()\n",
        "\n",
        "    def _bind_events(self):\n",
        "        \"\"\"Bind event handlers to view widgets.\"\"\"\n",
        "        self.view.run_button.on_click(self._on_run_click)\n",
        "        self.view.export_button.on_click(self._on_export_click)\n",
        "\n",
        "    def _initialize(self):\n",
        "        \"\"\"Initialize the view with data from model.\"\"\"\n",
        "        # Load moderator options\n",
        "        df = self.model.get_analysis_data()\n",
        "        if df is not None:\n",
        "            options = self.model.get_numeric_moderators(df)\n",
        "            self.view.update_moderator_options(options)\n",
        "\n",
        "        # Setup export tab\n",
        "        self.view.render_export_tab()\n",
        "\n",
        "    def _on_run_click(self, button):\n",
        "        \"\"\"Handle run button click.\"\"\"\n",
        "        # Clear previous output\n",
        "        self.view.clear_all_tabs()\n",
        "        self.view.show_loading()\n",
        "\n",
        "        # Get user inputs\n",
        "        moderator_col = self.view.mod_dropdown.value\n",
        "        df_spline = self.view.df_slider.value\n",
        "\n",
        "        # Run analysis\n",
        "        success = self.model.run_analysis(moderator_col, df_spline)\n",
        "\n",
        "        if not success:\n",
        "            self.view.show_error(self.model.error)\n",
        "            return\n",
        "\n",
        "        # Get results and render all tabs\n",
        "        stats = self.model.get_summary_stats()\n",
        "        config = self.model.get_analysis_config()\n",
        "\n",
        "        # Render results\n",
        "        self.view.render_results(stats)\n",
        "        self.view.render_diagnostics(stats['resid'])\n",
        "        self.view.render_details()\n",
        "        pub_text = self.view.render_publication(stats, config)\n",
        "\n",
        "        # Save publication text to config\n",
        "        self.model.set_analysis_config('spline_text', pub_text)\n",
        "\n",
        "    def _on_export_click(self, button):\n",
        "        \"\"\"Handle export button click.\"\"\"\n",
        "        # Check if export function exists in global scope\n",
        "        if 'export_analysis_report' in globals():\n",
        "            globals()['export_analysis_report'](\n",
        "                report_type='spline',\n",
        "                filename_prefix='Spline_Analysis_Audit'\n",
        "            )\n",
        "        else:\n",
        "            with self.view.tab_export:\n",
        "                display(HTML(\"<p style='color: orange;'>\u26a0\ufe0f Export function not available. \"\n",
        "                           \"Ensure export_analysis_report is defined in a previous cell.</p>\"))\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Display the UI and start the application.\"\"\"\n",
        "        self.view.display()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION: Instantiate and Display\n",
        "# =============================================================================\n",
        "\n",
        "# Create MVC components\n",
        "_spline_model = SplineMetaRegressionModel()\n",
        "_spline_view = SplineMetaRegressionView()\n",
        "_spline_controller = SplineMetaRegressionController(_spline_model, _spline_view)\n",
        "\n",
        "# Run the application\n",
        "_spline_controller.run()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5FuddHItwavn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 15. Visualization: Spline Plot\n",
        "# =============================================================================\n",
        "# CELL 11b: ADVANCED SPLINE PLOTTER (FIXED)\n",
        "# Purpose: Visualize results from Cell 11 with full customization.\n",
        "# Features: Tabs for Style, Points, Curve, Layout, and Label Editing.\n",
        "# Compatibility: Updated to work with the new Robust 3-Level Spline results.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import t, norm\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import traceback\n",
        "import patsy\n",
        "\n",
        "# --- 1. INITIALIZATION & CONFIG LOADING ---\n",
        "available_color_moderators = ['None']\n",
        "analysis_data_init = None\n",
        "default_x_label = \"Moderator\"\n",
        "default_y_label = \"Effect Size\"\n",
        "default_title = \"Natural Cubic Spline Analysis\"\n",
        "label_widgets_dict = {}\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        pass # Will be handled in plotting logic if missing\n",
        "\n",
        "    # Get data for dropdowns\n",
        "    if 'analysis_data' in globals():\n",
        "        analysis_data_init = analysis_data.copy()\n",
        "    elif 'data_filtered' in globals():\n",
        "        analysis_data_init = data_filtered.copy()\n",
        "    elif 'ANALYSIS_CONFIG' in globals() and 'analysis_data' in ANALYSIS_CONFIG:\n",
        "        analysis_data_init = ANALYSIS_CONFIG['analysis_data'].copy()\n",
        "    else:\n",
        "        # Fallback to reg_df if main data missing\n",
        "        if 'ANALYSIS_CONFIG' in globals() and 'spline_model_results' in ANALYSIS_CONFIG:\n",
        "            analysis_data_init = ANALYSIS_CONFIG['spline_model_results']['reg_df'].copy()\n",
        "\n",
        "    # Load Defaults from Results\n",
        "    if 'ANALYSIS_CONFIG' in globals() and 'spline_model_results' in ANALYSIS_CONFIG:\n",
        "        spline_results = ANALYSIS_CONFIG['spline_model_results']\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        default_x_label = spline_results.get('moderator_col', 'Moderator')\n",
        "        default_y_label = es_config.get('effect_label', 'Effect Size')\n",
        "        default_title = f\"Spline Regression: {default_y_label} vs. {default_x_label}\"\n",
        "\n",
        "    # Identify Categorical Moderators for Coloring\n",
        "    if analysis_data_init is not None:\n",
        "        excluded_cols = [\n",
        "            ANALYSIS_CONFIG.get('effect_col'), ANALYSIS_CONFIG.get('var_col'),\n",
        "            ANALYSIS_CONFIG.get('se_col'), 'w_fixed', 'w_random', 'id',\n",
        "            'xe', 'sde', 'ne', 'xc', 'sdc', 'nc'\n",
        "        ]\n",
        "\n",
        "        for col in analysis_data_init.columns:\n",
        "            if col in excluded_cols or col is None: continue\n",
        "            # Check if categorical (object or category) and reasonable size\n",
        "            if analysis_data_init[col].dtype == 'object' or isinstance(analysis_data_init[col].dtype, pd.CategoricalDtype):\n",
        "                if analysis_data_init[col].nunique() <= 15: # Limit to reasonable number of colors\n",
        "                    available_color_moderators.append(col)\n",
        "\n",
        "    # Find unique labels for Editor\n",
        "    all_categorical_labels = set()\n",
        "    for col in available_color_moderators:\n",
        "        if col != 'None' and col in analysis_data_init.columns:\n",
        "            all_categorical_labels.add(col)\n",
        "            unique_vals = analysis_data_init[col].astype(str).str.strip().unique()\n",
        "            all_categorical_labels.update(unique_vals)\n",
        "\n",
        "    all_categorical_labels.discard('')\n",
        "    all_categorical_labels.discard('nan')\n",
        "\n",
        "except Exception as e:\n",
        "    # Silent fail on init, wil warn later\n",
        "    pass\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# === TAB 1: STYLE ===\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_x_label, description='X Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_y_label, description='Y Label:', layout=widgets.Layout(width='450px'))\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=5.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False)\n",
        "height_widget = widgets.FloatSlider(value=6.0, min=4.0, max=12.0, step=0.5, description='Height (in):', continuous_update=False)\n",
        "png_dpi_widget = widgets.IntText(value=300, description='PNG DPI:', layout=widgets.Layout(width='150px')) # Added missing widget\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Dimensions</h4>\"),\n",
        "    show_title_widget, title_widget,\n",
        "    xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    width_widget, height_widget\n",
        "])\n",
        "\n",
        "# === TAB 2: POINTS ===\n",
        "show_points_widget = widgets.Checkbox(value=True, description='Show Data Points', indent=False)\n",
        "color_mod_widget = widgets.Dropdown(options=available_color_moderators, value='None', description='Color By:', layout=widgets.Layout(width='400px'))\n",
        "point_color_widget = widgets.Dropdown(options=['gray', 'steelblue', 'black', 'red', 'green', 'purple'], value='gray', description='Color:')\n",
        "point_size_widget = widgets.IntSlider(value=40, min=10, max=150, step=5, description='Size:')\n",
        "point_alpha_widget = widgets.FloatSlider(value=0.5, min=0.1, max=1.0, step=0.1, description='Opacity:')\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Points</h4>\"),\n",
        "    show_points_widget,\n",
        "    color_mod_widget,\n",
        "    point_color_widget,\n",
        "    point_size_widget,\n",
        "    point_alpha_widget\n",
        "])\n",
        "\n",
        "# === TAB 3: CURVE ===\n",
        "curve_color_widget = widgets.Dropdown(options=['blue', 'red', 'black', 'green', 'purple'], value='blue', description='Line Color:')\n",
        "curve_width_widget = widgets.FloatSlider(value=2.5, min=0.5, max=6.0, step=0.5, description='Line Width:')\n",
        "show_ci_widget = widgets.Checkbox(value=True, description='Show 95% Confidence Band', indent=False)\n",
        "ci_alpha_widget = widgets.FloatSlider(value=0.15, min=0.05, max=0.5, step=0.05, description='CI Opacity:')\n",
        "show_stats_widget = widgets.Checkbox(value=True, description='Show Stats (P-value)', indent=False)\n",
        "\n",
        "curve_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Spline Curve</h4>\"),\n",
        "    curve_color_widget, curve_width_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    show_ci_widget, ci_alpha_widget,\n",
        "    show_stats_widget\n",
        "])\n",
        "\n",
        "# === TAB 4: LAYOUT ===\n",
        "show_grid_widget = widgets.Checkbox(value=True, description='Show Grid', indent=False)\n",
        "show_null_line_widget = widgets.Checkbox(value=True, description='Show Null Line (y=0)', indent=False)\n",
        "legend_loc_widget = widgets.Dropdown(options=['best', 'upper right', 'upper left', 'lower right', 'lower left', 'none'], value='best', description='Legend:')\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "filename_prefix_widget = widgets.Text(value='Spline_Plot', description='Filename:', layout=widgets.Layout(width='300px'))\n",
        "\n",
        "layout_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Layout & Export</h4>\"),\n",
        "    show_grid_widget, show_null_line_widget, legend_loc_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 5px 0;'>\"),\n",
        "    save_pdf_widget, save_png_widget, png_dpi_widget, filename_prefix_widget\n",
        "])\n",
        "\n",
        "# === TAB 5: LABELS (Dynamic) ===\n",
        "label_editor_widgets = []\n",
        "label_widgets_dict = {}\n",
        "\n",
        "if all_categorical_labels:\n",
        "    for label in sorted(list(all_categorical_labels)):\n",
        "        w = widgets.Text(value=str(label), description=f\"{label}:\", layout=widgets.Layout(width='400px'))\n",
        "        label_editor_widgets.append(w)\n",
        "        label_widgets_dict[str(label)] = w\n",
        "else:\n",
        "    label_editor_widgets.append(widgets.Label(\"No categorical labels found to edit.\"))\n",
        "\n",
        "labels_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Label Editor</h4>\"),\n",
        "    widgets.HTML(\"<i>Rename data categories for the legend:</i>\"),\n",
        "    *label_editor_widgets\n",
        "])\n",
        "\n",
        "# Assemble Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, points_tab, curve_tab, layout_tab, labels_tab])\n",
        "tabs.set_title(0, '\ud83c\udfa8 Style')\n",
        "tabs.set_title(1, '\u26ab Points')\n",
        "tabs.set_title(2, '\ud83c\udf0a Curve')\n",
        "tabs.set_title(3, '\ud83d\udcbe Layout')\n",
        "tabs.set_title(4, '\u270f\ufe0f Labels')\n",
        "\n",
        "run_plot_btn = widgets.Button(\n",
        "    description='\ud83d\udcca Generate Spline Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# --- 3. PLOTTING LOGIC ---\n",
        "def generate_spline_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        try:\n",
        "            # --- Get Global Settings ---\n",
        "            gs = ANALYSIS_CONFIG.get('global_settings', {})\n",
        "            alpha = gs.get('alpha', 0.05)\n",
        "            dist_type = gs.get('dist_type', 'norm')\n",
        "            ci_pct = (1 - alpha) * 100\n",
        "\n",
        "            # 1. Load Results\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'spline_model_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"\u274c Error: Please run the Spline Analysis (Cell 11) first.\")\n",
        "                return\n",
        "\n",
        "            res = ANALYSIS_CONFIG['spline_model_results']\n",
        "            df = res['reg_df'].copy() # Dataframe used in model\n",
        "\n",
        "            # Extract Model info\n",
        "            betas = res['betas']\n",
        "            # FIX: Use get() to handle both new and old key names safely\n",
        "            cov = res.get('cov_beta', res.get('var_betas'))\n",
        "\n",
        "            formula = res['formula']\n",
        "            mod_mean = res['mod_mean']\n",
        "            mod_std = res['mod_std']\n",
        "            mod_col = res['moderator_col']\n",
        "            eff_col = ANALYSIS_CONFIG['effect_col']\n",
        "\n",
        "            # 2. Re-calculate Curve (High Resolution)\n",
        "            x_min, x_max = df[mod_col].min(), df[mod_col].max()\n",
        "            padding = (x_max - x_min) * 0.05\n",
        "            x_grid = np.linspace(x_min - padding, x_max + padding, 200)\n",
        "            x_grid_z = (x_grid - mod_mean) / mod_std\n",
        "\n",
        "            # Generate Basis for Grid\n",
        "            try:\n",
        "                # We use patsy to recreate the design matrix for the grid\n",
        "                pred_matrix = patsy.dmatrix(formula, {\"x\": x_grid_z}, return_type='matrix')\n",
        "                basis_matrix = np.asarray(pred_matrix)\n",
        "\n",
        "                # Add intercept\n",
        "                X_pred = np.column_stack([np.ones(len(x_grid)), basis_matrix])\n",
        "\n",
        "                # Calculate\n",
        "                y_pred = X_pred @ betas\n",
        "                pred_var = np.sum((X_pred @ cov) * X_pred, axis=1)\n",
        "                pred_se = np.sqrt(pred_var)\n",
        "\n",
        "                # --- UPDATED: Dynamic Critical Value ---\n",
        "                q_val = 1 - (alpha / 2)\n",
        "                if dist_type == 't':\n",
        "                    # Use residual df approx\n",
        "                    df_spline_resid = max(1, len(df) - len(betas))\n",
        "                    crit_val = t.ppf(q_val, df_spline_resid)\n",
        "                else:\n",
        "                    crit_val = norm.ppf(q_val)\n",
        "                # ---------------------------------------\n",
        "\n",
        "                ci_lower = y_pred - crit_val * pred_se\n",
        "                ci_upper = y_pred + crit_val * pred_se\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\u274c Error calculating curve: {e}\")\n",
        "                print(\"   (Model structure might have changed. Try re-running Step 11)\")\n",
        "                return\n",
        "\n",
        "            # 3. Prepare Plot\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, height_widget.value))\n",
        "\n",
        "            # Handle Colors & Labels\n",
        "            color_col = color_mod_widget.value\n",
        "            label_map = {k: v.value for k, v in label_widgets_dict.items()}\n",
        "\n",
        "            # --- Plot Points ---\n",
        "            if show_points_widget.value:\n",
        "                if color_col != 'None' and color_col in analysis_data_init.columns:\n",
        "                    # Check if color_col exists in df, if not, try merge from init data\n",
        "                    plot_df = df.copy()\n",
        "                    if color_col not in plot_df.columns:\n",
        "                        temp_merge = analysis_data_init[['id', color_col]].drop_duplicates()\n",
        "                        # Only merge if 'id' exists (it should in 3-level data)\n",
        "                        if 'id' in plot_df.columns:\n",
        "                            plot_df = plot_df.merge(temp_merge, on='id', how='left')\n",
        "\n",
        "                    # Get unique categories\n",
        "                    if color_col in plot_df.columns:\n",
        "                        categories = plot_df[color_col].dropna().unique()\n",
        "                        cmap = plt.get_cmap('tab10')\n",
        "\n",
        "                        for i, cat in enumerate(categories):\n",
        "                            cat_str = str(cat)\n",
        "                            display_label = label_map.get(cat_str, cat_str)\n",
        "                            mask = plot_df[color_col] == cat\n",
        "\n",
        "                            ax.scatter(plot_df.loc[mask, mod_col], plot_df.loc[mask, eff_col],\n",
        "                                      color=cmap(i % 10), alpha=point_alpha_widget.value,\n",
        "                                      s=point_size_widget.value, label=display_label,\n",
        "                                      edgecolors='k', linewidth=0.5)\n",
        "                        legend_title = label_map.get(color_col, color_col)\n",
        "                    else:\n",
        "                        # Fallback if merge failed\n",
        "                        ax.scatter(df[mod_col], df[eff_col], color='gray')\n",
        "                        legend_title = None\n",
        "                else:\n",
        "                    # Single color\n",
        "                    ax.scatter(df[mod_col], df[eff_col],\n",
        "                              color=point_color_widget.value, alpha=point_alpha_widget.value,\n",
        "                              s=point_size_widget.value, label='Observations',\n",
        "                              edgecolors='k', linewidth=0.5)\n",
        "                    legend_title = None\n",
        "\n",
        "            # --- Plot Curve ---\n",
        "            ax.plot(x_grid, y_pred, color=curve_color_widget.value,\n",
        "                   linewidth=curve_width_widget.value, label='Spline Fit')\n",
        "\n",
        "            if show_ci_widget.value:\n",
        "                ax.fill_between(x_grid, ci_lower, ci_upper,\n",
        "                               color=curve_color_widget.value, alpha=ci_alpha_widget.value,\n",
        "                               label=f'{ci_pct:.0f}% CI')\n",
        "\n",
        "            # --- Decoration ---\n",
        "            if show_null_line_widget.value:\n",
        "                ax.axhline(0, color='black', linestyle=':', linewidth=1.5, alpha=0.6)\n",
        "\n",
        "            if show_grid_widget.value:\n",
        "                ax.grid(True, linestyle=':', alpha=0.4)\n",
        "\n",
        "            if show_title_widget.value:\n",
        "                ax.set_title(title_widget.value, fontsize=14, fontweight='bold', pad=15)\n",
        "\n",
        "            ax.set_xlabel(xlabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(ylabel_widget.value, fontsize=12, fontweight='bold')\n",
        "\n",
        "            if legend_loc_widget.value != 'none':\n",
        "                ax.legend(loc=legend_loc_widget.value, title=legend_title, frameon=True, fancybox=True)\n",
        "\n",
        "            # Stats annotation\n",
        "            if show_stats_widget.value:\n",
        "                p_val = res.get('omnibus_p', None)\n",
        "                tau2 = res.get('tau_sq', None)\n",
        "\n",
        "                stats_text = []\n",
        "                if p_val is not None:\n",
        "                    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"ns\"\n",
        "                    stats_text.append(f\"Non-Linearity: p = {p_val:.4g} {sig}\")\n",
        "                if tau2 is not None:\n",
        "                    stats_text.append(f\"\u03c4\u00b2: {tau2:.3f}\")\n",
        "\n",
        "                if stats_text:\n",
        "                    ax.text(0.05, 0.95, \"\\n\".join(stats_text), transform=ax.transAxes,\n",
        "                            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- Export ---\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M%S\")\n",
        "            fn = filename_prefix_widget.value\n",
        "\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "                print(f\"\ud83d\udcbe Saved: {fn}_{ts}.pdf\")\n",
        "\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.png\", dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"\ud83d\udcbe Saved: {fn}_{ts}.png\")\n",
        "\n",
        "            plt.show()\n",
        "            print(f\"\u2705 Plot Generated (n={len(df)})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Plotting Error: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_plot_btn.on_click(generate_spline_plot)\n",
        "\n",
        "\n",
        "# Header\n",
        "header = widgets.HTML(\"\"\"\n",
        "    <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>\n",
        "        <h2 style='color: white; margin: 0; text-align: center;'>\n",
        "            \ud83d\udcca Cell 11b: Publication-Ready Spline Plot\n",
        "        </h2>\n",
        "        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0; text-align: center; font-size: 14px;'>\n",
        "            Visualize spline analysis results with full customization\n",
        "        </p>\n",
        "    </div>\n",
        "\"\"\")\n",
        "\n",
        "# --- 4. DISPLAY ---\n",
        "display(widgets.VBox([\n",
        "    header,\n",
        "    tabs,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    run_plot_btn,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ECwHJ38n9dHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcc9 16. Publication Bias: Diagnostics (Egger's & Trim-Fill) - MVC Refactored\n",
        "\n",
        "# =============================================================================\n",
        "# PUBLICATION BIAS ANALYSIS - MVC ARCHITECTURE\n",
        "# Drop-in replacement preserving all original math & logic\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import norm, t, rankdata\n",
        "import statsmodels.api as sm\n",
        "import datetime\n",
        "from scipy.optimize import minimize\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import warnings\n",
        "\n",
        "# =============================================================================\n",
        "# PART 1: MODEL - Business Logic & Data Processing\n",
        "# =============================================================================\n",
        "\n",
        "class PublicationBiasModel:\n",
        "    \"\"\"\n",
        "    Model: Contains all mathematical logic for publication bias assessment.\n",
        "    Preserves exact calculations from original code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.egger_results = None\n",
        "        self.trimfill_results = None\n",
        "        self.analysis_config = None\n",
        "        self.analysis_data = None\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"Load data and configuration from global context\"\"\"\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            raise ValueError(\"ANALYSIS_CONFIG not found. Run Step 1 first.\")\n",
        "\n",
        "        self.analysis_config = globals()['ANALYSIS_CONFIG']\n",
        "\n",
        "        if 'three_level_results' not in self.analysis_config:\n",
        "            raise ValueError(\"Three-level results not found. Run Step 2 first.\")\n",
        "\n",
        "        # Load analysis data\n",
        "        if 'analysis_data' in self.analysis_config:\n",
        "            self.analysis_data = self.analysis_config['analysis_data']\n",
        "        elif 'data_filtered' in globals():\n",
        "            self.analysis_data = globals()['data_filtered']\n",
        "        else:\n",
        "            raise ValueError(\"No analysis data found.\")\n",
        "\n",
        "        self.effect_col = self.analysis_config.get('effect_col', 'hedges_g')\n",
        "        self.var_col = self.analysis_config.get('var_col', 'Vg')\n",
        "        self.se_col = self.analysis_config.get('se_col', 'SE_g')\n",
        "\n",
        "        return self\n",
        "\n",
        "    def get_dataset_info(self):\n",
        "        \"\"\"Return sample size information\"\"\"\n",
        "        n_obs = len(self.analysis_data)\n",
        "        n_studies = self.analysis_data['id'].nunique()\n",
        "        return n_obs, n_studies\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # EGGER'S TEST - Using GLOBAL helper functions (no local copies)\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_eggers_test(self):\n",
        "        \"\"\"\n",
        "        Run Egger's Test using 3-Level Meta-Regression on SE.\n",
        "        Calls global _run_robust_eggers_test or implements it using global helpers.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            estimates = self._run_robust_eggers_test(\n",
        "                self.analysis_data,\n",
        "                self.effect_col,\n",
        "                self.var_col,\n",
        "                self.se_col\n",
        "            )\n",
        "\n",
        "            if not estimates:\n",
        "                raise ValueError(\"Egger's test optimization failed\")\n",
        "\n",
        "            intercept = estimates['betas'][0]\n",
        "            slope_val = estimates['betas'][1]\n",
        "            se_intercept = estimates['se_betas'][0]\n",
        "            t_stat = intercept / se_intercept\n",
        "            df = estimates.get('df', 100)\n",
        "            p_value = 2 * (1 - t.cdf(abs(t_stat), df))\n",
        "\n",
        "            # Store results\n",
        "            self.egger_results = {\n",
        "                'intercept': intercept,\n",
        "                'slope': slope_val,\n",
        "                'se': se_intercept,\n",
        "                't_stat': t_stat,\n",
        "                'df': df,\n",
        "                'p_value': p_value,\n",
        "                'estimates': estimates,\n",
        "                'timestamp': datetime.datetime.now()\n",
        "            }\n",
        "\n",
        "            # Save to global config (required for plotting cells)\n",
        "            self.analysis_config['funnel_results'] = {\n",
        "                'beta_slope': slope_val,\n",
        "                'timestamp': datetime.datetime.now(),\n",
        "                'intercept': intercept,\n",
        "                'se': se_intercept,\n",
        "                'p_value': p_value,\n",
        "                'estimates': estimates\n",
        "            }\n",
        "\n",
        "            return self.egger_results\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error running Egger's test: {str(e)}\")\n",
        "\n",
        "    def _run_robust_eggers_test(self, analysis_data, effect_col, var_col, se_col):\n",
        "        \"\"\"\n",
        "        Core Egger's test implementation - USES GLOBAL HELPER FUNCTIONS\n",
        "        \"\"\"\n",
        "        # Access global helper functions\n",
        "        neg_log_lik_reml_reg = globals()['_neg_log_lik_reml_reg']\n",
        "        get_three_level_regression_estimates_v2 = globals()['_get_three_level_regression_estimates_v2']\n",
        "\n",
        "        grouped = analysis_data.groupby('id')\n",
        "        y_all, v_all, X_all = [], [], []\n",
        "\n",
        "        for _, group in grouped:\n",
        "            y_all.append(group[effect_col].values)\n",
        "            v_all.append(group[var_col].values)\n",
        "            X_i = sm.add_constant(group[se_col].values, prepend=True)\n",
        "            X_all.append(X_i)\n",
        "\n",
        "        N_total = len(analysis_data)\n",
        "        M_studies = len(y_all)\n",
        "        p_params = 2\n",
        "\n",
        "        # Optimization with multiple starting points\n",
        "        best_res = None\n",
        "        best_fun = np.inf\n",
        "        start_points = [[0.1, 0.1], [1.0, 0.1], [5.0, 0.1]]\n",
        "\n",
        "        for start in start_points:\n",
        "            res = minimize(\n",
        "                neg_log_lik_reml_reg,  # GLOBAL FUNCTION\n",
        "                x0=start,\n",
        "                args=(y_all, v_all, X_all, N_total, M_studies, p_params),\n",
        "                method='L-BFGS-B',\n",
        "                bounds=[(1e-8, None), (1e-8, None)],\n",
        "                options={'ftol': 1e-10}\n",
        "            )\n",
        "            if res.success and res.fun < best_fun:\n",
        "                best_fun = res.fun\n",
        "                best_res = res\n",
        "\n",
        "        if not best_res:\n",
        "            return None\n",
        "\n",
        "        # Final refinement\n",
        "        final_res = minimize(\n",
        "            neg_log_lik_reml_reg,  # GLOBAL FUNCTION\n",
        "            x0=best_res.x,\n",
        "            args=(y_all, v_all, X_all, N_total, M_studies, p_params),\n",
        "            method='Nelder-Mead',\n",
        "            options={'xatol': 1e-10, 'fatol': 1e-10}\n",
        "        )\n",
        "\n",
        "        return get_three_level_regression_estimates_v2(  # GLOBAL FUNCTION\n",
        "            final_res.x, y_all, v_all, X_all, N_total, M_studies, p_params\n",
        "        )\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TRIM-AND-FILL - Preserving exact Duval & Tweedie implementation\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_trimfill_analysis(self, estimator='L0', side='auto', max_iter=100):\n",
        "        \"\"\"\n",
        "        Duval & Tweedie Trim-and-Fill - EXACT from original code\n",
        "        \"\"\"\n",
        "        try:\n",
        "            yi = self.analysis_data[self.effect_col].values\n",
        "            vi = self.analysis_data[self.var_col].values\n",
        "            ni = len(yi)\n",
        "\n",
        "            # Sort by effect size\n",
        "            sort_indices = np.argsort(yi)\n",
        "            yi = yi[sort_indices]\n",
        "            vi = vi[sort_indices]\n",
        "\n",
        "            # Determine side if auto\n",
        "            if side == 'auto':\n",
        "                wi = 1/vi\n",
        "                pooled_fe = np.sum(wi * yi) / np.sum(wi)\n",
        "                skew = np.sum(wi * (yi - pooled_fe)**3)\n",
        "                side = 'left' if skew > 0 else 'right'\n",
        "\n",
        "            # Iterative trimming\n",
        "            k0 = 0\n",
        "            iter_safe = 0\n",
        "\n",
        "            while iter_safe < max_iter:\n",
        "                n_curr = ni - k0\n",
        "\n",
        "                if side == 'left':\n",
        "                    yi_curr = yi[:n_curr]\n",
        "                    vi_curr = vi[:n_curr]\n",
        "                else:\n",
        "                    yi_curr = yi[k0:]\n",
        "                    vi_curr = vi[k0:]\n",
        "\n",
        "                wi_curr = 1 / vi_curr\n",
        "                pooled_fe = np.sum(wi_curr * yi_curr) / np.sum(wi_curr)\n",
        "\n",
        "                residuals = yi - pooled_fe\n",
        "                signed_res = residuals if side == 'left' else -residuals\n",
        "                abs_res = np.abs(signed_res)\n",
        "                ranks = rankdata(abs_res, method='average')\n",
        "\n",
        "                pos_ranks = np.where(signed_res > 0, ranks, 0)\n",
        "                Sn = np.sum(pos_ranks)\n",
        "\n",
        "                k0_new = int(round((4 * Sn - ni * (ni + 1)) / (2 * ni - 1)))\n",
        "                k0_new = max(0, k0_new)\n",
        "\n",
        "                if k0_new == k0:\n",
        "                    break\n",
        "\n",
        "                k0 = k0_new\n",
        "                k0 = min(k0, ni - 2)\n",
        "                iter_safe += 1\n",
        "\n",
        "            # Filling phase\n",
        "            if k0 > 0:\n",
        "                if side == 'left':\n",
        "                    idx_fill = slice(ni - k0, ni)\n",
        "                else:\n",
        "                    idx_fill = slice(0, k0)\n",
        "\n",
        "                yi_excess = yi[idx_fill]\n",
        "                vi_excess = vi[idx_fill]\n",
        "\n",
        "                yi_filled = 2 * pooled_fe - yi_excess\n",
        "                vi_filled = vi_excess\n",
        "\n",
        "                yi_final = np.concatenate([yi, yi_filled])\n",
        "                vi_final = np.concatenate([vi, vi_filled])\n",
        "            else:\n",
        "                yi_final = yi\n",
        "                vi_final = vi\n",
        "                yi_filled = []\n",
        "                vi_filled = []\n",
        "\n",
        "            # Compute pooled estimates\n",
        "            wi_final = 1 / vi_final\n",
        "            pooled_final = np.sum(wi_final * yi_final) / np.sum(wi_final)\n",
        "            var_final = 1 / np.sum(wi_final)\n",
        "            se_final = np.sqrt(var_final)\n",
        "\n",
        "            wi_orig = 1 / vi\n",
        "            pooled_orig = np.sum(wi_orig * yi) / np.sum(wi_orig)\n",
        "            se_orig = np.sqrt(1 / np.sum(wi_orig))\n",
        "\n",
        "            # Dynamic inference (from original code)\n",
        "            if 'ANALYSIS_CONFIG' in globals():\n",
        "                gs = globals()['ANALYSIS_CONFIG'].get('global_settings', {})\n",
        "                alpha_val = gs.get('alpha', 0.05)\n",
        "                dist_type = gs.get('dist_type', 'norm')\n",
        "            else:\n",
        "                alpha_val = 0.05\n",
        "                dist_type = 'norm'\n",
        "\n",
        "            q_val = 1 - (alpha_val / 2)\n",
        "\n",
        "            # Original CI\n",
        "            k_orig = len(yi)\n",
        "            if dist_type == 't':\n",
        "                crit_val_orig = t.ppf(q_val, max(1, k_orig - 1))\n",
        "            else:\n",
        "                crit_val_orig = norm.ppf(q_val)\n",
        "\n",
        "            ci_lo_orig = pooled_orig - crit_val_orig * se_orig\n",
        "            ci_hi_orig = pooled_orig + crit_val_orig * se_orig\n",
        "\n",
        "            # Filled CI\n",
        "            k_final = len(yi_final)\n",
        "            if dist_type == 't':\n",
        "                crit_val_final = t.ppf(q_val, max(1, k_final - 1))\n",
        "            else:\n",
        "                crit_val_final = norm.ppf(q_val)\n",
        "\n",
        "            ci_lo_fill = pooled_final - crit_val_final * se_final\n",
        "            ci_hi_fill = pooled_final + crit_val_final * se_final\n",
        "\n",
        "            self.trimfill_results = {\n",
        "                'k0': k0,\n",
        "                'side': side,\n",
        "                'pooled_original': pooled_orig,\n",
        "                'se_original': se_orig,\n",
        "                'ci_lower_original': ci_lo_orig,\n",
        "                'ci_upper_original': ci_hi_orig,\n",
        "                'pooled_filled': pooled_final,\n",
        "                'se_filled': se_final,\n",
        "                'ci_lower_filled': ci_lo_fill,\n",
        "                'ci_upper_filled': ci_hi_fill,\n",
        "                'yi_filled': yi_filled,\n",
        "                'vi_filled': vi_filled if k0 > 0 else [],\n",
        "                'yi_combined': yi_final,\n",
        "                'vi_combined': vi_final\n",
        "            }\n",
        "\n",
        "            # Save to global config (required for plotting cells)\n",
        "            self.analysis_config['trimfill_results'] = self.trimfill_results\n",
        "\n",
        "            return self.trimfill_results\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error running Trim-and-Fill: {str(e)}\")\n",
        "\n",
        "    def get_combined_assessment(self):\n",
        "        \"\"\"Generate combined interpretation of both tests\"\"\"\n",
        "        if not self.egger_results or not self.trimfill_results:\n",
        "            return None\n",
        "\n",
        "        egger_p = self.egger_results['p_value']\n",
        "        k0 = self.trimfill_results['k0']\n",
        "\n",
        "        egger_bias = egger_p < 0.10\n",
        "        tf_bias = k0 > 0\n",
        "\n",
        "        if egger_bias and tf_bias:\n",
        "            assessment = \"HIGH RISK\"\n",
        "            color = \"#dc3545\"\n",
        "            icon = \"\u26a0\ufe0f\"\n",
        "            message = \"Both tests suggest publication bias\"\n",
        "        elif egger_bias or tf_bias:\n",
        "            assessment = \"MODERATE RISK\"\n",
        "            color = \"#ffc107\"\n",
        "            icon = \"\u26a1\"\n",
        "            message = \"One test suggests publication bias\"\n",
        "        else:\n",
        "            assessment = \"LOW RISK\"\n",
        "            color = \"#28a745\"\n",
        "            icon = \"\u2713\"\n",
        "            message = \"Neither test suggests publication bias\"\n",
        "\n",
        "        return {\n",
        "            'assessment': assessment,\n",
        "            'color': color,\n",
        "            'icon': icon,\n",
        "            'message': message,\n",
        "            'egger_bias': egger_bias,\n",
        "            'tf_bias': tf_bias\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 2: VIEW - UI Components & HTML Generation\n",
        "# =============================================================================\n",
        "\n",
        "class PublicationBiasView:\n",
        "    \"\"\"\n",
        "    View: Handles all UI rendering, widgets, and HTML generation.\n",
        "    No business logic - only presentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.setup_widgets()\n",
        "\n",
        "    def setup_widgets(self):\n",
        "        \"\"\"Create all UI widgets\"\"\"\n",
        "        # Output tabs\n",
        "        self.tab_egger = widgets.Output()\n",
        "        self.tab_trimfill = widgets.Output()\n",
        "        self.tab_combined = widgets.Output()\n",
        "        self.tab_publication = widgets.Output()\n",
        "        self.tab_export = widgets.Output()\n",
        "\n",
        "        self.tabs = widgets.Tab(children=[\n",
        "            self.tab_egger,\n",
        "            self.tab_trimfill,\n",
        "            self.tab_combined,\n",
        "            self.tab_publication,\n",
        "            self.tab_export\n",
        "        ])\n",
        "\n",
        "        self.tabs.set_title(0, '\ud83d\udcca Egger\\'s Test')\n",
        "        self.tabs.set_title(1, '\ud83d\udcc9 Trim-and-Fill')\n",
        "        self.tabs.set_title(2, '\ud83d\udd0d Combined Assessment')\n",
        "        self.tabs.set_title(3, '\ud83d\udcdd Publication Text')\n",
        "        self.tabs.set_title(4, '\ud83d\udcbe Export')\n",
        "\n",
        "        # Run button\n",
        "        self.run_button = widgets.Button(\n",
        "            description='\u25b6 Run Publication Bias Analysis',\n",
        "            button_style='primary',\n",
        "            icon='play',\n",
        "            layout=widgets.Layout(width='300px')\n",
        "        )\n",
        "\n",
        "        # Export button\n",
        "        self.export_button = widgets.Button(\n",
        "            description=\"\ud83d\udce5 Download Bias Report\",\n",
        "            button_style='info',\n",
        "            icon='file-excel',\n",
        "            layout=widgets.Layout(width='300px', height='40px')\n",
        "        )\n",
        "\n",
        "    def clear_all_tabs(self):\n",
        "        \"\"\"Clear output from all tabs\"\"\"\n",
        "        for tab in [self.tab_egger, self.tab_trimfill, self.tab_combined,\n",
        "                    self.tab_publication, self.tab_export]:\n",
        "            tab.clear_output()\n",
        "\n",
        "    def display_error(self, tab, message):\n",
        "        \"\"\"Display error message in specified tab\"\"\"\n",
        "        with tab:\n",
        "            display(HTML(f\"<div style='color: red;'>\u274c {message}</div>\"))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Egger's Test Visualization\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_eggers_results(self, egger_results, n_obs, n_studies):\n",
        "        \"\"\"Render Egger's test results\"\"\"\n",
        "        with self.tab_egger:\n",
        "            clear_output()\n",
        "\n",
        "            intercept = egger_results['intercept']\n",
        "            se = egger_results['se']\n",
        "            p_value = egger_results['p_value']\n",
        "            t_stat = egger_results['t_stat']\n",
        "            df = egger_results['df']\n",
        "\n",
        "            sig = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
        "            color = \"#dc3545\" if p_value < 0.05 else \"#28a745\"\n",
        "\n",
        "            html = f\"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h2 style='color: #2c3e50; margin-bottom: 20px;'>Egger's Regression Test for Funnel Plot Asymmetry</h2>\n",
        "\n",
        "            <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; margin-bottom: 10px;'>ASYMMETRY TEST</div>\n",
        "                    <h1 style='margin: 0; font-size: 2.5em;'>{\"Significant\" if p_value < 0.05 else \"Not Significant\"}</h1>\n",
        "                    <p style='margin: 10px 0 0 0; font-size: 1.2em;'>p {p_value:.4g} {sig}</p>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div style='display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-bottom: 20px;'>\n",
        "                <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid #007bff;'>\n",
        "                    <div style='color: #6c757d; font-size: 0.9em;'>Intercept (\u03b2\u2080)</div>\n",
        "                    <div style='font-size: 1.5em; font-weight: bold;'>{intercept:.4f}</div>\n",
        "                    <div style='color: #6c757d; font-size: 0.85em; margin-top: 5px;'>SE = {se:.4f}</div>\n",
        "                </div>\n",
        "                <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border-left: 4px solid {color};'>\n",
        "                    <div style='color: #6c757d; font-size: 0.9em;'>P-value</div>\n",
        "                    <div style='font-size: 1.5em; font-weight: bold; color: {color};'>{p_value:.4g}</div>\n",
        "                    <div style='color: #6c757d; font-size: 0.85em; margin-top: 5px;'>t({df}) = {t_stat:.2f}</div>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "                <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "                <p style='margin: 0; font-size: 1.05em;'>\n",
        "            \"\"\"\n",
        "\n",
        "            if p_value < 0.05:\n",
        "                html += f\"\"\"<b style='color: #dc3545;'>\u26a0\ufe0f Significant funnel plot asymmetry detected.</b><br>\n",
        "                    This suggests potential publication bias or other sources of small-study effects.\n",
        "                    Smaller studies tend to report {'larger' if intercept > 0 else 'smaller'} effect sizes than larger studies.\n",
        "                    <br><br>However, asymmetry can also arise from genuine heterogeneity, methodological differences, or chance.\"\"\"\n",
        "            elif p_value < 0.10:\n",
        "                html += f\"\"\"<b style='color: #ffc107;'>\u26a1 Marginal evidence of asymmetry (p < 0.10).</b><br>\n",
        "                    Some suggestion of funnel plot asymmetry. Consider examining the funnel plot visually (Cell 12b).\"\"\"\n",
        "            else:\n",
        "                html += f\"\"\"<b style='color: #28a745;'>\u2713 No significant funnel plot asymmetry.</b><br>\n",
        "                    Little evidence of publication bias based on Egger's test. The distribution of effect sizes appears symmetric across study sizes.\"\"\"\n",
        "\n",
        "            html += f\"\"\"\n",
        "                </p>\n",
        "            </div>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Test Details</h3>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                <p style='margin: 5px 0;'><b>Method:</b> Three-level meta-regression (robust to within-study dependencies)</p>\n",
        "                <p style='margin: 5px 0;'><b>Predictor:</b> Standard error (SE)</p>\n",
        "                <p style='margin: 5px 0;'><b>Outcome:</b> Effect size</p>\n",
        "                <p style='margin: 5px 0;'><b>Sample:</b> {n_obs} observations from {n_studies} studies</p>\n",
        "                <p style='margin: 5px 0;'><b>Degrees of Freedom:</b> {df}</p>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "                <p style='margin: 0;'><b>\ud83d\udcca Next Step:</b> Use Cell 12b to generate the funnel plot for visual inspection of asymmetry.</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "            display(HTML(html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Trim-and-Fill Visualization\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_trimfill_results(self, tf_results, n_obs, n_studies):\n",
        "        \"\"\"Render Trim-and-Fill results\"\"\"\n",
        "        with self.tab_trimfill:\n",
        "            clear_output()\n",
        "\n",
        "            k0 = tf_results['k0']\n",
        "            side = tf_results['side']\n",
        "            pooled_orig = tf_results['pooled_original']\n",
        "            pooled_fill = tf_results['pooled_filled']\n",
        "\n",
        "            pct_change = abs((pooled_fill - pooled_orig) / pooled_orig) * 100 if pooled_orig != 0 else 0\n",
        "\n",
        "            html = f\"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h2 style='color: #2c3e50; margin-bottom: 20px;'>Trim-and-Fill Analysis</h2>\n",
        "\n",
        "            <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; margin-bottom: 10px;'>ESTIMATED MISSING STUDIES</div>\n",
        "                    <h1 style='margin: 0; font-size: 3em;'>{k0}</h1>\n",
        "                    <p style='margin: 10px 0 0 0; font-size: 1.2em;'>{side.capitalize()} side</p>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "                <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation</h4>\n",
        "                <p style='margin: 0; font-size: 1.05em;'>\n",
        "            \"\"\"\n",
        "\n",
        "            if k0 == 0:\n",
        "                html += \"\"\"<b style='color: #28a745;'>\u2713 No missing studies detected.</b><br>\n",
        "                    The funnel plot appears symmetric. No evidence of publication bias via trim-and-fill.\"\"\"\n",
        "            else:\n",
        "                html += f\"\"\"<b style='color: #dc3545;'>\u26a0\ufe0f {k0} potentially missing studies estimated.</b><br>\n",
        "                    After imputation, the effect changes by {pct_change:.1f}%. This suggests {'substantial' if pct_change > 20 else 'moderate' if pct_change > 10 else 'minimal'} potential impact of publication bias.\"\"\"\n",
        "\n",
        "            html += f\"\"\"\n",
        "                </p>\n",
        "            </div>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Effect Size Comparison</h3>\n",
        "            <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "                <thead style='background-color: #2c3e50; color: white;'>\n",
        "                    <tr>\n",
        "                        <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Estimate</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Effect</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>SE</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>95% CI</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr style='background-color: #f8f9fa;'>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Original</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_results['pooled_original']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_results['se_original']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{tf_results['ci_lower_original']:.4f}, {tf_results['ci_upper_original']:.4f}]</td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Adjusted</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_results['pooled_filled']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{tf_results['se_filled']:.4f}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>[{tf_results['ci_lower_filled']:.4f}, {tf_results['ci_upper_filled']:.4f}]</td>\n",
        "                    </tr>\n",
        "                    <tr style='background-color: #fff3cd;'>\n",
        "                    <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Change</b></td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;'>{pooled_fill - pooled_orig:+.4f}</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>\u2014</td>\n",
        "                    <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>{pct_change:.1f}% change</td>\n",
        "                    </tr>\n",
        "                    </tbody>\n",
        "                    </table>\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Method Details</h3>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                <p style='margin: 5px 0;'><b>Method:</b> Duval & Tweedie L0 estimator</p>\n",
        "                <p style='margin: 5px 0;'><b>Side:</b> {side.capitalize()} (automatically detected)</p>\n",
        "                <p style='margin: 5px 0;'><b>Original studies:</b> {n_obs} observations from {n_studies} studies</p>\n",
        "                <p style='margin: 5px 0;'><b>Imputed studies:</b> {k0}</p>\n",
        "                <p style='margin: 5px 0;'><b>Total after filling:</b> {n_obs + k0}</p>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "                <p style='margin: 0;'><b>\ud83d\udcca Next Step:</b> Use Cell 14b to visualize the trim-and-fill funnel plot showing original and imputed studies.</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "            display(HTML(html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Combined Assessment Visualization\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_combined_assessment(self, assessment, egger_results, tf_results, n_studies):\n",
        "        \"\"\"Render combined assessment of both tests\"\"\"\n",
        "        with self.tab_combined:\n",
        "            clear_output()\n",
        "\n",
        "            egger_p = egger_results['p_value']\n",
        "            k0 = tf_results['k0']\n",
        "            pct_change = abs((tf_results['pooled_filled'] - tf_results['pooled_original']) / tf_results['pooled_original']) * 100 if tf_results['pooled_original'] != 0 else 0\n",
        "\n",
        "            html = f\"\"\"\n",
        "            <div style='padding: 20px;'>\n",
        "            <h2 style='color: #2c3e50; margin-bottom: 20px;'>Combined Publication Bias Assessment</h2>\n",
        "\n",
        "            <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; margin-bottom: 10px;'>OVERALL ASSESSMENT</div>\n",
        "                    <h1 style='margin: 0; font-size: 2.5em;'>{assessment['icon']} {assessment['assessment']}</h1>\n",
        "                    <p style='margin: 10px 0 0 0; font-size: 1.2em;'>{assessment['message']}</p>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Summary of Tests</h3>\n",
        "            <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "                <thead style='background-color: #2c3e50; color: white;'>\n",
        "                    <tr>\n",
        "                        <th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>Test</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Result</th>\n",
        "                        <th style='padding: 12px; text-align: center; border: 1px solid #dee2e6;'>Evidence of Bias</th>\n",
        "                    </tr>\n",
        "                </thead>\n",
        "                <tbody>\n",
        "                    <tr style='background-color: #f8f9fa;'>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Egger's Test</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>p = {egger_p:.4g}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>\n",
        "                            <span style='color: {\"#dc3545\" if assessment['egger_bias'] else \"#28a745\"}; font-weight: bold;'>\n",
        "                                {\"Yes\" if assessment['egger_bias'] else \"No\"}\n",
        "                            </span>\n",
        "                        </td>\n",
        "                    </tr>\n",
        "                    <tr>\n",
        "                        <td style='padding: 10px; border: 1px solid #dee2e6;'><b>Trim-and-Fill</b></td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>k\u2080 = {k0}</td>\n",
        "                        <td style='padding: 10px; text-align: center; border: 1px solid #dee2e6;'>\n",
        "                            <span style='color: {\"#dc3545\" if assessment['tf_bias'] else \"#28a745\"}; font-weight: bold;'>\n",
        "                                {\"Yes\" if assessment['tf_bias'] else \"No\"}\n",
        "                            </span>\n",
        "                        </td>\n",
        "                    </tr>\n",
        "                </tbody>\n",
        "            </table>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Detailed Interpretation</h3>\n",
        "            <div style='background-color: #e7f3ff; padding: 20px; border-radius: 5px; margin-bottom: 20px;'>\n",
        "            \"\"\"\n",
        "\n",
        "            if assessment['egger_bias'] and assessment['tf_bias']:\n",
        "                html += f\"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Convergent Evidence:</b> Both tests indicate potential publication bias.</p>\n",
        "                <ul style='margin: 10px 0;'>\n",
        "                    <li>Egger's test detected significant funnel plot asymmetry (p = {egger_p:.4g})</li>\n",
        "                    <li>Trim-and-fill estimated {k0} missing studies</li>\n",
        "                    <li>Effect size changed by {pct_change:.1f}% after adjustment</li>\n",
        "                </ul>\n",
        "                <p style='margin: 10px 0 0 0;'><b>Recommendation:</b> Interpret main results with caution. Consider reporting both original and adjusted estimates. Discuss potential impact of publication bias on conclusions.</p>\n",
        "                \"\"\"\n",
        "            elif assessment['egger_bias'] or assessment['tf_bias']:\n",
        "                which = \"Egger's test\" if assessment['egger_bias'] else \"Trim-and-fill\"\n",
        "                which_not = \"Trim-and-fill\" if assessment['egger_bias'] else \"Egger's test\"\n",
        "                html += f\"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Mixed Evidence:</b> {which} suggests bias, but {which_not} does not.</p>\n",
        "                <ul style='margin: 10px 0;'>\n",
        "                    <li>{'Funnel plot asymmetry detected' if assessment['egger_bias'] else 'No significant asymmetry'} (Egger p = {egger_p:.4g})</li>\n",
        "                    <li>{k0} missing studies estimated (Trim-and-fill)</li>\n",
        "                </ul>\n",
        "                <p style='margin: 10px 0 0 0;'><b>Recommendation:</b> Exercise appropriate caution. Differences between tests may reflect limited power or different aspects of bias. Visual inspection of funnel plots recommended.</p>\n",
        "                \"\"\"\n",
        "            else:\n",
        "                html += f\"\"\"\n",
        "                <p style='margin: 5px 0;'><b>Consistent Evidence:</b> Neither test provides evidence of publication bias.</p>\n",
        "                <ul style='margin: 10px 0;'>\n",
        "                    <li>No significant funnel plot asymmetry (Egger p = {egger_p:.4g})</li>\n",
        "                    <li>No missing studies estimated (k\u2080 = 0)</li>\n",
        "                </ul>\n",
        "                <p style='margin: 10px 0 0 0;'><b>Recommendation:</b> Main results appear robust to publication bias. Standard reporting is appropriate.</p>\n",
        "                \"\"\"\n",
        "\n",
        "            html += f\"\"\"\n",
        "            </div>\n",
        "\n",
        "            <h3 style='color: #2c3e50; border-bottom: 2px solid #dee2e6; padding-bottom: 10px;'>Contextual Factors</h3>\n",
        "            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;'>\n",
        "                <p style='margin: 5px 0;'><b>Sample size:</b> k = {n_studies} studies {'(adequate power)' if n_studies >= 10 else '(limited power)' if n_studies >= 5 else '(very limited power)'}</p>\n",
        "                <p style='margin: 5px 0;'><i>Note: Publication bias tests have limited power with fewer than 10 studies</i></p>\n",
        "            </div>\n",
        "\n",
        "            <div style='background-color: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107; margin-top: 20px;'>\n",
        "                <p style='margin: 0;'><b>\ud83d\udcca Visualization:</b> Use Cells 12b and 14b to create funnel plots for visual assessment and manuscript figures.</p>\n",
        "            </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "            display(HTML(html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Publication Text Generation\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_publication_text(self, egger_results, tf_results, n_studies):\n",
        "        \"\"\"Render publication-ready text\"\"\"\n",
        "        with self.tab_publication:\n",
        "            clear_output()\n",
        "\n",
        "            display(HTML(\"<h3 style='color: #2c3e50;'>\ud83d\udcdd Publication-Ready Results Text</h3>\"))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Copy and paste this formatted text into your manuscript:</p>\"))\n",
        "\n",
        "            # Generate methods and results text\n",
        "            methods_html = self._generate_methods_text()\n",
        "            results_html = self._generate_results_text(egger_results, tf_results, n_studies)\n",
        "\n",
        "            display(HTML(methods_html))\n",
        "            display(HTML(results_html))\n",
        "\n",
        "            # Save combined text for audit report\n",
        "            if 'ANALYSIS_CONFIG' in globals():\n",
        "                globals()['ANALYSIS_CONFIG']['bias_text'] = methods_html + \"<br><hr><br>\" + results_html\n",
        "\n",
        "    def _generate_methods_text(self):\n",
        "        \"\"\"Generate Materials and Methods section\"\"\"\n",
        "        db = {\n",
        "            'egger': \"Egger, M., Davey Smith, G., Schneider, M., & Minder, C. (1997). Bias in meta-analysis detected by a simple, graphical test. <i>BMJ</i>, 315(7109), 629-634.\",\n",
        "            'trimfill': \"Duval, S., & Tweedie, R. (2000). Trim and fill: A simple funnel-plot-based method of testing and adjusting for publication bias in meta-analysis. <i>Biometrics</i>, 56(2), 455-463.\",\n",
        "            'rothstein': \"Rothstein, H. R., Sutton, A. J., & Borenstein, M. (Eds.). (2005). <i>Publication Bias in Meta-Analysis: Prevention, Assessment and Adjustments</i>. Chichester, UK: John Wiley & Sons.\",\n",
        "            'tool': \"<b>[CITATION FOR THIS TOOL]:</b> Author, A. A. (202X). <i>Co-Meta: An Interactive Pipeline for Meta-Analysis</i>. [Repository/DOI].\"\n",
        "        }\n",
        "\n",
        "        html = f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt; line-height: 1.8; padding: 20px; background-color: #ffffff; border: 1px solid #eee; margin-bottom: 20px;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-top: 0;'>Materials and Methods</h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Publication Bias Assessment.</b> To assess the potential impact of publication bias (the \"file-drawer problem\"), we employed two complementary methods [1].\n",
        "        First, we used Egger's linear regression test to statistically evaluate funnel plot asymmetry [2].\n",
        "        This test regresses the standardized effect size on precision (1/SE), where a significant intercept indicates asymmetry.\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Sensitivity Analysis.</b> Additionally, we applied the Trim-and-Fill method [3] to estimate the number of missing studies due to suppression of non-significant results.\n",
        "        This non-parametric method iteratively removes (trims) the most extreme small studies from the positive side of the funnel plot and re-computes the effect size, then adds (fills) imputed mirror-image studies to restore symmetry.\n",
        "        All analyses were conducted using the Co-Meta toolkit [4].\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 20px; font-size: 11pt;'>References</h4>\n",
        "        <ol style='font-size: 10pt; color: #555;'>\n",
        "            <li>{db['rothstein']}</li>\n",
        "            <li>{db['egger']}</li>\n",
        "            <li>{db['trimfill']}</li>\n",
        "            <li>{db['tool']}</li>\n",
        "        </ol>\n",
        "        </div>\"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    def _generate_results_text(self, egger_results, tf_results, n_studies, ci_level=95):\n",
        "        \"\"\"Generate publication-ready results text\"\"\"\n",
        "        egger_p = egger_results['p_value']\n",
        "        egger_int = egger_results['intercept']\n",
        "        egger_se = egger_results['se']\n",
        "\n",
        "        k0 = tf_results['k0']\n",
        "        side = tf_results['side']\n",
        "        orig_effect = tf_results['pooled_original']\n",
        "        adj_effect = tf_results['pooled_filled']\n",
        "\n",
        "        egger_sig = egger_p < 0.05\n",
        "        tf_bias = k0 > 0\n",
        "\n",
        "        egger_sig_text = \"significant\" if egger_sig else \"non-significant\"\n",
        "        p_format = f\"< 0.001\" if egger_p < 0.001 else f\"= {egger_p:.3f}\"\n",
        "\n",
        "        text = f\"\"\"<div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt; line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "<h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>Publication Bias Assessment</h3>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "We assessed potential publication bias using two complementary methods: Egger's regression test for funnel plot asymmetry and the Duval and Tweedie trim-and-fill procedure.\n",
        "</p>\n",
        "\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Egger's Regression Test</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "Egger's regression test evaluates funnel plot asymmetry by regressing effect sizes on their standard errors, with the intercept testing for asymmetry. We employed a three-level meta-regression model to account for the nested structure of effect sizes within studies, providing robust estimates that accommodate within-study dependencies.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The Egger's test intercept was <b>{egger_sig_text}</b> (\u03b2\u2080 = {egger_int:.3f}, SE = {egger_se:.3f}, <i>p</i> {p_format}). \"\"\"\n",
        "\n",
        "        if egger_sig:\n",
        "            text += f\"\"\"This indicates <b>significant funnel plot asymmetry</b>, suggesting potential publication bias or other sources of small-study effects. The {'positive' if egger_int > 0 else 'negative'} intercept suggests that smaller studies tend to report {'larger' if egger_int > 0 else 'smaller'} effect sizes than larger studies.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "However, it is important to note that funnel plot asymmetry can arise from sources other than publication bias, including genuine heterogeneity, chance, or differences in methodological quality between small and large studies. [<i>Consider discussing which alternative explanation(s) might apply to your meta-analysis.</i>]\n",
        "</p>\n",
        "\"\"\"\n",
        "        else:\n",
        "            text += f\"\"\"This suggests <b>no significant funnel plot asymmetry</b>, providing little evidence of publication bias based on this test. The symmetry of effect sizes across studies of different sizes supports the validity of the meta-analytic findings.\n",
        "</p>\n",
        "\"\"\"\n",
        "\n",
        "        # Trim-and-fill section\n",
        "        text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Trim-and-Fill Analysis</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The trim-and-fill method (Duval & Tweedie, 2000) provides a non-parametric approach to estimating the number of studies missing due to publication bias. The procedure iteratively trims the most extreme small studies from the {'positive' if side == 'right' else 'negative'} side of the funnel plot, re-computes the pooled effect, and then adds (fills) imputed mirror-image studies to restore funnel plot symmetry.\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "\"\"\"\n",
        "\n",
        "        if k0 == 0:\n",
        "            text += f\"\"\"The trim-and-fill procedure estimated <b>zero missing studies</b> (k\u2080 = 0), suggesting no asymmetry in the distribution of effect sizes. The pooled effect estimate remained unchanged at {orig_effect:.3f} ({ci_level:.0f}% CI [{tf_results['ci_lower_original']:.3f}, {tf_results['ci_upper_original']:.3f}]).\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "This result is consistent with low risk of publication bias and suggests that the observed pooled effect size is robust to selective reporting.\n",
        "</p>\n",
        "\"\"\"\n",
        "        else:\n",
        "            pct_change = abs((adj_effect - orig_effect) / orig_effect) * 100 if orig_effect != 0 else 0\n",
        "            direction_change = \"decreased\" if adj_effect < orig_effect else \"increased\"\n",
        "\n",
        "            text += f\"\"\"The trim-and-fill procedure estimated <b>{k0} potentially missing studies</b> on the {side} side of the funnel plot. After imputing these missing studies, the adjusted pooled effect was {adj_effect:.3f} ({ci_level:.0f}% CI [{tf_results['ci_lower_filled']:.3f}, {tf_results['ci_upper_filled']:.3f}]), compared to the original estimate of {orig_effect:.3f} ({ci_level:.0f}% CI [{tf_results['ci_lower_original']:.3f}, {tf_results['ci_upper_original']:.3f}]).\n",
        "</p>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "The pooled effect {direction_change} by <b>{abs(adj_effect - orig_effect):.3f}</b> units ({pct_change:.1f}% relative change) after adjustment. \"\"\"\n",
        "\n",
        "            if pct_change > 20:\n",
        "                text += f\"\"\"This substantial change suggests that publication bias, if present, could have a meaningful impact on the meta-analytic conclusions. The adjusted estimate should be considered as a sensitivity analysis, though it should be noted that trim-and-fill can sometimes overestimate the number of missing studies.\n",
        "\"\"\"\n",
        "            elif pct_change > 10:\n",
        "                text += f\"\"\"This moderate change suggests some potential impact of publication bias on the pooled estimate, though the direction and significance of the effect remain {'' if adj_effect * orig_effect > 0 else 'un'}consistent between original and adjusted estimates.\n",
        "\"\"\"\n",
        "            else:\n",
        "                text += f\"\"\"This small change suggests that publication bias, if present, has minimal impact on the meta-analytic conclusions. The robustness of the pooled estimate to adjustment increases confidence in the findings.\n",
        "\"\"\"\n",
        "\n",
        "            text += \"</p>\"\n",
        "\n",
        "        # Combined interpretation\n",
        "        text += f\"\"\"\n",
        "<h4 style='color: #34495e; margin-top: 25px;'>Combined Interpretation</h4>\n",
        "\n",
        "<p style='text-align: justify;'>\n",
        "\"\"\"\n",
        "\n",
        "        if egger_sig and tf_bias:\n",
        "            text += f\"\"\"Both Egger's test and the trim-and-fill procedure suggest potential publication bias. Egger's test detected significant asymmetry (p {p_format}), and trim-and-fill estimated {k0} missing studies. This convergent evidence warrants cautious interpretation of the meta-analytic findings. \"\"\"\n",
        "            if k0 > 0:\n",
        "                pct_change = abs((adj_effect - orig_effect) / orig_effect) * 100 if orig_effect != 0 else 0\n",
        "                if pct_change > 10:\n",
        "                    text += f\"\"\"Given the substantial adjustment to the pooled effect ({pct_change:.1f}% change), we recommend reporting both the original and adjusted estimates and considering the adjusted estimate in sensitivity analyses.\n",
        "\"\"\"\n",
        "                else:\n",
        "                    text += f\"\"\"However, the modest change in the pooled effect ({pct_change:.1f}%) suggests the main conclusions are relatively robust to potential publication bias.\n",
        "\"\"\"\n",
        "        elif egger_sig or tf_bias:\n",
        "            which_test = \"Egger's test\" if egger_sig else \"trim-and-fill\"\n",
        "            text += f\"\"\"The evidence for publication bias is mixed. {which_test.capitalize()} suggests potential bias, but the other test does not. This inconsistency could reflect differences in what these tests detect (asymmetry vs. missing studies) or limited statistical power. We recommend interpreting results with appropriate caution and considering whether other factors (heterogeneity, methodological quality) might explain any observed asymmetry.\n",
        "\"\"\"\n",
        "        else:\n",
        "            text += f\"\"\"Neither Egger's test nor trim-and-fill provided evidence of publication bias. The non-significant Egger's intercept (p {p_format}) and absence of estimated missing studies (k\u2080 = 0) both suggest low risk of selective reporting. These results support the validity and robustness of the meta-analytic findings.\n",
        "\"\"\"\n",
        "\n",
        "        text += \"</p>\"\n",
        "\n",
        "        # Tables\n",
        "        text += f\"\"\"\n",
        "<hr style='margin: 30px 0; border: none; border-top: 1px solid #bdc3c7;'>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 25px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>\ud83d\udcca Table 1. Publication Bias Assessment Summary</h4>\n",
        "<table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "<thead style='background-color: #34495e; color: white;'>\n",
        "<tr>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Test</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Statistic</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>p-value</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Interpretation</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Egger's Test</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>\u03b2\u2080 = {egger_int:.3f} (SE = {egger_se:.3f})</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{\"<0.001\" if egger_p < 0.001 else f\"{egger_p:.3f}\"}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>{\"Significant asymmetry\" if egger_sig else \"No significant asymmetry\"}</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Trim-and-Fill</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>k\u2080 = {k0} ({side} side)</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>\u2014</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>{\"Missing studies detected\" if k0 > 0 else \"No missing studies\"}</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #ecf0f1; padding: 20px; border-left: 4px solid #3498db; margin-top: 15px;'>\n",
        "<h4 style='margin-top: 0; color: #2c3e50;'>\ud83d\udcca Table 2. Effect Size Estimates</h4>\n",
        "<table style='width: 100%; border-collapse: collapse; margin-top: 15px; background-color: white;'>\n",
        "<thead style='background-color: #34495e; color: white;'>\n",
        "<tr>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: left;'>Model</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Pooled Effect</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>95% CI</th>\n",
        "<th style='border: 1px solid #bdc3c7; padding: 10px; text-align: center;'>Change</th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr style='background-color: #f8f9fa;'>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Original</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{orig_effect:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{tf_results['ci_lower_original']:.3f}, {tf_results['ci_upper_original']:.3f}]</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>\u2014</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px;'>Trim-and-Fill Adjusted</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{adj_effect:.3f}</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>[{tf_results['ci_lower_filled']:.3f}, {tf_results['ci_upper_filled']:.3f}]</td>\n",
        "<td style='border: 1px solid #bdc3c7; padding: 8px; text-align: center;'>{adj_effect - orig_effect:+.3f}</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n",
        "<p style='margin-top: 10px; font-size: 0.9em; color: #6c757d;'><i>Note:</i> Negative change indicates adjusted effect is smaller than original.</p>\n",
        "</div>\n",
        "\n",
        "<div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin-top: 15px;'>\n",
        "<p style='margin: 0;'><b>\ud83d\udca1 Tip:</b> Select all text (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C), and paste into your word processor. Use Cells 12b and 14b to generate funnel plots for your manuscript figures.</p>\n",
        "</div>\n",
        "\n",
        "</div>\"\"\"\n",
        "\n",
        "        return text\n",
        "\n",
        "    def render_export_tab(self):\n",
        "        \"\"\"Setup export tab\"\"\"\n",
        "        with self.tab_export:\n",
        "            display(HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcbe Download Audit Report</h3>\"))\n",
        "            display(HTML(\"<p>Export results of Egger's test and Trim-and-Fill analysis.</p>\"))\n",
        "            display(self.export_button)\n",
        "\n",
        "    def display_ui(self):\n",
        "        \"\"\"Display the complete UI\"\"\"\n",
        "        display(HTML(\"<h3>\ud83d\udcc9 Publication Bias Diagnostics (MVC Refactored)</h3>\"))\n",
        "        display(HTML(\"<p style='color: #6c757d;'>Assess publication bias using Egger's test and Trim-and-Fill. Results appear in organized tabs below.</p>\"))\n",
        "        display(self.run_button)\n",
        "        display(self.tabs)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3: CONTROLLER - Event Handling & Coordination\n",
        "# =============================================================================\n",
        "\n",
        "class PublicationBiasController:\n",
        "    \"\"\"\n",
        "    Controller: Coordinates Model and View, handles user interactions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = PublicationBiasModel()\n",
        "        self.view = PublicationBiasView()\n",
        "\n",
        "        # Wire up event handlers\n",
        "        self.view.run_button.on_click(self.on_run_analysis)\n",
        "        self.view.export_button.on_click(self.on_export_report)\n",
        "\n",
        "    def on_run_analysis(self, button):\n",
        "        \"\"\"Handle run button click\"\"\"\n",
        "        self.view.clear_all_tabs()\n",
        "\n",
        "        try:\n",
        "            # Initialize model\n",
        "            self.model.initialize()\n",
        "            n_obs, n_studies = self.model.get_dataset_info()\n",
        "\n",
        "            # Run Egger's test\n",
        "            try:\n",
        "                egger_results = self.model.run_eggers_test()\n",
        "                self.view.render_eggers_results(egger_results, n_obs, n_studies)\n",
        "            except Exception as e:\n",
        "                self.view.display_error(self.view.tab_egger, f\"Error running Egger's test: {str(e)}\")\n",
        "                return\n",
        "\n",
        "            # Run Trim-and-Fill\n",
        "            try:\n",
        "                tf_results = self.model.run_trimfill_analysis()\n",
        "                self.view.render_trimfill_results(tf_results, n_obs, n_studies)\n",
        "            except Exception as e:\n",
        "                self.view.display_error(self.view.tab_trimfill, f\"Error running Trim-and-Fill: {str(e)}\")\n",
        "                return\n",
        "\n",
        "            # Combined assessment\n",
        "            assessment = self.model.get_combined_assessment()\n",
        "            if assessment:\n",
        "                self.view.render_combined_assessment(assessment, egger_results, tf_results, n_studies)\n",
        "\n",
        "            # Publication text\n",
        "            self.view.render_publication_text(egger_results, tf_results, n_studies)\n",
        "\n",
        "            # Setup export tab\n",
        "            self.view.render_export_tab()\n",
        "\n",
        "        except ValueError as e:\n",
        "            self.view.display_error(self.view.tab_egger, str(e))\n",
        "        except Exception as e:\n",
        "            self.view.display_error(self.view.tab_egger, f\"Unexpected error: {str(e)}\")\n",
        "\n",
        "    def on_export_report(self, button):\n",
        "        \"\"\"Handle export button click\"\"\"\n",
        "        try:\n",
        "            # Call global export function if it exists\n",
        "            if 'export_analysis_report' in globals():\n",
        "                export_func = globals()['export_analysis_report']\n",
        "                export_func(report_type='publication_bias', filename_prefix='Publication_Bias_Audit')\n",
        "            else:\n",
        "                with self.view.tab_export:\n",
        "                  display(HTML(\"<div style='color: orange;'>\u26a0\ufe0f Export function not found. Please ensure previous cells have been run.</div>\"))\n",
        "        except Exception as e:\n",
        "            with self.view.tab_export:\n",
        "                display(HTML(f\"<div style='color: red;'>\u274c Export failed: {str(e)}</div>\"))\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Initialize and display the UI\"\"\"\n",
        "        self.view.display_ui()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION - Instantiate and Run\n",
        "# =============================================================================\n",
        "\n",
        "controller = PublicationBiasController()\n",
        "controller.start()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vCNH2fqWHYHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 17. Publication Bias: PET-PEESE - DATA LAYER (Model)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 1/4: DATA LAYER - PET-PEESE CORRECTION\n",
        "# Purpose: Centralized data management for PET-PEESE analysis\n",
        "# Dependencies: ANALYSIS_CONFIG global dictionary\n",
        "# Math validated: PET (Effect ~ SE) and PEESE (Effect ~ Variance) regression\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA CLASSES\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class PETPEESEConfig:\n",
        "    \"\"\"Configuration for PET-PEESE analysis\"\"\"\n",
        "    effect_col: str\n",
        "    var_col: str\n",
        "    p_threshold: float = 0.10  # Decision threshold for PET slope\n",
        "    alpha: float = 0.05\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration\"\"\"\n",
        "        if not self.effect_col:\n",
        "            raise ValueError(\"effect_col cannot be empty\")\n",
        "        if not self.var_col:\n",
        "            raise ValueError(\"var_col cannot be empty\")\n",
        "        if self.p_threshold <= 0 or self.p_threshold >= 1:\n",
        "            raise ValueError(f\"p_threshold must be between 0 and 1, got {self.p_threshold}\")\n",
        "        if self.alpha <= 0 or self.alpha >= 1:\n",
        "            raise ValueError(f\"alpha must be between 0 and 1, got {self.alpha}\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PETResult:\n",
        "    \"\"\"Results from PET model (Effect ~ SE)\"\"\"\n",
        "    intercept: float\n",
        "    intercept_se: float\n",
        "    intercept_ci: Tuple[float, float]\n",
        "    slope: float\n",
        "    slope_se: float\n",
        "    slope_p: float\n",
        "\n",
        "    # Full estimates (for advanced users)\n",
        "    estimates: Optional[Dict[str, Any]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PEESEResult:\n",
        "    \"\"\"Results from PEESE model (Effect ~ Variance)\"\"\"\n",
        "    intercept: float\n",
        "    intercept_se: float\n",
        "    intercept_ci: Tuple[float, float]\n",
        "    slope: float\n",
        "    slope_se: float\n",
        "    slope_p: float\n",
        "\n",
        "    # Full estimates (for advanced users)\n",
        "    estimates: Optional[Dict[str, Any]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class NaiveEstimate:\n",
        "    \"\"\"Original unadjusted pooled estimate\"\"\"\n",
        "    estimate: Optional[float]\n",
        "    se: Optional[float]\n",
        "    ci_lower: Optional[float]\n",
        "    ci_upper: Optional[float]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PETPEESEDecision:\n",
        "    \"\"\"Decision rule outcome\"\"\"\n",
        "    bias_detected: bool\n",
        "    p_threshold: float\n",
        "    recommended_model: str  # 'PET' or 'PEESE'\n",
        "    recommended_estimate: float\n",
        "    recommended_se: float\n",
        "    recommended_ci: Tuple[float, float]\n",
        "    rationale: str\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PETPEESEResult:\n",
        "    \"\"\"Complete PET-PEESE analysis result\"\"\"\n",
        "    pet: PETResult\n",
        "    peese: PEESEResult\n",
        "    decision: PETPEESEDecision\n",
        "    naive: NaiveEstimate\n",
        "\n",
        "    # Sample info\n",
        "    n_obs: int\n",
        "    n_studies: int\n",
        "    effect_col: str\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA MANAGER CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class PETPEESEDataManager:\n",
        "    \"\"\"\n",
        "    Centralized data access layer for PET-PEESE analysis.\n",
        "    Handles all interactions with ANALYSIS_CONFIG and data validation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize data manager.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self._config = analysis_config\n",
        "        self._validate_prerequisites()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # VALIDATION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _validate_prerequisites(self) -> None:\n",
        "        \"\"\"Validate that required configuration exists\"\"\"\n",
        "        if 'effect_col' not in self._config:\n",
        "            warnings.warn(\"effect_col not in ANALYSIS_CONFIG, using default 'hedges_g'\")\n",
        "        if 'var_col' not in self._config:\n",
        "            warnings.warn(\"var_col not in ANALYSIS_CONFIG, using default 'Vg'\")\n",
        "\n",
        "    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Validate that data is suitable for PET-PEESE analysis.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if df is None or len(df) == 0:\n",
        "            return False, \"No data available\"\n",
        "\n",
        "        if self.effect_col not in df.columns:\n",
        "            return False, f\"Effect column '{self.effect_col}' not found\"\n",
        "\n",
        "        if self.var_col not in df.columns:\n",
        "            return False, f\"Variance column '{self.var_col}' not found\"\n",
        "\n",
        "        # Check for minimum observations (need at least 3 for regression)\n",
        "        n_valid = df[[self.effect_col, self.var_col]].notna().all(axis=1).sum()\n",
        "        if n_valid < 3:\n",
        "            return False, f\"Need at least 3 valid observations for PET-PEESE, found {n_valid}\"\n",
        "\n",
        "        # Check for study ID\n",
        "        if 'id' not in df.columns:\n",
        "            warnings.warn(\"'id' column not found - will treat all observations as independent\")\n",
        "\n",
        "        return True, None\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROPERTY ACCESSORS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def analysis_data(self) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Get analysis dataset\"\"\"\n",
        "        if 'analysis_data' in self._config:\n",
        "            return self._config['analysis_data'].copy()\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def effect_col(self) -> str:\n",
        "        \"\"\"Get effect size column name\"\"\"\n",
        "        return self._config.get('effect_col', 'hedges_g')\n",
        "\n",
        "    @property\n",
        "    def var_col(self) -> str:\n",
        "        \"\"\"Get variance column name\"\"\"\n",
        "        return self._config.get('var_col', 'Vg')\n",
        "\n",
        "    @property\n",
        "    def es_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get effect size configuration\"\"\"\n",
        "        return self._config.get('es_config', {})\n",
        "\n",
        "    @property\n",
        "    def global_settings(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get global settings (with defaults)\"\"\"\n",
        "        return self._config.get('global_settings', {\n",
        "            'alpha': 0.05\n",
        "        })\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA EXTRACTION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def prepare_data(\n",
        "        self,\n",
        "        df: Optional[pd.DataFrame] = None\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Prepare and clean data for PET-PEESE analysis.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to prepare (uses analysis_data if None)\n",
        "\n",
        "        Returns:\n",
        "            Cleaned DataFrame with SE and Var columns\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If data cannot be prepared\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            df = self.analysis_data\n",
        "\n",
        "        if df is None:\n",
        "            raise ValueError(\"No data available for analysis\")\n",
        "\n",
        "        # Validate\n",
        "        is_valid, error_msg = self.validate_data(df)\n",
        "        if not is_valid:\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        # Create working copy\n",
        "        clean_df = df.copy()\n",
        "\n",
        "        # Ensure SE column exists\n",
        "        if 'SE' not in clean_df.columns:\n",
        "            if self.var_col in clean_df.columns:\n",
        "                clean_df['SE'] = np.sqrt(clean_df[self.var_col])\n",
        "            else:\n",
        "                raise ValueError(f\"Cannot compute SE: '{self.var_col}' column not found\")\n",
        "\n",
        "        # Ensure Var column exists\n",
        "        if 'Var' not in clean_df.columns:\n",
        "            if 'SE' in clean_df.columns:\n",
        "                clean_df['Var'] = clean_df['SE'] ** 2\n",
        "            elif self.var_col in clean_df.columns:\n",
        "                clean_df['Var'] = clean_df[self.var_col]\n",
        "            else:\n",
        "                raise ValueError(\"Cannot compute Variance\")\n",
        "\n",
        "        # Remove missing values\n",
        "        clean_df = clean_df[[self.effect_col, 'SE', 'Var', 'id']].dropna().copy()\n",
        "\n",
        "        # Remove zero or negative variances\n",
        "        clean_df = clean_df[clean_df['Var'] > 0].copy()\n",
        "        clean_df = clean_df[clean_df['SE'] > 0].copy()\n",
        "\n",
        "        # Final check\n",
        "        if len(clean_df) < 3:\n",
        "            raise ValueError(\n",
        "                f\"Insufficient data after cleaning: {len(clean_df)} observations. \"\n",
        "                f\"Need at least 3 for PET-PEESE analysis.\"\n",
        "            )\n",
        "\n",
        "        return clean_df\n",
        "\n",
        "    def get_naive_estimate(self) -> NaiveEstimate:\n",
        "        \"\"\"\n",
        "        Extract original unadjusted pooled estimate from overall results.\n",
        "\n",
        "        Returns:\n",
        "            NaiveEstimate object (may contain None values if not available)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            overall_res = self._config.get('overall_results', {})\n",
        "            return NaiveEstimate(\n",
        "                estimate=overall_res.get('pooled_effect_random'),\n",
        "                se=overall_res.get('pooled_SE_random_reported'),\n",
        "                ci_lower=overall_res.get('ci_lower_random'),\n",
        "                ci_upper=overall_res.get('ci_upper_random')\n",
        "            )\n",
        "        except:\n",
        "            return NaiveEstimate(\n",
        "                estimate=None,\n",
        "                se=None,\n",
        "                ci_lower=None,\n",
        "                ci_upper=None\n",
        "            )\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RESULT PERSISTENCE METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def save_petpeese_results(self, result: PETPEESEResult) -> None:\n",
        "        \"\"\"\n",
        "        Save PET-PEESE results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: PETPEESEResult object\n",
        "        \"\"\"\n",
        "        import datetime\n",
        "\n",
        "        self._config['pet_peese_results'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'pet': {\n",
        "                'intercept': result.pet.intercept,\n",
        "                'intercept_se': result.pet.intercept_se,\n",
        "                'intercept_ci': result.pet.intercept_ci,\n",
        "                'slope': result.pet.slope,\n",
        "                'slope_se': result.pet.slope_se,\n",
        "                'slope_p': result.pet.slope_p,\n",
        "            },\n",
        "            'peese': {\n",
        "                'intercept': result.peese.intercept,\n",
        "                'intercept_se': result.peese.intercept_se,\n",
        "                'intercept_ci': result.peese.intercept_ci,\n",
        "                'slope': result.peese.slope,\n",
        "                'slope_se': result.peese.slope_se,\n",
        "                'slope_p': result.peese.slope_p,\n",
        "            },\n",
        "            'decision': {\n",
        "                'bias_detected': result.decision.bias_detected,\n",
        "                'p_threshold': result.decision.p_threshold,\n",
        "                'recommended_model': result.decision.recommended_model,\n",
        "                'recommended_estimate': result.decision.recommended_estimate,\n",
        "                'recommended_se': result.decision.recommended_se,\n",
        "                'recommended_ci': result.decision.recommended_ci,\n",
        "                'rationale': result.decision.rationale,\n",
        "            },\n",
        "            'naive': {\n",
        "                'estimate': result.naive.estimate,\n",
        "                'se': result.naive.se,\n",
        "                'ci_lower': result.naive.ci_lower,\n",
        "                'ci_upper': result.naive.ci_upper,\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTILITY METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def summary_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get summary of current configuration\"\"\"\n",
        "        df = self.analysis_data\n",
        "\n",
        "        return {\n",
        "            'effect_col': self.effect_col,\n",
        "            'var_col': self.var_col,\n",
        "            'n_observations': len(df) if df is not None else 0,\n",
        "            'n_studies': df['id'].nunique() if df is not None and 'id' in df.columns else 0,\n",
        "            'has_overall_results': 'overall_results' in self._config\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 PET-PEESE Data Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - PETPEESEConfig\")\n",
        "    print(\"   - PETResult\")\n",
        "    print(\"   - PEESEResult\")\n",
        "    print(\"   - NaiveEstimate\")\n",
        "    print(\"   - PETPEESEDecision\")\n",
        "    print(\"   - PETPEESEResult\")\n",
        "    print(\"   - PETPEESEDataManager\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PET ENGINE (Effect ~ Standard Error)\n",
        "# =============================================================================\n",
        "\n",
        "class PETEngine:\n",
        "    \"\"\"\n",
        "    PET (Precision Effect Test) regression engine.\n",
        "\n",
        "    Mathematical implementation: Effect_Size ~ Intercept + Slope * SE\n",
        "    Uses three-level REML to account for within-study dependencies.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, effect_col: str, var_col: str = 'Var'):\n",
        "        \"\"\"\n",
        "        Initialize engine.\n",
        "\n",
        "        Args:\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name (for weighting)\n",
        "        \"\"\"\n",
        "        self.effect_col = effect_col\n",
        "        self.var_col = var_col\n",
        "\n",
        "    def run_pet_regression(\n",
        "        self,\n",
        "        df: pd.DataFrame\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Run PET regression: Effect ~ SE\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame with effect sizes, SE, and Var columns\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with regression results or None if fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use the three-level REML regression function\n",
        "            estimates, metadata, opt_result = _run_three_level_reml_regression_v2(\n",
        "                df,\n",
        "                moderator_col='SE',\n",
        "                effect_col=self.effect_col,\n",
        "                var_col=self.var_col\n",
        "            )\n",
        "\n",
        "            if estimates is None:\n",
        "                return None\n",
        "\n",
        "            return estimates\n",
        "\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"PET regression failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PEESE ENGINE (Effect ~ Variance)\n",
        "# =============================================================================\n",
        "\n",
        "class PEESEEngine:\n",
        "    \"\"\"\n",
        "    PEESE (Precision Effect Estimate with Standard Error) regression engine.\n",
        "\n",
        "    Mathematical implementation: Effect_Size ~ Intercept + Slope * Variance\n",
        "    Uses three-level REML to account for within-study dependencies.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, effect_col: str, var_col: str = 'Var'):\n",
        "        \"\"\"\n",
        "        Initialize engine.\n",
        "\n",
        "        Args:\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name (used as moderator)\n",
        "        \"\"\"\n",
        "        self.effect_col = effect_col\n",
        "        self.var_col = var_col\n",
        "\n",
        "    def run_peese_regression(\n",
        "        self,\n",
        "        df: pd.DataFrame\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Run PEESE regression: Effect ~ Variance\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame with effect sizes and Var columns\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with regression results or None if fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use the three-level REML regression function\n",
        "            estimates, metadata, opt_result = _run_three_level_reml_regression_v2(\n",
        "                df,\n",
        "                moderator_col='Var',\n",
        "                effect_col=self.effect_col,\n",
        "                var_col=self.var_col\n",
        "            )\n",
        "\n",
        "            if estimates is None:\n",
        "                return None\n",
        "\n",
        "            return estimates\n",
        "\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"PEESE regression failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DECISION MAKER\n",
        "# =============================================================================\n",
        "\n",
        "class PETPEESEDecisionMaker:\n",
        "    \"\"\"\n",
        "    Implements the conditional decision rule for PET-PEESE.\n",
        "\n",
        "    Decision Logic:\n",
        "    - If PET slope p-value < threshold (default 0.10):\n",
        "        \u2192 Evidence of small-study effects \u2192 Use PEESE estimate\n",
        "    - Otherwise:\n",
        "        \u2192 No strong evidence of bias \u2192 Use PET estimate\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def make_decision(\n",
        "        pet_slope_p: float,\n",
        "        pet_intercept: float,\n",
        "        pet_intercept_se: float,\n",
        "        pet_intercept_ci: Tuple[float, float],\n",
        "        peese_intercept: float,\n",
        "        peese_intercept_se: float,\n",
        "        peese_intercept_ci: Tuple[float, float],\n",
        "        p_threshold: float = 0.10\n",
        "    ) -> 'PETPEESEDecision':\n",
        "        \"\"\"\n",
        "        Apply decision rule to select recommended estimate.\n",
        "\n",
        "        Args:\n",
        "            pet_slope_p: P-value for PET slope coefficient\n",
        "            pet_intercept: PET intercept (bias-corrected estimate)\n",
        "            pet_intercept_se: Standard error of PET intercept\n",
        "            pet_intercept_ci: Confidence interval for PET intercept\n",
        "            peese_intercept: PEESE intercept (bias-corrected estimate)\n",
        "            peese_intercept_se: Standard error of PEESE intercept\n",
        "            peese_intercept_ci: Confidence interval for PEESE intercept\n",
        "            p_threshold: P-value threshold for decision (default 0.10)\n",
        "\n",
        "        Returns:\n",
        "            PETPEESEDecision object with recommendation\n",
        "        \"\"\"\n",
        "        bias_detected = pet_slope_p < p_threshold\n",
        "\n",
        "        if bias_detected:\n",
        "            # Use PEESE estimate\n",
        "            recommended_model = \"PEESE\"\n",
        "            recommended_estimate = peese_intercept\n",
        "            recommended_se = peese_intercept_se\n",
        "            recommended_ci = peese_intercept_ci\n",
        "            rationale = (\n",
        "                f\"The PET slope was statistically significant (p = {pet_slope_p:.4f} < {p_threshold:.2f}), \"\n",
        "                f\"indicating small-study effects/publication bias. The PEESE estimate is recommended.\"\n",
        "            )\n",
        "        else:\n",
        "            # Use PET estimate\n",
        "            recommended_model = \"PET\"\n",
        "            recommended_estimate = pet_intercept\n",
        "            recommended_se = pet_intercept_se\n",
        "            recommended_ci = pet_intercept_ci\n",
        "            rationale = (\n",
        "                f\"The PET slope was not statistically significant (p = {pet_slope_p:.4f} \u2265 {p_threshold:.2f}), \"\n",
        "                f\"suggesting no strong evidence of small-study effects. The PET estimate is recommended.\"\n",
        "            )\n",
        "\n",
        "        return PETPEESEDecision(\n",
        "            bias_detected=bias_detected,\n",
        "            p_threshold=p_threshold,\n",
        "            recommended_model=recommended_model,\n",
        "            recommended_estimate=recommended_estimate,\n",
        "            recommended_se=recommended_se,\n",
        "            recommended_ci=recommended_ci,\n",
        "            rationale=rationale\n",
        "        )\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PET-PEESE ORCHESTRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class PETPEESEEngine:\n",
        "    \"\"\"\n",
        "    High-level orchestrator for PET-PEESE analysis.\n",
        "    Coordinates PET regression, PEESE regression, and decision rule.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_manager: 'PETPEESEDataManager'):\n",
        "        \"\"\"\n",
        "        Initialize engine with data manager.\n",
        "\n",
        "        Args:\n",
        "            data_manager: PETPEESEDataManager instance\n",
        "        \"\"\"\n",
        "        self.data_manager = data_manager\n",
        "        self.pet_engine = PETEngine(\n",
        "            effect_col=data_manager.effect_col,\n",
        "            var_col='Var'\n",
        "        )\n",
        "        self.peese_engine = PEESEEngine(\n",
        "            effect_col=data_manager.effect_col,\n",
        "            var_col='Var'\n",
        "        )\n",
        "        self.decision_maker = PETPEESEDecisionMaker()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(\n",
        "        self,\n",
        "        p_threshold: float = 0.10,\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> Optional['PETPEESEResult']:\n",
        "        \"\"\"\n",
        "        Execute complete PET-PEESE analysis.\n",
        "\n",
        "        WORKFLOW:\n",
        "        1. Prepare data\n",
        "        2. Run PET regression (Effect ~ SE)\n",
        "        3. Run PEESE regression (Effect ~ Variance)\n",
        "        4. Apply decision rule\n",
        "        5. Get naive estimate for comparison\n",
        "\n",
        "        Args:\n",
        "            p_threshold: P-value threshold for decision rule (default 0.10)\n",
        "            progress_callback: Optional progress updates\n",
        "\n",
        "        Returns:\n",
        "            PETPEESEResult object or None if analysis fails\n",
        "        \"\"\"\n",
        "        # Step 1: Prepare data\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udcca Preparing data...\")\n",
        "\n",
        "        try:\n",
        "            df = self.data_manager.prepare_data()\n",
        "        except ValueError as e:\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"\u274c Data preparation failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        n_obs = len(df)\n",
        "        n_studies = df['id'].nunique() if 'id' in df.columns else n_obs\n",
        "\n",
        "        # Step 2: Run PET regression\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udd0d Running PET model (Effect ~ SE)...\")\n",
        "\n",
        "        pet_estimates = self.pet_engine.run_pet_regression(df)\n",
        "\n",
        "        if pet_estimates is None:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\u274c PET regression failed\")\n",
        "            return None\n",
        "\n",
        "        # Extract PET results\n",
        "        pet_result = self._extract_pet_result(pet_estimates)\n",
        "\n",
        "        # Step 3: Run PEESE regression\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udd0d Running PEESE model (Effect ~ Variance)...\")\n",
        "\n",
        "        peese_estimates = self.peese_engine.run_peese_regression(df)\n",
        "\n",
        "        if peese_estimates is None:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\u274c PEESE regression failed\")\n",
        "            return None\n",
        "\n",
        "        # Extract PEESE results\n",
        "        peese_result = self._extract_peese_result(peese_estimates)\n",
        "\n",
        "        # Step 4: Apply decision rule\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83c\udfaf Applying decision rule...\")\n",
        "\n",
        "        decision = self.decision_maker.make_decision(\n",
        "            pet_slope_p=pet_result.slope_p,\n",
        "            pet_intercept=pet_result.intercept,\n",
        "            pet_intercept_se=pet_result.intercept_se,\n",
        "            pet_intercept_ci=pet_result.intercept_ci,\n",
        "            peese_intercept=peese_result.intercept,\n",
        "            peese_intercept_se=peese_result.intercept_se,\n",
        "            peese_intercept_ci=peese_result.intercept_ci,\n",
        "            p_threshold=p_threshold\n",
        "        )\n",
        "\n",
        "        # Step 5: Get naive estimate\n",
        "        naive_estimate = self.data_manager.get_naive_estimate()\n",
        "\n",
        "        # Build result object\n",
        "        result = PETPEESEResult(\n",
        "            pet=pet_result,\n",
        "            peese=peese_result,\n",
        "            decision=decision,\n",
        "            naive=naive_estimate,\n",
        "            n_obs=n_obs,\n",
        "            n_studies=n_studies,\n",
        "            effect_col=self.data_manager.effect_col\n",
        "        )\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback(\n",
        "                f\"\u2705 {decision.recommended_model} recommended: \"\n",
        "                f\"{decision.recommended_estimate:.4f} (p = {pet_result.slope_p:.4f})\"\n",
        "            )\n",
        "\n",
        "        return result\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RESULT EXTRACTION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _extract_pet_result(self, estimates: Dict[str, Any]) -> PETResult:\n",
        "        \"\"\"\n",
        "        Extract PET results from regression output.\n",
        "\n",
        "        Args:\n",
        "            estimates: Dictionary from _run_three_level_reml_regression_v2\n",
        "\n",
        "        Returns:\n",
        "            PETResult object\n",
        "        \"\"\"\n",
        "        intercept = estimates['betas'][0]\n",
        "        slope = estimates['betas'][1]\n",
        "\n",
        "        intercept_se = estimates['se_betas'][0]\n",
        "        slope_se = estimates['se_betas'][1]\n",
        "\n",
        "        slope_p = estimates['p_values'][1]\n",
        "\n",
        "        intercept_ci = (estimates['ci_lower'][0], estimates['ci_upper'][0])\n",
        "\n",
        "        return PETResult(\n",
        "            intercept=intercept,\n",
        "            intercept_se=intercept_se,\n",
        "            intercept_ci=intercept_ci,\n",
        "            slope=slope,\n",
        "            slope_se=slope_se,\n",
        "            slope_p=slope_p,\n",
        "            estimates=estimates\n",
        "        )\n",
        "\n",
        "    def _extract_peese_result(self, estimates: Dict[str, Any]) -> PEESEResult:\n",
        "        \"\"\"\n",
        "        Extract PEESE results from regression output.\n",
        "\n",
        "        Args:\n",
        "            estimates: Dictionary from _run_three_level_reml_regression_v2\n",
        "\n",
        "        Returns:\n",
        "            PEESEResult object\n",
        "        \"\"\"\n",
        "        intercept = estimates['betas'][0]\n",
        "        slope = estimates['betas'][1]\n",
        "\n",
        "        intercept_se = estimates['se_betas'][0]\n",
        "        slope_se = estimates['se_betas'][1]\n",
        "\n",
        "        slope_p = estimates['p_values'][1]\n",
        "\n",
        "        intercept_ci = (estimates['ci_lower'][0], estimates['ci_upper'][0])\n",
        "\n",
        "        return PEESEResult(\n",
        "            intercept=intercept,\n",
        "            intercept_se=intercept_se,\n",
        "            intercept_ci=intercept_ci,\n",
        "            slope=slope,\n",
        "            slope_se=slope_se,\n",
        "            slope_p=slope_p,\n",
        "            estimates=estimates\n",
        "        )\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HELPER: COMPARISON CALCULATOR\n",
        "# =============================================================================\n",
        "\n",
        "class ComparisonCalculator:\n",
        "    \"\"\"\n",
        "    Calculate comparisons between naive and adjusted estimates.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_change(\n",
        "        naive: float,\n",
        "        adjusted: float\n",
        "    ) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Calculate absolute and percent change.\n",
        "\n",
        "        Args:\n",
        "            naive: Original unadjusted estimate\n",
        "            adjusted: PET-PEESE adjusted estimate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (absolute_change, percent_change)\n",
        "        \"\"\"\n",
        "        if naive is None:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "        abs_change = adjusted - naive\n",
        "\n",
        "        if naive == 0:\n",
        "            pct_change = 0.0\n",
        "        else:\n",
        "            pct_change = (abs_change / naive) * 100\n",
        "\n",
        "        return abs_change, pct_change\n",
        "\n",
        "    @staticmethod\n",
        "    def assess_impact(percent_change: float) -> str:\n",
        "        \"\"\"\n",
        "        Assess the magnitude of impact.\n",
        "\n",
        "        Args:\n",
        "            percent_change: Percent change in effect size\n",
        "\n",
        "        Returns:\n",
        "            Impact assessment string\n",
        "        \"\"\"\n",
        "        abs_pct = abs(percent_change)\n",
        "\n",
        "        if abs_pct < 5:\n",
        "            return \"minimal\"\n",
        "        elif abs_pct < 15:\n",
        "            return \"small\"\n",
        "        elif abs_pct < 30:\n",
        "            return \"moderate\"\n",
        "        else:\n",
        "            return \"substantial\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 PET-PEESE Analysis Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - PETEngine (Effect ~ SE)\")\n",
        "    print(\"   - PEESEEngine (Effect ~ Variance)\")\n",
        "    print(\"   - PETPEESEDecisionMaker (conditional rule)\")\n",
        "    print(\"   - PETPEESEEngine (main orchestrator)\")\n",
        "    print(\"   - ComparisonCalculator (change metrics)\")\n",
        "\n",
        "#@title \ud83d\udcca 17. Publication Bias: PET-PEESE - PRESENTATION LAYER (View)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 3/4: PRESENTATION LAYER - PET-PEESE CORRECTION\n",
        "# Purpose: Pure UI rendering without business logic\n",
        "# Dependencies: Data & Analysis Layers\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Any, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import sys\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HTML TEMPLATE GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class PETPEESEHTMLTemplates:\n",
        "    \"\"\"\n",
        "    Static HTML template generators for PET-PEESE visualizations.\n",
        "    All methods are pure functions returning HTML strings.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def comparison_table(result: 'PETPEESEResult') -> str:\n",
        "        \"\"\"Generate comparison table for all three estimates\"\"\"\n",
        "\n",
        "        rows = []\n",
        "\n",
        "        # Naive estimate (if available)\n",
        "        if result.naive.estimate is not None:\n",
        "            rows.append({\n",
        "                'Model': 'Original (Naive)',\n",
        "                'Estimate': f\"{result.naive.estimate:.4f}\",\n",
        "                'SE': f\"{result.naive.se:.4f}\" if result.naive.se else \"\u2014\",\n",
        "                '95% CI': f\"[{result.naive.ci_lower:.4f}, {result.naive.ci_upper:.4f}]\"\n",
        "                         if result.naive.ci_lower is not None else \"\u2014\",\n",
        "                'Note': 'Unadjusted pooled estimate'\n",
        "            })\n",
        "\n",
        "        # PET estimate\n",
        "        rows.append({\n",
        "            'Model': 'PET',\n",
        "            'Estimate': f\"{result.pet.intercept:.4f}\",\n",
        "            'SE': f\"{result.pet.intercept_se:.4f}\",\n",
        "            '95% CI': f\"[{result.pet.intercept_ci[0]:.4f}, {result.pet.intercept_ci[1]:.4f}]\",\n",
        "            'Note': f\"Slope p = {result.pet.slope_p:.4f}\"\n",
        "        })\n",
        "\n",
        "        # PEESE estimate\n",
        "        rows.append({\n",
        "            'Model': 'PEESE',\n",
        "            'Estimate': f\"{result.peese.intercept:.4f}\",\n",
        "            'SE': f\"{result.peese.intercept_se:.4f}\",\n",
        "            '95% CI': f\"[{result.peese.intercept_ci[0]:.4f}, {result.peese.intercept_ci[1]:.4f}]\",\n",
        "            'Note': f\"Slope p = {result.peese.slope_p:.4f}\"\n",
        "        })\n",
        "\n",
        "        # Build HTML table\n",
        "        html = \"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse; margin-top: 20px;'>\n",
        "            <thead>\n",
        "                <tr style='background-color: #f8f9fa; border-bottom: 2px solid #dee2e6;'>\n",
        "                    <th style='padding: 12px; text-align: left; font-weight: bold;'>Model</th>\n",
        "                    <th style='padding: 12px; text-align: left; font-weight: bold;'>Estimate</th>\n",
        "                    <th style='padding: 12px; text-align: left; font-weight: bold;'>SE</th>\n",
        "                    <th style='padding: 12px; text-align: left; font-weight: bold;'>95% CI</th>\n",
        "                    <th style='padding: 12px; text-align: left; font-weight: bold;'>Note</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "        \"\"\"\n",
        "\n",
        "        for row in rows:\n",
        "            is_recommended = row['Model'] == result.decision.recommended_model\n",
        "            bg_color = \"#d4edda\" if is_recommended else \"white\"\n",
        "            html += f\"<tr style='background-color: {bg_color}; border-bottom: 1px solid #dee2e6;'>\"\n",
        "            for col in ['Model', 'Estimate', 'SE', '95% CI', 'Note']:\n",
        "                html += f\"<td style='padding: 10px;'>{row[col]}</td>\"\n",
        "            html += \"</tr>\"\n",
        "\n",
        "        html += \"</tbody></table>\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def recommendation_box(result: 'PETPEESEResult') -> str:\n",
        "        \"\"\"Generate recommendation box with decision\"\"\"\n",
        "        decision = result.decision\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='margin-top: 30px; padding: 20px; background-color: #d4edda;\n",
        "                    border-left: 5px solid #28a745; border-radius: 5px;'>\n",
        "            <h4 style='margin-top: 0; color: #155724;'>\u2713 Recommended Adjustment</h4>\n",
        "            <p style='font-size: 16px; margin: 10px 0;'>\n",
        "                <b>Model:</b> {decision.recommended_model}<br>\n",
        "                <b>Adjusted Estimate:</b> {decision.recommended_estimate:.4f}\n",
        "                (SE = {decision.recommended_se:.4f})<br>\n",
        "                <b>95% CI:</b> [{decision.recommended_ci[0]:.4f}, {decision.recommended_ci[1]:.4f}]\n",
        "            </p>\n",
        "            <p style='color: #6c757d; font-size: 14px; margin-top: 15px;'>\n",
        "                {decision.rationale}\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def decision_badge(result: 'PETPEESEResult') -> str:\n",
        "        \"\"\"Generate decision status badge\"\"\"\n",
        "        if result.decision.bias_detected:\n",
        "            color = \"#856404\"\n",
        "            bg_color = \"#fff3cd\"\n",
        "            icon = \"\u26a0\"\n",
        "            title = \"Publication Bias Detected\"\n",
        "        else:\n",
        "            color = \"#155724\"\n",
        "            bg_color = \"#d4edda\"\n",
        "            icon = \"\u2713\"\n",
        "            title = \"No Strong Evidence of Bias\"\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='margin-top: 20px; padding: 20px; background-color: {bg_color};\n",
        "                    border-left: 5px solid {color}; border-radius: 5px;'>\n",
        "            <h4 style='margin-top: 0; color: {color};'>{icon} {title}</h4>\n",
        "            <p style='font-size: 14px; color: #6c757d;'>\n",
        "                {result.decision.rationale}\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def model_details_box(result: 'PETPEESEResult') -> str:\n",
        "        \"\"\"Generate model details box\"\"\"\n",
        "        pet = result.pet\n",
        "        peese = result.peese\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='margin-top: 30px; padding: 15px; background-color: #f8f9fa; border-radius: 5px;'>\n",
        "            <h4 style='color: #495057;'>Model Details</h4>\n",
        "\n",
        "            <h5 style='color: #6c757d; margin-top: 20px;'>PET Model (Effect ~ SE)</h5>\n",
        "            <p style='color: #6c757d; font-size: 14px; margin-left: 20px;'>\n",
        "                <b>Intercept:</b> {pet.intercept:.4f} (SE = {pet.intercept_se:.4f})<br>\n",
        "                <b>Slope:</b> {pet.slope:.4f} (SE = {pet.slope_se:.4f}, p = {pet.slope_p:.4f})<br>\n",
        "                <b>95% CI for Intercept:</b> [{pet.intercept_ci[0]:.4f}, {pet.intercept_ci[1]:.4f}]\n",
        "            </p>\n",
        "\n",
        "            <h5 style='color: #6c757d; margin-top: 20px;'>PEESE Model (Effect ~ Variance)</h5>\n",
        "            <p style='color: #6c757d; font-size: 14px; margin-left: 20px;'>\n",
        "                <b>Intercept:</b> {peese.intercept:.4f} (SE = {peese.intercept_se:.4f})<br>\n",
        "                <b>Slope:</b> {peese.slope:.4f} (SE = {peese.slope_se:.4f}, p = {peese.slope_p:.4f})<br>\n",
        "                <b>95% CI for Intercept:</b> [{peese.intercept_ci[0]:.4f}, {peese.intercept_ci[1]:.4f}]\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def interpretation_guide() -> str:\n",
        "        \"\"\"Generate interpretation guide\"\"\"\n",
        "        return \"\"\"\n",
        "        <div style='margin-top: 30px;'>\n",
        "            <h4 style='color: #495057;'>Understanding PET-PEESE</h4>\n",
        "            <p style='color: #6c757d; font-size: 14px; line-height: 1.6;'>\n",
        "                <b>PET-PEESE</b> is a conditional meta-regression method for correcting publication bias:\n",
        "            </p>\n",
        "            <ul style='color: #6c757d; font-size: 14px; line-height: 1.8;'>\n",
        "                <li><b>PET (Precision Effect Test):</b> Regresses effect size on standard error.\n",
        "                    A significant slope suggests that smaller studies report larger effects (publication bias).</li>\n",
        "                <li><b>PEESE (Precision Effect Estimate with SE):</b> Regresses effect size on variance (SE\u00b2).\n",
        "                    Provides a better-calibrated estimate when bias is detected.</li>\n",
        "                <li><b>Decision Rule:</b> If PET slope p < 0.10, use the PEESE intercept as the\n",
        "                    bias-corrected estimate. Otherwise, use the PET intercept.</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def recommendations_box() -> str:\n",
        "        \"\"\"Generate recommendations box\"\"\"\n",
        "        return \"\"\"\n",
        "        <div style='margin-top: 30px; padding: 15px; background-color: #e7f3ff;\n",
        "                    border-left: 4px solid #2E86AB; border-radius: 5px;'>\n",
        "            <h4 style='color: #2E86AB; margin-top: 0;'>\ud83d\udca1 Recommendations</h4>\n",
        "            <ul style='color: #6c757d; font-size: 14px; line-height: 1.8;'>\n",
        "                <li>Report both the original pooled estimate and the PET-PEESE adjusted estimate.</li>\n",
        "                <li>Consider PET-PEESE as one of several bias assessment methods (alongside Egger's test, trim-and-fill, etc.).</li>\n",
        "                <li>If the adjusted estimate differs substantially from the original, investigate potential sources of bias.</li>\n",
        "                <li>PET-PEESE assumes bias is related to precision; other bias mechanisms may not be captured.</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_interpretation_note() -> str:\n",
        "        \"\"\"Generate plot interpretation note\"\"\"\n",
        "        return \"\"\"\n",
        "        <div style='margin-top: 20px; padding: 15px; background-color: #f8f9fa;\n",
        "                    border-left: 4px solid #6c757d; border-radius: 5px;'>\n",
        "            <h4 style='margin-top: 0; color: #495057;'>\ud83d\udcdd Plot Interpretation</h4>\n",
        "            <ul style='color: #6c757d; font-size: 14px;'>\n",
        "                <li><b>Red dashed line (PET):</b> Linear relationship between effect size and standard error.</li>\n",
        "                <li><b>Green solid line (PEESE):</b> Quadratic relationship (effect ~ SE\u00b2), appears curved when plotted against SE.</li>\n",
        "                <li><b>Horizontal dotted line:</b> The recommended bias-corrected estimate (intercept of chosen model).</li>\n",
        "                <li>If studies cluster above/below the zero-effect line asymmetrically, publication bias may be present.</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# VIEW COMPONENTS (Tab Renderers)\n",
        "# =============================================================================\n",
        "\n",
        "class PETPEESEResultsView:\n",
        "    \"\"\"\n",
        "    Manages all UI rendering for PET-PEESE analysis.\n",
        "    Contains zero business logic - only presentation code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize view with display settings\"\"\"\n",
        "        self.templates = PETPEESEHTMLTemplates()\n",
        "\n",
        "        # Create tab widgets\n",
        "        self.tab_summary = widgets.Output()\n",
        "        self.tab_visuals = widgets.Output()\n",
        "        self.tab_interpretation = widgets.Output()\n",
        "\n",
        "        self.tabs = widgets.Tab(children=[\n",
        "            self.tab_summary,\n",
        "            self.tab_visuals,\n",
        "            self.tab_interpretation\n",
        "        ])\n",
        "\n",
        "        self.tabs.set_title(0, '\ud83d\udcca Summary')\n",
        "        self.tabs.set_title(1, '\ud83d\udcc8 Visuals')\n",
        "        self.tabs.set_title(2, '\ud83d\udcdd Interpretation')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 1: SUMMARY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_summary_tab(self, result: 'PETPEESEResult') -> None:\n",
        "        \"\"\"Render summary tab with comparison table\"\"\"\n",
        "\n",
        "        with self.tab_summary:\n",
        "            self.tab_summary.clear_output()\n",
        "\n",
        "            display(HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcca PET-PEESE Summary</h3>\"))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Comparison of effect size estimates with and without publication bias correction.</p>\"))\n",
        "\n",
        "            # Comparison table\n",
        "            table_html = self.templates.comparison_table(result)\n",
        "            display(HTML(table_html))\n",
        "\n",
        "            # Recommendation box\n",
        "            rec_html = self.templates.recommendation_box(result)\n",
        "            display(HTML(rec_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 2: VISUALS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_visuals_tab(\n",
        "        self,\n",
        "        result: 'PETPEESEResult',\n",
        "        df: pd.DataFrame\n",
        "    ) -> None:\n",
        "        \"\"\"Render visuals tab with scatter plot and regression lines\"\"\"\n",
        "\n",
        "        with self.tab_visuals:\n",
        "            self.tab_visuals.clear_output()\n",
        "\n",
        "            # Create figure\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "            # Scatter plot\n",
        "            ax.scatter(\n",
        "                df['SE'],\n",
        "                df[result.effect_col],\n",
        "                alpha=0.6,\n",
        "                s=80,\n",
        "                color='steelblue',\n",
        "                edgecolors='black',\n",
        "                linewidth=0.5,\n",
        "                label='Observed Studies'\n",
        "            )\n",
        "\n",
        "            # PET regression line (linear in SE)\n",
        "            se_range = np.linspace(df['SE'].min(), df['SE'].max(), 100)\n",
        "            pet_line = result.pet.intercept + result.pet.slope * se_range\n",
        "            ax.plot(\n",
        "                se_range,\n",
        "                pet_line,\n",
        "                color='red',\n",
        "                linewidth=2,\n",
        "                linestyle='--',\n",
        "                label=f\"PET: y = {result.pet.intercept:.3f} + {result.pet.slope:.3f}\u00b7SE\"\n",
        "            )\n",
        "\n",
        "            # PEESE regression line (quadratic in SE, linear in Var)\n",
        "            # Effect = intercept + slope * Var = intercept + slope * SE\u00b2\n",
        "            peese_line = result.peese.intercept + result.peese.slope * (se_range ** 2)\n",
        "            ax.plot(\n",
        "                se_range,\n",
        "                peese_line,\n",
        "                color='green',\n",
        "                linewidth=2,\n",
        "                linestyle='-',\n",
        "                label=f\"PEESE: y = {result.peese.intercept:.3f} + {result.peese.slope:.3f}\u00b7SE\u00b2\"\n",
        "            )\n",
        "\n",
        "            # Highlight recommended estimate\n",
        "            if result.decision.recommended_model == 'PET':\n",
        "                ax.axhline(\n",
        "                    y=result.pet.intercept,\n",
        "                    color='red',\n",
        "                    linestyle=':',\n",
        "                    linewidth=2,\n",
        "                    label=f\"Recommended (PET): {result.pet.intercept:.3f}\"\n",
        "                )\n",
        "            else:\n",
        "                ax.axhline(\n",
        "                    y=result.peese.intercept,\n",
        "                    color='green',\n",
        "                    linestyle=':',\n",
        "                    linewidth=2,\n",
        "                    label=f\"Recommended (PEESE): {result.peese.intercept:.3f}\"\n",
        "                )\n",
        "\n",
        "            # Labels and styling\n",
        "            ax.set_xlabel('Standard Error', fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel('Effect Size', fontsize=12, fontweight='bold')\n",
        "            ax.set_title(\n",
        "                'PET-PEESE Analysis: Effect Size vs. Standard Error',\n",
        "                fontsize=14,\n",
        "                fontweight='bold',\n",
        "                pad=20\n",
        "            )\n",
        "            ax.legend(loc='best', frameon=True, shadow=True, fontsize=10)\n",
        "            ax.grid(True, alpha=0.3, linestyle='--')\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Add interpretation note\n",
        "            note_html = self.templates.plot_interpretation_note()\n",
        "            display(HTML(note_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 3: INTERPRETATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_interpretation_tab(self, result: 'PETPEESEResult') -> None:\n",
        "        \"\"\"Render interpretation tab with detailed explanation\"\"\"\n",
        "\n",
        "        with self.tab_interpretation:\n",
        "            self.tab_interpretation.clear_output()\n",
        "\n",
        "            display(HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcdd PET-PEESE Interpretation</h3>\"))\n",
        "\n",
        "            # Decision summary\n",
        "            decision_html = self.templates.decision_badge(result)\n",
        "            display(HTML(decision_html))\n",
        "\n",
        "            # Understanding guide\n",
        "            guide_html = self.templates.interpretation_guide()\n",
        "            display(HTML(guide_html))\n",
        "\n",
        "            # Model details\n",
        "            details_html = self.templates.model_details_box(result)\n",
        "            display(HTML(details_html))\n",
        "\n",
        "            # Recommendations\n",
        "            rec_html = self.templates.recommendations_box()\n",
        "            display(HTML(rec_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR DISPLAY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_error(self, message: str, details: Optional[str] = None) -> None:\n",
        "        \"\"\"Render error message in summary tab\"\"\"\n",
        "        with self.tab_summary:\n",
        "            self.tab_summary.clear_output()\n",
        "            error_html = f\"\"\"\n",
        "            <div style='color: red; padding: 10px; border: 1px solid red; border-radius: 5px;'>\n",
        "                <b>\u26a0 Error:</b> {message}\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            if details:\n",
        "                error_html += f\"<pre style='margin-top: 10px; color: #6c757d;'>{details}</pre>\"\n",
        "            display(HTML(error_html))\n",
        "\n",
        "\n",
        "print(\"\u2705 PET-PEESE View Layer Loaded Successfully\")\n",
        "\n",
        "#@title \ud83d\udcca 17. Publication Bias: PET-PEESE - CONTROLLER LAYER (Orchestration)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 4/4: CONTROLLER LAYER - PET-PEESE CORRECTION\n",
        "# Purpose: Orchestrates data, analysis, and view components\n",
        "# Dependencies: All previous layers (Data, Analysis, View)\n",
        "# =============================================================================\n",
        "\n",
        "import traceback\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN CONTROLLER\n",
        "# =============================================================================\n",
        "\n",
        "class PETPEESEController:\n",
        "    \"\"\"\n",
        "    Master controller that orchestrates the entire PET-PEESE analysis workflow.\n",
        "    Coordinates data management, statistical computation, and UI rendering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize controller with ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self.analysis_config = analysis_config\n",
        "\n",
        "        # Initialize components\n",
        "        try:\n",
        "            self.data_manager = PETPEESEDataManager(analysis_config)\n",
        "            self.engine = PETPEESEEngine(self.data_manager)\n",
        "            self.view = PETPEESEResultsView()\n",
        "\n",
        "            self._initialization_error = None\n",
        "\n",
        "        except Exception as e:\n",
        "            # If initialization fails, create minimal view to show error\n",
        "            self.view = PETPEESEResultsView()\n",
        "            self.data_manager = None\n",
        "            self.engine = None\n",
        "            self._initialization_error = e\n",
        "\n",
        "        # Create settings widgets\n",
        "        self._create_settings_widgets()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # SETTINGS WIDGETS CREATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _create_settings_widgets(self) -> None:\n",
        "        \"\"\"Create all settings widgets\"\"\"\n",
        "\n",
        "        self.p_threshold_widget = widgets.FloatSlider(\n",
        "            value=0.10,\n",
        "            min=0.01,\n",
        "            max=0.20,\n",
        "            step=0.01,\n",
        "            description='P-threshold:',\n",
        "            style={'description_width': '100px'},\n",
        "            layout=widgets.Layout(width='400px'),\n",
        "            readout_format='.2f'\n",
        "        )\n",
        "\n",
        "        self.run_button = widgets.Button(\n",
        "            description='\u25b6 Run PET-PEESE',\n",
        "            button_style='success',\n",
        "            icon='play',\n",
        "            layout=widgets.Layout(width='200px', height='40px')\n",
        "        )\n",
        "\n",
        "        # Attach event handler\n",
        "        self.run_button.on_click(self._handle_run_click)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UI CREATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def create_ui(self) -> widgets.VBox:\n",
        "        \"\"\"\n",
        "        Create the user interface with settings and run button.\n",
        "\n",
        "        Returns:\n",
        "            VBox widget containing the UI\n",
        "        \"\"\"\n",
        "        # Help text\n",
        "        help_html = \"\"\"\n",
        "        <p style='color: #6c757d; font-size: 14px; margin-top: 10px;'>\n",
        "            <b>P-threshold:</b> If PET slope p-value < threshold, use PEESE estimate.\n",
        "            Default is 0.10 (standard practice).\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        ui = widgets.VBox([\n",
        "            widgets.HTML(\"<h3>\ud83d\udcca PET-PEESE: Publication Bias Correction</h3>\"),\n",
        "            widgets.HTML(\"<p style='color: #6c757d;'>Estimate the true effect size adjusted for small-study effects using conditional meta-regression.</p>\"),\n",
        "            widgets.HTML(\"<b>Settings:</b>\"),\n",
        "            self.p_threshold_widget,\n",
        "            widgets.HTML(help_html),\n",
        "            widgets.HTML(\"<hr>\"),\n",
        "            self.run_button,\n",
        "            widgets.HTML(\"<br>\")\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(self) -> None:\n",
        "        \"\"\"\n",
        "        Execute complete PET-PEESE analysis workflow.\n",
        "        \"\"\"\n",
        "        # Clear all tabs\n",
        "        for tab in [self.view.tab_summary, self.view.tab_visuals,\n",
        "                    self.view.tab_interpretation]:\n",
        "            tab.clear_output()\n",
        "\n",
        "        # Check for initialization errors\n",
        "        if self._initialization_error:\n",
        "            self._handle_initialization_error()\n",
        "            return\n",
        "\n",
        "        # Validate ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            self.view.render_error(\"ANALYSIS_CONFIG not found. Run Step 1 first.\")\n",
        "            return\n",
        "\n",
        "        # Get settings from widgets\n",
        "        p_threshold = self.p_threshold_widget.value\n",
        "\n",
        "        # Progress callback\n",
        "        def progress_callback(message: str):\n",
        "            \"\"\"Callback for progress updates\"\"\"\n",
        "            with self.view.tab_summary:\n",
        "                display(HTML(f\"<p style='color: #6c757d;'>{message}</p>\"))\n",
        "\n",
        "        try:\n",
        "            # Execute PET-PEESE engine\n",
        "            result = self.engine.run_analysis(\n",
        "                p_threshold=p_threshold,\n",
        "                progress_callback=progress_callback\n",
        "            )\n",
        "\n",
        "            if result is None:\n",
        "                self.view.render_error(\n",
        "                    \"Analysis failed\",\n",
        "                    \"Unable to compute PET-PEESE analysis. Check your data (need \u22653 observations with variance column).\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # Get prepared data for plotting\n",
        "            df = self.data_manager.prepare_data()\n",
        "\n",
        "            # Render all tabs\n",
        "            self._render_all_tabs(result, df)\n",
        "\n",
        "            # Save results\n",
        "            self._save_results(result)\n",
        "\n",
        "        except ValueError as e:\n",
        "            self.view.render_error(\"Data Error\", str(e))\n",
        "        except RuntimeError as e:\n",
        "            self.view.render_error(\"Runtime Error\", str(e))\n",
        "        except Exception as e:\n",
        "            self._handle_unexpected_error(e)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB RENDERING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _render_all_tabs(\n",
        "        self,\n",
        "        result: 'PETPEESEResult',\n",
        "        df: 'pd.DataFrame'\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Render all tabs with results.\n",
        "\n",
        "        Args:\n",
        "            result: PETPEESEResult object\n",
        "            df: Prepared DataFrame for plotting\n",
        "        \"\"\"\n",
        "        # Tab 1: Summary\n",
        "        self.view.render_summary_tab(result)\n",
        "\n",
        "        # Tab 2: Visuals\n",
        "        self.view.render_visuals_tab(result, df)\n",
        "\n",
        "        # Tab 3: Interpretation\n",
        "        self.view.render_interpretation_tab(result)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA PERSISTENCE\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _save_results(self, result: 'PETPEESEResult') -> None:\n",
        "        \"\"\"\n",
        "        Save results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: PETPEESEResult object\n",
        "        \"\"\"\n",
        "        self.data_manager.save_petpeese_results(result)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # EVENT HANDLERS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_run_click(self, button) -> None:\n",
        "        \"\"\"Handle run button click event\"\"\"\n",
        "        self.run_analysis()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_initialization_error(self) -> None:\n",
        "        \"\"\"Handle errors during controller initialization\"\"\"\n",
        "        error = self._initialization_error\n",
        "        if error is None:\n",
        "            return\n",
        "\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "    def _handle_unexpected_error(self, error: Exception) -> None:\n",
        "        \"\"\"Handle unexpected errors during analysis\"\"\"\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION ENTRY POINT\n",
        "# =============================================================================\n",
        "\n",
        "def run_pet_peese_analysis():\n",
        "    \"\"\"\n",
        "    Main entry point for PET-PEESE analysis.\n",
        "    Call this function to display the UI and enable analysis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check for ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            print(\"\u274c ERROR: ANALYSIS_CONFIG not found\")\n",
        "            print(\"Please run previous analysis cells first:\")\n",
        "            print(\"  - Step 1: Data Loading\")\n",
        "            print(\"  - Step 7: Overall Meta-Analysis (recommended)\")\n",
        "            return\n",
        "\n",
        "        # Check for three-level regression function\n",
        "        if '_run_three_level_reml_regression_v2' not in globals():\n",
        "            print(\"\u274c ERROR: Three-level regression function not found\")\n",
        "            print(\"Please ensure the regression utilities are loaded.\")\n",
        "            return\n",
        "\n",
        "        # Create controller\n",
        "        controller = PETPEESEController(ANALYSIS_CONFIG)\n",
        "\n",
        "        # Display UI\n",
        "        ui = controller.create_ui()\n",
        "        display(ui)\n",
        "\n",
        "        # Display tabs\n",
        "        display(controller.view.tabs)\n",
        "\n",
        "        # Store controller globally for access (optional)\n",
        "        globals()['_petpeese_controller'] = controller\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Fatal Error: {type(e).__name__}\")\n",
        "        print(f\"Message: {str(e)}\")\n",
        "        print(\"\\nFull traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STANDALONE TESTING UTILITIES (Optional)\n",
        "# =============================================================================\n",
        "\n",
        "class MockPETPEESEConfig:\n",
        "    \"\"\"\n",
        "    Mock ANALYSIS_CONFIG for testing without running full pipeline.\n",
        "    Only for development/testing purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_sample_config():\n",
        "        \"\"\"Create a minimal valid config for testing\"\"\"\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "\n",
        "        # Sample data with publication bias (small studies have larger effects)\n",
        "        np.random.seed(42)\n",
        "        n = 25\n",
        "\n",
        "        # Create biased data\n",
        "        se = np.random.uniform(0.05, 0.5, n)\n",
        "        effects = 0.6 + np.random.randn(n) * 0.15 - 0.4 * se  # Negative correlation with SE\n",
        "\n",
        "        sample_data = pd.DataFrame({\n",
        "            'id': range(1, n+1),\n",
        "            'hedges_g': effects,\n",
        "            'Vg': se**2,\n",
        "            'SE': se\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'analysis_data': sample_data,\n",
        "            'effect_col': 'hedges_g',\n",
        "            'var_col': 'Vg',\n",
        "            'es_config': {\n",
        "                'type': \"Hedges' g\",\n",
        "                'effect_label': \"Hedges' g\",\n",
        "                'effect_label_short': 'g'\n",
        "            },\n",
        "            'global_settings': {\n",
        "                'alpha': 0.05\n",
        "            },\n",
        "            'overall_results': {\n",
        "                'pooled_effect_random': 0.45,\n",
        "                'pooled_SE_random_reported': 0.08,\n",
        "                'ci_lower_random': 0.29,\n",
        "                'ci_upper_random': 0.61\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "run_pet_peese_analysis()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2xz11WgvzWLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 18. Visualization: Funnel Plot\n",
        "# =============================================================================\n",
        "# CELL 12b: ADVANCED FUNNEL PLOT (FIXED)\n",
        "# Purpose: Visualize publication bias with contours and Egger's test results.\n",
        "# Fixes: Resolved 'funnel_fill_alpha' NameError.\n",
        "# =============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import norm\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import traceback\n",
        "import datetime\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "available_color_moderators = ['None']\n",
        "analysis_data_init = None\n",
        "default_x_label = \"Effect Size (Hedges' g)\"\n",
        "default_y_label = \"Standard Error\"\n",
        "default_title = \"Funnel Plot\"\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' not in globals():\n",
        "        pass\n",
        "\n",
        "    # Get data for dropdowns\n",
        "    if 'analysis_data' in globals():\n",
        "        analysis_data_init = analysis_data.copy()\n",
        "    elif 'data_filtered' in globals():\n",
        "        analysis_data_init = data_filtered.copy()\n",
        "    elif 'ANALYSIS_CONFIG' in globals() and 'analysis_data' in ANALYSIS_CONFIG:\n",
        "        analysis_data_init = ANALYSIS_CONFIG['analysis_data'].copy()\n",
        "\n",
        "    # Identify Categorical Moderators\n",
        "    if analysis_data_init is not None:\n",
        "        excluded_cols = [\n",
        "            ANALYSIS_CONFIG.get('effect_col'), ANALYSIS_CONFIG.get('var_col'),\n",
        "            ANALYSIS_CONFIG.get('se_col'), 'w_fixed', 'w_random', 'id',\n",
        "            'xe', 'sde', 'ne', 'xc', 'sdc', 'nc'\n",
        "        ]\n",
        "        for col in analysis_data_init.columns:\n",
        "            if col in excluded_cols or col is None: continue\n",
        "            if analysis_data_init[col].dtype == 'object' or isinstance(analysis_data_init[col].dtype, pd.CategoricalDtype):\n",
        "                if analysis_data_init[col].nunique() <= 15:\n",
        "                    available_color_moderators.append(col)\n",
        "\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# Style Tab\n",
        "title_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_x_label, description='X Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_y_label, description='Y Label:', layout=widgets.Layout(width='450px'))\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=5.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False)\n",
        "height_widget = widgets.FloatSlider(value=7.0, min=4.0, max=12.0, step=0.5, description='Height (in):', continuous_update=False)\n",
        "png_dpi_widget = widgets.IntText(value=300, description='PNG DPI:', layout=widgets.Layout(width='150px'))\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Dimensions & Labels</h4>\"),\n",
        "    title_widget, xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    width_widget, height_widget\n",
        "])\n",
        "\n",
        "# Points Tab\n",
        "color_mod_widget = widgets.Dropdown(options=available_color_moderators, value='None', description='Color By:', layout=widgets.Layout(width='400px'))\n",
        "point_color_widget = widgets.Dropdown(options=['gray', 'steelblue', 'black', 'red', 'purple'], value='gray', description='Color:')\n",
        "point_size_widget = widgets.IntSlider(value=50, min=10, max=200, step=10, description='Size:')\n",
        "point_alpha_widget = widgets.FloatSlider(value=0.6, min=0.1, max=1.0, step=0.1, description='Opacity:')\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Points</h4>\"),\n",
        "    color_mod_widget, point_color_widget, point_size_widget, point_alpha_widget\n",
        "])\n",
        "\n",
        "# Funnel Tab\n",
        "show_contours_widget = widgets.Checkbox(value=True, description='Show Significance Contours (1%, 5%, 10%)')\n",
        "fill_funnel_widget = widgets.Checkbox(value=True, description='Fill Confidence Region')\n",
        "fill_color_widget = widgets.ColorPicker(value='#e6f3ff', description='Fill Color:')\n",
        "fill_alpha_widget = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.1, description='Fill Opacity:') # <--- The source widget\n",
        "center_line_color_widget = widgets.ColorPicker(value='#2c3e50', description='Center Line:')\n",
        "show_egger_widget = widgets.Checkbox(value=True, description=\"Show Egger's Test Stats\")\n",
        "\n",
        "funnel_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Funnel Guidelines</h4>\"),\n",
        "    show_contours_widget,\n",
        "    fill_funnel_widget, fill_color_widget, fill_alpha_widget,\n",
        "    center_line_color_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    show_egger_widget\n",
        "])\n",
        "\n",
        "# Export Tab\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF')\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG')\n",
        "filename_widget = widgets.Text(value='Funnel_Plot', description='Filename:')\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Export Options</h4>\"),\n",
        "    save_pdf_widget, save_png_widget, png_dpi_widget, filename_widget\n",
        "])\n",
        "\n",
        "# Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, points_tab, funnel_tab, export_tab])\n",
        "tabs.set_title(0, '\ud83c\udfa8 Style')\n",
        "tabs.set_title(1, '\u26ab Points')\n",
        "tabs.set_title(2, '\u25bc Funnel')\n",
        "tabs.set_title(3, '\ud83d\udcbe Export')\n",
        "\n",
        "run_btn = widgets.Button(description='\ud83d\udcca Generate Funnel Plot', button_style='success', layout=widgets.Layout(width='100%'))\n",
        "output = widgets.Output()\n",
        "\n",
        "# --- 3. PLOTTING FUNCTION ---\n",
        "def generate_funnel_plot(b):\n",
        "    with output:\n",
        "        clear_output(wait=True)\n",
        "        print(\"=\"*70)\n",
        "        print(\"GENERATING FUNNEL PLOT\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            # 1. Validation\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'overall_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"\u274c Error: No analysis results found. Run Step 8 (Overall Analysis) first.\")\n",
        "                return\n",
        "\n",
        "            res = ANALYSIS_CONFIG['overall_results']\n",
        "\n",
        "            # Determine which pooled effect to use (Robust is preferred)\n",
        "            if 'mu_robust' in res:\n",
        "                pooled_effect = res['mu_robust']\n",
        "                model_type = \"Robust 3-Level\"\n",
        "            else:\n",
        "                pooled_effect = res.get('mu', res.get('pooled_effect', 0))\n",
        "                model_type = \"Standard\"\n",
        "\n",
        "            # Get Data\n",
        "            if 'analysis_data' in ANALYSIS_CONFIG:\n",
        "                df = ANALYSIS_CONFIG['analysis_data'].copy()\n",
        "            else:\n",
        "                print(\"\u274c Error: Data not found in config.\")\n",
        "                return\n",
        "\n",
        "            eff_col = ANALYSIS_CONFIG['effect_col']\n",
        "            var_col = ANALYSIS_CONFIG['var_col']\n",
        "\n",
        "            # Calculate SE if needed\n",
        "            if 'se' not in df.columns:\n",
        "                df['se'] = np.sqrt(df[var_col])\n",
        "\n",
        "            # Prepare Plot Data\n",
        "            y_vals = df['se']\n",
        "            x_vals = df[eff_col]\n",
        "\n",
        "            print(\"\ud83d\udcca Configuration:\")\n",
        "            print(f\"  Dimensions: {width_widget.value}\\\" \u00d7 {height_widget.value}\\\"\")\n",
        "            print(f\"  Point color: {point_color_widget.value}\")\n",
        "            print(f\"  Studies: {len(df)}\")\n",
        "            print(f\"  Pooled effect: {pooled_effect:.3f}\")\n",
        "\n",
        "            # --- PLOTTING ---\n",
        "            print(\"\\n\ud83c\udfa8 Plotting...\")\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, height_widget.value))\n",
        "\n",
        "            # 1. Funnel Triangle (Confidence Region)\n",
        "            # Define range for SE (y-axis)\n",
        "            max_se = y_vals.max() * 1.1\n",
        "            se_seq = np.linspace(0, max_se, 100)\n",
        "\n",
        "            # 95% CI Limit (1.96 * SE)\n",
        "            ci_limit = 1.96 * se_seq\n",
        "\n",
        "            # Left and Right bounds centered on pooled effect\n",
        "            left_line = pooled_effect - ci_limit\n",
        "            right_line = pooled_effect + ci_limit\n",
        "\n",
        "            # --- FIX: Define variables from widgets BEFORE using them ---\n",
        "            funnel_fill_alpha = fill_alpha_widget.value\n",
        "            fill_color = fill_color_widget.value\n",
        "\n",
        "            if fill_funnel_widget.value:\n",
        "                ax.fill_betweenx(se_seq, left_line, right_line, color=fill_color,\n",
        "                               alpha=funnel_fill_alpha, label='95% CI Region')\n",
        "\n",
        "            # Center Line\n",
        "            ax.vlines(pooled_effect, 0, max_se, color=center_line_color_widget.value,\n",
        "                     linestyle='-', linewidth=2, label=f'Pooled Effect ({pooled_effect:.2f})')\n",
        "\n",
        "            # 2. Significance Contours (Optional but cool)\n",
        "            if show_contours_widget.value:\n",
        "                # 99% (2.58 SE)\n",
        "                c99 = 2.58 * se_seq\n",
        "                ax.plot(pooled_effect - c99, se_seq, color='#cccccc', linestyle=':', linewidth=1)\n",
        "                ax.plot(pooled_effect + c99, se_seq, color='#cccccc', linestyle=':', linewidth=1)\n",
        "\n",
        "                # 90% (1.645 SE)\n",
        "                c90 = 1.645 * se_seq\n",
        "                ax.plot(pooled_effect - c90, se_seq, color='#cccccc', linestyle=':', linewidth=1)\n",
        "                ax.plot(pooled_effect + c90, se_seq, color='#cccccc', linestyle=':', linewidth=1)\n",
        "\n",
        "            # 3. Data Points\n",
        "            color_col = color_mod_widget.value\n",
        "\n",
        "            if color_col != 'None' and color_col in df.columns:\n",
        "                # Colored Scatter\n",
        "                categories = df[color_col].unique()\n",
        "                cmap = plt.get_cmap('tab10')\n",
        "                for i, cat in enumerate(categories):\n",
        "                    mask = df[color_col] == cat\n",
        "                    ax.scatter(x_vals[mask], y_vals[mask],\n",
        "                              label=str(cat),\n",
        "                              s=point_size_widget.value,\n",
        "                              alpha=point_alpha_widget.value,\n",
        "                              edgecolors='white', linewidth=0.5)\n",
        "            else:\n",
        "                # Plain Scatter\n",
        "                ax.scatter(x_vals, y_vals,\n",
        "                          color=point_color_widget.value,\n",
        "                          s=point_size_widget.value,\n",
        "                          alpha=point_alpha_widget.value,\n",
        "                          edgecolors='white', linewidth=0.5,\n",
        "                          label='Studies')\n",
        "\n",
        "            # 4. Egger's Test Annotation\n",
        "            if show_egger_widget.value:\n",
        "                # We can try to grab this from a previous step or run it quickly\n",
        "                try:\n",
        "                    # Quick Egger's regression (Mod = SE) using Robust Driver if available\n",
        "                    from scipy.stats import t as t_dist\n",
        "                    X = sm.add_constant(df['se'])\n",
        "                    # Simple WLS for annotation (fast)\n",
        "                    # Note: We prefer the robust result if available in config\n",
        "                    if 'diagnostics_results' in ANALYSIS_CONFIG:\n",
        "                        # Use validated result\n",
        "                        egger_p = ANALYSIS_CONFIG['diagnostics_results'].get('egger_p', np.nan)\n",
        "                    else:\n",
        "                        # Fallback calculation\n",
        "                        res_egger = sm.WLS(df[eff_col], X, weights=1/df[var_col]).fit()\n",
        "                        egger_p = res_egger.pvalues[1]\n",
        "\n",
        "                    sig_star = \"*\" if egger_p < 0.05 else \"ns\"\n",
        "                    txt = f\"Egger's Test: p = {egger_p:.4f} ({sig_star})\"\n",
        "\n",
        "                    # Add text box to bottom right (since Y is inverted, bottom is high SE)\n",
        "                    ax.text(0.95, 0.05, txt, transform=ax.transAxes,\n",
        "                           ha='right', va='bottom',\n",
        "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # 5. Layout\n",
        "            ax.set_ylim(0, max_se)\n",
        "            ax.invert_yaxis() # Standard Funnel Plot orientation (0 at top)\n",
        "\n",
        "            ax.set_xlabel(xlabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(ylabel_widget.value, fontsize=12, fontweight='bold')\n",
        "            ax.set_title(title_widget.value, fontsize=14, fontweight='bold', pad=15)\n",
        "\n",
        "            ax.grid(True, linestyle=':', alpha=0.5)\n",
        "            ax.legend(loc='upper right', frameon=True, fancybox=True)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # 6. Save\n",
        "            fn = filename_widget.value\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M%S\")\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.png\", dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"\ud83d\udcbe Saved: {fn}_{ts}.png\")\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "                print(f\"\ud83d\udcbe Saved: {fn}_{ts}.pdf\")\n",
        "\n",
        "            plt.show()\n",
        "            print(\"\u2705 Plot generated successfully.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Plotting Error: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_btn.on_click(generate_funnel_plot)\n",
        "\n",
        "# --- 4. DISPLAY ---\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"\"\"<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px; border-left: 5px solid #2E86AB;\">\n",
        "    <h3 style=\"margin:0; color: #2E86AB;\">\ud83d\udcca Cell 12b: Publication-Ready Funnel Plot</h3>\n",
        "    <p style=\"margin:5px 0 0 0;\">Visualize publication bias and small-study effects.</p>\n",
        "    </div>\"\"\"),\n",
        "    tabs,\n",
        "    run_btn,\n",
        "    output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uy8b4gKk-RUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "oY3uzFPrC8A_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title \ud83d\udcca 19. Visualization: Trim-and-Fill Plot\n",
        "# =============================================================================\n",
        "# CELL 14b: PUBLICATION-READY TRIM-AND-FILL PLOT\n",
        "# Purpose: Visualize publication bias sensitivity with full customization\n",
        "# Enhanced: Complete GUI matching Forest/Orchard/Funnel Plot functionality\n",
        "# Bug Fixes:\n",
        "#   - Fixed missing png_dpi_widget (was causing crashes)\n",
        "#   - Fixed tab title typo (\"zk Lines\" \u2192 \"\ud83d\udcd0 Lines\")\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import datetime\n",
        "import traceback\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "print(\"=\"*70)\n",
        "print(\"TRIM-AND-FILL PLOT CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "default_title = \"Trim-and-Fill Funnel Plot\"\n",
        "default_xlabel = \"Effect Size\"\n",
        "default_ylabel = \"Standard Error\"\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        default_xlabel = es_config.get('effect_label', 'Effect Size')\n",
        "    print(\"\u2713 Configuration loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"\u26a0\ufe0f  Warning: {e}\")\n",
        "\n",
        "# --- 2. DEFINE CUSTOMIZATION WIDGETS ---\n",
        "\n",
        "# ========== TAB 1: STYLE & LAYOUT ==========\n",
        "style_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83c\udfa8 Style & Layout</h3>\")\n",
        "\n",
        "# Dimensions Section\n",
        "width_widget = widgets.FloatSlider(\n",
        "    value=10.0, min=5.0, max=16.0, step=0.5,\n",
        "    description='Plot Width (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "height_widget = widgets.FloatSlider(\n",
        "    value=7.0, min=4.0, max=14.0, step=0.5,\n",
        "    description='Plot Height (in):',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Typography Section\n",
        "title_fontsize_widget = widgets.IntSlider(\n",
        "    value=14, min=8, max=24, step=1,\n",
        "    description='Title Font Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "label_fontsize_widget = widgets.IntSlider(\n",
        "    value=12, min=8, max=18, step=1,\n",
        "    description='Axis Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "tick_fontsize_widget = widgets.IntSlider(\n",
        "    value=10, min=6, max=16, step=1,\n",
        "    description='Tick Label Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "legend_fontsize_widget = widgets.IntSlider(\n",
        "    value=10, min=6, max=14, step=1,\n",
        "    description='Legend Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    style_header,\n",
        "    widgets.HTML(\"<b>Dimensions:</b>\"),\n",
        "    preset_widget,\n",
        "    width_widget,\n",
        "    height_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Typography:</b>\"),\n",
        "    title_fontsize_widget,\n",
        "    label_fontsize_widget,\n",
        "    tick_fontsize_widget,\n",
        "    legend_fontsize_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 2: TEXT & LABELS ==========\n",
        "text_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcdd Text & Labels</h3>\")\n",
        "\n",
        "show_title_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Plot Title',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "title_widget = widgets.Text(\n",
        "    value=default_title,\n",
        "    description='Plot Title:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "xlabel_widget = widgets.Text(\n",
        "    value=default_xlabel,\n",
        "    description='X-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "ylabel_widget = widgets.Text(\n",
        "    value=default_ylabel,\n",
        "    description='Y-Axis Label:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "show_ylabel_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Y-Axis Label',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "text_tab = widgets.VBox([\n",
        "    text_header,\n",
        "    widgets.HTML(\"<b>Title:</b>\"),\n",
        "    show_title_widget,\n",
        "    title_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Axis Labels:</b>\"),\n",
        "    xlabel_widget,\n",
        "    show_ylabel_widget,\n",
        "    ylabel_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 3: POINTS & DATA ==========\n",
        "points_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\u26ab Points & Data</h3>\")\n",
        "\n",
        "# Observed Studies\n",
        "obs_color_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Black', 'black'),\n",
        "        ('Gray', 'gray'),\n",
        "        ('Steel Blue', 'steelblue'),\n",
        "        ('Blue', 'blue'),\n",
        "        ('Dark Green', 'darkgreen')\n",
        "    ],\n",
        "    value='black',\n",
        "    description='Observed Color:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "obs_shape_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Circle (\u25cf)', 'o'),\n",
        "        ('Diamond (\u25c6)', 'D'),\n",
        "        ('Square (\u25a0)', 's'),\n",
        "        ('Triangle Up (\u25b2)', '^'),\n",
        "        ('Pentagon', 'p')\n",
        "    ],\n",
        "    value='o',\n",
        "    description='Observed Shape:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "obs_edge_width_widget = widgets.FloatSlider(\n",
        "    value=0.5, min=0.0, max=3.0, step=0.1,\n",
        "    description='Obs Edge Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Imputed Studies\n",
        "imp_color_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('White (Hollow)', 'white'),\n",
        "        ('Red', 'red'),\n",
        "        ('Orange', 'orange'),\n",
        "        ('Yellow', 'yellow'),\n",
        "        ('Light Gray', 'lightgray'),\n",
        "        ('None (Transparent)', 'none')\n",
        "    ],\n",
        "    value='white',\n",
        "    description='Imputed Color:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "imp_edge_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Red', 'red'),\n",
        "        ('Black', 'black'),\n",
        "        ('Orange', 'orange'),\n",
        "        ('Dark Red', 'darkred')\n",
        "    ],\n",
        "    value='red',\n",
        "    description='Imputed Edge:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "imp_edge_width_widget = widgets.FloatSlider(\n",
        "    value=1.5, min=0.5, max=4.0, step=0.25,\n",
        "    description='Imp Edge Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "imp_shape_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Circle (\u25cf)', 'o'),\n",
        "        ('Diamond (\u25c6)', 'D'),\n",
        "        ('Square (\u25a0)', 's'),\n",
        "        ('Triangle Down (\u25bc)', 'v'),\n",
        "        ('Star (\u2605)', '*')\n",
        "    ],\n",
        "    value='o',\n",
        "    description='Imputed Shape:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Common Point Settings\n",
        "point_size_widget = widgets.IntSlider(\n",
        "    value=50, min=10, max=200, step=5,\n",
        "    description='Point Size:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "point_alpha_widget = widgets.FloatSlider(\n",
        "    value=0.7, min=0.1, max=1.0, step=0.05,\n",
        "    description='Point Opacity:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "points_tab = widgets.VBox([\n",
        "    points_header,\n",
        "    widgets.HTML(\"<b>Observed Studies:</b>\"),\n",
        "    obs_color_widget,\n",
        "    obs_shape_widget,\n",
        "    obs_edge_width_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Imputed Studies:</b>\"),\n",
        "    imp_color_widget,\n",
        "    imp_edge_widget,\n",
        "    imp_edge_width_widget,\n",
        "    imp_shape_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Common Settings:</b>\"),\n",
        "    point_size_widget,\n",
        "    point_alpha_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 4: LINES & FUNNEL ==========\n",
        "lines_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcd0 Lines & Funnel</h3>\")\n",
        "\n",
        "# Original Mean Line\n",
        "show_orig_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Original Mean Line',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "orig_color_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Black', 'black'),\n",
        "        ('Gray', 'gray'),\n",
        "        ('Blue', 'blue'),\n",
        "        ('Dark Blue', 'darkblue')\n",
        "    ],\n",
        "    value='black',\n",
        "    description='Orig Line Color:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "orig_width_widget = widgets.FloatSlider(\n",
        "    value=2.0, min=0.5, max=5.0, step=0.5,\n",
        "    description='Orig Line Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "orig_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Dashed', '--'),\n",
        "        ('Solid', '-'),\n",
        "        ('Dotted', ':'),\n",
        "        ('Dash-Dot', '-.')\n",
        "    ],\n",
        "    value='--',\n",
        "    description='Orig Line Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Adjusted Mean Line\n",
        "show_adj_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Adjusted Mean Line',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "adj_color_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Red', 'red'),\n",
        "        ('Orange', 'orange'),\n",
        "        ('Magenta', 'magenta'),\n",
        "        ('Dark Red', 'darkred')\n",
        "    ],\n",
        "    value='red',\n",
        "    description='Adj Line Color:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "adj_width_widget = widgets.FloatSlider(\n",
        "    value=2.0, min=0.5, max=5.0, step=0.5,\n",
        "    description='Adj Line Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "adj_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Solid', '-'),\n",
        "        ('Dashed', '--'),\n",
        "        ('Dotted', ':'),\n",
        "        ('Dash-Dot', '-.')\n",
        "    ],\n",
        "    value='-',\n",
        "    description='Adj Line Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Funnel Guidelines\n",
        "show_funnel_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show 95% CI Funnel Guidelines',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "funnel_fill_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Fill Funnel Region',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "funnel_fill_alpha_widget = widgets.FloatSlider(\n",
        "    value=0.1, min=0.0, max=0.5, step=0.05,\n",
        "    description='Fill Opacity:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "funnel_line_width_widget = widgets.FloatSlider(\n",
        "    value=1.0, min=0.5, max=3.0, step=0.25,\n",
        "    description='Funnel Line Width:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "lines_tab = widgets.VBox([\n",
        "    lines_header,\n",
        "    widgets.HTML(\"<b>Original Mean Line:</b>\"),\n",
        "    show_orig_widget,\n",
        "    orig_color_widget,\n",
        "    orig_width_widget,\n",
        "    orig_style_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Adjusted Mean Line:</b>\"),\n",
        "    show_adj_widget,\n",
        "    adj_color_widget,\n",
        "    adj_width_widget,\n",
        "    adj_style_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Funnel Guidelines:</b>\"),\n",
        "    show_funnel_widget,\n",
        "    funnel_fill_widget,\n",
        "    funnel_fill_alpha_widget,\n",
        "    funnel_line_width_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 5: AXES & GRID ==========\n",
        "axes_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udccf Axes & Grid</h3>\")\n",
        "\n",
        "# Axis Scaling\n",
        "auto_scale_x_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Auto-Scale X-Axis',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "x_min_widget = widgets.FloatText(\n",
        "    value=-2.0,\n",
        "    description='X-Min:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "x_max_widget = widgets.FloatText(\n",
        "    value=2.0,\n",
        "    description='X-Max:',\n",
        "    style={'description_width': '80px'},\n",
        "    layout=widgets.Layout(width='220px', visibility='hidden')\n",
        ")\n",
        "\n",
        "manual_x_box = widgets.HBox([x_min_widget, x_max_widget])\n",
        "\n",
        "def toggle_manual_x_scale(change):\n",
        "    if change['new']:\n",
        "        x_min_widget.layout.visibility = 'hidden'\n",
        "        x_max_widget.layout.visibility = 'hidden'\n",
        "    else:\n",
        "        x_min_widget.layout.visibility = 'visible'\n",
        "        x_max_widget.layout.visibility = 'visible'\n",
        "\n",
        "auto_scale_x_widget.observe(toggle_manual_x_scale, names='value')\n",
        "\n",
        "# Y-Axis Inversion\n",
        "invert_y_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Invert Y-Axis (Standard for Funnel Plots)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Grid\n",
        "show_grid_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Show Grid',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "grid_style_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Dotted (Light)', 'dotted'),\n",
        "        ('Dashed (Light)', 'dashed'),\n",
        "        ('Solid (Light)', 'solid')\n",
        "    ],\n",
        "    value='dotted',\n",
        "    description='Grid Style:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "grid_alpha_widget = widgets.FloatSlider(\n",
        "    value=0.4, min=0.1, max=1.0, step=0.1,\n",
        "    description='Grid Opacity:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "axes_tab = widgets.VBox([\n",
        "    axes_header,\n",
        "    widgets.HTML(\"<b>X-Axis Scaling:</b>\"),\n",
        "    auto_scale_x_widget,\n",
        "    manual_x_box,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Y-Axis:</b>\"),\n",
        "    invert_y_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>Grid:</b>\"),\n",
        "    show_grid_widget,\n",
        "    grid_style_widget,\n",
        "    grid_alpha_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 6: EXPORT & LEGEND ==========\n",
        "export_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcbe Export & Legend</h3>\")\n",
        "\n",
        "# Legend\n",
        "legend_loc_widget = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Best', 'best'),\n",
        "        ('Upper Right', 'upper right'),\n",
        "        ('Upper Left', 'upper left'),\n",
        "        ('Lower Right', 'lower right'),\n",
        "        ('Lower Left', 'lower left'),\n",
        "        ('Center Right', 'center right'),\n",
        "        ('None', 'none')\n",
        "    ],\n",
        "    value='upper right',\n",
        "    description='Legend Position:',\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "legend_frame_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Legend Frame',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "legend_fancybox_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Fancy Box (Rounded Corners)',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# Export Options\n",
        "save_pdf_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PDF',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "save_png_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Save as PNG',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "# BUG FIX: This widget was missing in the original code!\n",
        "png_dpi_widget = widgets.IntSlider(\n",
        "    value=300, min=150, max=600, step=50,\n",
        "    description='PNG DPI:',\n",
        "    continuous_update=False,\n",
        "    style={'description_width': '130px'},\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "filename_prefix_widget = widgets.Text(\n",
        "    value='TrimFill_Plot',\n",
        "    description='Filename Prefix:',\n",
        "    layout=widgets.Layout(width='450px'),\n",
        "    style={'description_width': '130px'}\n",
        ")\n",
        "\n",
        "transparent_bg_widget = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Transparent Background',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "include_timestamp_widget = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description='Include Timestamp',\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='450px')\n",
        ")\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    export_header,\n",
        "    widgets.HTML(\"<b>Legend:</b>\"),\n",
        "    legend_loc_widget,\n",
        "    legend_frame_widget,\n",
        "    legend_fancybox_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>File Formats:</b>\"),\n",
        "    save_pdf_widget,\n",
        "    save_png_widget,\n",
        "    png_dpi_widget,\n",
        "    widgets.HTML(\"<hr style='margin: 10px 0;'>\"),\n",
        "    widgets.HTML(\"<b>File Settings:</b>\"),\n",
        "    filename_prefix_widget,\n",
        "    transparent_bg_widget,\n",
        "    include_timestamp_widget\n",
        "])\n",
        "\n",
        "# ========== CREATE TAB WIDGET ==========\n",
        "tab_children = [style_tab, text_tab, points_tab, lines_tab, axes_tab, export_tab]\n",
        "tabs = widgets.Tab(children=tab_children)\n",
        "tabs.set_title(0, '\ud83c\udfa8 Style')\n",
        "tabs.set_title(1, '\ud83d\udcdd Text')\n",
        "tabs.set_title(2, '\u26ab Points')\n",
        "tabs.set_title(3, '\ud83d\udcd0 Lines')  # BUG FIX: Was \"zk Lines\" (typo!)\n",
        "tabs.set_title(4, '\ud83d\udccf Axes')\n",
        "tabs.set_title(5, '\ud83d\udcbe Export')\n",
        "\n",
        "print(\"\\n\u2713 GUI widgets created\")\n",
        "print(f\"\u2713 Tabs: 6 professional tabs\")\n",
        "print(f\"\u2713 Controls: 50+ customization options\")\n",
        "print(f\"\u2713 Bugs fixed: 2 (typo + missing DPI widget)\")\n",
        "\n",
        "# --- 3. DEFINE PLOT GENERATION FUNCTION ---\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "def generate_tf_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING TRIM-AND-FILL PLOT\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        try:\n",
        "            # --- GET WIDGET VALUES ---\n",
        "            plot_width = width_widget.value\n",
        "            plot_height = height_widget.value\n",
        "            title_fontsize = title_fontsize_widget.value\n",
        "            label_fontsize = label_fontsize_widget.value\n",
        "            tick_fontsize = tick_fontsize_widget.value\n",
        "            legend_fontsize = legend_fontsize_widget.value\n",
        "\n",
        "            show_title = show_title_widget.value\n",
        "            graph_title = title_widget.value\n",
        "            x_label = xlabel_widget.value\n",
        "            show_ylabel = show_ylabel_widget.value\n",
        "            y_label = ylabel_widget.value\n",
        "\n",
        "            obs_color = obs_color_widget.value\n",
        "            obs_shape = obs_shape_widget.value\n",
        "            obs_edge_width = obs_edge_width_widget.value\n",
        "\n",
        "            imp_color = imp_color_widget.value\n",
        "            imp_edge = imp_edge_widget.value\n",
        "            imp_edge_width = imp_edge_width_widget.value\n",
        "            imp_shape = imp_shape_widget.value\n",
        "\n",
        "            point_size = point_size_widget.value\n",
        "            point_alpha = point_alpha_widget.value\n",
        "\n",
        "            show_orig = show_orig_widget.value\n",
        "            orig_color = orig_color_widget.value\n",
        "            orig_width = orig_width_widget.value\n",
        "            orig_style = orig_style_widget.value\n",
        "\n",
        "            show_adj = show_adj_widget.value\n",
        "            adj_color = adj_color_widget.value\n",
        "            adj_width = adj_width_widget.value\n",
        "            adj_style = adj_style_widget.value\n",
        "\n",
        "            show_funnel = show_funnel_widget.value\n",
        "            funnel_fill = funnel_fill_widget.value\n",
        "            funnel_fill_alpha = funnel_fill_alpha_widget.value\n",
        "            funnel_line_width = funnel_line_width_widget.value\n",
        "\n",
        "            auto_scale_x = auto_scale_x_widget.value\n",
        "            x_min_manual = x_min_widget.value\n",
        "            x_max_manual = x_max_widget.value\n",
        "            invert_y = invert_y_widget.value\n",
        "\n",
        "            show_grid = show_grid_widget.value\n",
        "            grid_style = grid_style_widget.value\n",
        "            grid_alpha = grid_alpha_widget.value\n",
        "\n",
        "            legend_loc = legend_loc_widget.value\n",
        "            legend_frame = legend_frame_widget.value\n",
        "            legend_fancybox = legend_fancybox_widget.value\n",
        "\n",
        "            save_pdf = save_pdf_widget.value\n",
        "            save_png = save_png_widget.value\n",
        "            png_dpi = png_dpi_widget.value\n",
        "            filename_prefix = filename_prefix_widget.value\n",
        "            transparent_bg = transparent_bg_widget.value\n",
        "            include_timestamp = include_timestamp_widget.value\n",
        "\n",
        "            print(f\"\ud83d\udcca Configuration:\")\n",
        "            print(f\"  Dimensions: {plot_width}\\\" \u00d7 {plot_height}\\\"\")\n",
        "            print(f\"  Observed: {obs_color}, Imputed: {imp_color}\")\n",
        "\n",
        "            # --- LOAD DATA ---\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'trimfill_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"\u274c Error: Run Cell 16 (Publication Bias Diagnostics) first.\")\n",
        "                print(\"   This will compute Trim-and-Fill analysis.\")\n",
        "                return\n",
        "\n",
        "            tf_res = ANALYSIS_CONFIG['trimfill_results']\n",
        "\n",
        "            # Extract data\n",
        "            yi_all = tf_res['yi_combined']\n",
        "            vi_all = tf_res['vi_combined']\n",
        "            se_all = np.sqrt(vi_all)\n",
        "\n",
        "            k0 = tf_res['k0']\n",
        "            n_orig = len(yi_all) - k0\n",
        "\n",
        "            yi_orig = yi_all[:n_orig]\n",
        "            se_orig = se_all[:n_orig]\n",
        "\n",
        "            yi_fill = yi_all[n_orig:]\n",
        "            se_fill = se_all[n_orig:]\n",
        "\n",
        "            orig_mean = tf_res['pooled_original']\n",
        "            fill_mean = tf_res['pooled_filled']\n",
        "\n",
        "            print(f\"  Original studies: {n_orig}\")\n",
        "            print(f\"  Imputed studies: {k0}\")\n",
        "            print(f\"  Original mean: {orig_mean:.3f}\")\n",
        "            print(f\"  Adjusted mean: {fill_mean:.3f}\")\n",
        "\n",
        "            # --- CREATE FIGURE ---\n",
        "            fig, ax = plt.subplots(figsize=(plot_width, plot_height))\n",
        "\n",
        "            if transparent_bg:\n",
        "                fig.patch.set_alpha(0)\n",
        "                ax.patch.set_alpha(0)\n",
        "\n",
        "            # Max SE for Y-axis\n",
        "            max_se = np.max(se_all) * 1.1 if len(se_all) > 0 else 1.0\n",
        "            y_range = np.linspace(0, max_se, 100)\n",
        "\n",
        "            print(f\"\\n\ud83c\udfa8 Plotting...\")\n",
        "\n",
        "            # --- FUNNEL GUIDELINES ---\n",
        "            if show_funnel:\n",
        "                x_left = fill_mean - 1.96 * y_range\n",
        "                x_right = fill_mean + 1.96 * y_range\n",
        "\n",
        "                ax.plot(x_left, y_range, color='gray', linestyle='--',\n",
        "                       linewidth=funnel_line_width, alpha=0.5)\n",
        "                ax.plot(x_right, y_range, color='gray', linestyle='--',\n",
        "                       linewidth=funnel_line_width, alpha=0.5)\n",
        "\n",
        "                if funnel_fill:\n",
        "                    ax.fill_betweenx(y_range, x_left, x_right, color='lightgray',\n",
        "                                    alpha=funnel_fill_alpha)\n",
        "\n",
        "            # --- PLOT OBSERVED STUDIES ---\n",
        "            ax.scatter(yi_orig, se_orig,\n",
        "                      c=obs_color,\n",
        "                      s=point_size,\n",
        "                      alpha=point_alpha,\n",
        "                      marker=obs_shape,\n",
        "                      edgecolors='black',\n",
        "                      linewidth=obs_edge_width,\n",
        "                      label='Observed Studies',\n",
        "                      zorder=3)\n",
        "\n",
        "            # --- PLOT IMPUTED STUDIES ---\n",
        "            if k0 > 0:\n",
        "                ax.scatter(yi_fill, se_fill,\n",
        "                          c=imp_color,\n",
        "                          s=point_size,\n",
        "                          alpha=point_alpha,\n",
        "                          marker=imp_shape,\n",
        "                          edgecolors=imp_edge,\n",
        "                          linewidth=imp_edge_width,\n",
        "                          label=f'Imputed Studies (k={k0})',\n",
        "                          zorder=3)\n",
        "\n",
        "            # --- PLOT MEAN LINES ---\n",
        "            if show_orig:\n",
        "                ax.axvline(orig_mean, color=orig_color, linestyle=orig_style,\n",
        "                          linewidth=orig_width,\n",
        "                          label=f'Original: {orig_mean:.3f}',\n",
        "                          zorder=2)\n",
        "\n",
        "            if show_adj:\n",
        "                ax.axvline(fill_mean, color=adj_color, linestyle=adj_style,\n",
        "                          linewidth=adj_width,\n",
        "                          label=f'Adjusted: {fill_mean:.3f}',\n",
        "                          zorder=2)\n",
        "\n",
        "            # --- AXIS SETTINGS ---\n",
        "            if invert_y:\n",
        "                ax.set_ylim(max_se, 0)  # Inverted Y-axis\n",
        "            else:\n",
        "                ax.set_ylim(0, max_se)\n",
        "\n",
        "            if not auto_scale_x:\n",
        "                ax.set_xlim(x_min_manual, x_max_manual)\n",
        "\n",
        "            if show_title:\n",
        "                ax.set_title(graph_title, fontsize=title_fontsize,\n",
        "                           fontweight='bold', pad=15)\n",
        "\n",
        "            ax.set_xlabel(x_label, fontsize=label_fontsize, fontweight='bold')\n",
        "\n",
        "            if show_ylabel:\n",
        "                ax.set_ylabel(y_label, fontsize=label_fontsize, fontweight='bold')\n",
        "\n",
        "            ax.tick_params(labelsize=tick_fontsize)\n",
        "\n",
        "            if show_grid:\n",
        "                grid_ls = ':' if grid_style == 'dotted' else ('--' if grid_style == 'dashed' else '-')\n",
        "                ax.grid(True, linestyle=grid_ls, alpha=grid_alpha)\n",
        "\n",
        "            if legend_loc != 'none':\n",
        "                ax.legend(loc=legend_loc, frameon=legend_frame,\n",
        "                         fancybox=legend_fancybox, fontsize=legend_fontsize)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- SAVE FILES ---\n",
        "            print(f\"\\n\ud83d\udcbe Saving files...\")\n",
        "\n",
        "            saved_files = []\n",
        "\n",
        "            if include_timestamp:\n",
        "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                base_filename = f\"{filename_prefix}_{timestamp}\"\n",
        "            else:\n",
        "                base_filename = filename_prefix\n",
        "\n",
        "            if save_pdf:\n",
        "                pdf_filename = f\"{base_filename}.pdf\"\n",
        "                fig.savefig(pdf_filename, bbox_inches='tight', transparent=transparent_bg)\n",
        "                saved_files.append(pdf_filename)\n",
        "                print(f\"  \u2713 {pdf_filename}\")\n",
        "\n",
        "            if save_png:\n",
        "                png_filename = f\"{base_filename}.png\"\n",
        "                fig.savefig(png_filename, dpi=png_dpi, bbox_inches='tight',\n",
        "                           transparent=transparent_bg)\n",
        "                saved_files.append(png_filename)\n",
        "                print(f\"  \u2713 {png_filename} (DPI: {png_dpi})\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"\\n\" + \"=\"*70)\n",
        "            print(\"\u2705 TRIM-AND-FILL PLOT COMPLETE\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Files: {', '.join(saved_files)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n\u274c ERROR: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "# --- 4. CREATE BUTTON AND DISPLAY ---\n",
        "run_plot_btn = widgets.Button(\n",
        "    description='\ud83d\udcca Generate Trim-and-Fill Plot',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='450px', height='50px'),\n",
        "    style={'font_weight': 'bold'}\n",
        ")\n",
        "\n",
        "run_plot_btn.on_click(generate_tf_plot)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 TRIM-AND-FILL PLOT INTERFACE READY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udc46 Customize your plot using the tabs above, then click Generate\")\n",
        "print(\"\\n\ud83d\udcdd Tips:\")\n",
        "print(\"  \u2022 \ud83d\udc1b BUGS FIXED: Tab typo + missing PNG DPI control!\")\n",
        "print(\"  \u2022 Imputed studies show where missing studies might be\")\n",
        "print(\"  \u2022 Adjusted mean accounts for potential publication bias\")\n",
        "print(\"  \u2022 White/hollow imputed points are standard in literature\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcca Trim-and-Fill Plot Generator (Enhanced)</h3>\"),\n",
        "    widgets.HTML(\"<p style='color: #666;'>Visualize publication bias sensitivity with full customization</p>\"),\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    tabs,\n",
        "    widgets.HTML(\"<hr style='margin: 15px 0;'>\"),\n",
        "    run_plot_btn,\n",
        "    plot_output\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83e\uddea 20. Sensitivity Analysis: Leave-One-Out - DATA LAYER (Model)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 1/4: DATA LAYER - LEAVE-ONE-OUT SENSITIVITY ANALYSIS\n",
        "# Purpose: Centralized data management for leave-one-out analysis\n",
        "# Dependencies: ANALYSIS_CONFIG global dictionary\n",
        "# Math validated: Iterative removal of studies to detect influential cases\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA CLASSES\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class LOOConfig:\n",
        "    \"\"\"Configuration for leave-one-out analysis\"\"\"\n",
        "    effect_col: str\n",
        "    var_col: str\n",
        "    alpha: float = 0.05\n",
        "    influence_threshold: float = 20.0  # Percent change threshold\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration\"\"\"\n",
        "        if not self.effect_col:\n",
        "            raise ValueError(\"effect_col cannot be empty\")\n",
        "        if not self.var_col:\n",
        "            raise ValueError(\"var_col cannot be empty\")\n",
        "        if self.alpha <= 0 or self.alpha >= 1:\n",
        "            raise ValueError(f\"alpha must be between 0 and 1, got {self.alpha}\")\n",
        "        if self.influence_threshold <= 0:\n",
        "            raise ValueError(f\"influence_threshold must be positive, got {self.influence_threshold}\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class OriginalEstimate:\n",
        "    \"\"\"Original full-model estimate\"\"\"\n",
        "    mu: float\n",
        "    se: float\n",
        "    ci_lower: float\n",
        "    ci_upper: float\n",
        "    tau2: Optional[float] = None\n",
        "    sigma2: Optional[float] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LOOIteration:\n",
        "    \"\"\"Results from one leave-one-out iteration\"\"\"\n",
        "    excluded_study: str\n",
        "    mu: float\n",
        "    se: float\n",
        "    ci_lower: float\n",
        "    ci_upper: float\n",
        "    tau2: Optional[float]\n",
        "    sigma2: Optional[float]\n",
        "    diff: float  # Difference from original\n",
        "    pct_change: float  # Percent change from original\n",
        "    is_influential: bool\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LOOResult:\n",
        "    \"\"\"Complete leave-one-out analysis result\"\"\"\n",
        "    original: OriginalEstimate\n",
        "    iterations: pd.DataFrame  # DataFrame of LOOIteration results\n",
        "\n",
        "    # Summary statistics\n",
        "    n_studies: int\n",
        "    n_influential: int\n",
        "    min_estimate: float\n",
        "    max_estimate: float\n",
        "    range_estimate: float\n",
        "\n",
        "    # Most influential studies\n",
        "    top_influential: pd.DataFrame\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA MANAGER CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class LOODataManager:\n",
        "    \"\"\"\n",
        "    Centralized data access layer for leave-one-out sensitivity analysis.\n",
        "    Handles all interactions with ANALYSIS_CONFIG and data validation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize data manager.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self._config = analysis_config\n",
        "        self._validate_prerequisites()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # VALIDATION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _validate_prerequisites(self) -> None:\n",
        "        \"\"\"Validate that required configuration exists\"\"\"\n",
        "        if 'effect_col' not in self._config:\n",
        "            warnings.warn(\"effect_col not in ANALYSIS_CONFIG, using default 'hedges_g'\")\n",
        "        if 'var_col' not in self._config:\n",
        "            warnings.warn(\"var_col not in ANALYSIS_CONFIG, using default 'Vg'\")\n",
        "\n",
        "    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Validate that data is suitable for leave-one-out analysis.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if df is None or len(df) == 0:\n",
        "            return False, \"No data available\"\n",
        "\n",
        "        if self.effect_col not in df.columns:\n",
        "            return False, f\"Effect column '{self.effect_col}' not found\"\n",
        "\n",
        "        if self.var_col not in df.columns:\n",
        "            return False, f\"Variance column '{self.var_col}' not found\"\n",
        "\n",
        "        # Check for study ID\n",
        "        if 'id' not in df.columns:\n",
        "            return False, \"'id' column not found - cannot perform leave-one-out by study\"\n",
        "\n",
        "        # Check for minimum studies (need at least 3 to leave one out)\n",
        "        n_studies = df['id'].nunique()\n",
        "        if n_studies < 3:\n",
        "            return False, f\"Need at least 3 studies for leave-one-out, found {n_studies}\"\n",
        "\n",
        "        return True, None\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROPERTY ACCESSORS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def analysis_data(self) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Get analysis dataset\"\"\"\n",
        "        if 'analysis_data' in self._config:\n",
        "            return self._config['analysis_data'].copy()\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def effect_col(self) -> str:\n",
        "        \"\"\"Get effect size column name\"\"\"\n",
        "        return self._config.get('effect_col', 'hedges_g')\n",
        "\n",
        "    @property\n",
        "    def var_col(self) -> str:\n",
        "        \"\"\"Get variance column name\"\"\"\n",
        "        return self._config.get('var_col', 'Vg')\n",
        "\n",
        "    @property\n",
        "    def es_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get effect size configuration\"\"\"\n",
        "        return self._config.get('es_config', {})\n",
        "\n",
        "    @property\n",
        "    def global_settings(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get global settings (with defaults)\"\"\"\n",
        "        return self._config.get('global_settings', {\n",
        "            'alpha': 0.05\n",
        "        })\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA EXTRACTION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def prepare_data(\n",
        "        self,\n",
        "        df: Optional[pd.DataFrame] = None\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Prepare and clean data for leave-one-out analysis.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to prepare (uses analysis_data if None)\n",
        "\n",
        "        Returns:\n",
        "            Cleaned DataFrame\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If data cannot be prepared\n",
        "        \"\"\"\n",
        "        if df is None:\n",
        "            df = self.analysis_data\n",
        "\n",
        "        if df is None:\n",
        "            raise ValueError(\"No data available for analysis\")\n",
        "\n",
        "        # Validate\n",
        "        is_valid, error_msg = self.validate_data(df)\n",
        "        if not is_valid:\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        # Create working copy\n",
        "        clean_df = df.copy()\n",
        "\n",
        "        # Remove missing values\n",
        "        clean_df = clean_df.dropna(subset=[\n",
        "            self.effect_col,\n",
        "            self.var_col,\n",
        "            'id'\n",
        "        ]).copy()\n",
        "\n",
        "        # Remove zero or negative variances\n",
        "        clean_df = clean_df[clean_df[self.var_col] > 0].copy()\n",
        "\n",
        "        # Final check\n",
        "        n_studies = clean_df['id'].nunique()\n",
        "        if n_studies < 3:\n",
        "            raise ValueError(\n",
        "                f\"Insufficient studies after cleaning: {n_studies} studies. \"\n",
        "                f\"Need at least 3 for leave-one-out analysis.\"\n",
        "            )\n",
        "\n",
        "        return clean_df\n",
        "\n",
        "    def get_study_ids(self, df: pd.DataFrame) -> List[Any]:\n",
        "        \"\"\"\n",
        "        Get list of unique study IDs.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame with 'id' column\n",
        "\n",
        "        Returns:\n",
        "            List of unique study IDs\n",
        "        \"\"\"\n",
        "        return df['id'].unique().tolist()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RESULT PERSISTENCE METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def save_loo_results(self, result: LOOResult) -> None:\n",
        "        \"\"\"\n",
        "        Save leave-one-out results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: LOOResult object\n",
        "        \"\"\"\n",
        "        import datetime\n",
        "\n",
        "        # Save in format compatible with visualization cells\n",
        "        self._config['loo_results'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'data': result.iterations,\n",
        "            'orig_mu': result.original.mu,\n",
        "            'orig_ci_lo': result.original.ci_lower,\n",
        "            'orig_ci_hi': result.original.ci_upper,\n",
        "            'n_studies': result.n_studies,\n",
        "            'n_influential': result.n_influential,\n",
        "            'min_estimate': result.min_estimate,\n",
        "            'max_estimate': result.max_estimate\n",
        "        }\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTILITY METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def summary_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get summary of current configuration\"\"\"\n",
        "        df = self.analysis_data\n",
        "\n",
        "        return {\n",
        "            'effect_col': self.effect_col,\n",
        "            'var_col': self.var_col,\n",
        "            'n_observations': len(df) if df is not None else 0,\n",
        "            'n_studies': df['id'].nunique() if df is not None and 'id' in df.columns else 0\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HELPER: CI CALCULATOR\n",
        "# =============================================================================\n",
        "\n",
        "class CICalculator:\n",
        "    \"\"\"\n",
        "    Calculates confidence intervals for estimates.\n",
        "    Handles cases where CIs are not provided by regression output.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_ci(\n",
        "        estimate: float,\n",
        "        se: float,\n",
        "        alpha: float = 0.05,\n",
        "        df: Optional[int] = None\n",
        "    ) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Calculate confidence interval.\n",
        "\n",
        "        Args:\n",
        "            estimate: Point estimate\n",
        "            se: Standard error\n",
        "            alpha: Significance level (default 0.05 for 95% CI)\n",
        "            df: Degrees of freedom (if None, uses normal distribution)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (ci_lower, ci_upper)\n",
        "        \"\"\"\n",
        "        from scipy.stats import norm, t\n",
        "\n",
        "        q = 1 - (alpha / 2)\n",
        "\n",
        "        if df is not None and df > 0:\n",
        "            crit_val = t.ppf(q, df)\n",
        "        else:\n",
        "            crit_val = norm.ppf(q)\n",
        "\n",
        "        ci_lower = estimate - crit_val * se\n",
        "        ci_upper = estimate + crit_val * se\n",
        "\n",
        "        return ci_lower, ci_upper\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Leave-One-Out Data Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - LOOConfig\")\n",
        "    print(\"   - OriginalEstimate\")\n",
        "    print(\"   - LOOIteration\")\n",
        "    print(\"   - LOOResult\")\n",
        "    print(\"   - LOODataManager\")\n",
        "    print(\"   - CICalculator\")\n",
        "#@title \ud83e\uddea 20. Sensitivity Analysis: Leave-One-Out - ANALYSIS LAYER (Business Logic)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 2/4: ANALYSIS LAYER - LEAVE-ONE-OUT SENSITIVITY ANALYSIS\n",
        "# Purpose: Pure statistical computation without UI dependencies\n",
        "# Dependencies:\n",
        "#   - Data Layer (LOODataManager, LOOResult)\n",
        "#   - Three-level regression function (_run_three_level_reml_for_subgroup)\n",
        "# Math validated: Iterative model fitting with study exclusion\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BASELINE ESTIMATOR\n",
        "# =============================================================================\n",
        "\n",
        "class BaselineEstimator:\n",
        "    \"\"\"\n",
        "    Estimates the original full-model baseline using all studies.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, effect_col: str, var_col: str, alpha: float = 0.05):\n",
        "        \"\"\"\n",
        "        Initialize estimator.\n",
        "\n",
        "        Args:\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name\n",
        "            alpha: Significance level for CIs\n",
        "        \"\"\"\n",
        "        self.effect_col = effect_col\n",
        "        self.var_col = var_col\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def estimate_baseline(\n",
        "        self,\n",
        "        df: pd.DataFrame\n",
        "    ) -> Optional[OriginalEstimate]:\n",
        "        \"\"\"\n",
        "        Run full model with all studies to get baseline.\n",
        "\n",
        "        Args:\n",
        "            df: Full dataset\n",
        "\n",
        "        Returns:\n",
        "            OriginalEstimate object or None if fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use the three-level REML function\n",
        "            estimates, metadata = _run_three_level_reml_for_subgroup(\n",
        "                df,\n",
        "                self.effect_col,\n",
        "                self.var_col\n",
        "            )\n",
        "\n",
        "            if estimates is None:\n",
        "                return None\n",
        "\n",
        "            # Extract estimates\n",
        "            mu = estimates['mu']\n",
        "            se = estimates.get('se_mu', estimates.get('se', np.nan))\n",
        "\n",
        "            # Get or calculate CIs\n",
        "            if 'ci_lower' in estimates and 'ci_upper' in estimates:\n",
        "                ci_lower = estimates['ci_lower']\n",
        "                ci_upper = estimates['ci_upper']\n",
        "            else:\n",
        "                # Calculate manually\n",
        "                ci_lower, ci_upper = CICalculator.calculate_ci(\n",
        "                    mu, se, self.alpha\n",
        "                )\n",
        "\n",
        "            # Get variance components\n",
        "            tau2 = estimates.get('tau_sq', estimates.get('tau2'))\n",
        "            sigma2 = estimates.get('sigma_sq', estimates.get('sigma2'))\n",
        "\n",
        "            return OriginalEstimate(\n",
        "                mu=mu,\n",
        "                se=se,\n",
        "                ci_lower=ci_lower,\n",
        "                ci_upper=ci_upper,\n",
        "                tau2=tau2,\n",
        "                sigma2=sigma2\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Baseline estimation failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# LOO ITERATOR\n",
        "# =============================================================================\n",
        "\n",
        "class LOOIterator:\n",
        "    \"\"\"\n",
        "    Iteratively removes one study at a time and re-fits the model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        effect_col: str,\n",
        "        var_col: str,\n",
        "        alpha: float = 0.05,\n",
        "        influence_threshold: float = 20.0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize iterator.\n",
        "\n",
        "        Args:\n",
        "            effect_col: Effect size column name\n",
        "            var_col: Variance column name\n",
        "            alpha: Significance level for CIs\n",
        "            influence_threshold: Percent change threshold for influential studies\n",
        "        \"\"\"\n",
        "        self.effect_col = effect_col\n",
        "        self.var_col = var_col\n",
        "        self.alpha = alpha\n",
        "        self.influence_threshold = influence_threshold\n",
        "\n",
        "    def run_iterations(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        study_ids: List[Any],\n",
        "        baseline: OriginalEstimate,\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> List[LOOIteration]:\n",
        "        \"\"\"\n",
        "        Run leave-one-out iterations for all studies.\n",
        "\n",
        "        Args:\n",
        "            df: Full dataset\n",
        "            study_ids: List of study IDs to exclude one at a time\n",
        "            baseline: Original baseline estimate\n",
        "            progress_callback: Optional progress updates\n",
        "\n",
        "        Returns:\n",
        "            List of LOOIteration objects\n",
        "        \"\"\"\n",
        "        iterations = []\n",
        "        n_studies = len(study_ids)\n",
        "\n",
        "        for i, exclude_id in enumerate(study_ids):\n",
        "            if progress_callback:\n",
        "                progress_callback(i, n_studies, exclude_id)\n",
        "\n",
        "            # Create subset without this study\n",
        "            subset_df = df[df['id'] != exclude_id].copy()\n",
        "\n",
        "            # Run model on subset\n",
        "            try:\n",
        "                estimates, metadata = _run_three_level_reml_for_subgroup(\n",
        "                    subset_df,\n",
        "                    self.effect_col,\n",
        "                    self.var_col\n",
        "                )\n",
        "\n",
        "                if estimates is None:\n",
        "                    warnings.warn(f\"Failed to fit model without study {exclude_id}\")\n",
        "                    continue\n",
        "\n",
        "                # Extract estimates\n",
        "                mu = estimates['mu']\n",
        "                se = estimates.get('se_mu', estimates.get('se', np.nan))\n",
        "\n",
        "                # Get or calculate CIs\n",
        "                if 'ci_lower' in estimates and 'ci_upper' in estimates:\n",
        "                    ci_lower = estimates['ci_lower']\n",
        "                    ci_upper = estimates['ci_upper']\n",
        "                else:\n",
        "                    ci_lower, ci_upper = CICalculator.calculate_ci(\n",
        "                        mu, se, self.alpha\n",
        "                    )\n",
        "\n",
        "                # Get variance components\n",
        "                tau2 = estimates.get('tau_sq', estimates.get('tau2'))\n",
        "                sigma2 = estimates.get('sigma_sq', estimates.get('sigma2'))\n",
        "\n",
        "                # Calculate differences\n",
        "                diff = mu - baseline.mu\n",
        "\n",
        "                if baseline.mu != 0:\n",
        "                    pct_change = (diff / baseline.mu) * 100\n",
        "                else:\n",
        "                    pct_change = 0.0\n",
        "\n",
        "                # Check if influential\n",
        "                is_influential = abs(pct_change) > self.influence_threshold\n",
        "\n",
        "                # Create iteration result\n",
        "                iteration = LOOIteration(\n",
        "                    excluded_study=str(exclude_id),\n",
        "                    mu=mu,\n",
        "                    se=se,\n",
        "                    ci_lower=ci_lower,\n",
        "                    ci_upper=ci_upper,\n",
        "                    tau2=tau2,\n",
        "                    sigma2=sigma2,\n",
        "                    diff=diff,\n",
        "                    pct_change=pct_change,\n",
        "                    is_influential=is_influential\n",
        "                )\n",
        "\n",
        "                iterations.append(iteration)\n",
        "\n",
        "            except Exception as e:\n",
        "                warnings.warn(f\"Error processing study {exclude_id}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return iterations\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# INFLUENCE DETECTOR\n",
        "# =============================================================================\n",
        "\n",
        "class InfluenceDetector:\n",
        "    \"\"\"\n",
        "    Analyzes iterations to identify influential studies and summary statistics.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def analyze_iterations(\n",
        "        iterations: List[LOOIteration],\n",
        "        baseline: OriginalEstimate,\n",
        "        n_studies: int\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze iterations to get summary statistics.\n",
        "\n",
        "        Args:\n",
        "            iterations: List of LOOIteration objects\n",
        "            baseline: Original baseline estimate\n",
        "            n_studies: Total number of studies\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with summary statistics\n",
        "        \"\"\"\n",
        "        if not iterations:\n",
        "            return {\n",
        "                'n_influential': 0,\n",
        "                'min_estimate': baseline.mu,\n",
        "                'max_estimate': baseline.mu,\n",
        "                'range_estimate': 0.0,\n",
        "                'top_influential': pd.DataFrame()\n",
        "            }\n",
        "\n",
        "        # Convert to DataFrame for analysis\n",
        "        iter_df = pd.DataFrame([\n",
        "            {\n",
        "                'excluded_study': it.excluded_study,\n",
        "                'mu': it.mu,\n",
        "                'se': it.se,\n",
        "                'ci_lower': it.ci_lower,\n",
        "                'ci_upper': it.ci_upper,\n",
        "                'tau2': it.tau2,\n",
        "                'sigma2': it.sigma2,\n",
        "                'diff': it.diff,\n",
        "                'pct_change': it.pct_change,\n",
        "                'is_influential': it.is_influential\n",
        "            }\n",
        "            for it in iterations\n",
        "        ])\n",
        "\n",
        "        # Count influential studies\n",
        "        n_influential = iter_df['is_influential'].sum()\n",
        "\n",
        "        # Get range of estimates\n",
        "        min_estimate = iter_df['mu'].min()\n",
        "        max_estimate = iter_df['mu'].max()\n",
        "        range_estimate = max_estimate - min_estimate\n",
        "\n",
        "        # Get top influential studies (by absolute difference)\n",
        "        iter_df['abs_diff'] = iter_df['diff'].abs()\n",
        "        top_influential = iter_df.sort_values('abs_diff', ascending=False).head(5)\n",
        "\n",
        "        return {\n",
        "            'n_influential': n_influential,\n",
        "            'min_estimate': min_estimate,\n",
        "            'max_estimate': max_estimate,\n",
        "            'range_estimate': range_estimate,\n",
        "            'top_influential': top_influential\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# LEAVE-ONE-OUT ORCHESTRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class LOOEngine:\n",
        "    \"\"\"\n",
        "    High-level orchestrator for leave-one-out sensitivity analysis.\n",
        "    Coordinates baseline estimation, iterative exclusion, and influence detection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_manager: 'LOODataManager'):\n",
        "        \"\"\"\n",
        "        Initialize engine with data manager.\n",
        "\n",
        "        Args:\n",
        "            data_manager: LOODataManager instance\n",
        "        \"\"\"\n",
        "        self.data_manager = data_manager\n",
        "\n",
        "        settings = data_manager.global_settings\n",
        "        alpha = settings.get('alpha', 0.05)\n",
        "\n",
        "        self.baseline_estimator = BaselineEstimator(\n",
        "            effect_col=data_manager.effect_col,\n",
        "            var_col=data_manager.var_col,\n",
        "            alpha=alpha\n",
        "        )\n",
        "\n",
        "        self.iterator = LOOIterator(\n",
        "            effect_col=data_manager.effect_col,\n",
        "            var_col=data_manager.var_col,\n",
        "            alpha=alpha,\n",
        "            influence_threshold=20.0  # Can be made configurable\n",
        "        )\n",
        "\n",
        "        self.influence_detector = InfluenceDetector()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(\n",
        "        self,\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> Optional['LOOResult']:\n",
        "        \"\"\"\n",
        "        Execute complete leave-one-out sensitivity analysis.\n",
        "\n",
        "        WORKFLOW:\n",
        "        1. Prepare data\n",
        "        2. Estimate baseline (full model)\n",
        "        3. Run k iterations (exclude one study each time)\n",
        "        4. Analyze influence\n",
        "        5. Build result object\n",
        "\n",
        "        Args:\n",
        "            progress_callback: Optional progress updates\n",
        "\n",
        "        Returns:\n",
        "            LOOResult object or None if analysis fails\n",
        "        \"\"\"\n",
        "        # Step 1: Prepare data\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udcca Preparing data...\")\n",
        "\n",
        "        try:\n",
        "            df = self.data_manager.prepare_data()\n",
        "        except ValueError as e:\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"\u274c Data preparation failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        study_ids = self.data_manager.get_study_ids(df)\n",
        "        n_studies = len(study_ids)\n",
        "\n",
        "        # Step 2: Estimate baseline\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udd0d Estimating baseline (full model)...\")\n",
        "\n",
        "        baseline = self.baseline_estimator.estimate_baseline(df)\n",
        "\n",
        "        if baseline is None:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\u274c Baseline estimation failed\")\n",
        "            return None\n",
        "\n",
        "        # Step 3: Run iterations\n",
        "        if progress_callback:\n",
        "            progress_callback(f\"\ud83d\udd04 Running {n_studies} leave-one-out iterations...\")\n",
        "\n",
        "        def iter_progress(i, total, study_id):\n",
        "            if progress_callback:\n",
        "                progress_callback(\n",
        "                    f\"Processing {i+1}/{total}: Excluding study {study_id}\",\n",
        "                    progress=(i+1)/total\n",
        "                )\n",
        "\n",
        "        iterations = self.iterator.run_iterations(\n",
        "            df=df,\n",
        "            study_ids=study_ids,\n",
        "            baseline=baseline,\n",
        "            progress_callback=iter_progress\n",
        "        )\n",
        "\n",
        "        if not iterations:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\u274c No iterations completed successfully\")\n",
        "            return None\n",
        "\n",
        "        # Step 4: Analyze influence\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udcc8 Analyzing influential studies...\")\n",
        "\n",
        "        analysis = self.influence_detector.analyze_iterations(\n",
        "            iterations=iterations,\n",
        "            baseline=baseline,\n",
        "            n_studies=n_studies\n",
        "        )\n",
        "\n",
        "        # Step 5: Build result object\n",
        "        # Convert iterations to DataFrame\n",
        "        iter_df = pd.DataFrame([\n",
        "            {\n",
        "                'excluded_study': it.excluded_study,\n",
        "                'mu': it.mu,\n",
        "                'se': it.se,\n",
        "                'ci_lower': it.ci_lower,\n",
        "                'ci_upper': it.ci_upper,\n",
        "                'tau2': it.tau2,\n",
        "                'sigma2': it.sigma2,\n",
        "                'diff': it.diff,\n",
        "                'pct_change': it.pct_change,\n",
        "                'is_influential': it.is_influential\n",
        "            }\n",
        "            for it in iterations\n",
        "        ])\n",
        "\n",
        "        result = LOOResult(\n",
        "            original=baseline,\n",
        "            iterations=iter_df,\n",
        "            n_studies=n_studies,\n",
        "            n_influential=analysis['n_influential'],\n",
        "            min_estimate=analysis['min_estimate'],\n",
        "            max_estimate=analysis['max_estimate'],\n",
        "            range_estimate=analysis['range_estimate'],\n",
        "            top_influential=analysis['top_influential']\n",
        "        )\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback(\n",
        "                f\"\u2705 Analysis complete: {analysis['n_influential']} influential studies found\"\n",
        "            )\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HELPER: SUMMARY TEXT GENERATOR\n",
        "# =============================================================================\n",
        "\n",
        "class SummaryTextGenerator:\n",
        "    \"\"\"\n",
        "    Generates summary text for leave-one-out results.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_summary(result: 'LOOResult') -> str:\n",
        "        \"\"\"\n",
        "        Generate text summary of results.\n",
        "\n",
        "        Args:\n",
        "            result: LOOResult object\n",
        "\n",
        "        Returns:\n",
        "            Summary text string\n",
        "        \"\"\"\n",
        "        orig = result.original\n",
        "        n_infl = result.n_influential\n",
        "        min_est = result.min_estimate\n",
        "        max_est = result.max_estimate\n",
        "\n",
        "        text = (\n",
        "            f\"A leave-one-out sensitivity analysis was conducted to assess the robustness \"\n",
        "            f\"of the pooled estimate. The pooled effect size varied between \"\n",
        "            f\"{min_est:.3f} and {max_est:.3f} (Original: {orig.mu:.3f}). \"\n",
        "        )\n",
        "\n",
        "        if n_infl == 0:\n",
        "            text += (\n",
        "                \"No single study disproportionately influenced the results \"\n",
        "                \"(all shifts < 20%), indicating robust findings.\"\n",
        "            )\n",
        "        else:\n",
        "            text += (\n",
        "                f\"However, {n_infl} study/studies were identified as potentially influential, \"\n",
        "                f\"causing shifts > 20% in the pooled estimate.\"\n",
        "            )\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Leave-One-Out Analysis Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - BaselineEstimator (full model)\")\n",
        "    print(\"   - LOOIterator (k iterations)\")\n",
        "    print(\"   - InfluenceDetector (summary statistics)\")\n",
        "    print(\"   - LOOEngine (main orchestrator)\")\n",
        "    print(\"   - SummaryTextGenerator (interpretation text)\")\n",
        "\n",
        "#@title \ud83e\uddea 20. Sensitivity Analysis: Leave-One-Out - PRESENTATION LAYER (View)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 3/4: PRESENTATION LAYER - LEAVE-ONE-OUT SENSITIVITY ANALYSIS\n",
        "# Purpose: Pure UI rendering without business logic\n",
        "# Dependencies: Data & Analysis Layers\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Any, Optional\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import sys\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HTML TEMPLATE GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class LOOHTMLTemplates:\n",
        "    \"\"\"\n",
        "    Static HTML template generators for leave-one-out visualizations.\n",
        "    All methods are pure functions returning HTML strings.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def summary_header(result: 'LOOResult') -> str:\n",
        "        \"\"\"Generate summary header with key statistics\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                    padding: 25px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
        "            <h3 style='margin: 0 0 15px 0; font-size: 1.5em;'>\ud83d\udd0d Sensitivity Analysis Summary</h3>\n",
        "            <div style='display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px;'>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; opacity: 0.9;'>Studies Analyzed</div>\n",
        "                    <div style='font-size: 2em; font-weight: bold;'>{result.n_studies}</div>\n",
        "                </div>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; opacity: 0.9;'>Influential Studies</div>\n",
        "                    <div style='font-size: 2em; font-weight: bold;'>{result.n_influential}</div>\n",
        "                </div>\n",
        "                <div style='text-align: center;'>\n",
        "                    <div style='font-size: 0.9em; opacity: 0.9;'>Estimate Range</div>\n",
        "                    <div style='font-size: 2em; font-weight: bold;'>{result.range_estimate:.3f}</div>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def baseline_box(result: 'LOOResult') -> str:\n",
        "        \"\"\"Generate baseline estimate box\"\"\"\n",
        "        orig = result.original\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px;\n",
        "                    border-left: 4px solid #007bff; margin-bottom: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #0056b3;'>\ud83d\udcca Original Full Model Estimate</h4>\n",
        "            <p style='font-size: 16px; margin: 5px 0;'>\n",
        "                <b>Effect Size (\u03bc):</b> {orig.mu:.4f}<br>\n",
        "                <b>Standard Error:</b> {orig.se:.4f}<br>\n",
        "                <b>95% CI:</b> [{orig.ci_lower:.4f}, {orig.ci_upper:.4f}]\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def styled_table(df: pd.DataFrame, columns: list) -> str:\n",
        "        \"\"\"Generate styled HTML table\"\"\"\n",
        "        html = \"\"\"\n",
        "        <table style='width: 100%; border-collapse: collapse; margin: 20px 0;'>\n",
        "            <thead style='background-color: #2c3e50; color: white;'>\n",
        "                <tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Headers\n",
        "        header_names = {\n",
        "            'excluded_study': 'Excluded Study',\n",
        "            'mu': 'Effect Size (\u03bc)',\n",
        "            'diff': 'Difference',\n",
        "            'pct_change': '% Change',\n",
        "            'ci_lower': 'CI Lower',\n",
        "            'ci_upper': 'CI Upper'\n",
        "        }\n",
        "\n",
        "        for col in columns:\n",
        "            html += f\"<th style='padding: 12px; text-align: left; border: 1px solid #dee2e6;'>{header_names.get(col, col)}</th>\"\n",
        "\n",
        "        html += \"</tr></thead><tbody>\"\n",
        "\n",
        "        # Rows\n",
        "        for idx, row in df.iterrows():\n",
        "            # Color code based on influence\n",
        "            if row.get('is_influential', False):\n",
        "                bg_color = \"#fff3cd\"  # Yellow for influential\n",
        "            else:\n",
        "                bg_color = \"white\"\n",
        "\n",
        "            html += f\"<tr style='background-color: {bg_color}; border-bottom: 1px solid #dee2e6;'>\"\n",
        "\n",
        "            for col in columns:\n",
        "                value = row[col]\n",
        "\n",
        "                # Format based on column type\n",
        "                if col == 'mu':\n",
        "                    formatted = f\"{value:.4f}\"\n",
        "                elif col == 'diff':\n",
        "                    formatted = f\"{value:+.4f}\"\n",
        "                    # Color code difference\n",
        "                    if value > 0:\n",
        "                        formatted = f\"<span style='color: #dc3545;'>{formatted}</span>\"\n",
        "                    elif value < 0:\n",
        "                        formatted = f\"<span style='color: #28a745;'>{formatted}</span>\"\n",
        "                elif col == 'pct_change':\n",
        "                    formatted = f\"{value:+.1f}%\"\n",
        "                    # Color code percent change\n",
        "                    if abs(value) > 20:\n",
        "                        formatted = f\"<b style='color: #dc3545;'>{formatted}</b>\"\n",
        "                elif col in ['ci_lower', 'ci_upper']:\n",
        "                    formatted = f\"{value:.4f}\"\n",
        "                else:\n",
        "                    formatted = str(value)\n",
        "\n",
        "                html += f\"<td style='padding: 10px; border: 1px solid #dee2e6;'>{formatted}</td>\"\n",
        "\n",
        "            html += \"</tr>\"\n",
        "\n",
        "        html += \"</tbody></table>\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    @staticmethod\n",
        "    def interpretation_box(summary_text: str, is_robust: bool) -> str:\n",
        "        \"\"\"Generate interpretation box with summary text\"\"\"\n",
        "        if is_robust:\n",
        "            bg_color = \"#d4edda\"\n",
        "            border_color = \"#28a745\"\n",
        "            icon = \"\u2713\"\n",
        "            title = \"Robust Findings\"\n",
        "        else:\n",
        "            bg_color = \"#fff3cd\"\n",
        "            border_color = \"#ffc107\"\n",
        "            icon = \"\u26a0\"\n",
        "            title = \"Influential Studies Detected\"\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: {bg_color}; padding: 20px; border-radius: 5px;\n",
        "                    border-left: 5px solid {border_color}; margin-top: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #495057;'>{icon} {title}</h4>\n",
        "            <p style='color: #6c757d; font-size: 14px; line-height: 1.6;'>\n",
        "                {summary_text}\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def guidance_box() -> str:\n",
        "        \"\"\"Generate interpretation guidance box\"\"\"\n",
        "        return \"\"\"\n",
        "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px;\n",
        "                    border-left: 4px solid #6c757d; margin-top: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #495057;'>\ud83d\udca1 Interpretation Guide</h4>\n",
        "            <ul style='color: #6c757d; font-size: 14px; line-height: 1.8; margin-bottom: 0;'>\n",
        "                <li><b>Influential Study:</b> A study whose removal causes the pooled estimate to\n",
        "                    change by more than 20%.</li>\n",
        "                <li><b>Robust Findings:</b> If no influential studies are detected, the meta-analytic\n",
        "                    conclusion is not driven by any single study.</li>\n",
        "                <li><b>Interpretation:</b> If influential studies exist, examine their characteristics\n",
        "                    (sample size, quality, population) to understand why they differ.</li>\n",
        "                <li><b>Action:</b> Consider reporting both the original and sensitivity-adjusted estimates\n",
        "                    if influential studies are present.</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def next_steps_box() -> str:\n",
        "        \"\"\"Generate next steps box\"\"\"\n",
        "        return \"\"\"\n",
        "        <div style='background-color: #e7f3ff; padding: 15px; border-radius: 5px;\n",
        "                    border-left: 4px solid #007bff; margin-top: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #0056b3;'>\ud83d\udcca Next Steps</h4>\n",
        "            <p style='color: #6c757d; font-size: 14px; margin-bottom: 0;'>\n",
        "                <b>Visualization:</b> Run the plotting cell (if available) to visualize how the\n",
        "                estimate changes with each study removed. This forest plot shows the range of\n",
        "                possible estimates and helps identify which studies have the greatest impact.\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# VIEW COMPONENTS\n",
        "# =============================================================================\n",
        "\n",
        "class LOOResultsView:\n",
        "    \"\"\"\n",
        "    Manages all UI rendering for leave-one-out sensitivity analysis.\n",
        "    Contains zero business logic - only presentation code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize view with display settings\"\"\"\n",
        "        self.templates = LOOHTMLTemplates()\n",
        "        self.text_gen = SummaryTextGenerator()\n",
        "\n",
        "        # Create output widget\n",
        "        self.output = widgets.Output()\n",
        "\n",
        "        # Create progress bar\n",
        "        self.progress_bar = widgets.IntProgress(\n",
        "            value=0,\n",
        "            min=0,\n",
        "            max=100,\n",
        "            description='Progress:',\n",
        "            bar_style='info',\n",
        "            orientation='horizontal',\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN RENDERING METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_results(self, result: 'LOOResult') -> None:\n",
        "        \"\"\"\n",
        "        Render complete results display.\n",
        "\n",
        "        Args:\n",
        "            result: LOOResult object\n",
        "        \"\"\"\n",
        "        with self.output:\n",
        "            self.output.clear_output()\n",
        "\n",
        "            # Hide progress bar\n",
        "            self.progress_bar.layout.display = 'none'\n",
        "\n",
        "            # Summary header\n",
        "            header_html = self.templates.summary_header(result)\n",
        "            display(HTML(header_html))\n",
        "\n",
        "            # Baseline box\n",
        "            baseline_html = self.templates.baseline_box(result)\n",
        "            display(HTML(baseline_html))\n",
        "\n",
        "            # Top influential studies section\n",
        "            display(HTML(\"<h4 style='color: #2c3e50; margin-top: 30px;'>\ud83d\udcca Most Influential Studies</h4>\"))\n",
        "            display(HTML(\"<p style='color: #6c757d;'>Studies that cause the largest change in the pooled estimate when removed.</p>\"))\n",
        "\n",
        "            # Top influential table\n",
        "            top_cols = ['excluded_study', 'mu', 'diff', 'pct_change']\n",
        "            table_html = self.templates.styled_table(result.top_influential, top_cols)\n",
        "            display(HTML(table_html))\n",
        "\n",
        "            # Summary interpretation\n",
        "            summary_text = self.text_gen.generate_summary(result)\n",
        "            is_robust = result.n_influential == 0\n",
        "            interp_html = self.templates.interpretation_box(summary_text, is_robust)\n",
        "            display(HTML(interp_html))\n",
        "\n",
        "            # Guidance\n",
        "            guidance_html = self.templates.guidance_box()\n",
        "            display(HTML(guidance_html))\n",
        "\n",
        "            # Next steps\n",
        "            next_steps_html = self.templates.next_steps_box()\n",
        "            display(HTML(next_steps_html))\n",
        "\n",
        "            # Success message\n",
        "            display(HTML(\"<p style='color: #28a745; font-weight: bold; margin-top: 20px;'>\u2705 Analysis Complete.</p>\"))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROGRESS DISPLAY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def update_progress(self, message: str, progress: Optional[float] = None) -> None:\n",
        "        \"\"\"\n",
        "        Update progress display.\n",
        "\n",
        "        Args:\n",
        "            message: Progress message\n",
        "            progress: Progress value (0.0 to 1.0), if None just shows message\n",
        "        \"\"\"\n",
        "        with self.output:\n",
        "            # Show progress bar if hidden\n",
        "            if self.progress_bar.layout.display == 'none':\n",
        "                self.progress_bar.layout.display = 'block'\n",
        "\n",
        "            if progress is not None:\n",
        "                self.progress_bar.value = int(progress * 100)\n",
        "\n",
        "            # Update description\n",
        "            self.progress_bar.description = message[:20] + \"...\" if len(message) > 20 else message\n",
        "\n",
        "    def show_progress_bar(self) -> None:\n",
        "        \"\"\"Show progress bar\"\"\"\n",
        "        self.progress_bar.layout.display = 'block'\n",
        "        self.progress_bar.value = 0\n",
        "        display(self.progress_bar)\n",
        "\n",
        "    def hide_progress_bar(self) -> None:\n",
        "        \"\"\"Hide progress bar\"\"\"\n",
        "        self.progress_bar.layout.display = 'none'\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR DISPLAY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_error(self, message: str, details: Optional[str] = None) -> None:\n",
        "        \"\"\"\n",
        "        Render error message.\n",
        "\n",
        "        Args:\n",
        "            message: Error message\n",
        "            details: Optional detailed error information\n",
        "        \"\"\"\n",
        "        with self.output:\n",
        "            self.output.clear_output()\n",
        "\n",
        "            error_html = f\"\"\"\n",
        "            <div style='color: #721c24; background-color: #f8d7da; padding: 15px;\n",
        "                        border-radius: 5px; border: 1px solid #f5c6cb;'>\n",
        "                <h4 style='margin-top: 0;'>\u274c Error</h4>\n",
        "                <p style='margin-bottom: 0;'>{message}</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(error_html))\n",
        "\n",
        "            if details:\n",
        "                details_html = f\"\"\"\n",
        "                <div style='background-color: #f8f9fa; padding: 10px; margin-top: 10px;\n",
        "                            border-radius: 5px; border-left: 3px solid #dc3545;'>\n",
        "                    <pre style='margin: 0; font-size: 12px; color: #6c757d;'>{details}</pre>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "                display(HTML(details_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # INFO MESSAGES\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_info(self, message: str) -> None:\n",
        "        \"\"\"\n",
        "        Render informational message.\n",
        "\n",
        "        Args:\n",
        "            message: Info message\n",
        "        \"\"\"\n",
        "        with self.output:\n",
        "            info_html = f\"\"\"\n",
        "            <div style='color: #004085; background-color: #cce5ff; padding: 10px;\n",
        "                        border-radius: 5px; border: 1px solid #b8daff; margin: 10px 0;'>\n",
        "                <p style='margin: 0;'>{message}</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(info_html))\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STYLED TABLE ALTERNATIVE (DataFrame with pandas styling)\n",
        "# =============================================================================\n",
        "\n",
        "class StyledTableRenderer:\n",
        "    \"\"\"\n",
        "    Alternative renderer using pandas styling capabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def render_styled_dataframe(\n",
        "        df: pd.DataFrame,\n",
        "        columns: list,\n",
        "        highlight_influential: bool = True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Render DataFrame with pandas styling.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to render\n",
        "            columns: Columns to display\n",
        "            highlight_influential: Whether to highlight influential studies\n",
        "        \"\"\"\n",
        "        display_df = df[columns].copy()\n",
        "\n",
        "        # Rename columns for display\n",
        "        display_df.columns = [\n",
        "            col.replace('_', ' ').title()\n",
        "            for col in display_df.columns\n",
        "        ]\n",
        "\n",
        "        # Create styled DataFrame\n",
        "        styled = display_df.style.format({\n",
        "            'Mu': '{:.4f}',\n",
        "            'Diff': '{:+.4f}',\n",
        "            'Pct Change': '{:+.1f}%',\n",
        "            'Ci Lower': '{:.4f}',\n",
        "            'Ci Upper': '{:.4f}'\n",
        "        })\n",
        "\n",
        "        # Apply background gradient to difference column\n",
        "        if 'Diff' in display_df.columns:\n",
        "            styled = styled.background_gradient(\n",
        "                subset=['Diff'],\n",
        "                cmap='coolwarm',\n",
        "                vmin=-display_df['Diff'].abs().max(),\n",
        "                vmax=display_df['Diff'].abs().max()\n",
        "            )\n",
        "\n",
        "        # Highlight influential rows\n",
        "        if highlight_influential and 'Is Influential' in display_df.columns:\n",
        "            def highlight_rows(row):\n",
        "                if row['Is Influential']:\n",
        "                    return ['background-color: #fff3cd'] * len(row)\n",
        "                return [''] * len(row)\n",
        "\n",
        "            styled = styled.apply(highlight_rows, axis=1)\n",
        "\n",
        "        display(styled)\n",
        "\n",
        "\n",
        "print(\"\u2705 Leave-One-Out View Layer Loaded Successfully\")\n",
        "\n",
        "#@title \ud83e\uddea 20. Sensitivity Analysis: Leave-One-Out - CONTROLLER LAYER (Orchestration)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 4/4: CONTROLLER LAYER - LEAVE-ONE-OUT SENSITIVITY ANALYSIS\n",
        "# Purpose: Orchestrates data, analysis, and view components\n",
        "# Dependencies: All previous layers (Data, Analysis, View)\n",
        "# =============================================================================\n",
        "\n",
        "import traceback\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN CONTROLLER\n",
        "# =============================================================================\n",
        "\n",
        "class LOOController:\n",
        "    \"\"\"\n",
        "    Master controller that orchestrates the entire leave-one-out analysis workflow.\n",
        "    Coordinates data management, statistical computation, and UI rendering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize controller with ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self.analysis_config = analysis_config\n",
        "\n",
        "        # Initialize components\n",
        "        try:\n",
        "            self.data_manager = LOODataManager(analysis_config)\n",
        "            self.engine = LOOEngine(self.data_manager)\n",
        "            self.view = LOOResultsView()\n",
        "\n",
        "            self._initialization_error = None\n",
        "\n",
        "        except Exception as e:\n",
        "            # If initialization fails, create minimal view to show error\n",
        "            self.view = LOOResultsView()\n",
        "            self.data_manager = None\n",
        "            self.engine = None\n",
        "            self._initialization_error = e\n",
        "\n",
        "        # Create run button\n",
        "        self._create_run_button()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UI CREATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _create_run_button(self) -> None:\n",
        "        \"\"\"Create run button\"\"\"\n",
        "        self.run_button = widgets.Button(\n",
        "            description='\ud83d\udd04 Run Leave-One-Out Analysis',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='400px', height='50px'),\n",
        "            icon='filter'\n",
        "        )\n",
        "\n",
        "        # Attach event handler\n",
        "        self.run_button.on_click(self._handle_run_click)\n",
        "\n",
        "    def create_ui(self) -> widgets.VBox:\n",
        "        \"\"\"\n",
        "        Create the user interface with run button.\n",
        "\n",
        "        Returns:\n",
        "            VBox widget containing the UI\n",
        "        \"\"\"\n",
        "        ui = widgets.VBox([\n",
        "            widgets.HTML(\"<h3>\ud83d\udd0d Sensitivity Analysis</h3>\"),\n",
        "            widgets.HTML(\"<p style='color: #6c757d;'>Check if any single study drives the entire result.</p>\"),\n",
        "            self.run_button\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(self) -> None:\n",
        "        \"\"\"\n",
        "        Execute complete leave-one-out sensitivity analysis workflow.\n",
        "        \"\"\"\n",
        "        # Clear output\n",
        "        with self.view.output:\n",
        "            self.view.output.clear_output()\n",
        "\n",
        "        # Check for initialization errors\n",
        "        if self._initialization_error:\n",
        "            self._handle_initialization_error()\n",
        "            return\n",
        "\n",
        "        # Validate ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            self.view.render_error(\"ANALYSIS_CONFIG not found. Run Step 1 first.\")\n",
        "            return\n",
        "\n",
        "        # Check for required function\n",
        "        if '_run_three_level_reml_for_subgroup' not in globals():\n",
        "            self.view.render_error(\n",
        "                \"Required function not found\",\n",
        "                \"_run_three_level_reml_for_subgroup must be available. Run previous analysis cells.\"\n",
        "            )\n",
        "            return\n",
        "\n",
        "        # Show progress bar\n",
        "        self.view.show_progress_bar()\n",
        "\n",
        "        # Progress callback\n",
        "        def progress_callback(message: str, progress: Optional[float] = None):\n",
        "            \"\"\"Callback for progress updates\"\"\"\n",
        "            self.view.update_progress(message, progress)\n",
        "\n",
        "        try:\n",
        "            # Pre-flight check\n",
        "            progress_callback(\"\ud83d\udcca Validating data...\")\n",
        "\n",
        "            df = self.data_manager.analysis_data\n",
        "            if df is None or len(df) == 0:\n",
        "                self.view.render_error(\"No data found. Run Step 1 & 8 first.\")\n",
        "                return\n",
        "\n",
        "            # Check minimum studies\n",
        "            n_studies = df['id'].nunique() if 'id' in df.columns else 0\n",
        "            if n_studies < 3:\n",
        "                self.view.render_error(\n",
        "                    f\"Insufficient studies for leave-one-out analysis\",\n",
        "                    f\"Found {n_studies} studies, need at least 3.\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            progress_callback(f\"\ud83d\udd0d Found {n_studies} studies\")\n",
        "\n",
        "            # Execute LOO engine\n",
        "            result = self.engine.run_analysis(\n",
        "                progress_callback=progress_callback\n",
        "            )\n",
        "\n",
        "            if result is None:\n",
        "                self.view.render_error(\n",
        "                    \"Analysis failed\",\n",
        "                    \"Unable to complete leave-one-out analysis. Check your data and model setup.\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # Save results\n",
        "            self._save_results(result)\n",
        "\n",
        "            # Render results\n",
        "            self.view.render_results(result)\n",
        "\n",
        "        except ValueError as e:\n",
        "            self.view.render_error(\"Data Error\", str(e))\n",
        "        except RuntimeError as e:\n",
        "            self.view.render_error(\"Runtime Error\", str(e))\n",
        "        except Exception as e:\n",
        "            self._handle_unexpected_error(e)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA PERSISTENCE\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _save_results(self, result: 'LOOResult') -> None:\n",
        "        \"\"\"\n",
        "        Save results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: LOOResult object\n",
        "        \"\"\"\n",
        "        self.data_manager.save_loo_results(result)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # EVENT HANDLERS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_run_click(self, button) -> None:\n",
        "        \"\"\"Handle run button click event\"\"\"\n",
        "        self.run_analysis()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_initialization_error(self) -> None:\n",
        "        \"\"\"Handle errors during controller initialization\"\"\"\n",
        "        error = self._initialization_error\n",
        "        if error is None:\n",
        "            return\n",
        "\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "    def _handle_unexpected_error(self, error: Exception) -> None:\n",
        "        \"\"\"Handle unexpected errors during analysis\"\"\"\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION ENTRY POINT\n",
        "# =============================================================================\n",
        "\n",
        "def run_leave_one_out_analysis():\n",
        "    \"\"\"\n",
        "    Main entry point for leave-one-out sensitivity analysis.\n",
        "    Call this function to display the UI and enable analysis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check for ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            print(\"\u274c ERROR: ANALYSIS_CONFIG not found\")\n",
        "            print(\"Please run previous analysis cells first:\")\n",
        "            print(\"  - Step 1: Data Loading\")\n",
        "            print(\"  - Step 7 or 8: Meta-Analysis\")\n",
        "            return\n",
        "\n",
        "        # Check for required function\n",
        "        if '_run_three_level_reml_for_subgroup' not in globals():\n",
        "            print(\"\u274c ERROR: Required function not found\")\n",
        "            print(\"Please ensure _run_three_level_reml_for_subgroup is available.\")\n",
        "            print(\"This function should be loaded from the three-level regression utilities.\")\n",
        "            return\n",
        "\n",
        "        # Create controller\n",
        "        controller = LOOController(ANALYSIS_CONFIG)\n",
        "\n",
        "        # Display UI\n",
        "        ui = controller.create_ui()\n",
        "        display(ui)\n",
        "\n",
        "        # Display output area\n",
        "        display(controller.view.output)\n",
        "\n",
        "        # Store controller globally for access (optional)\n",
        "        globals()['_loo_controller'] = controller\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Fatal Error: {type(e).__name__}\")\n",
        "        print(f\"Message: {str(e)}\")\n",
        "        print(\"\\nFull traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STANDALONE TESTING UTILITIES (Optional)\n",
        "# =============================================================================\n",
        "\n",
        "class MockLOOConfig:\n",
        "    \"\"\"\n",
        "    Mock ANALYSIS_CONFIG for testing without running full pipeline.\n",
        "    Only for development/testing purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_sample_config():\n",
        "        \"\"\"Create a minimal valid config for testing\"\"\"\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "\n",
        "        # Sample data with 10 studies, some observations per study\n",
        "        np.random.seed(42)\n",
        "\n",
        "        data_list = []\n",
        "        for study_id in range(1, 11):\n",
        "            n_obs = np.random.randint(3, 8)\n",
        "            for _ in range(n_obs):\n",
        "                effect = np.random.randn() * 0.2 + 0.5\n",
        "                variance = np.random.uniform(0.01, 0.1)\n",
        "                data_list.append({\n",
        "                    'id': study_id,\n",
        "                    'hedges_g': effect,\n",
        "                    'Vg': variance\n",
        "                })\n",
        "\n",
        "        sample_data = pd.DataFrame(data_list)\n",
        "\n",
        "        return {\n",
        "            'analysis_data': sample_data,\n",
        "            'effect_col': 'hedges_g',\n",
        "            'var_col': 'Vg',\n",
        "            'es_config': {\n",
        "                'type': \"Hedges' g\",\n",
        "                'effect_label': \"Hedges' g\",\n",
        "                'effect_label_short': 'g'\n",
        "            },\n",
        "            'global_settings': {\n",
        "                'alpha': 0.05\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST & INFORMATION\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Leave-One-Out Controller Layer Loaded Successfully\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - LOOController\")\n",
        "    print(\"   - MockLOOConfig (for testing)\")\n",
        "    print()\n",
        "    print(\"\ud83d\ude80 Main Entry Point:\")\n",
        "    print(\"   run_leave_one_out_analysis()\")\n",
        "    print()\n",
        "    print(\"\ud83d\udca1 Usage:\")\n",
        "    print(\"   Just call: run_leave_one_out_analysis()\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "\n",
        "run_leave_one_out_analysis()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1ZtlAPNP2PY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 21. Visualization: Sensitivity Plot\n",
        "# =============================================================================\n",
        "# CELL 13b: LEAVE-ONE-OUT FOREST PLOT (LAYOUT FIXED)\n",
        "# Purpose: Visualize sensitivity analysis.\n",
        "# Fixes: Applied the 'Locked Axis' and 'Total Slots' logic from Cell 12\n",
        "#        to prevent infinite stretching and misplaced axes.\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import datetime\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "default_title = \"Leave-One-Out Sensitivity Analysis\"\n",
        "default_xlabel = \"Pooled Effect Size (if study removed)\"\n",
        "default_ylabel = \"Study Removed\"\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        label = es_config.get('effect_label', 'Effect Size')\n",
        "        default_xlabel = f\"Pooled {label} (if study removed)\"\n",
        "except: pass\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# Style Tab\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_xlabel, description='X Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_ylabel, description='Y Label:', layout=widgets.Layout(width='450px'))\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=5.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False)\n",
        "height_auto_widget = widgets.Checkbox(value=True, description='Auto-Height', indent=False)\n",
        "height_widget = widgets.FloatSlider(value=12.0, min=4.0, max=100.0, step=0.5, description='Manual Height:', continuous_update=False)\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Labels & Dimensions</h4>\"),\n",
        "    show_title_widget, title_widget, xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr>\"), width_widget, height_auto_widget, height_widget\n",
        "])\n",
        "\n",
        "# Data Tab\n",
        "sort_by_widget = widgets.Dropdown(\n",
        "    options=[('Effect Size (Low to High)', 'effect'),\n",
        "             ('Influence (Diff from Original)', 'influence'),\n",
        "             ('Study ID', 'id')],\n",
        "    value='effect', description='Sort By:', layout=widgets.Layout(width='400px')\n",
        ")\n",
        "highlight_sig_widget = widgets.Checkbox(value=True, description='Highlight Significance Changers (Red)', indent=False)\n",
        "point_color_widget = widgets.Dropdown(options=['blue', 'black', 'gray', 'steelblue'], value='blue', description='Point Color:')\n",
        "point_size_widget = widgets.IntSlider(value=40, min=10, max=100, description='Point Size:')\n",
        "\n",
        "data_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Data Presentation</h4>\"),\n",
        "    sort_by_widget, widgets.HTML(\"<hr>\"),\n",
        "    highlight_sig_widget, point_color_widget, point_size_widget\n",
        "])\n",
        "\n",
        "# Reference Lines Tab\n",
        "show_orig_line_widget = widgets.Checkbox(value=True, description='Show Original Effect Line')\n",
        "orig_color_widget = widgets.Dropdown(options=['red', 'black', 'green'], value='red', description='Line Color:')\n",
        "show_orig_ci_widget = widgets.Checkbox(value=True, description='Show Original 95% CI Band')\n",
        "ci_band_alpha_widget = widgets.FloatSlider(value=0.1, min=0.05, max=0.5, step=0.05, description='Band Alpha:')\n",
        "show_null_line_widget = widgets.Checkbox(value=True, description='Show Null Effect Line')\n",
        "\n",
        "lines_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Reference Lines</h4>\"),\n",
        "    show_orig_line_widget, orig_color_widget,\n",
        "    show_orig_ci_widget, ci_band_alpha_widget,\n",
        "    widgets.HTML(\"<hr>\"), show_null_line_widget\n",
        "])\n",
        "\n",
        "# Export Tab\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF')\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG')\n",
        "filename_prefix_widget = widgets.Text(value='LOO_Plot', description='Filename:')\n",
        "dpi_widget = widgets.IntText(value=300, description='DPI:')\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    widgets.HTML(\"<h4 style='color: #2E86AB;'>Export</h4>\"),\n",
        "    save_pdf_widget, save_png_widget, filename_prefix_widget, dpi_widget\n",
        "])\n",
        "\n",
        "tabs = widgets.Tab(children=[style_tab, data_tab, lines_tab, export_tab])\n",
        "tabs.set_title(0, '\ud83c\udfa8 Style')\n",
        "tabs.set_title(1, '\ud83d\udcca Data')\n",
        "tabs.set_title(2, '\ud83d\udcd0 Lines')\n",
        "tabs.set_title(3, '\ud83d\udcbe Export')\n",
        "\n",
        "run_plot_btn = widgets.Button(description='\ud83d\udcca Generate LOO Plot', button_style='success', layout=widgets.Layout(width='450px'))\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "# --- 3. PLOTTING LOGIC ---\n",
        "def generate_loo_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        try:\n",
        "            # 1. Load Results\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'loo_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"\u274c Error: Run Cell 13 (Leave-One-Out Analysis) first.\")\n",
        "                return\n",
        "\n",
        "            loo_data = ANALYSIS_CONFIG['loo_results']\n",
        "\n",
        "            # Handle Data Structure\n",
        "            if isinstance(loo_data, pd.DataFrame):\n",
        "                df = loo_data.copy()\n",
        "                # Try to find original effect from overall results if not in LOO packet\n",
        "                if 'overall_results' in ANALYSIS_CONFIG:\n",
        "                    orig_res = ANALYSIS_CONFIG['overall_results']\n",
        "                    orig_eff = orig_res.get('mu_robust', orig_res.get('mu', 0))\n",
        "                    orig_ci_lower = orig_res.get('ci_lower_robust', orig_res.get('ci_lower', 0))\n",
        "                    orig_ci_upper = orig_res.get('ci_upper_robust', orig_res.get('ci_upper', 0))\n",
        "                else:\n",
        "                    orig_eff = df['mu'].median()\n",
        "                    orig_ci_lower, orig_ci_upper = orig_eff - 0.1, orig_eff + 0.1\n",
        "            else:\n",
        "                df = loo_data['data'].copy()\n",
        "                orig_eff = loo_data['orig_mu']\n",
        "                orig_ci_lower = loo_data['orig_ci_lo']\n",
        "                orig_ci_upper = loo_data['orig_ci_hi']\n",
        "\n",
        "            # Normalize Columns\n",
        "            if 'mu' in df.columns:\n",
        "                df = df.rename(columns={'mu': 'pooled_effect', 'excluded_study': 'unit_removed'})\n",
        "\n",
        "            # Ensure CIs exist\n",
        "            if 'ci_lower' not in df.columns:\n",
        "                df['ci_lower'] = df['pooled_effect'] - 1.96 * df['se']\n",
        "                df['ci_upper'] = df['pooled_effect'] + 1.96 * df['se']\n",
        "\n",
        "            # Calculate Significance Changes\n",
        "            null_val = ANALYSIS_CONFIG.get('es_config', {}).get('null_value', 0)\n",
        "            orig_sig = not (orig_ci_lower <= null_val <= orig_ci_upper)\n",
        "\n",
        "            def check_sig_change(row):\n",
        "                curr_sig = not (row['ci_lower'] <= null_val <= row['ci_upper'])\n",
        "                return curr_sig != orig_sig\n",
        "\n",
        "            df['changes_sig'] = df.apply(check_sig_change, axis=1)\n",
        "            df['abs_diff'] = (df['pooled_effect'] - orig_eff).abs()\n",
        "\n",
        "            # 2. Sorting\n",
        "            sort_mode = sort_by_widget.value\n",
        "            if sort_mode == 'influence':\n",
        "                df = df.sort_values('abs_diff', ascending=True) # Least influence at bottom\n",
        "            elif sort_mode == 'id':\n",
        "                try:\n",
        "                    df['id_temp'] = df['unit_removed'].astype(int)\n",
        "                    df = df.sort_values('id_temp', ascending=False)\n",
        "                except:\n",
        "                    df = df.sort_values('unit_removed', ascending=False)\n",
        "            else:\n",
        "                df = df.sort_values('pooled_effect', ascending=True)\n",
        "\n",
        "            df = df.reset_index(drop=True)\n",
        "            n_studies = len(df)\n",
        "\n",
        "            # 3. Setup Canvas (FIXED LAYOUT)\n",
        "            # Use same spacing logic as Cell 12\n",
        "            total_slots = n_studies + 2\n",
        "\n",
        "            if height_auto_widget.value:\n",
        "                fig_h = max(6, total_slots * 0.25)\n",
        "            else:\n",
        "                fig_h = height_widget.value\n",
        "\n",
        "            # Cap extreme heights\n",
        "            if height_auto_widget.value and fig_h > 100:\n",
        "                print(f\"\u26a0\ufe0f Warning: Plot height capped at 100 inches.\")\n",
        "                fig_h = 100\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, fig_h))\n",
        "\n",
        "            # 4. Plotting Loop (Top to Bottom)\n",
        "            # We plot from y = n_studies down to 0\n",
        "            current_y = total_slots - 2\n",
        "\n",
        "            # Identify masks for coloring\n",
        "            if highlight_sig_widget.value:\n",
        "                df['color'] = df['changes_sig'].apply(lambda x: 'red' if x else point_color_widget.value)\n",
        "            else:\n",
        "                df['color'] = point_color_widget.value\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                # CI Line\n",
        "                ax.plot([row['ci_lower'], row['ci_upper']], [current_y, current_y],\n",
        "                       color='black', linewidth=1, zorder=1)\n",
        "\n",
        "                # Point\n",
        "                ax.scatter(row['pooled_effect'], current_y,\n",
        "                          color=row['color'], s=point_size_widget.value, zorder=2)\n",
        "\n",
        "                # Label (Left Axis style)\n",
        "                # We put the label on the left side of the plot area\n",
        "                # Or we can use the secondary axis approach\n",
        "                # Here we stick to text labels for consistency\n",
        "                label_x = df['ci_lower'].min() - (df['ci_upper'].max() - df['ci_lower'].min()) * 0.02\n",
        "                ax.text(label_x, current_y, str(row['unit_removed']),\n",
        "                       ha='right', va='center', fontsize=9)\n",
        "\n",
        "                current_y -= 1\n",
        "\n",
        "            # 5. Reference Lines\n",
        "            if show_null_line_widget.value:\n",
        "                ax.axvline(null_val, color='black', linestyle='-', linewidth=1, alpha=0.5, zorder=0)\n",
        "\n",
        "            if show_orig_ci_widget.value:\n",
        "                ax.axvspan(orig_ci_lower, orig_ci_upper, color=orig_color_widget.value,\n",
        "                          alpha=ci_band_alpha_widget.value, label='Original 95% CI', zorder=0)\n",
        "\n",
        "            if show_orig_line_widget.value:\n",
        "                ax.axvline(orig_eff, color=orig_color_widget.value, linestyle='--', linewidth=2,\n",
        "                          label=f'Original: {orig_eff:.3f}', zorder=0)\n",
        "\n",
        "            # 6. Formatting (THE FIX)\n",
        "            # Lock Y Limits\n",
        "            ax.set_ylim(-1, total_slots)\n",
        "\n",
        "            ax.set_xlabel(xlabel_widget.value, fontweight='bold', fontsize=12)\n",
        "            ax.set_title(title_widget.value, fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "            # Hide default Y ticks\n",
        "            ax.set_yticks([])\n",
        "            ax.spines['left'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.spines['top'].set_visible(False)\n",
        "\n",
        "            # X-Axis Ticks on both top and bottom\n",
        "            ax.xaxis.set_ticks_position('both')\n",
        "            ax.xaxis.set_label_position('bottom')\n",
        "\n",
        "            # Legend\n",
        "            handles, _ = ax.get_legend_handles_labels()\n",
        "            if highlight_sig_widget.value and df['changes_sig'].any():\n",
        "                handles.append(mpatches.Patch(color='red', label='Changed Significance'))\n",
        "\n",
        "            ax.legend(handles=handles, loc='best', frameon=True, fancybox=True)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Export\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M%S\")\n",
        "            fn = filename_prefix_widget.value\n",
        "            if save_png_widget.value: plt.savefig(f\"{fn}_{ts}.png\", dpi=dpi_widget.value, bbox_inches='tight')\n",
        "            if save_pdf_widget.value: plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Plotting Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "run_plot_btn.on_click(generate_loo_plot)\n",
        "\n",
        "display(widgets.VBox([header, tabs, widgets.HTML(\"<hr>\"), run_plot_btn, plot_output]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lYo33X8hSyJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 22. Visualization: Baujat Plot (Diagnostics\n",
        "# =============================================================================\n",
        "# CELL 13c: BAUJAT PLOT (FIXED DATA LOADING)\n",
        "# Purpose: Identify studies that contribute heavily to both\n",
        "#          heterogeneity AND influence the pooled effect.\n",
        "# Fixes:\n",
        "#   1. Reads new 'loo_results' dictionary format.\n",
        "#   2. Manually calculates Fixed-Effect mean for strict Q-statistic definition.\n",
        "#   3. Handles column renaming (excluded_study -> unit_removed).\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import datetime\n",
        "\n",
        "# --- 0. VALIDATION ---\n",
        "# Check for data, but don't crash on import if missing (handled in function)\n",
        "if 'ANALYSIS_CONFIG' not in globals():\n",
        "    pass\n",
        "\n",
        "# --- 1. WIDGET DEFINITIONS ---\n",
        "\n",
        "# ========== TAB 1: PLOT STYLE ==========\n",
        "style_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Plot Style & Layout</h3>\")\n",
        "\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=6.0, max=16.0, step=0.5, description='Plot Width (in):', layout=widgets.Layout(width='450px'))\n",
        "height_widget = widgets.FloatSlider(value=8.0, min=6.0, max=14.0, step=0.5, description='Plot Height (in):', layout=widgets.Layout(width='450px'))\n",
        "point_size_widget = widgets.IntSlider(value=80, min=20, max=200, step=10, description='Point Size:', layout=widgets.Layout(width='450px'))\n",
        "point_color_widget = widgets.Dropdown(options=['steelblue', 'darkblue', 'black', 'gray', 'crimson', 'forestgreen'], value='steelblue', description='Point Color:', layout=widgets.Layout(width='450px'))\n",
        "alpha_widget = widgets.FloatSlider(value=0.6, min=0.1, max=1.0, step=0.05, description='Opacity (Alpha):', layout=widgets.Layout(width='450px'))\n",
        "show_median_lines_widget = widgets.Checkbox(value=True, description='Show Median Reference Lines', indent=False)\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    style_header, width_widget, height_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    point_size_widget, point_color_widget, alpha_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    show_median_lines_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 2: LABELS ==========\n",
        "text_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Text & Labels</h3>\")\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        effect_label = es_config.get('effect_label', 'Effect Size')\n",
        "    else:\n",
        "        effect_label = 'Effect Size'\n",
        "except:\n",
        "    effect_label = 'Effect Size'\n",
        "\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Plot Title', indent=False)\n",
        "title_widget = widgets.Text(value='Baujat Plot: Heterogeneity vs Influence', description='Plot Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value='Contribution to Heterogeneity (Q)', description='X-Axis Label:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=f'Influence on Pooled {effect_label}', description='Y-Axis Label:', layout=widgets.Layout(width='450px'))\n",
        "title_fontsize_widget = widgets.IntSlider(value=14, min=8, max=20, description='Title Size:', layout=widgets.Layout(width='450px'))\n",
        "label_fontsize_widget = widgets.IntSlider(value=12, min=8, max=16, description='Axis Label Size:', layout=widgets.Layout(width='450px'))\n",
        "\n",
        "text_tab = widgets.VBox([\n",
        "    text_header, show_title_widget, title_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    xlabel_widget, ylabel_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    title_fontsize_widget, label_fontsize_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 3: OUTLIER LABELS ==========\n",
        "outlier_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Outlier Study Labels</h3>\")\n",
        "\n",
        "show_labels_widget = widgets.Checkbox(value=True, description='Show Study Labels', indent=False)\n",
        "label_method_widget = widgets.Dropdown(\n",
        "    options=[('Top Outliers (Combined Score)', 'combined'), ('Top by Heterogeneity Only', 'heterogeneity'),\n",
        "             ('Top by Influence Only', 'influence'), ('All Studies', 'all')],\n",
        "    value='combined', description='Labeling Method:', layout=widgets.Layout(width='450px')\n",
        ")\n",
        "label_threshold_widget = widgets.IntSlider(value=5, min=1, max=20, description='Max Labels:', layout=widgets.Layout(width='450px'))\n",
        "label_position_widget = widgets.Dropdown(\n",
        "    options=[('Auto (Best)', 'best'), ('Right', 'right'), ('Left', 'left'), ('Top', 'top'), ('Bottom', 'bottom')],\n",
        "    value='best', description='Label Position:', layout=widgets.Layout(width='450px')\n",
        ")\n",
        "label_font_size_widget = widgets.IntSlider(value=9, min=6, max=14, description='Label Size:', layout=widgets.Layout(width='450px'))\n",
        "\n",
        "outlier_tab = widgets.VBox([\n",
        "    outlier_header, show_labels_widget, label_method_widget, label_threshold_widget,\n",
        "    widgets.HTML(\"<hr>\"), label_position_widget, label_font_size_widget\n",
        "])\n",
        "\n",
        "# ========== TAB 4: EXPORT ==========\n",
        "export_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>Export Options</h3>\")\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "png_dpi_widget = widgets.IntSlider(value=300, min=72, max=600, step=50, description='PNG DPI:', layout=widgets.Layout(width='450px'))\n",
        "filename_prefix_widget = widgets.Text(value='Baujat_Plot', description='Filename:', layout=widgets.Layout(width='450px'))\n",
        "include_timestamp_widget = widgets.Checkbox(value=True, description='Include Timestamp', indent=False)\n",
        "\n",
        "export_tab = widgets.VBox([\n",
        "    export_header, save_pdf_widget, save_png_widget, png_dpi_widget,\n",
        "    widgets.HTML(\"<hr>\"), filename_prefix_widget, include_timestamp_widget\n",
        "])\n",
        "\n",
        "# Assemble Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, text_tab, outlier_tab, export_tab])\n",
        "tabs.set_title(0, '\ud83c\udfa8 Style')\n",
        "tabs.set_title(1, '\ud83d\udcdd Labels')\n",
        "tabs.set_title(2, '\ud83c\udff7\ufe0f Labels')\n",
        "tabs.set_title(3, '\ud83d\udcbe Export')\n",
        "\n",
        "# --- 2. MAIN PLOTTING FUNCTION ---\n",
        "\n",
        "def generate_baujat_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "        print(\"=\" * 70)\n",
        "        print(\"GENERATING BAUJAT PLOT\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        try:\n",
        "            # --- A. LOAD DATA (ROBUST) ---\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'loo_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"\u274c ERROR: LOO results not found. Run Cell 13 first.\")\n",
        "                return\n",
        "\n",
        "            if 'analysis_data' not in globals() and 'analysis_data' not in ANALYSIS_CONFIG:\n",
        "                print(\"\u274c ERROR: Raw data not found.\")\n",
        "                return\n",
        "\n",
        "            # Load LOO Results (Handle Dictionary format from Robust Cell 13)\n",
        "            loo_packet = ANALYSIS_CONFIG['loo_results']\n",
        "            if isinstance(loo_packet, dict):\n",
        "                loo_results = loo_packet['data'].copy()\n",
        "            else:\n",
        "                loo_results = loo_packet.copy()\n",
        "\n",
        "            # Normalize Columns (Robust Cell 13 uses 'excluded_study', old used 'unit_removed')\n",
        "            if 'excluded_study' in loo_results.columns:\n",
        "                loo_results = loo_results.rename(columns={'excluded_study': 'unit_removed'})\n",
        "\n",
        "            # Ensure 'abs_diff' exists\n",
        "            if 'abs_diff' not in loo_results.columns:\n",
        "                # If missing, calculate from original mean in packet or mean of column\n",
        "                orig_mu = loo_packet.get('orig_mu', loo_results['mu'].mean())\n",
        "                loo_results['abs_diff'] = (loo_results['mu'] - orig_mu).abs()\n",
        "\n",
        "            # Load Raw Data\n",
        "            raw_data = ANALYSIS_CONFIG.get('analysis_data', None)\n",
        "            if raw_data is None: raw_data = analysis_data.copy()\n",
        "\n",
        "            effect_col = ANALYSIS_CONFIG.get('effect_col', 'hedges_g')\n",
        "            var_col = ANALYSIS_CONFIG.get('var_col', 'Vg')\n",
        "\n",
        "            # --- B. CALCULATE FIXED EFFECT POOLED MEAN ---\n",
        "            # Baujat plots use the Fixed Effect mean to calculate Q contributions.\n",
        "            # We calculate it here to ensure accuracy regardless of the main model type.\n",
        "            # FE Mean = sum(w * y) / sum(w)\n",
        "\n",
        "            temp_df = raw_data[[effect_col, var_col]].dropna()\n",
        "            temp_df = temp_df[temp_df[var_col] > 0]\n",
        "            weights = 1.0 / temp_df[var_col]\n",
        "            fe_pooled = np.average(temp_df[effect_col], weights=weights)\n",
        "\n",
        "            print(f\"\u2713 Loaded LOO results: {len(loo_results)} studies\")\n",
        "            print(f\"\u2713 Calculated Fixed-Effect Mean (for Q-stat): {fe_pooled:.4f}\")\n",
        "\n",
        "            # --- C. CALCULATE Q CONTRIBUTION ---\n",
        "            # Q_contrib = sum( w_ij * (y_ij - mu_fixed)^2 ) for all j in study i\n",
        "\n",
        "            q_contrib_data = []\n",
        "\n",
        "            # Group by ID\n",
        "            for study_id, study_group in raw_data.groupby('id'):\n",
        "                # Filter valid rows\n",
        "                valid_rows = study_group.dropna(subset=[effect_col, var_col])\n",
        "                if valid_rows.empty: continue\n",
        "\n",
        "                # Q calculation\n",
        "                w_i = 1.0 / valid_rows[var_col]\n",
        "                q_i = np.sum(w_i * (valid_rows[effect_col] - fe_pooled)**2)\n",
        "\n",
        "                q_contrib_data.append({\n",
        "                    'unit_removed': str(study_id),\n",
        "                    'q_contrib': q_i\n",
        "                })\n",
        "\n",
        "            q_contrib_df = pd.DataFrame(q_contrib_data)\n",
        "\n",
        "            # --- D. MERGE ---\n",
        "            # Merge Influence (LOO) with Heterogeneity (Q)\n",
        "            # Ensure types match for merging\n",
        "            loo_results['unit_removed'] = loo_results['unit_removed'].astype(str)\n",
        "            q_contrib_df['unit_removed'] = q_contrib_df['unit_removed'].astype(str)\n",
        "\n",
        "            baujat_data = pd.merge(\n",
        "                loo_results[['unit_removed', 'abs_diff']],\n",
        "                q_contrib_df,\n",
        "                on='unit_removed',\n",
        "                how='inner'\n",
        "            )\n",
        "\n",
        "            if len(baujat_data) == 0:\n",
        "                print(\"\u274c ERROR: No matching studies found between LOO and Raw Data.\")\n",
        "                return\n",
        "\n",
        "            # --- E. IDENTIFY OUTLIERS ---\n",
        "            studies_to_label = []\n",
        "            if show_labels_widget.value:\n",
        "                method = label_method_widget.value\n",
        "                n_lbl = label_threshold_widget.value\n",
        "\n",
        "                if method == 'combined':\n",
        "                    # Euclidean distance from origin after normalization\n",
        "                    q_norm = (baujat_data['q_contrib'] - baujat_data['q_contrib'].mean()) / baujat_data['q_contrib'].std()\n",
        "                    inf_norm = (baujat_data['abs_diff'] - baujat_data['abs_diff'].mean()) / baujat_data['abs_diff'].std()\n",
        "                    baujat_data['score'] = np.sqrt(q_norm.fillna(0)**2 + inf_norm.fillna(0)**2)\n",
        "                    top = baujat_data.nlargest(n_lbl, 'score')\n",
        "                elif method == 'heterogeneity':\n",
        "                    top = baujat_data.nlargest(n_lbl, 'q_contrib')\n",
        "                elif method == 'influence':\n",
        "                    top = baujat_data.nlargest(n_lbl, 'abs_diff')\n",
        "                else:\n",
        "                    top = baujat_data\n",
        "\n",
        "                studies_to_label = top['unit_removed'].tolist()\n",
        "\n",
        "            # --- F. PLOT ---\n",
        "            fig, ax = plt.subplots(figsize=(width_widget.value, height_widget.value), facecolor='white')\n",
        "\n",
        "            # Scatter\n",
        "            ax.scatter(\n",
        "                baujat_data['q_contrib'],\n",
        "                baujat_data['abs_diff'],\n",
        "                s=point_size_widget.value,\n",
        "                c=point_color_widget.value,\n",
        "                alpha=alpha_widget.value,\n",
        "                edgecolors='black', linewidths=0.5, zorder=3\n",
        "            )\n",
        "\n",
        "            # Reference Lines\n",
        "            if show_median_lines_widget.value:\n",
        "                ax.axvline(baujat_data['q_contrib'].median(), color='gray', linestyle='--', alpha=0.5)\n",
        "                ax.axhline(baujat_data['abs_diff'].median(), color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "            # Labels\n",
        "            if studies_to_label:\n",
        "                texts = []\n",
        "                for _, row in baujat_data[baujat_data['unit_removed'].isin(studies_to_label)].iterrows():\n",
        "                    # Smart positioning logic based on widget\n",
        "                    pos = label_position_widget.value\n",
        "                    ha, va = 'center', 'center'\n",
        "                    xytext = (0,0)\n",
        "\n",
        "                    if pos == 'right': xytext = (8, 0); ha='left'\n",
        "                    elif pos == 'left': xytext = (-8, 0); ha='right'\n",
        "                    elif pos == 'top': xytext = (0, 8); va='bottom'\n",
        "                    elif pos == 'bottom': xytext = (0, -8); va='top'\n",
        "                    else: xytext = (5, 5); ha='left'; va='bottom' # Best/Default\n",
        "\n",
        "                    t = ax.annotate(row['unit_removed'], (row['q_contrib'], row['abs_diff']),\n",
        "                                   xytext=xytext, textcoords='offset points',\n",
        "                                   ha=ha, va=va, fontsize=label_font_size_widget.value,\n",
        "                                   bbox=dict(boxstyle='round,pad=0.2', facecolor='yellow', alpha=0.3))\n",
        "                    texts.append(t)\n",
        "\n",
        "                # Optional: adjustText if installed\n",
        "                try:\n",
        "                    from adjustText import adjust_text\n",
        "                    if label_position_widget.value == 'best':\n",
        "                        adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n",
        "                except: pass\n",
        "\n",
        "            # Formatting\n",
        "            ax.set_xlabel(xlabel_widget.value, fontsize=label_fontsize_widget.value, fontweight='bold')\n",
        "            ax.set_ylabel(ylabel_widget.value, fontsize=label_fontsize_widget.value, fontweight='bold')\n",
        "            if show_title_widget.value:\n",
        "                ax.set_title(title_widget.value, fontsize=title_fontsize_widget.value, fontweight='bold', pad=15)\n",
        "\n",
        "            ax.grid(True, linestyle=':', alpha=0.4)\n",
        "            ax.set_xlim(left=0)\n",
        "            ax.set_ylim(bottom=0)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Export\n",
        "            if save_png_widget.value or save_pdf_widget.value:\n",
        "                ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") if include_timestamp_widget.value else \"\"\n",
        "                fn = filename_prefix_widget.value\n",
        "                if save_png_widget.value:\n",
        "                    n = f\"{fn}_{ts}.png\" if ts else f\"{fn}.png\"\n",
        "                    plt.savefig(n, dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                    print(f\"\ud83d\udcbe Saved: {n}\")\n",
        "                if save_pdf_widget.value:\n",
        "                    n = f\"{fn}_{ts}.pdf\" if ts else f\"{fn}.pdf\"\n",
        "                    plt.savefig(n, bbox_inches='tight')\n",
        "                    print(f\"\ud83d\udcbe Saved: {n}\")\n",
        "\n",
        "            plt.show()\n",
        "            print(f\"\u2705 Plotted {len(baujat_data)} studies.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c ERROR: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# --- 3. DISPLAY ---\n",
        "run_plot_btn = widgets.Button(description='\ud83d\udcca Generate Baujat Plot', button_style='success', layout=widgets.Layout(width='450px', height='50px'))\n",
        "plot_output = widgets.Output()\n",
        "run_plot_btn.on_click(generate_baujat_plot)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>\ud83d\udcca Cell 13c: Baujat Plot</h3><p>Diagnostic for Heterogeneity vs Influence</p>\"),\n",
        "    tabs, run_plot_btn, plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uAMgPwcmgawm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcc8 23. Cumulative Meta-Analysis: DATA LAYER (Model)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 1/4: DATA LAYER - CUMULATIVE META-ANALYSIS\n",
        "# Purpose: Centralized data management for cumulative meta-analysis\n",
        "# Dependencies: ANALYSIS_CONFIG global dictionary\n",
        "# Math validated: Iterative REML estimation for temporal evolution\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA CLASSES\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class CumulativeConfig:\n",
        "    \"\"\"Configuration for cumulative meta-analysis\"\"\"\n",
        "    effect_col: str\n",
        "    var_col: str\n",
        "    year_col: str = 'year'\n",
        "    sort_order: str = 'ascending'  # 'ascending' or 'descending'\n",
        "    aggregation_method: str = 'study'  # 'study' or 'obs'\n",
        "    alpha: float = 0.05\n",
        "    dist_type: str = 'norm'  # 'norm' or 't'\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration\"\"\"\n",
        "        if not self.effect_col:\n",
        "            raise ValueError(\"effect_col cannot be empty\")\n",
        "        if not self.var_col:\n",
        "            raise ValueError(\"var_col cannot be empty\")\n",
        "        if self.sort_order not in ['ascending', 'descending']:\n",
        "            raise ValueError(f\"sort_order must be 'ascending' or 'descending', got {self.sort_order}\")\n",
        "        if self.aggregation_method not in ['study', 'obs']:\n",
        "            raise ValueError(f\"aggregation_method must be 'study' or 'obs', got {self.aggregation_method}\")\n",
        "        if self.alpha <= 0 or self.alpha >= 1:\n",
        "            raise ValueError(f\"alpha must be between 0 and 1, got {self.alpha}\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CumulativeStep:\n",
        "    \"\"\"Single step in cumulative meta-analysis\"\"\"\n",
        "    step: int\n",
        "    year: int\n",
        "    study_added: str\n",
        "    k_studies: int\n",
        "    pooled_effect: float\n",
        "    se: float\n",
        "    ci_lower: float\n",
        "    ci_upper: float\n",
        "    tau2: float\n",
        "    I2: float\n",
        "    ci_pct: float\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CumulativeResult:\n",
        "    \"\"\"Complete cumulative meta-analysis result\"\"\"\n",
        "    steps: pd.DataFrame  # All cumulative steps\n",
        "    start_step: CumulativeStep\n",
        "    end_step: CumulativeStep\n",
        "    n_steps: int\n",
        "    year_range: Tuple[int, int]\n",
        "    aggregation_method: str\n",
        "    sort_order: str\n",
        "\n",
        "    # Summary metrics\n",
        "    effect_stable: bool = False  # Did effect stabilize?\n",
        "    precision_improved: bool = False  # Did CI narrow?\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# DATA MANAGER CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativeDataManager:\n",
        "    \"\"\"\n",
        "    Centralized data access layer for cumulative meta-analysis.\n",
        "    Handles all interactions with ANALYSIS_CONFIG and data validation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize data manager.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self._config = analysis_config\n",
        "        self._validate_prerequisites()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # VALIDATION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _validate_prerequisites(self) -> None:\n",
        "        \"\"\"Validate that required configuration exists\"\"\"\n",
        "        if 'effect_col' not in self._config:\n",
        "            warnings.warn(\"effect_col not in ANALYSIS_CONFIG, using default 'hedges_g'\")\n",
        "        if 'var_col' not in self._config:\n",
        "            warnings.warn(\"var_col not in ANALYSIS_CONFIG, using default 'Vg'\")\n",
        "\n",
        "    def validate_data(self, df: pd.DataFrame) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"\n",
        "        Validate that data is suitable for cumulative analysis.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if df is None or len(df) == 0:\n",
        "            return False, \"No data available\"\n",
        "\n",
        "        if self.effect_col not in df.columns:\n",
        "            return False, f\"Effect column '{self.effect_col}' not found\"\n",
        "\n",
        "        if self.var_col not in df.columns:\n",
        "            return False, f\"Variance column '{self.var_col}' not found\"\n",
        "\n",
        "        if 'year' not in df.columns:\n",
        "            return False, \"'year' column not found - required for cumulative analysis\"\n",
        "\n",
        "        # Check for minimum observations\n",
        "        n_valid = df[['year', self.effect_col, self.var_col]].notna().all(axis=1).sum()\n",
        "        if n_valid < 3:\n",
        "            return False, f\"Need at least 3 valid observations, found {n_valid}\"\n",
        "\n",
        "        return True, None\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PROPERTY ACCESSORS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    @property\n",
        "    def analysis_data(self) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Get analysis dataset\"\"\"\n",
        "        if 'analysis_data' in self._config:\n",
        "            return self._config['analysis_data'].copy()\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def effect_col(self) -> str:\n",
        "        \"\"\"Get effect size column name\"\"\"\n",
        "        return self._config.get('effect_col', 'hedges_g')\n",
        "\n",
        "    @property\n",
        "    def var_col(self) -> str:\n",
        "        \"\"\"Get variance column name\"\"\"\n",
        "        return self._config.get('var_col', 'Vg')\n",
        "\n",
        "    @property\n",
        "    def es_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get effect size configuration\"\"\"\n",
        "        return self._config.get('es_config', {})\n",
        "\n",
        "    @property\n",
        "    def global_settings(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get global settings (with defaults)\"\"\"\n",
        "        return self._config.get('global_settings', {\n",
        "            'alpha': 0.05,\n",
        "            'dist_type': 'norm'\n",
        "        })\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA EXTRACTION METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def prepare_data(\n",
        "        self,\n",
        "        aggregation_method: str = 'study',\n",
        "        raw_dataframe: Optional[pd.DataFrame] = None\n",
        "    ) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Prepare and clean data for cumulative analysis.\n",
        "\n",
        "        Args:\n",
        "            aggregation_method: 'study' or 'obs'\n",
        "            df: DataFrame to prepare (uses analysis_data if None)\n",
        "\n",
        "        Returns:\n",
        "            Cleaned DataFrame\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If data cannot be prepared\n",
        "        \"\"\"\n",
        "        if raw_dataframe is None:\n",
        "            raw_dataframe = self.analysis_data\n",
        "\n",
        "        if raw_dataframe is None:\n",
        "            raise ValueError(\"No data available for analysis\")\n",
        "\n",
        "        # Validate\n",
        "        is_valid, error_msg = self.validate_data(raw_dataframe)\n",
        "        if not is_valid:\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        # Create working copy\n",
        "        clean_df = raw_dataframe.copy()\n",
        "\n",
        "        # Convert year to numeric\n",
        "        clean_df['year'] = pd.to_numeric(clean_df['year'], errors='coerce')\n",
        "\n",
        "        # Remove missing values\n",
        "        clean_df = clean_df.dropna(subset=['year', self.effect_col, self.var_col]).copy()\n",
        "\n",
        "        # Remove zero or negative variances\n",
        "        clean_df = clean_df[clean_df[self.var_col] > 0].copy()\n",
        "\n",
        "        # Aggregate to study level if requested\n",
        "        if aggregation_method == 'study':\n",
        "            clean_df = self._aggregate_to_study_level(clean_df)\n",
        "\n",
        "        # Final check\n",
        "        if len(clean_df) < 3:\n",
        "            raise ValueError(f\"Insufficient data after cleaning: {len(clean_df)} observations. Need at least 3.\")\n",
        "\n",
        "        return clean_df\n",
        "\n",
        "    def _aggregate_to_study_level(self, input_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Aggregate effect sizes to study level using inverse-variance weights.\n",
        "        Optimized with vectorized pandas operations.\n",
        "\n",
        "        Args:\n",
        "            input_df: DataFrame with multiple observations per study\n",
        "\n",
        "        Returns:\n",
        "            Aggregated DataFrame (one row per study)\n",
        "        \"\"\"\n",
        "        # Work on a copy to avoid side effects\n",
        "        df_copy = input_df.copy()\n",
        "        \n",
        "        # Calculate inverse-variance weights\n",
        "        df_copy['weight'] = 1.0 / df_copy[self.var_col]\n",
        "        df_copy['weighted_effect'] = df_copy[self.effect_col] * df_copy['weight']\n",
        "        \n",
        "        # Group by study ID\n",
        "        grouped = df_copy.groupby('id')\n",
        "        \n",
        "        # Vectorized aggregation\n",
        "        sum_weights = grouped['weight'].sum()\n",
        "        sum_weighted_effects = grouped['weighted_effect'].sum()\n",
        "        min_years = grouped['year'].min()\n",
        "        \n",
        "        # Reconstruct DataFrame\n",
        "        # Note: sum_weights.index contains the 'id's\n",
        "        agg_df = pd.DataFrame({\n",
        "            'id': sum_weights.index,\n",
        "            self.effect_col: sum_weighted_effects / sum_weights,\n",
        "            self.var_col: 1.0 / sum_weights,\n",
        "            'year': min_years\n",
        "        }).reset_index(drop=True)\n",
        "\n",
        "        return agg_df\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # RESULT PERSISTENCE METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def save_cumulative_results(self, result: CumulativeResult) -> None:\n",
        "        \"\"\"\n",
        "        Save cumulative analysis results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: CumulativeResult object\n",
        "        \"\"\"\n",
        "        import datetime\n",
        "\n",
        "        self._config['cumulative_results'] = result.steps\n",
        "        self._config['cumulative_metadata'] = {\n",
        "            'timestamp': datetime.datetime.now(),\n",
        "            'n_steps': result.n_steps,\n",
        "            'year_range': result.year_range,\n",
        "            'aggregation_method': result.aggregation_method,\n",
        "            'sort_order': result.sort_order,\n",
        "            'start_effect': result.start_step.pooled_effect,\n",
        "            'end_effect': result.end_step.pooled_effect,\n",
        "            'effect_stable': result.effect_stable,\n",
        "            'precision_improved': result.precision_improved\n",
        "        }\n",
        "\n",
        "    def save_publication_text(self, text: str) -> None:\n",
        "        \"\"\"Save publication-ready text\"\"\"\n",
        "        self._config['cumulative_text'] = text\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTILITY METHODS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def summary_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get summary of current configuration\"\"\"\n",
        "        df = self.analysis_data\n",
        "\n",
        "        return {\n",
        "            'effect_col': self.effect_col,\n",
        "            'var_col': self.var_col,\n",
        "            'has_year': 'year' in df.columns if df is not None else False,\n",
        "            'n_observations': len(df) if df is not None else 0,\n",
        "            'n_studies': df['id'].nunique() if df is not None and 'id' in df.columns else 0,\n",
        "            'year_range': (df['year'].min(), df['year'].max()) if df is not None and 'year' in df.columns else None\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Cumulative Meta-Analysis Data Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - CumulativeConfig\")\n",
        "    print(\"   - CumulativeStep\")\n",
        "    print(\"   - CumulativeResult\")\n",
        "    print(\"   - CumulativeDataManager\")\n",
        "\n",
        "#@title \ud83d\udcc8 23. Cumulative Meta-Analysis: ANALYSIS LAYER (Business Logic)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 2/4: ANALYSIS LAYER - CUMULATIVE META-ANALYSIS\n",
        "# Purpose: Pure statistical computation without UI dependencies\n",
        "# Dependencies: Data Layer (CumulativeDataManager, CumulativeResult)\n",
        "# Math validated: Iterative REML estimation for temporal evolution\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, t, chi2\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "import warnings\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# REML TAU\u00b2 ESTIMATOR\n",
        "# =============================================================================\n",
        "\n",
        "class REMLTauEstimator:\n",
        "    \"\"\"\n",
        "    Iterative REML estimator for \u03c4\u00b2 in cumulative analysis.\n",
        "\n",
        "    Mathematical implementation: Self-contained Fisher scoring algorithm.\n",
        "    PRESERVED: Your original iterative REML logic.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def estimate(\n",
        "        effect_sizes: np.ndarray,\n",
        "        variances: np.ndarray,\n",
        "        max_iter: int = 10,\n",
        "        tol: float = 1e-5\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Estimate \u03c4\u00b2 using iterative REML.\n",
        "\n",
        "        MATH PRESERVED: Original Fisher scoring approach\n",
        "\n",
        "        Args:\n",
        "            y: Effect sizes\n",
        "            v: Variances\n",
        "            max_iter: Maximum iterations\n",
        "            tol: Convergence tolerance\n",
        "\n",
        "        Returns:\n",
        "            \u03c4\u00b2 estimate\n",
        "        \"\"\"\n",
        "        num_studies = len(effect_sizes)\n",
        "\n",
        "        # Initial guess (DerSimonian-Laird)\n",
        "        fixed_weights = 1.0 / variances\n",
        "        fixed_effect_mean = np.sum(fixed_weights * effect_sizes) / np.sum(fixed_weights)\n",
        "        Q_statistic = np.sum(fixed_weights * (effect_sizes - fixed_effect_mean)**2)\n",
        "        C_constant = np.sum(fixed_weights) - np.sum(fixed_weights**2) / np.sum(fixed_weights)\n",
        "        tau_squared = max(0, (Q_statistic - (num_studies - 1)) / C_constant) if C > 0 else 0\n",
        "\n",
        "        # Iterative REML refinement\n",
        "        for iteration in range(max_iter):\n",
        "            random_weights = 1.0 / (variances + tau_squared)\n",
        "            sum_weights = np.sum(random_weights)\n",
        "            sum_sq_weights = np.sum(random_weights**2)\n",
        "            weighted_mean = np.sum(random_weights * effect_sizes) / sum_weights\n",
        "\n",
        "            # Fisher scoring step\n",
        "            try:\n",
        "                # Calculate the score function component (numerator)\n",
        "                num = np.sum(random_weights**2 * ((effect_sizes - weighted_mean)**2 - variances))\n",
        "                # Fisher information component (denominator)\n",
        "                den = sum_sq_weights\n",
        "                # Update tau_squared using Fisher Scoring step\n",
        "                tau2_new = max(0, tau_squared + (num / den))\n",
        "\n",
        "                # Check convergence\n",
        "                if abs(tau2_new - tau_squared) < tol:\n",
        "                    tau_squared = tau2_new\n",
        "                    break\n",
        "\n",
        "                tau_squared = tau2_new\n",
        "\n",
        "            except:\n",
        "                break  # Keep last good value\n",
        "\n",
        "        return max(0, tau_squared)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HETEROGENEITY CALCULATOR\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativeHeterogeneityEngine:\n",
        "    \"\"\"\n",
        "    Calculate heterogeneity statistics for each cumulative step.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_Q_and_I2(\n",
        "        effect_sizes: np.ndarray,\n",
        "        variances: np.ndarray,\n",
        "        fixed_effect_mean: float\n",
        "    ) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        Calculate Q statistic and I\u00b2.\n",
        "\n",
        "        Args:\n",
        "            y: Effect sizes\n",
        "            v: Variances\n",
        "            mu_fe: Fixed-effect pooled estimate\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (Q, I2)\n",
        "        \"\"\"\n",
        "        num_studies = len(effect_sizes)\n",
        "        weights = 1.0 / variances\n",
        "        Q_statistic = np.sum(weights * (effect_sizes - fixed_effect_mean)**2)\n",
        "        I2_score = max(0, (Q_statistic - (num_studies - 1)) / Q_statistic * 100) if Q_statistic > 0 else 0.0\n",
        "\n",
        "        return Q_statistic, I2_score\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CUMULATIVE STEP CALCULATOR\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativeStepEngine:\n",
        "    \"\"\"\n",
        "    Calculate meta-analysis for a single cumulative step.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha: float = 0.05, dist_type: str = 'norm'):\n",
        "        \"\"\"\n",
        "        Initialize engine.\n",
        "\n",
        "        Args:\n",
        "            alpha: Significance level\n",
        "            dist_type: 'norm' or 't'\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "        self.dist_type = dist_type\n",
        "        self.tau_estimator = REMLTauEstimator()\n",
        "        self.het_engine = CumulativeHeterogeneityEngine()\n",
        "\n",
        "    def calculate_step(\n",
        "        self,\n",
        "        cumulative_effects: np.ndarray,\n",
        "        cumulative_variances: np.ndarray,\n",
        "        step: int,\n",
        "        year: int,\n",
        "        study_id: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Calculate meta-analysis for current cumulative step.\n",
        "\n",
        "        MATH PRESERVED: Complete REML random-effects pooling\n",
        "\n",
        "        Args:\n",
        "            y: Effect sizes (cumulative to this point)\n",
        "            v: Variances (cumulative to this point)\n",
        "            step: Step number\n",
        "            year: Year of study added\n",
        "            study_id: ID of study added\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with step results\n",
        "        \"\"\"\n",
        "        num_studies = len(effect_sizes)\n",
        "        ci_pct = (1 - self.alpha) * 100\n",
        "\n",
        "        # Step 1: Estimate \u03c4\u00b2\n",
        "        tau2 = self.tau_estimator.estimate(cumulative_effects, cumulative_variances)\n",
        "\n",
        "        # Step 2: Random-effects pooling\n",
        "        random_weights = 1.0 / (cumulative_variances + tau2)\n",
        "        sum_random_weights = np.sum(random_weights)\n",
        "        pooled_effect = np.sum(random_weights * cumulative_effects) / sum_random_weights\n",
        "        pooled_se = np.sqrt(1.0 / sum_random_weights)\n",
        "\n",
        "        # Step 3: Heterogeneity statistics\n",
        "        fixed_weights = 1.0 / variances\n",
        "        fixed_effect_mean = np.sum(fixed_weights * effect_sizes) / np.sum(fixed_weights)\n",
        "        Q, I2 = self.het_engine.calculate_Q_and_I2(cumulative_effects, cumulative_variances, fixed_mean)\n",
        "\n",
        "        # Step 4: Critical value and CI\n",
        "        q_val = 1 - (self.alpha / 2)\n",
        "\n",
        "        if self.dist_type == 't':\n",
        "            df_cum = max(1, num_studies - 1)\n",
        "            crit_val = t.ppf(q_val, df_cum)\n",
        "        else:\n",
        "            crit_val = norm.ppf(q_val)\n",
        "\n",
        "        ci_lower = pooled_effect - crit_val * pooled_se\n",
        "        ci_upper = pooled_effect + crit_val * pooled_se\n",
        "\n",
        "        return {\n",
        "            'step': step,\n",
        "            'year': int(year) if pd.notna(year) else 0,\n",
        "            'study_added': study_id,\n",
        "            'k_studies': k,\n",
        "            'pooled_effect': pooled_effect,\n",
        "            'se': pooled_se,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'tau2': tau2,\n",
        "            'I2': I2,\n",
        "            'ci_pct': ci_pct\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STABILITY ANALYZER\n",
        "# =============================================================================\n",
        "\n",
        "class StabilityAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze whether effect size has stabilized over time.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def assess_stability(steps_df: pd.DataFrame) -> bool:\n",
        "        \"\"\"\n",
        "        Assess if effect size has stabilized in recent steps.\n",
        "\n",
        "        Logic: Check if effect size changed by <10% in last 5 steps\n",
        "\n",
        "        Args:\n",
        "            steps_df: DataFrame with cumulative steps\n",
        "\n",
        "        Returns:\n",
        "            True if effect appears stable\n",
        "        \"\"\"\n",
        "        if len(steps_df) < 5:\n",
        "            return False\n",
        "\n",
        "        recent_steps = steps_df.tail(5)\n",
        "        effects = recent_steps['pooled_effect'].values\n",
        "\n",
        "        # Calculate percentage change from first to last of recent steps\n",
        "        if effects[0] == 0:\n",
        "            return False\n",
        "\n",
        "        pct_change = abs((effects[-1] - effects[0]) / effects[0]) * 100\n",
        "\n",
        "        return pct_change < 10\n",
        "\n",
        "    @staticmethod\n",
        "    def assess_precision_improvement(\n",
        "        start_step: 'CumulativeStep',\n",
        "        end_step: 'CumulativeStep'\n",
        "    ) -> bool:\n",
        "        \"\"\"\n",
        "        Assess if precision improved (CI narrowed).\n",
        "\n",
        "        Args:\n",
        "            start_step: First cumulative step\n",
        "            end_step: Last cumulative step\n",
        "\n",
        "        Returns:\n",
        "            True if CI width decreased\n",
        "        \"\"\"\n",
        "        ci_width_start = start_step.ci_upper - start_step.ci_lower\n",
        "        ci_width_end = end_step.ci_upper - end_step.ci_lower\n",
        "\n",
        "        return ci_width_end < ci_width_start\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CUMULATIVE META-ANALYSIS ORCHESTRATOR\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativeEngine:\n",
        "    \"\"\"\n",
        "    High-level orchestrator for cumulative meta-analysis.\n",
        "    Coordinates iterative calculations across all time steps.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_manager: 'CumulativeDataManager'):\n",
        "        \"\"\"\n",
        "        Initialize engine with data manager.\n",
        "\n",
        "        Args:\n",
        "            data_manager: CumulativeDataManager instance\n",
        "        \"\"\"\n",
        "        self.data_manager = data_manager\n",
        "\n",
        "        # Get settings from global config\n",
        "        settings = data_manager.global_settings\n",
        "        self.step_engine = CumulativeStepEngine(\n",
        "            alpha=settings.get('alpha', 0.05),\n",
        "            dist_type=settings.get('dist_type', 'norm')\n",
        "        )\n",
        "        self.stability_analyzer = StabilityAnalyzer()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(\n",
        "        self,\n",
        "        sort_order: str = 'ascending',\n",
        "        aggregation_method: str = 'study',\n",
        "        progress_callback: Optional[callable] = None\n",
        "    ) -> Optional['CumulativeResult']:\n",
        "        \"\"\"\n",
        "        Execute complete cumulative meta-analysis.\n",
        "\n",
        "        WORKFLOW:\n",
        "        1. Prepare and sort data\n",
        "        2. Iterate through time points\n",
        "        3. Calculate meta-analysis at each step\n",
        "        4. Assess stability\n",
        "\n",
        "        Args:\n",
        "            sort_order: 'ascending' or 'descending'\n",
        "            aggregation_method: 'study' or 'obs'\n",
        "            progress_callback: Optional progress updates\n",
        "\n",
        "        Returns:\n",
        "            CumulativeResult object or None if analysis fails\n",
        "        \"\"\"\n",
        "        # Step 1: Prepare data\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udcca Preparing data...\")\n",
        "\n",
        "        try:\n",
        "            df = self.data_manager.prepare_data(aggregation_method)\n",
        "        except ValueError as e:\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"\u274c Data preparation failed: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        # Step 2: Sort by year\n",
        "        if progress_callback:\n",
        "            progress_callback(f\"\ud83d\udcc5 Sorting by year ({sort_order})...\")\n",
        "\n",
        "        df_sorted = df.sort_values(\n",
        "            'year',\n",
        "            ascending=(sort_order == 'ascending')\n",
        "        ).reset_index(drop=True)\n",
        "\n",
        "        # Step 3: Iterative calculation\n",
        "        if progress_callback:\n",
        "            progress_callback(\"\ud83d\udd04 Running iterative meta-analysis...\")\n",
        "\n",
        "        results = []\n",
        "        n_steps = len(df_sorted)\n",
        "\n",
        "        # Need at least 2 studies to start\n",
        "        for i in range(2, n_steps + 1):\n",
        "            current_slice = df_sorted.iloc[:i]\n",
        "\n",
        "            y = current_slice[self.data_manager.effect_col].values\n",
        "            v = current_slice[self.data_manager.var_col].values\n",
        "            year = current_slice.iloc[-1]['year']\n",
        "            study_id = current_slice.iloc[-1]['id'] if 'id' in current_slice.columns else f\"Study_{i}\"\n",
        "\n",
        "            step_result = self.step_engine.calculate_step(\n",
        "                y, v, i, year, study_id\n",
        "            )\n",
        "\n",
        "            results.append(step_result)\n",
        "\n",
        "        if not results:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"\u274c No results generated\")\n",
        "            return None\n",
        "\n",
        "        # Step 4: Create results DataFrame\n",
        "        steps_df = pd.DataFrame(results)\n",
        "\n",
        "        # Step 5: Extract start and end steps\n",
        "        start_row = steps_df.iloc[0]\n",
        "        end_row = steps_df.iloc[-1]\n",
        "\n",
        "        start_step = CumulativeStep(\n",
        "            step=int(start_row['step']),\n",
        "            year=int(start_row['year']),\n",
        "            study_added=start_row['study_added'],\n",
        "            k_studies=int(start_row['k_studies']),\n",
        "            pooled_effect=start_row['pooled_effect'],\n",
        "            se=start_row['se'],\n",
        "            ci_lower=start_row['ci_lower'],\n",
        "            ci_upper=start_row['ci_upper'],\n",
        "            tau2=start_row['tau2'],\n",
        "            I2=start_row['I2'],\n",
        "            ci_pct=start_row['ci_pct']\n",
        "        )\n",
        "\n",
        "        end_step = CumulativeStep(\n",
        "            step=int(end_row['step']),\n",
        "            year=int(end_row['year']),\n",
        "            study_added=end_row['study_added'],\n",
        "            k_studies=int(end_row['k_studies']),\n",
        "            pooled_effect=end_row['pooled_effect'],\n",
        "            se=end_row['se'],\n",
        "            ci_lower=end_row['ci_lower'],\n",
        "            ci_upper=end_row['ci_upper'],\n",
        "            tau2=end_row['tau2'],\n",
        "            I2=end_row['I2'],\n",
        "            ci_pct=end_row['ci_pct']\n",
        "        )\n",
        "\n",
        "        # Step 6: Assess stability and precision\n",
        "        effect_stable = self.stability_analyzer.assess_stability(steps_df)\n",
        "        precision_improved = self.stability_analyzer.assess_precision_improvement(\n",
        "            start_step, end_step\n",
        "        )\n",
        "\n",
        "        # Step 7: Build result object\n",
        "        result = CumulativeResult(\n",
        "            steps=steps_df,\n",
        "            start_step=start_step,\n",
        "            end_step=end_step,\n",
        "            n_steps=len(results),\n",
        "            year_range=(int(steps_df['year'].min()), int(steps_df['year'].max())),\n",
        "            aggregation_method=aggregation_method,\n",
        "            sort_order=sort_order,\n",
        "            effect_stable=effect_stable,\n",
        "            precision_improved=precision_improved\n",
        "        )\n",
        "\n",
        "        if progress_callback:\n",
        "            progress_callback(\n",
        "                f\"\u2705 Complete: {result.n_steps} steps, \"\n",
        "                f\"\u03bc: {start_step.pooled_effect:.3f} \u2192 {end_step.pooled_effect:.3f}\"\n",
        "            )\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Cumulative Meta-Analysis Analysis Layer Module Loaded Successfully\")\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - REMLTauEstimator (iterative Fisher scoring)\")\n",
        "    print(\"   - CumulativeHeterogeneityEngine\")\n",
        "    print(\"   - CumulativeStepEngine\")\n",
        "    print(\"   - StabilityAnalyzer\")\n",
        "    print(\"   - CumulativeEngine (main orchestrator)\")\n",
        "\n",
        "#@title \ud83d\udcc8 23. Cumulative Meta-Analysis: PRESENTATION LAYER (View) - PART 1\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 3/4: PRESENTATION LAYER - CUMULATIVE META-ANALYSIS\n",
        "# Purpose: Pure UI rendering without business logic\n",
        "# Dependencies: Data & Analysis Layers\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Any, Optional\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import sys\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# HTML TEMPLATE GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativeHTMLTemplates:\n",
        "    \"\"\"\n",
        "    Static HTML template generators for cumulative meta-analysis visualizations.\n",
        "    All methods are pure functions returning HTML strings.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def comparison_cards(\n",
        "        start_step: 'CumulativeStep',\n",
        "        end_step: 'CumulativeStep'\n",
        "    ) -> str:\n",
        "        \"\"\"Generate start vs end comparison cards\"\"\"\n",
        "        return f\"\"\"\n",
        "        <div style='padding:10px;'>\n",
        "            <h3 style='color:#2E86AB; margin-top:0;'>Analysis Complete</h3>\n",
        "            <div style='display:flex; gap:20px;'>\n",
        "                <div style='flex:1; background:#f8f9fa; padding:15px; border-radius:5px;\n",
        "                            border-left:4px solid #6c757d;'>\n",
        "                    <h4 style='margin:0; color:#666;'>Start (k={start_step.k_studies})</h4>\n",
        "                    <div style='font-size:18px; font-weight:bold; margin-top:5px;'>\n",
        "                        {start_step.pooled_effect:.3f}\n",
        "                    </div>\n",
        "                    <div style='font-size:12px;'>\n",
        "                        {start_step.ci_pct:.0f}% CI [{start_step.ci_lower:.3f}, {start_step.ci_upper:.3f}]\n",
        "                    </div>\n",
        "                    <div style='font-size:12px; color:#666;'>Year: {start_step.year}</div>\n",
        "                </div>\n",
        "                <div style='flex:0.2; display:flex; align-items:center; justify-content:center;\n",
        "                            font-size:24px; color:#ccc;'>\n",
        "                    \u2794\n",
        "                </div>\n",
        "                <div style='flex:1; background:#e7f3ff; padding:15px; border-radius:5px;\n",
        "                            border-left:4px solid #007bff;'>\n",
        "                    <h4 style='margin:0; color:#0056b3;'>End (k={end_step.k_studies})</h4>\n",
        "                    <div style='font-size:18px; font-weight:bold; margin-top:5px; color:#0056b3;'>\n",
        "                        {end_step.pooled_effect:.3f}\n",
        "                    </div>\n",
        "                    <div style='font-size:12px; color:#0056b3;'>\n",
        "                        {end_step.ci_pct:.0f}% CI [{end_step.ci_lower:.3f}, {end_step.ci_upper:.3f}]\n",
        "                    </div>\n",
        "                    <div style='font-size:12px; color:#0056b3;'>Year: {end_step.year}</div>\n",
        "                </div>\n",
        "            </div>\n",
        "            <p style='margin-top:15px; color:#555;'>\n",
        "                <b>Method:</b> Iterative REML (Consistent with Overall Analysis).\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def stability_badges(\n",
        "        effect_stable: bool,\n",
        "        precision_improved: bool\n",
        "    ) -> str:\n",
        "        \"\"\"Generate stability assessment badges\"\"\"\n",
        "        stable_color = \"#28a745\" if effect_stable else \"#ffc107\"\n",
        "        stable_text = \"\u2713 Stabilized\" if effect_stable else \"\u26a0 Still Evolving\"\n",
        "        stable_icon = \"\u2713\" if effect_stable else \"\u26a0\"\n",
        "\n",
        "        precision_color = \"#28a745\" if precision_improved else \"#dc3545\"\n",
        "        precision_text = \"\u2713 Improved\" if precision_improved else \"\u2717 Wider CI\"\n",
        "        precision_icon = \"\u2713\" if precision_improved else \"\u2717\"\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='display: flex; gap: 15px; margin: 15px 0;'>\n",
        "            <div style='background-color: {stable_color}; color: white; padding: 10px 20px;\n",
        "                        border-radius: 5px; font-weight: bold;'>\n",
        "                {stable_icon} Effect: {stable_text}\n",
        "            </div>\n",
        "            <div style='background-color: {precision_color}; color: white; padding: 10px 20px;\n",
        "                        border-radius: 5px; font-weight: bold;'>\n",
        "                {precision_icon} Precision: {precision_text}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def method_note(aggregation_method: str) -> str:\n",
        "        \"\"\"Generate method description note\"\"\"\n",
        "        if aggregation_method == 'study':\n",
        "            desc = \"Effect sizes aggregated to study level (recommended for nested data)\"\n",
        "        else:\n",
        "            desc = \"Each observation treated independently (no aggregation)\"\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: #f8f9fa; padding: 10px; border-left: 3px solid #007bff;\n",
        "                    margin: 10px 0; font-size: 0.9em;'>\n",
        "            <b>Data Structure:</b> {desc}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# PUBLICATION TEXT GENERATORS\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativePublicationTextGenerator:\n",
        "    \"\"\"\n",
        "    Generates publication-ready text for manuscripts.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate_methods_section(\n",
        "        self,\n",
        "        result: 'CumulativeResult',\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate Materials and Methods section.\n",
        "\n",
        "        PRESERVED: Original citation logic\n",
        "        \"\"\"\n",
        "        es_label = es_config.get('effect_label', 'Effect Size')\n",
        "        n_steps = result.n_steps\n",
        "        start_year, end_year = result.year_range\n",
        "        ci_pct = result.start_step.ci_pct\n",
        "\n",
        "        # Citation database\n",
        "        db = {\n",
        "            'lau': \"Lau, J., Antman, E. M., Jimenez-Silva, J., Kupelnick, B., Mosteller, F., & Chalmers, T. C. (1992). Cumulative meta-analysis of therapeutic trials for myocardial infarction. <i>New England Journal of Medicine</i>, 327(4), 248-254.\",\n",
        "            'reml': \"Viechtbauer, W. (2005). Bias and efficiency of meta-analytic variance estimators in the random-effects model. <i>Journal of Educational and Behavioral Statistics</i>, 30(3), 261-293.\",\n",
        "            'borenstein': \"Borenstein, M., Hedges, L. V., Higgins, J. P., & Rothstein, H. R. (2009). <i>Introduction to Meta-Analysis</i>. Chichester, UK: John Wiley & Sons.\",\n",
        "            'tool': \"<b>[CITATION FOR THIS TOOL]:</b> Author, A. A. (202X). <i>Co-Meta: An Interactive Pipeline for Meta-Analysis</i>. [Repository/DOI].\"\n",
        "        }\n",
        "\n",
        "        # Aggregation description\n",
        "        if result.aggregation_method == 'study':\n",
        "            agg_desc = \"Prior to the cumulative analysis, effect sizes were aggregated at the study level to ensure independence. A fixed-effect weighted mean was calculated for studies reporting multiple outcomes.\"\n",
        "        else:\n",
        "            agg_desc = \"Effect sizes were treated as independent observations for the cumulative analysis.\"\n",
        "\n",
        "        html = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;\n",
        "                    border: 1px solid #eee; margin-bottom: 20px;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;\n",
        "                   margin-top: 0;'>Materials and Methods</h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Cumulative Meta-Analysis.</b> To evaluate the accumulation of evidence over time and\n",
        "        assess the sufficiency and stability of the pooled effect size, we performed a cumulative\n",
        "        meta-analysis [1]. Studies were sorted chronologically by publication year (Range: {start_year}\u2013{end_year}),\n",
        "        and a new meta-analysis was performed each time a new study was added to the pool.\n",
        "        </p>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        <b>Model Specification.</b> {agg_desc} For each of the {n_steps} cumulative steps, a\n",
        "        random-effects model was fitted using the Restricted Maximum Likelihood (REML) estimator [2]\n",
        "        to calculate the updated pooled effect and {ci_pct:.0f}% confidence interval. This approach\n",
        "        allows for the visualization of how the precision of the estimate evolves and whether the\n",
        "        effect size stabilizes as sample size increases [3]. All analyses were performed using the\n",
        "        Co-Meta toolkit [4].\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 20px; font-size: 11pt;'>References</h4>\n",
        "        <ol style='font-size: 10pt; color: #555;'>\n",
        "            <li>{db['lau']}</li>\n",
        "            <li>{db['reml']}</li>\n",
        "            <li>{db['borenstein']}</li>\n",
        "            <li>{db['tool']}</li>\n",
        "        </ol>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    def generate_results_section(\n",
        "        self,\n",
        "        result: 'CumulativeResult',\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate complete Results section with interpretation.\n",
        "\n",
        "        PRESERVED: Original publication text logic with temporal interpretation\n",
        "        \"\"\"\n",
        "        start = result.start_step\n",
        "        end = result.end_step\n",
        "\n",
        "        es_label = es_config.get('effect_label', 'Effect Size')\n",
        "        ci_pct = start.ci_pct\n",
        "\n",
        "        # Calculate trends\n",
        "        ci_width_start = start.ci_upper - start.ci_lower\n",
        "        ci_width_end = end.ci_upper - end.ci_lower\n",
        "        precision_change = (ci_width_end - ci_width_start) / ci_width_start * 100\n",
        "        prec_text = \"improved\" if precision_change < 0 else \"decreased\"\n",
        "\n",
        "        # Effect stability\n",
        "        abs_change = abs(end.pooled_effect - start.pooled_effect)\n",
        "        pct_change = (abs_change / abs(start.pooled_effect) * 100) if start.pooled_effect != 0 else 0\n",
        "\n",
        "        if pct_change < 10:\n",
        "            trend_desc = \"remained remarkably stable\"\n",
        "        elif pct_change < 30:\n",
        "            trend_desc = \"remained relatively consistent\"\n",
        "        else:\n",
        "            direction = \"increased\" if abs(end.pooled_effect) > abs(start.pooled_effect) else \"decreased\"\n",
        "            trend_desc = f\"gradually {direction} in magnitude\"\n",
        "\n",
        "        # Heterogeneity trend\n",
        "        het_trend = \"increased\" if end.I2 > start.I2 + 5 else \"decreased\" if end.I2 < start.I2 - 5 else \"remained stable\"\n",
        "\n",
        "        # Build HTML\n",
        "        html = f\"\"\"\n",
        "        <div style='font-family: \"Times New Roman\", Times, serif; font-size: 12pt;\n",
        "                    line-height: 1.8; padding: 20px; background-color: #ffffff;'>\n",
        "\n",
        "        <h3 style='color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px;'>\n",
        "            Cumulative Meta-Analysis Results\n",
        "        </h3>\n",
        "\n",
        "        <p style='text-align: justify;'>\n",
        "        A cumulative meta-analysis was conducted to examine the temporal evolution of the pooled\n",
        "        effect size and assess the sufficiency of the evidence. Studies were added to the analysis\n",
        "        in chronological order based on publication year.\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 20px;'>Evolution of Effect Size</h4>\n",
        "        <p style='text-align: justify;'>\n",
        "        The analysis began with the earliest available studies (k={start.k_studies}, Year: {start.year}),\n",
        "        yielding an initial pooled effect of {start.pooled_effect:.3f} ({ci_pct:.0f}% CI [{start.ci_lower:.3f},\n",
        "        {start.ci_upper:.3f}]). As evidence accumulated over the subsequent years (Total k={end.k_studies},\n",
        "        Range: {result.year_range[0]}\u2013{result.year_range[1]}), the pooled estimate <b>{trend_desc}</b>,\n",
        "        resulting in a final estimate of <b>{end.pooled_effect:.3f}</b> ({ci_pct:.0f}% CI [{end.ci_lower:.3f},\n",
        "        {end.ci_upper:.3f}]).\n",
        "        </p>\n",
        "\n",
        "        <h4 style='color: #34495e; margin-top: 20px;'>Precision and Heterogeneity</h4>\n",
        "        <p style='text-align: justify;'>\n",
        "        The precision of the estimate <b>{prec_text}</b> over time, as indicated by a\n",
        "        {abs(precision_change):.1f}% {prec_text[:-1] if prec_text.endswith('ed') else prec_text}\n",
        "        in the width of the {ci_pct:.0f}% confidence interval. Meanwhile, the between-study\n",
        "        heterogeneity (<i>I</i>\u00b2) {het_trend} from {start.I2:.1f}% in the initial wave to\n",
        "        {end.I2:.1f}% in the final analysis.\n",
        "        </p>\n",
        "        \"\"\"\n",
        "\n",
        "        # Stability interpretation\n",
        "        if result.effect_stable:\n",
        "            html += \"\"\"\n",
        "            <h4 style='color: #34495e; margin-top: 20px;'>Evidence Sufficiency</h4>\n",
        "            <p style='text-align: justify;'>\n",
        "            The pooled effect size demonstrated <b>stability in recent years</b>, with minimal change\n",
        "            (<10%) over the last five studies added. This suggests that the current body of evidence\n",
        "            is likely sufficient to provide a reliable estimate of the true effect size, and that\n",
        "            additional studies are unlikely to substantially alter this conclusion.\n",
        "            </p>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            html += \"\"\"\n",
        "            <h4 style='color: #34495e; margin-top: 20px;'>Evidence Sufficiency</h4>\n",
        "            <p style='text-align: justify;'>\n",
        "            The pooled effect size continues to <b>evolve in recent years</b>, suggesting that the\n",
        "            evidence base may not yet be sufficient to provide a definitive estimate. Additional\n",
        "            research may be warranted to clarify the magnitude and direction of the effect.\n",
        "            </p>\n",
        "            \"\"\"\n",
        "\n",
        "        # Guidance\n",
        "        html += \"\"\"\n",
        "        <div style='background-color: #ecf0f1; padding: 15px; border-left: 4px solid #3498db;\n",
        "                    margin-top: 20px;'>\n",
        "            <h4 style='margin-top: 0; color: #2c3e50;'>Interpretation Guidance:</h4>\n",
        "            <ul style='margin-bottom: 0;'>\n",
        "                <li><b>Stability:</b> If the line flattens out in recent years, the finding is robust.\n",
        "                    If it is still moving up or down, more research is needed.</li>\n",
        "                <li><b>Sufficiency:</b> Narrowing confidence intervals suggest that we are converging\n",
        "                    on the \"true\" effect size.</li>\n",
        "                <li><b>Heterogeneity:</b> Increasing I\u00b2 over time may indicate that newer studies differ\n",
        "                    systematically from older ones (consider moderator analysis).</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "\n",
        "        <div style='background-color: #fff3cd; padding: 10px; border-left: 4px solid #ffc107;\n",
        "                    margin-top: 15px;'>\n",
        "            <p style='margin: 0;'><b>\ud83d\udca1 Tip:</b> Select all text (Ctrl+A / Cmd+A), copy (Ctrl+C / Cmd+C),\n",
        "            and paste into your word processor.</p>\n",
        "        </div>\n",
        "\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "\n",
        "print(\"\u2705 Cumulative View Layer (Part 1) Loaded Successfully\")\n",
        "\n",
        "#@title \ud83d\udcc8 23. Cumulative Meta-Analysis: PRESENTATION LAYER (View) - PART 2\n",
        "# =============================================================================\n",
        "# VIEW COMPONENTS (Tab Renderers)\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativeResultsView:\n",
        "    \"\"\"\n",
        "    Manages all UI rendering for cumulative meta-analysis.\n",
        "    Contains zero business logic - only presentation code.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize view with display settings\"\"\"\n",
        "        self.templates = CumulativeHTMLTemplates()\n",
        "        self.text_gen = CumulativePublicationTextGenerator()\n",
        "\n",
        "        # Create tab widgets\n",
        "        self.tab_results = widgets.Output()\n",
        "        self.tab_data = widgets.Output()\n",
        "        self.tab_publication = widgets.Output()\n",
        "        self.tab_export = widgets.Output()\n",
        "\n",
        "        self.tabs = widgets.Tab(children=[\n",
        "            self.tab_results,\n",
        "            self.tab_data,\n",
        "            self.tab_publication,\n",
        "            self.tab_export\n",
        "        ])\n",
        "\n",
        "        self.tabs.set_title(0, '\ud83d\udcca Analysis Summary')\n",
        "        self.tabs.set_title(1, '\ud83d\udccb Step-by-Step Data')\n",
        "        self.tabs.set_title(2, '\ud83d\udcdd Publication Text')\n",
        "        self.tabs.set_title(3, '\ud83d\udcbe Export')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 1: RESULTS SUMMARY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_results_tab(self, result: 'CumulativeResult') -> None:\n",
        "        \"\"\"Render results summary tab\"\"\"\n",
        "\n",
        "        with self.tab_results:\n",
        "            self.tab_results.clear_output()\n",
        "\n",
        "            # Comparison cards\n",
        "            comparison_html = self.templates.comparison_cards(\n",
        "                result.start_step,\n",
        "                result.end_step\n",
        "            )\n",
        "            display(HTML(comparison_html))\n",
        "\n",
        "            # Stability badges\n",
        "            stability_html = self.templates.stability_badges(\n",
        "                result.effect_stable,\n",
        "                result.precision_improved\n",
        "            )\n",
        "            display(HTML(stability_html))\n",
        "\n",
        "            # Method note\n",
        "            method_html = self.templates.method_note(result.aggregation_method)\n",
        "            display(HTML(method_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 2: STEP-BY-STEP DATA\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_data_tab(self, result: 'CumulativeResult') -> None:\n",
        "        \"\"\"Render step-by-step data table\"\"\"\n",
        "\n",
        "        with self.tab_data:\n",
        "            self.tab_data.clear_output()\n",
        "\n",
        "            display(HTML(\"<h4 style='margin-top:0;'>Step-by-Step Evolution</h4>\"))\n",
        "\n",
        "            # Prepare display DataFrame\n",
        "            disp_df = result.steps.copy()\n",
        "            cols = ['step', 'year', 'study_added', 'pooled_effect', 'ci_lower',\n",
        "                    'ci_upper', 'I2', 'tau2']\n",
        "\n",
        "            # Format and display with styling\n",
        "            try:\n",
        "                styled_df = disp_df[cols].style.format({\n",
        "                    'pooled_effect': '{:.3f}',\n",
        "                    'ci_lower': '{:.3f}',\n",
        "                    'ci_upper': '{:.3f}',\n",
        "                    'I2': '{:.1f}%',\n",
        "                    'tau2': '{:.4f}'\n",
        "                }).background_gradient(subset=['pooled_effect'], cmap='Blues')\n",
        "\n",
        "                display(styled_df)\n",
        "            except:\n",
        "                # Fallback without styling\n",
        "                display(disp_df[cols])\n",
        "\n",
        "            # Download tip\n",
        "            tip_html = \"\"\"\n",
        "            <div style='background-color: #e7f3ff; padding: 10px; margin-top: 15px;\n",
        "                        border-left: 3px solid #007bff;'>\n",
        "                <b>\ud83d\udca1 Tip:</b> Use the Export tab to download this data as an Excel file.\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(tip_html))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 3: PUBLICATION TEXT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_publication_tab(\n",
        "        self,\n",
        "        result: 'CumulativeResult',\n",
        "        es_config: Dict[str, Any]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Render publication text tab.\n",
        "\n",
        "        Returns:\n",
        "            Combined HTML text for saving\n",
        "        \"\"\"\n",
        "        with self.tab_publication:\n",
        "            self.tab_publication.clear_output()\n",
        "\n",
        "            # Generate both sections\n",
        "            methods_html = self.text_gen.generate_methods_section(result, es_config)\n",
        "            results_html = self.text_gen.generate_results_section(result, es_config)\n",
        "\n",
        "            # Display\n",
        "            display(HTML(methods_html))\n",
        "            display(HTML(results_html))\n",
        "\n",
        "            # Return combined for saving\n",
        "            return methods_html + \"<br><hr><br>\" + results_html\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB 4: EXPORT\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_export_tab(self, export_callback: callable) -> None:\n",
        "        \"\"\"Render export tab with download button\"\"\"\n",
        "\n",
        "        with self.tab_export:\n",
        "            self.tab_export.clear_output()\n",
        "\n",
        "            display(HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcbe Download Audit Report</h3>\"))\n",
        "            display(HTML(\"<p>Download the cumulative analysis results including step-by-step evolution data.</p>\"))\n",
        "\n",
        "            btn_export = widgets.Button(\n",
        "                description=\"\ud83d\udce5 Download Cumulative Report\",\n",
        "                button_style='info',\n",
        "                icon='file-excel',\n",
        "                layout=widgets.Layout(width='300px', height='40px')\n",
        "            )\n",
        "\n",
        "            btn_export.on_click(export_callback)\n",
        "            display(btn_export)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR DISPLAY\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def render_error(self, message: str, details: Optional[str] = None) -> None:\n",
        "        \"\"\"Render error message in results tab\"\"\"\n",
        "        with self.tab_results:\n",
        "            self.tab_results.clear_output()\n",
        "            error_html = f\"<div style='color: red; background-color: #f8d7da; padding: 15px; border-radius: 5px;'>\u274c {message}</div>\"\n",
        "            if details:\n",
        "                error_html += f\"<pre style='margin-top: 10px;'>{details}</pre>\"\n",
        "            display(HTML(error_html))\n",
        "\n",
        "\n",
        "print(\"\u2705 Cumulative View Layer (Part 2) Loaded Successfully\")\n",
        "\n",
        "#@title \ud83d\udcc8 23. Cumulative Meta-Analysis: CONTROLLER LAYER (Orchestration)\n",
        "# =============================================================================\n",
        "# CELL COMPONENT 4/4: CONTROLLER LAYER - CUMULATIVE META-ANALYSIS\n",
        "# Purpose: Orchestrates data, analysis, and view components\n",
        "# Dependencies: All previous layers (Data, Analysis, View)\n",
        "# =============================================================================\n",
        "\n",
        "import traceback\n",
        "from typing import Optional, Dict, Any\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN CONTROLLER\n",
        "# =============================================================================\n",
        "\n",
        "class CumulativeController:\n",
        "    \"\"\"\n",
        "    Master controller that orchestrates the entire cumulative meta-analysis workflow.\n",
        "    Coordinates data management, statistical computation, and UI rendering.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, analysis_config: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Initialize controller with ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            analysis_config: Global ANALYSIS_CONFIG dictionary\n",
        "        \"\"\"\n",
        "        self.analysis_config = analysis_config\n",
        "\n",
        "        # Initialize components\n",
        "        try:\n",
        "            self.data_manager = CumulativeDataManager(analysis_config)\n",
        "            self.engine = CumulativeEngine(self.data_manager)\n",
        "            self.view = CumulativeResultsView()\n",
        "\n",
        "            self._initialization_error = None\n",
        "\n",
        "        except Exception as e:\n",
        "            # If initialization fails, create minimal view to show error\n",
        "            self.view = CumulativeResultsView()\n",
        "            self.data_manager = None\n",
        "            self.engine = None\n",
        "            self._initialization_error = e\n",
        "\n",
        "        # Create settings widgets\n",
        "        self._create_settings_widgets()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # SETTINGS WIDGETS CREATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _create_settings_widgets(self) -> None:\n",
        "        \"\"\"Create all settings widgets\"\"\"\n",
        "\n",
        "        self.sort_order_widget = widgets.Dropdown(\n",
        "            options=[('Chronological (Oldest \u2192 Newest)', 'ascending'),\n",
        "                     ('Reverse Chronological (Newest \u2192 Oldest)', 'descending')],\n",
        "            value='ascending',\n",
        "            description='Sort Order:',\n",
        "            style={'description_width': '120px'},\n",
        "            layout=widgets.Layout(width='450px')\n",
        "        )\n",
        "\n",
        "        self.agg_method_widget = widgets.Dropdown(\n",
        "            options=[('By Study (Recommended)', 'study'),\n",
        "                     ('By Observation (Ignore nesting)', 'obs')],\n",
        "            value='study',\n",
        "            description='Aggregation:',\n",
        "            style={'description_width': '120px'},\n",
        "            layout=widgets.Layout(width='450px')\n",
        "        )\n",
        "\n",
        "        self.run_button = widgets.Button(\n",
        "            description='\u25b6 Run Cumulative Analysis (REML)',\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='450px', height='50px'),\n",
        "            style={'font_weight': 'bold'}\n",
        "        )\n",
        "\n",
        "        # Attach event handler\n",
        "        self.run_button.on_click(self._handle_run_click)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # UI CREATION\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def create_ui(self) -> widgets.VBox:\n",
        "        \"\"\"\n",
        "        Create the user interface with settings and run button.\n",
        "\n",
        "        Returns:\n",
        "            VBox widget containing the UI\n",
        "        \"\"\"\n",
        "        ui = widgets.VBox([\n",
        "            widgets.HTML(\"<h3 style='color:#2E86AB;'>\ud83d\udcc8 Cumulative Meta-Analysis (Part 1: Calculation)</h3>\"),\n",
        "            widgets.HTML(\"<b>Settings:</b>\"),\n",
        "            self.sort_order_widget,\n",
        "            self.agg_method_widget,\n",
        "            widgets.HTML(\"<hr>\"),\n",
        "            self.run_button,\n",
        "            widgets.HTML(\"<br>\")\n",
        "        ])\n",
        "\n",
        "        return ui\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MAIN EXECUTION METHOD\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def run_analysis(self) -> None:\n",
        "        \"\"\"\n",
        "        Execute complete cumulative meta-analysis workflow.\n",
        "        \"\"\"\n",
        "        # Clear all tabs\n",
        "        for tab in [self.view.tab_results, self.view.tab_data,\n",
        "                    self.view.tab_publication]:\n",
        "            tab.clear_output()\n",
        "\n",
        "        # Check for initialization errors\n",
        "        if self._initialization_error:\n",
        "            self._handle_initialization_error()\n",
        "            return\n",
        "\n",
        "        # Validate ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            self.view.render_error(\"ANALYSIS_CONFIG not found. Run Step 1 first.\")\n",
        "            return\n",
        "\n",
        "        # Get settings from widgets\n",
        "        sort_order = self.sort_order_widget.value\n",
        "        aggregation_method = self.agg_method_widget.value\n",
        "\n",
        "        # Progress callback\n",
        "        def progress_callback(message: str):\n",
        "            \"\"\"Callback for progress updates\"\"\"\n",
        "            with self.view.tab_results:\n",
        "                clear_output(wait=True)\n",
        "                print(message)\n",
        "\n",
        "        try:\n",
        "            # Execute cumulative engine\n",
        "            result = self.engine.run_analysis(\n",
        "                sort_order=sort_order,\n",
        "                aggregation_method=aggregation_method,\n",
        "                progress_callback=progress_callback\n",
        "            )\n",
        "\n",
        "            if result is None:\n",
        "                self.view.render_error(\n",
        "                    \"Analysis failed\",\n",
        "                    \"Unable to compute cumulative analysis. Check your data (need \u22653 observations with 'year' column).\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # Render all tabs\n",
        "            self._render_all_tabs(result)\n",
        "\n",
        "            # Save results\n",
        "            self._save_results(result)\n",
        "\n",
        "        except ValueError as e:\n",
        "            self.view.render_error(\"Data Error\", str(e))\n",
        "        except RuntimeError as e:\n",
        "            self.view.render_error(\"Runtime Error\", str(e))\n",
        "        except Exception as e:\n",
        "            self._handle_unexpected_error(e)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # TAB RENDERING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _render_all_tabs(self, result: 'CumulativeResult') -> None:\n",
        "        \"\"\"\n",
        "        Render all tabs with results.\n",
        "\n",
        "        Args:\n",
        "            result: CumulativeResult object\n",
        "        \"\"\"\n",
        "        # Tab 1: Results Summary\n",
        "        self.view.render_results_tab(result)\n",
        "\n",
        "        # Tab 2: Step-by-Step Data\n",
        "        self.view.render_data_tab(result)\n",
        "\n",
        "        # Tab 3: Publication Text\n",
        "        combined_text = self.view.render_publication_tab(\n",
        "            result,\n",
        "            self.data_manager.es_config\n",
        "        )\n",
        "\n",
        "        # Save publication text\n",
        "        self.data_manager.save_publication_text(combined_text)\n",
        "\n",
        "        # Tab 4: Export\n",
        "        self.view.render_export_tab(export_callback=self._handle_export)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DATA PERSISTENCE\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _save_results(self, result: 'CumulativeResult') -> None:\n",
        "        \"\"\"\n",
        "        Save results to ANALYSIS_CONFIG.\n",
        "\n",
        "        Args:\n",
        "            result: CumulativeResult object\n",
        "        \"\"\"\n",
        "        self.data_manager.save_cumulative_results(result)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # EVENT HANDLERS\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_run_click(self, button) -> None:\n",
        "        \"\"\"Handle run button click event\"\"\"\n",
        "        self.run_analysis()\n",
        "\n",
        "    def _handle_export(self, button) -> None:\n",
        "        \"\"\"Handle export button click\"\"\"\n",
        "        try:\n",
        "            # Call the external export function if it exists\n",
        "            if 'export_analysis_report' in globals():\n",
        "                export_analysis_report(\n",
        "                    report_type='cumulative',\n",
        "                    filename_prefix='Cumulative_Meta_Analysis'\n",
        "                )\n",
        "            else:\n",
        "                with self.view.tab_export:\n",
        "                    print(\"\u26a0\ufe0f Export function not found. Please run the export cell first.\")\n",
        "        except Exception as e:\n",
        "            with self.view.tab_export:\n",
        "                print(f\"\u274c Export failed: {str(e)}\")\n",
        "                traceback.print_exc()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # ERROR HANDLING\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    def _handle_initialization_error(self) -> None:\n",
        "        \"\"\"Handle errors during controller initialization\"\"\"\n",
        "        error = self._initialization_error\n",
        "        if error is None:\n",
        "            return\n",
        "\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "    def _handle_unexpected_error(self, error: Exception) -> None:\n",
        "        \"\"\"Handle unexpected errors during analysis\"\"\"\n",
        "        error_type = type(error).__name__\n",
        "        error_msg = str(error)\n",
        "        details = traceback.format_exc()\n",
        "\n",
        "        self.view.render_error(f\"{error_type}: {error_msg}\", details)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION ENTRY POINT\n",
        "# =============================================================================\n",
        "\n",
        "def run_cumulative_meta_analysis():\n",
        "    \"\"\"\n",
        "    Main entry point for cumulative meta-analysis.\n",
        "    Call this function to display the UI and enable analysis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check for ANALYSIS_CONFIG\n",
        "        if 'ANALYSIS_CONFIG' not in globals():\n",
        "            print(\"\u274c ERROR: ANALYSIS_CONFIG not found\")\n",
        "            print(\"Please run previous analysis cells first:\")\n",
        "            print(\"  - Step 1: Data Loading\")\n",
        "            return\n",
        "\n",
        "        # Create controller\n",
        "        controller = CumulativeController(ANALYSIS_CONFIG)\n",
        "\n",
        "        # Display UI\n",
        "        ui = controller.create_ui()\n",
        "        display(ui)\n",
        "\n",
        "        # Display tabs\n",
        "        display(controller.view.tabs)\n",
        "\n",
        "        # Store controller globally for access (optional)\n",
        "        globals()['_cumulative_controller'] = controller\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Fatal Error: {type(e).__name__}\")\n",
        "        print(f\"Message: {str(e)}\")\n",
        "        print(\"\\nFull traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STANDALONE TESTING UTILITIES (Optional)\n",
        "# =============================================================================\n",
        "\n",
        "class MockCumulativeConfig:\n",
        "    \"\"\"\n",
        "    Mock ANALYSIS_CONFIG for testing without running full pipeline.\n",
        "    Only for development/testing purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_sample_config():\n",
        "        \"\"\"Create a minimal valid config for testing\"\"\"\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "\n",
        "        # Sample data with years\n",
        "        np.random.seed(42)\n",
        "        years = [2010, 2010, 2012, 2012, 2015, 2015, 2018, 2018, 2020, 2020]\n",
        "        sample_data = pd.DataFrame({\n",
        "            'id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "            'hedges_g': np.random.randn(10) * 0.3 + 0.5,\n",
        "            'Vg': np.random.uniform(0.01, 0.1, 10),\n",
        "            'year': years\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'analysis_data': sample_data,\n",
        "            'effect_col': 'hedges_g',\n",
        "            'var_col': 'Vg',\n",
        "            'es_config': {\n",
        "                'type': \"Hedges' g\",\n",
        "                'effect_label': \"Hedges' g\",\n",
        "                'effect_label_short': 'g'\n",
        "            },\n",
        "            'global_settings': {\n",
        "                'alpha': 0.05,\n",
        "                'dist_type': 'norm'\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MODULE TEST & INFORMATION\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\u2705 Cumulative Meta-Analysis Controller Layer Loaded Successfully\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\ud83d\udce6 Available Classes:\")\n",
        "    print(\"   - CumulativeController\")\n",
        "    print(\"   - MockCumulativeConfig (for testing)\")\n",
        "    print()\n",
        "    print(\"\ud83d\ude80 Main Entry Point:\")\n",
        "    print(\"   run_cumulative_meta_analysis()\")\n",
        "    print()\n",
        "    print(\"\ud83d\udca1 Usage:\")\n",
        "    print(\"   Just call: run_cumulative_meta_analysis()\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "run_cumulative_meta_analysis()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nl84R1xY-gz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \ud83d\udcca 24. Visualization: Cumulative Trends\n",
        "# =============================================================================\n",
        "# CELL 14b: CUMULATIVE FOREST PLOT (VISUALIZATION)\n",
        "# Purpose: Generate publication-ready plots of temporal trends.\n",
        "# Features: Dual-axis support (Effect Size vs. I2), custom styling, and export.\n",
        "# Dependencies: Cell 14 (Calculation)\n",
        "# =============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. INITIALIZATION ---\n",
        "default_title = \"Cumulative Meta-Analysis\"\n",
        "default_xlabel = \"Publication Year\"\n",
        "default_ylabel = \"Pooled Effect Size\"\n",
        "\n",
        "try:\n",
        "    if 'ANALYSIS_CONFIG' in globals():\n",
        "        es_config = ANALYSIS_CONFIG.get('es_config', {})\n",
        "        default_ylabel = f\"Pooled {es_config.get('effect_label', 'Effect Size')}\"\n",
        "except: pass\n",
        "\n",
        "# --- 2. WIDGET DEFINITIONS ---\n",
        "\n",
        "# === TAB 1: STYLE ===\n",
        "style_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83c\udfa8 Style & Dimensions</h3>\")\n",
        "width_widget = widgets.FloatSlider(value=10.0, min=6.0, max=16.0, step=0.5, description='Width (in):', continuous_update=False, layout=widgets.Layout(width='450px'))\n",
        "height_widget = widgets.FloatSlider(value=6.0, min=4.0, max=12.0, step=0.5, description='Height (in):', continuous_update=False, layout=widgets.Layout(width='450px'))\n",
        "title_font_widget = widgets.IntSlider(value=14, min=8, max=24, description='Title Font:', layout=widgets.Layout(width='450px'))\n",
        "label_font_widget = widgets.IntSlider(value=12, min=8, max=18, description='Label Font:', layout=widgets.Layout(width='450px'))\n",
        "grid_widget = widgets.Checkbox(value=True, description='Show Grid', indent=False)\n",
        "\n",
        "style_tab = widgets.VBox([\n",
        "    style_header,\n",
        "    preset_widget,\n",
        "    widgets.HTML(\"<b>Plot Size:</b>\"), width_widget, height_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    widgets.HTML(\"<b>Typography:</b>\"), title_font_widget, label_font_widget,\n",
        "    widgets.HTML(\"<hr>\"), grid_widget\n",
        "])\n",
        "\n",
        "# === TAB 2: TEXT ===\n",
        "text_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcdd Labels</h3>\")\n",
        "show_title_widget = widgets.Checkbox(value=True, description='Show Title', indent=False)\n",
        "title_text_widget = widgets.Text(value=default_title, description='Title:', layout=widgets.Layout(width='450px'))\n",
        "xlabel_widget = widgets.Text(value=default_xlabel, description='X-Axis:', layout=widgets.Layout(width='450px'))\n",
        "ylabel_widget = widgets.Text(value=default_ylabel, description='Y-Axis:', layout=widgets.Layout(width='450px'))\n",
        "\n",
        "text_tab = widgets.VBox([\n",
        "    text_header,\n",
        "    show_title_widget, title_text_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    xlabel_widget, ylabel_widget\n",
        "])\n",
        "\n",
        "# === TAB 3: PRIMARY AXIS (Effect Size) ===\n",
        "vis_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcc8 Primary Axis (Effect Size)</h3>\")\n",
        "line_color_widget = widgets.Dropdown(options=['blue', 'black', 'red', 'green', 'purple', 'navy'], value='navy', description='Line Color:')\n",
        "line_width_widget = widgets.FloatSlider(value=2.5, min=0.5, max=5.0, step=0.5, description='Line Width:')\n",
        "marker_style_widget = widgets.Dropdown(options=[('Circle', 'o'), ('Square', 's'), ('Diamond', 'D'), ('None', 'None')], value='o', description='Marker:')\n",
        "show_ci_widget = widgets.Checkbox(value=True, description='Show Confidence Band', indent=False)\n",
        "ci_alpha_widget = widgets.FloatSlider(value=0.2, min=0.05, max=0.5, step=0.05, description='CI Opacity:')\n",
        "show_null_widget = widgets.Checkbox(value=True, description='Show Null Line (y=0)', indent=False)\n",
        "\n",
        "vis_tab = widgets.VBox([\n",
        "    vis_header,\n",
        "    line_color_widget, line_width_widget, marker_style_widget,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    show_ci_widget, ci_alpha_widget, show_null_widget\n",
        "])\n",
        "\n",
        "# === TAB 4: SECONDARY AXIS (Heterogeneity) ===\n",
        "het_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcc9 Secondary Axis (Heterogeneity)</h3>\")\n",
        "show_i2_widget = widgets.Checkbox(value=True, description='Show I\u00b2 Trajectory (Right Axis)', indent=False)\n",
        "i2_color_widget = widgets.Dropdown(options=['orange', 'red', 'gray', 'brown', 'teal'], value='orange', description='I\u00b2 Color:')\n",
        "i2_style_widget = widgets.Dropdown(options=[('Dashed', '--'), ('Dotted', ':'), ('Solid', '-')], value='--', description='Line Style:')\n",
        "i2_alpha_widget = widgets.FloatSlider(value=0.8, min=0.1, max=1.0, description='Opacity:')\n",
        "\n",
        "het_tab = widgets.VBox([\n",
        "    het_header,\n",
        "    show_i2_widget,\n",
        "    i2_color_widget, i2_style_widget, i2_alpha_widget\n",
        "])\n",
        "\n",
        "# === TAB 5: EXPORT ===\n",
        "exp_header = widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcbe Export Options</h3>\")\n",
        "save_pdf_widget = widgets.Checkbox(value=True, description='Save as PDF', indent=False)\n",
        "save_png_widget = widgets.Checkbox(value=True, description='Save as PNG', indent=False)\n",
        "png_dpi_widget = widgets.IntSlider(value=300, min=100, max=600, step=50, description='PNG DPI:')\n",
        "filename_widget = widgets.Text(value='Cumulative_Trend_Plot', description='Filename:', layout=widgets.Layout(width='300px'))\n",
        "\n",
        "exp_tab = widgets.VBox([\n",
        "    exp_header,\n",
        "    save_pdf_widget, save_png_widget, png_dpi_widget, filename_widget\n",
        "])\n",
        "\n",
        "# Assemble Tabs\n",
        "tabs = widgets.Tab(children=[style_tab, text_tab, vis_tab, het_tab, exp_tab])\n",
        "tabs.set_title(0, '\ud83c\udfa8 Style'); tabs.set_title(1, '\ud83d\udcdd Text'); tabs.set_title(2, '\ud83d\udcc8 Effect')\n",
        "tabs.set_title(3, '\ud83d\udcc9 I\u00b2'); tabs.set_title(4, '\ud83d\udcbe Export')\n",
        "\n",
        "# --- 3. PLOTTING FUNCTION ---\n",
        "plot_output = widgets.Output()\n",
        "\n",
        "def generate_cum_plot(b):\n",
        "    with plot_output:\n",
        "        clear_output(wait=True)\n",
        "        print(\"\u23f3 Generating Plot...\")\n",
        "\n",
        "        try:\n",
        "            # 1. Load Data\n",
        "            if 'ANALYSIS_CONFIG' not in globals() or 'cumulative_results' not in ANALYSIS_CONFIG:\n",
        "                print(\"\u274c Error: Please run the Calculation Cell (Cell 14) first.\")\n",
        "                return\n",
        "\n",
        "            df = ANALYSIS_CONFIG['cumulative_results'].copy()\n",
        "\n",
        "            if df.empty:\n",
        "                print(\"\u274c Error: Cumulative results table is empty.\")\n",
        "                return\n",
        "\n",
        "            # 2. Setup Figure\n",
        "            fig, ax1 = plt.subplots(figsize=(width_widget.value, height_widget.value))\n",
        "\n",
        "            # Data Vectors\n",
        "            x_data = df['year']\n",
        "            y_data = df['pooled_effect']\n",
        "\n",
        "            # 3. Primary Axis (Effect Size)\n",
        "            color_main = line_color_widget.value\n",
        "            marker = marker_style_widget.value if marker_style_widget.value != 'None' else None\n",
        "\n",
        "            # Plot Main Line\n",
        "            line1, = ax1.plot(x_data, y_data, color=color_main, linewidth=line_width_widget.value,\n",
        "                             marker=marker, markersize=8, label='Pooled Effect', zorder=10)\n",
        "\n",
        "            # Confidence Band\n",
        "            if show_ci_widget.value:\n",
        "                # Get dynamic label\n",
        "                gs = ANALYSIS_CONFIG.get('global_settings', {})\n",
        "                alpha_val = gs.get('alpha', 0.05)\n",
        "                ci_pct = (1 - alpha_val) * 100\n",
        "\n",
        "                ax1.fill_between(x_data, df['ci_lower'], df['ci_upper'],\n",
        "                                color=color_main, alpha=ci_alpha_widget.value, label=f'{ci_pct:.0f}% CI', zorder=5)\n",
        "\n",
        "\n",
        "            # Null Line\n",
        "            if show_null_widget.value:\n",
        "                null_val = ANALYSIS_CONFIG.get('es_config', {}).get('null_value', 0)\n",
        "                ax1.axhline(null_val, color='gray', linestyle='-', linewidth=1.5, alpha=0.5, zorder=1)\n",
        "\n",
        "            # 4. Secondary Axis (Heterogeneity)\n",
        "            lines = [line1]\n",
        "\n",
        "            if show_i2_widget.value:\n",
        "                ax2 = ax1.twinx()\n",
        "                color_i2 = i2_color_widget.value\n",
        "\n",
        "                line2, = ax2.plot(x_data, df['I2'], color=color_i2, linestyle=i2_style_widget.value,\n",
        "                                 linewidth=line_width_widget.value, alpha=i2_alpha_widget.value,\n",
        "                                 label='Heterogeneity (I\u00b2)', zorder=8)\n",
        "\n",
        "                ax2.set_ylabel('Heterogeneity (I\u00b2 %)', color=color_i2,\n",
        "                              fontsize=label_font_widget.value, fontweight='bold')\n",
        "                ax2.tick_params(axis='y', labelcolor=color_i2, labelsize=10)\n",
        "                ax2.set_ylim(0, 100)\n",
        "                ax2.spines['right'].set_color(color_i2)\n",
        "                ax2.spines['right'].set_linewidth(2)\n",
        "\n",
        "                lines.append(line2)\n",
        "\n",
        "            # 5. Formatting\n",
        "            ax1.set_xlabel(xlabel_widget.value, fontsize=label_font_widget.value, fontweight='bold')\n",
        "            ax1.set_ylabel(ylabel_widget.value, fontsize=label_font_widget.value, fontweight='bold', color='black')\n",
        "            ax1.tick_params(axis='both', labelsize=10)\n",
        "\n",
        "            if show_title_widget.value:\n",
        "                ax1.set_title(title_text_widget.value, fontsize=title_font_widget.value, fontweight='bold', pad=15)\n",
        "\n",
        "            if grid_widget.value:\n",
        "                ax1.grid(True, linestyle=':', alpha=0.4)\n",
        "\n",
        "            # Legend logic (Combine handles from both axes if needed)\n",
        "            labels = [l.get_label() for l in lines]\n",
        "            ax1.legend(lines, labels, loc='upper left', frameon=True, fancybox=True, fontsize=10)\n",
        "\n",
        "            # Force integer ticks for Year if range is small\n",
        "            if df['year'].nunique() < 15:\n",
        "                ax1.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # 6. Export\n",
        "            ts = datetime.datetime.now().strftime(\"%H%M\")\n",
        "            fn = filename_widget.value\n",
        "\n",
        "            print(f\"\u2705 Plot Generated. Range: {df['year'].min()} - {df['year'].max()} (k={len(df)})\")\n",
        "\n",
        "            if save_pdf_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.pdf\", bbox_inches='tight')\n",
        "                print(f\"\ud83d\udcbe Saved PDF: {fn}_{ts}.pdf\")\n",
        "\n",
        "            if save_png_widget.value:\n",
        "                plt.savefig(f\"{fn}_{ts}.png\", dpi=png_dpi_widget.value, bbox_inches='tight')\n",
        "                print(f\"\ud83d\udcbe Saved PNG: {fn}_{ts}.png\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c Plotting Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# --- 4. DISPLAY ---\n",
        "run_btn = widgets.Button(description='\ud83d\udcca Generate Cumulative Plot', button_style='success',\n",
        "                        layout=widgets.Layout(width='400px', height='50px'), style={'font_weight':'bold'})\n",
        "run_btn.on_click(generate_cum_plot)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3 style='color: #2E86AB;'>\ud83d\udcca Cumulative Plot Generator</h3>\"),\n",
        "    widgets.HTML(\"<p style='color: #666;'>Visualize how the pooled effect (and heterogeneity) stabilizes over time.</p>\"),\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    tabs,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    run_btn,\n",
        "    plot_output\n",
        "]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y_8dmwWgeq5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}